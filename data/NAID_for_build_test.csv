title,TNCSI,abstract
Attention Based Neural Networks for Wireless Channel Estimation,0.76809,"In this paper, we deploy the self-attention mechanism to achieve improved
channel estimation for orthogonal frequency-division multiplexing waveforms in
the downlink. Specifically, we propose a new hybrid encoder-decoder structure
(called HA02) for the first time which exploits the attention mechanism to
focus on the most important input information. In particular, we implement a
transformer encoder block as the encoder to achieve the sparsity in the input
features and a residual neural network as the decoder respectively, inspired by
the success of the attention mechanism. Using 3GPP channel models, our
simulations show superior estimation performance compared with other candidate
neural network methods for channel estimation."
Auction-Based Scheduling,0.207711,"Many sequential decision-making tasks require satisfaction of multiple,
partially contradictory objectives. Existing approaches are monolithic, namely
all objectives are fulfilled using a single policy, which is a function that
selects a sequence of actions. We present auction-based scheduling, a modular
framework for multi-objective decision-making problems. Each objective is
fulfilled using a separate policy, and the policies can be independently
created, modified, and replaced. Understandably, different policies with
conflicting goals may choose conflicting actions at a given time. In order to
resolve conflicts, and compose policies, we employ a novel auction-based
mechanism. We allocate a bounded budget to each policy, and at each step, the
policies simultaneously bid from their available budgets for the privilege of
being scheduled and choosing an action. Policies express their scheduling
urgency using their bids and the bounded budgets ensure long-run scheduling
fairness. We lay the foundations of auction-based scheduling using path
planning problems on finite graphs with two temporal objectives. We present
decentralized algorithms to synthesize a pair of policies, their initially
allocated budgets, and bidding strategies. We consider three categories of
decentralized synthesis problems, parameterized by the assumptions that the
policies make on each other: (a) strong synthesis, with no assumptions and
strongest guarantees, (b) assume-admissible synthesis, with weakest rationality
assumptions, and (c) assume-guarantee synthesis, with explicit contract-based
assumptions. For reachability objectives, we show that, surprisingly,
decentralized assume-admissible synthesis is always possible when the
out-degrees of all vertices are at most two."
Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture,0.994785,"This paper demonstrates an approach for learning highly semantic image
representations without relying on hand-crafted data-augmentations. We
introduce the Image-based Joint-Embedding Predictive Architecture (I-JEPA), a
non-generative approach for self-supervised learning from images. The idea
behind I-JEPA is simple: from a single context block, predict the
representations of various target blocks in the same image. A core design
choice to guide I-JEPA towards producing semantic representations is the
masking strategy; specifically, it is crucial to (a) sample target blocks with
sufficiently large scale (semantic), and to (b) use a sufficiently informative
(spatially distributed) context block. Empirically, when combined with Vision
Transformers, we find I-JEPA to be highly scalable. For instance, we train a
ViT-Huge/14 on ImageNet using 16 A100 GPUs in under 72 hours to achieve strong
downstream performance across a wide range of tasks, from linear classification
to object counting and depth prediction."
DNA: Proximal Policy Optimization with a Dual Network Architecture,0.0420847,"This paper explores the problem of simultaneously learning a value function
and policy in deep actor-critic reinforcement learning models. We find that the
common practice of learning these functions jointly is sub-optimal, due to an
order-of-magnitude difference in noise levels between these two tasks. Instead,
we show that learning these tasks independently, but with a constrained
distillation phase, significantly improves performance. Furthermore, we find
that the policy gradient noise levels can be decreased by using a lower
\textit{variance} return estimate. Whereas, the value learning noise level
decreases with a lower \textit{bias} estimate. Together these insights inform
an extension to Proximal Policy Optimization we call \textit{Dual Network
Architecture} (DNA), which significantly outperforms its predecessor. DNA also
exceeds the performance of the popular Rainbow DQN algorithm on four of the
five environments tested, even under more difficult stochastic control
settings."
Boundary Smoothing for Named Entity Recognition,0.903493,"Neural named entity recognition (NER) models may easily encounter the
over-confidence issue, which degrades the performance and calibration. Inspired
by label smoothing and driven by the ambiguity of boundary annotation in NER
engineering, we propose boundary smoothing as a regularization technique for
span-based neural NER models. It re-assigns entity probabilities from annotated
spans to the surrounding ones. Built on a simple but strong baseline, our model
achieves results better than or competitive with previous state-of-the-art
systems on eight well-known NER benchmarks. Further empirical analysis suggests
that boundary smoothing effectively mitigates over-confidence, improves model
calibration, and brings flatter neural minima and more smoothed loss
landscapes."
Hard Gate Knowledge Distillation -- Leverage Calibration for Robust and Reliable Language Model,0.143721,"In knowledge distillation, a student model is trained with supervisions from
both knowledge from a teacher and observations drawn from a training data
distribution. Knowledge of a teacher is considered a subject that holds
inter-class relations which send a meaningful supervision to a student; hence,
much effort has been put to find such knowledge to be distilled. In this paper,
we explore a question that has been given little attention: ""when to distill
such knowledge."" The question is answered in our work with the concept of model
calibration; we view a teacher model not only as a source of knowledge but also
as a gauge to detect miscalibration of a student. This simple and yet novel
view leads to a hard gate knowledge distillation scheme that switches between
learning from a teacher model and training data. We verify the gating mechanism
in the context of natural language generation at both the token-level and the
sentence-level. Empirical comparisons with strong baselines show that hard gate
knowledge distillation not only improves model generalization, but also
significantly lowers model calibration error."
"CVM-Cervix: A Hybrid Cervical Pap-Smear Image Classification Framework Using CNN, Visual Transformer and Multilayer Perceptron",0.768205,"Cervical cancer is the seventh most common cancer among all the cancers
worldwide and the fourth most common cancer among women. Cervical cytopathology
image classification is an important method to diagnose cervical cancer. Manual
screening of cytopathology images is time-consuming and error-prone. The
emergence of the automatic computer-aided diagnosis system solves this problem.
This paper proposes a framework called CVM-Cervix based on deep learning to
perform cervical cell classification tasks. It can analyze pap slides quickly
and accurately. CVM-Cervix first proposes a Convolutional Neural Network module
and a Visual Transformer module for local and global feature extraction
respectively, then a Multilayer Perceptron module is designed to fuse the local
and global features for the final classification. Experimental results show the
effectiveness and potential of the proposed CVM-Cervix in the field of cervical
Pap smear image classification. In addition, according to the practical needs
of clinical work, we perform a lightweight post-processing to compress the
model."
Turning Stocks into Memes: A Dataset for Understanding How Social Communities Can Drive Wall Street,0.148272,"Who actually expresses an intent to buy GameStop shares on Reddit? What
convinces people to buy stocks? Are people convinced to support a coordinated
plan to adversely impact Wall Street investors? Existing literature on
understanding intent has mainly relied on surveys and self reporting; however
there are limitations to these methodologies. Hence, in this paper, we develop
an annotated dataset of communications centered on the GameStop phenomenon to
analyze the subscriber intentions behaviors within the r/WallStreetBets
community to buy (or not buy) stocks. Likewise, we curate a dataset to better
understand how intent interacts with a user's general support towards the
coordinated actions of the community for GameStop. Overall, our dataset can
provide insight to social scientists on the persuasive power to buy into social
movements online by adopting common language and narrative. WARNING: This paper
contains offensive language that commonly appears on Reddit's r/WallStreetBets
subreddit."
Incorporating Graph Information in Transformer-based AMR Parsing,0.767792,"Abstract Meaning Representation (AMR) is a Semantic Parsing formalism that
aims at providing a semantic graph abstraction representing a given text.
Current approaches are based on autoregressive language models such as BART or
T5, fine-tuned through Teacher Forcing to obtain a linearized version of the
AMR graph from a sentence. In this paper, we present LeakDistill, a model and
method that explores a modification to the Transformer architecture, using
structural adapters to explicitly incorporate graph information into the
learned representations and improve AMR parsing performance. Our experiments
show how, by employing word-to-node alignment to embed graph structural
information into the encoder at training time, we can obtain state-of-the-art
AMR parsing through self-knowledge distillation, even without the use of
additional data. We release the code at
\url{http://www.github.com/sapienzanlp/LeakDistill}."
"Low-Resource End-to-end Sanskrit TTS using Tacotron2, WaveGlow and Transfer Learning",0.540624,"End-to-end text-to-speech (TTS) systems have been developed for European
languages like English and Spanish with state-of-the-art speech quality,
prosody, and naturalness. However, development of end-to-end TTS for Indian
languages is lagging behind in terms of quality. The challenges involved in
such a task are: 1) scarcity of quality training data; 2) low efficiency during
training and inference; 3) slow convergence in the case of large vocabulary
size. In our work reported in this paper, we have investigated the use of
fine-tuning the English-pretrained Tacotron2 model with limited Sanskrit data
to synthesize natural sounding speech in Sanskrit in low resource settings. Our
experiments show encouraging results, achieving an overall MOS of 3.38 from 37
evaluators with good Sanskrit spoken knowledge. This is really a very good
result, considering the fact that the speech data we have used is of duration
2.5 hours only."
UniMSE: Towards Unified Multimodal Sentiment Analysis and Emotion Recognition,0.955418,"Multimodal sentiment analysis (MSA) and emotion recognition in conversation
(ERC) are key research topics for computers to understand human behaviors. From
a psychological perspective, emotions are the expression of affect or feelings
during a short period, while sentiments are formed and held for a longer
period. However, most existing works study sentiment and emotion separately and
do not fully exploit the complementary knowledge behind the two. In this paper,
we propose a multimodal sentiment knowledge-sharing framework (UniMSE) that
unifies MSA and ERC tasks from features, labels, and models. We perform
modality fusion at the syntactic and semantic levels and introduce contrastive
learning between modalities and samples to better capture the difference and
consistency between sentiments and emotions. Experiments on four public
benchmark datasets, MOSI, MOSEI, MELD, and IEMOCAP, demonstrate the
effectiveness of the proposed method and achieve consistent improvements
compared with state-of-the-art methods."
Persian Emotion Detection using ParsBERT and Imbalanced Data Handling Approaches,0.410207,"Emotion recognition is one of the machine learning applications which can be
done using text, speech, or image data gathered from social media spaces.
Detecting emotion can help us in different fields, including opinion mining.
With the spread of social media, different platforms like Twitter have become
data sources, and the language used in these platforms is informal, making the
emotion detection task difficult. EmoPars and ArmanEmo are two new
human-labeled emotion datasets for the Persian language. These datasets,
especially EmoPars, are suffering from inequality between several samples
between two classes. In this paper, we evaluate EmoPars and compare them with
ArmanEmo. Throughout this analysis, we use data augmentation techniques, data
re-sampling, and class-weights with Transformer-based Pretrained Language
Models(PLMs) to handle the imbalance problem of these datasets. Moreover,
feature selection is used to enhance the models' performance by emphasizing the
text's specific features. In addition, we provide a new policy for selecting
data from EmoPars, which selects the high-confidence samples; as a result, the
model does not see samples that do not have specific emotion during training.
Our model reaches a Macro-averaged F1-score of 0.81 and 0.76 on ArmanEmo and
EmoPars, respectively, which are new state-of-the-art results in these
benchmarks."
Is Vanilla Policy Gradient Overlooked? Analyzing Deep Reinforcement Learning for Hanabi,0.0688755,"In pursuit of enhanced multi-agent collaboration, we analyze several
on-policy deep reinforcement learning algorithms in the recently published
Hanabi benchmark. Our research suggests a perhaps counter-intuitive finding,
where Proximal Policy Optimization (PPO) is outperformed by Vanilla Policy
Gradient over multiple random seeds in a simplified environment of the
multi-agent cooperative card game. In our analysis of this behavior we look
into Hanabi-specific metrics and hypothesize a reason for PPO's plateau. In
addition, we provide proofs for the maximum length of a perfect game (71 turns)
and any game (89 turns). Our code can be found at:
https://github.com/bramgrooten/DeepRL-for-Hanabi"
Joint Alignment of Multi-Task Feature and Label Spaces for Emotion Cause Pair Extraction,0.950781,"Emotion cause pair extraction (ECPE), as one of the derived subtasks of
emotion cause analysis (ECA), shares rich inter-related features with emotion
extraction (EE) and cause extraction (CE). Therefore EE and CE are frequently
utilized as auxiliary tasks for better feature learning, modeled via multi-task
learning (MTL) framework by prior works to achieve state-of-the-art (SoTA) ECPE
results. However, existing MTL-based methods either fail to simultaneously
model the specific features and the interactive feature in between, or suffer
from the inconsistency of label prediction. In this work, we consider
addressing the above challenges for improving ECPE by performing two alignment
mechanisms with a novel A^2Net model. We first propose a feature-task alignment
to explicitly model the specific emotion-&cause-specific features and the
shared interactive feature. Besides, an inter-task alignment is implemented, in
which the label distance between the ECPE and the combinations of EE&CE are
learned to be narrowed for better label consistency. Evaluations of benchmarks
show that our methods outperform current best-performing systems on all ECA
subtasks. Further analysis proves the importance of our proposed alignment
mechanisms for the task."
Adaptive Testing of Computer Vision Models,0.658418,"Vision models often fail systematically on groups of data that share common
semantic characteristics (e.g., rare objects or unusual scenes), but
identifying these failure modes is a challenge. We introduce AdaVision, an
interactive process for testing vision models which helps users identify and
fix coherent failure modes. Given a natural language description of a coherent
group, AdaVision retrieves relevant images from LAION-5B with CLIP. The user
then labels a small amount of data for model correctness, which is used in
successive retrieval rounds to hill-climb towards high-error regions, refining
the group definition. Once a group is saturated, AdaVision uses GPT-3 to
suggest new group descriptions for the user to explore. We demonstrate the
usefulness and generality of AdaVision in user studies, where users find major
bugs in state-of-the-art classification, object detection, and image captioning
models. These user-discovered groups have failure rates 2-3x higher than those
surfaced by automatic error clustering methods. Finally, finetuning on examples
found with AdaVision fixes the discovered bugs when evaluated on unseen
examples, without degrading in-distribution accuracy, and while also improving
performance on out-of-distribution datasets."
GDDS: Pulmonary Bronchioles Segmentation with Group Deep Dense Supervision,0.734749,"Airway segmentation, especially bronchioles segmentation, is an important but
challenging task because distal bronchus are sparsely distributed and of a fine
scale. Existing neural networks usually exploit sparse topology to learn the
connectivity of bronchioles and inefficient shallow features to capture such
high-frequency information, leading to the breakage or missed detection of
individual thin branches. To address these problems, we contribute a new
bronchial segmentation method based on Group Deep Dense Supervision (GDDS) that
emphasizes fine-scale bronchioles segmentation in a simple-but-effective
manner. First, Deep Dense Supervision (DDS) is proposed by constructing local
dense topology skillfully and implementing dense topological learning on a
specific shallow feature layer. GDDS further empowers the shallow features with
better perception ability to detect bronchioles, even the ones that are not
easily discernible to the naked eye. Extensive experiments on the BAS benchmark
dataset have shown that our method promotes the network to have a high
sensitivity in capturing fine-scale branches and outperforms state-of-the-art
methods by a large margin (+12.8 % in BD and +8.8 % in TD) while only
introducing a small number of extra parameters."
An Effective Scheme for Maize Disease Recognition based on Deep Networks,0.109605,"In the last decades, the area under cultivation of maize products has
increased because of its essential role in the food cycle for humans,
livestock, and poultry. Moreover, the diseases of plants impact food safety and
can significantly reduce both the quality and quantity of agricultural
products. There are many challenges to accurate and timely diagnosis of the
disease. This research presents a novel scheme based on a deep neural network
to overcome the mentioned challenges. Due to the limited number of data, the
transfer learning technique is employed with the help of two well-known
architectures. In this way, a new effective model is adopted by a combination
of pre-trained MobileNetV2 and Inception Networks due to their effective
performance on object detection problems. The convolution layers of MoblieNetV2
and Inception modules are parallelly arranged as earlier layers to extract
crucial features. In addition, the imbalance problem of classes has been solved
by an augmentation strategy. The proposed scheme has a superior performance
compared to other state-of-the-art models published in recent years. The
accuracy of the model reaches 97%, approximately. In summary, experimental
results prove the method's validity and significant performance in diagnosing
disease in plant leaves."
"Vision-Language Pre-training: Basics, Recent Advances, and Future Trends",0.90895,"This paper surveys vision-language pre-training (VLP) methods for multimodal
intelligence that have been developed in the last few years. We group these
approaches into three categories: ($i$) VLP for image-text tasks, such as image
captioning, image-text retrieval, visual question answering, and visual
grounding; ($ii$) VLP for core computer vision tasks, such as (open-set) image
classification, object detection, and segmentation; and ($iii$) VLP for
video-text tasks, such as video captioning, video-text retrieval, and video
question answering. For each category, we present a comprehensive review of
state-of-the-art methods, and discuss the progress that has been made and
challenges still being faced, using specific systems and models as case
studies. In addition, for each category, we discuss advanced topics being
actively explored in the research community, such as big foundation models,
unified modeling, in-context few-shot learning, knowledge, robustness, and
computer vision in the wild, to name a few."
An Executable Formal Model of the VHDL in Isabelle/HOL,0.0884039,"In the hardware design process, hardware components are usually described in
a hardware description language. Most of the hardware description languages,
such as Verilog and VHDL, do not have mathematical foundation and hence are not
fit for formal reasoning about the design. To enable formal reasoning in one of
the most commonly used description language VHDL, we define a formal model of
the VHDL language in Isabelle/HOL. Our model targets the functional part of
VHDL designs used in industry, specifically the design of the LEON3 processor's
integer unit. We cover a wide range of features in the VHDL language that are
usually not modelled in the literature and define a novel operational semantics
for it. Furthermore, our model can be exported to OCaml code for execution,
turning the formal model into a VHDL simulator. We have tested our simulator
against simple designs used in the literature, as well as the div32 module in
the LEON3 design. The Isabelle/HOL code is publicly available:
https://zhehou.github.io/apps/VHDLModel.zip"
Compositional Generalization Requires Compositional Parsers,0.157564,"A rapidly growing body of research on compositional generalization
investigates the ability of a semantic parser to dynamically recombine
linguistic elements seen in training into unseen sequences. We present a
systematic comparison of sequence-to-sequence models and models guided by
compositional principles on the recent COGS corpus (Kim and Linzen, 2020).
Though seq2seq models can perform well on lexical tasks, they perform with
near-zero accuracy on structural generalization tasks that require novel
syntactic structures; this holds true even when they are trained to predict
syntax instead of semantics. In contrast, compositional models achieve
near-perfect accuracy on structural generalization; we present new results
confirming this from the AM parser (Groschwitz et al., 2021). Our findings show
structural generalization is a key measure of compositional generalization and
requires models that are aware of complex structure."
TurbuGAN: An Adversarial Learning Approach to Spatially-Varying Multiframe Blind Deconvolution with Applications to Imaging Through Turbulence,0.950213,"We present a self-supervised and self-calibrating multi-shot approach to
imaging through atmospheric turbulence, called TurbuGAN. Our approach requires
no paired training data, adapts itself to the distribution of the turbulence,
leverages domain-specific data priors, and can generalize from tens to
thousands of measurements. We achieve such functionality through an adversarial
sensing framework adapted from CryoGAN, which uses a discriminator network to
match the distributions of captured and simulated measurements. Our framework
builds on CryoGAN by (1) generalizing the forward measurement model to
incorporate physically accurate and computationally efficient models for light
propagation through anisoplanatic turbulence, (2) enabling adaptation to
slightly misspecified forward models, and (3) leveraging domain-specific prior
knowledge using pretrained generative networks, when available. We validate
TurbuGAN on both computationally simulated and experimentally captured images
distorted with anisoplanatic turbulence."
Dynamic Point Cloud Compression with Cross-Sectional Approach,0.0847754,"The recent development of dynamic point clouds has introduced the possibility
of mimicking natural reality, and greatly assisting quality of life. However,
to broadcast successfully, the dynamic point clouds require higher compression
due to their huge volume of data compared to the traditional video. Recently,
MPEG finalized a Video-based Point Cloud Compression standard known as V-PCC.
However, V-PCC requires huge computational time due to expensive normal
calculation and segmentation, sacrifices some points to limit the number of 2D
patches, and cannot occupy all spaces in the 2D frame. The proposed method
addresses these limitations by using a novel cross-sectional approach. This
approach reduces expensive normal estimation and segmentation, retains more
points, and utilizes more spaces for 2D frame generation compared to the VPCC.
The experimental results using standard video sequences show that the proposed
technique can achieve better compression in both geometric and texture data
compared to the V-PCC standard."
Text2Room: Extracting Textured 3D Meshes from 2D Text-to-Image Models,0.893902,"We present Text2Room, a method for generating room-scale textured 3D meshes
from a given text prompt as input. To this end, we leverage pre-trained 2D
text-to-image models to synthesize a sequence of images from different poses.
In order to lift these outputs into a consistent 3D scene representation, we
combine monocular depth estimation with a text-conditioned inpainting model.
The core idea of our approach is a tailored viewpoint selection such that the
content of each image can be fused into a seamless, textured 3D mesh. More
specifically, we propose a continuous alignment strategy that iteratively fuses
scene frames with the existing geometry to create a seamless mesh. Unlike
existing works that focus on generating single objects or zoom-out trajectories
from text, our method generates complete 3D scenes with multiple objects and
explicit 3D geometry. We evaluate our approach using qualitative and
quantitative metrics, demonstrating it as the first method to generate
room-scale 3D geometry with compelling textures from only text as input."
Comprehensive Analysis of Negative Sampling in Knowledge Graph Representation Learning,0.547085,"Negative sampling (NS) loss plays an important role in learning knowledge
graph embedding (KGE) to handle a huge number of entities. However, the
performance of KGE degrades without hyperparameters such as the margin term and
number of negative samples in NS loss being appropriately selected. Currently,
empirical hyperparameter tuning addresses this problem at the cost of
computational time. To solve this problem, we theoretically analyzed NS loss to
assist hyperparameter tuning and understand the better use of the NS loss in
KGE learning. Our theoretical analysis showed that scoring methods with
restricted value ranges, such as TransE and RotatE, require appropriate
adjustment of the margin term or the number of negative samples different from
those without restricted value ranges, such as RESCAL, ComplEx, and DistMult.
We also propose subsampling methods specialized for the NS loss in KGE studied
from a theoretical aspect. Our empirical analysis on the FB15k-237, WN18RR, and
YAGO3-10 datasets showed that the results of actually trained models agree with
our theoretical findings."
Diverse Generative Perturbations on Attention Space for Transferable Adversarial Attacks,0.199579,"Adversarial attacks with improved transferability - the ability of an
adversarial example crafted on a known model to also fool unknown models - have
recently received much attention due to their practicality. Nevertheless,
existing transferable attacks craft perturbations in a deterministic manner and
often fail to fully explore the loss surface, thus falling into a poor local
optimum and suffering from low transferability. To solve this problem, we
propose Attentive-Diversity Attack (ADA), which disrupts diverse salient
features in a stochastic manner to improve transferability. Primarily, we
perturb the image attention to disrupt universal features shared by different
models. Then, to effectively avoid poor local optima, we disrupt these features
in a stochastic manner and explore the search space of transferable
perturbations more exhaustively. More specifically, we use a generator to
produce adversarial perturbations that each disturbs features in different ways
depending on an input latent code. Extensive experimental evaluations
demonstrate the effectiveness of our method, outperforming the transferability
of state-of-the-art methods. Codes are available at
https://github.com/wkim97/ADA."
TabRepo: A Large Scale Repository of Tabular Model Evaluations and its AutoML Applications,0.67874,"We introduce TabRepo, a new dataset of tabular model evaluations and
predictions. TabRepo contains the predictions and metrics of 1310 models
evaluated on 200 classification and regression datasets. We illustrate the
benefit of our dataset in multiple ways. First, we show that it allows to
perform analysis such as comparing Hyperparameter Optimization against current
AutoML systems while also considering ensembling at marginal cost by using
precomputed model predictions. Second, we show that our dataset can be readily
leveraged to perform transfer-learning. In particular, we show that applying
standard transfer-learning techniques allows to outperform current
state-of-the-art tabular systems in accuracy, runtime and latency."
On the Role of Field of View for Occlusion Removal with Airborne Optical Sectioning,0.312833,"Occlusion caused by vegetation is an essential problem for remote sensing
applications in areas, such as search and rescue, wildfire detection, wildlife
observation, surveillance, border control, and others. Airborne Optical
Sectioning (AOS) is an optical, wavelength-independent synthetic aperture
imaging technique that supports computational occlusion removal in real-time.
It can be applied with manned or unmanned aircrafts, such as drones. In this
article, we demonstrate a relationship between forest density and field of view
(FOV) of applied imaging systems. This finding was made with the help of a
simulated procedural forest model which offers the consideration of more
realistic occlusion properties than our previous statistical model. While AOS
has been explored with automatic and autonomous research prototypes in the
past, we present a free AOS integration for DJI systems. It enables bluelight
organizations and others to use and explore AOS with compatible, manually
operated, off-the-shelf drones. The (digitally cropped) default FOV for this
implementation was chosen based on our new finding."
Static Hand Gesture Recognition for American Sign Language using Neuromorphic Hardware,0.78339,"In this paper, we develop four spiking neural network (SNN) models for two
static American Sign Language (ASL) hand gesture classification tasks, i.e.,
the ASL Alphabet and ASL Digits. The SNN models are deployed on Intel's
neuromorphic platform, Loihi, and then compared against equivalent deep neural
network (DNN) models deployed on an edge computing device, the Intel Neural
Compute Stick 2 (NCS2). We perform a comprehensive comparison between the two
systems in terms of accuracy, latency, power consumption, and energy. The best
DNN model achieves an accuracy of 99.93% on the ASL Alphabet dataset, whereas
the best performing SNN model has an accuracy of 99.30%. For the ASL-Digits
dataset, the best DNN model achieves an accuracy of 99.76% accuracy while the
SNN achieves 99.03%. Moreover, our obtained experimental results show that the
Loihi neuromorphic hardware implementations achieve up to 20.64x and 4.10x
reduction in power consumption and energy, respectively, when compared to NCS2."
Towards End-to-End Generative Modeling of Long Videos with Memory-Efficient Bidirectional Transformers,0.104671,"Autoregressive transformers have shown remarkable success in video
generation. However, the transformers are prohibited from directly learning the
long-term dependency in videos due to the quadratic complexity of
self-attention, and inherently suffering from slow inference time and error
propagation due to the autoregressive process. In this paper, we propose
Memory-efficient Bidirectional Transformer (MeBT) for end-to-end learning of
long-term dependency in videos and fast inference. Based on recent advances in
bidirectional transformers, our method learns to decode the entire
spatio-temporal volume of a video in parallel from partially observed patches.
The proposed transformer achieves a linear time complexity in both encoding and
decoding, by projecting observable context tokens into a fixed number of latent
tokens and conditioning them to decode the masked tokens through the
cross-attention. Empowered by linear complexity and bidirectional modeling, our
method demonstrates significant improvement over the autoregressive
Transformers for generating moderately long videos in both quality and speed.
Videos and code are available at https://sites.google.com/view/mebt-cvpr2023 ."
Policy Optimization with Linear Temporal Logic Constraints,0.685316,"We study the problem of policy optimization (PO) with linear temporal logic
(LTL) constraints. The language of LTL allows flexible description of tasks
that may be unnatural to encode as a scalar cost function. We consider
LTL-constrained PO as a systematic framework, decoupling task specification
from policy selection, and as an alternative to the standard of cost shaping.
With access to a generative model, we develop a model-based approach that
enjoys a sample complexity analysis for guaranteeing both task satisfaction and
cost optimality (through a reduction to a reachability problem). Empirically,
our algorithm can achieve strong performance even in low-sample regimes."
Neural Polarizer: A Lightweight and Effective Backdoor Defense via Purifying Poisoned Features,0.831646,"Recent studies have demonstrated the susceptibility of deep neural networks
to backdoor attacks. Given a backdoored model, its prediction of a poisoned
sample with trigger will be dominated by the trigger information, though
trigger information and benign information coexist. Inspired by the mechanism
of the optical polarizer that a polarizer could pass light waves with
particular polarizations while filtering light waves with other polarizations,
we propose a novel backdoor defense method by inserting a learnable neural
polarizer into the backdoored model as an intermediate layer, in order to
purify the poisoned sample via filtering trigger information while maintaining
benign information. The neural polarizer is instantiated as one lightweight
linear transformation layer, which is learned through solving a well designed
bi-level optimization problem, based on a limited clean dataset. Compared to
other fine-tuning-based defense methods which often adjust all parameters of
the backdoored model, the proposed method only needs to learn one additional
layer, such that it is more efficient and requires less clean data. Extensive
experiments demonstrate the effectiveness and efficiency of our method in
removing backdoors across various neural network architectures and datasets,
especially in the case of very limited clean data."
Self-directed Learning of Action Models using Exploratory Planning,0.0413488,"Complex, real-world domains may not be fully modeled for an agent, especially
if the agent has never operated in the domain before. The agent's ability to
effectively plan and act in such a domain is influenced by its knowledge of
when it can perform specific actions and the effects of those actions. We
describe a novel exploratory planning agent that is capable of learning action
preconditions and effects without expert traces or a given goal. The agent's
architecture allows it to perform both exploratory actions as well as
goal-directed actions, which opens up important considerations for how
exploratory planning and goal planning should be controlled, as well as how the
agent's behavior should be explained to any teammates it may have. The
contributions of this work include a new representation for contexts called
Lifted Linked Clauses, a novel exploration action selection approach using
these clauses, an exploration planner that uses lifted linked clauses as goals
in order to reach new states, and an empirical evaluation in a scenario from an
exploration-focused video game demonstrating that lifted linked clauses improve
exploration and action model learning against non-planning baseline agents."
MotionDiffuse: Text-Driven Human Motion Generation with Diffusion Model,0.999818,"Human motion modeling is important for many modern graphics applications,
which typically require professional skills. In order to remove the skill
barriers for laymen, recent motion generation methods can directly generate
human motions conditioned on natural languages. However, it remains challenging
to achieve diverse and fine-grained motion generation with various text inputs.
To address this problem, we propose MotionDiffuse, the first diffusion
model-based text-driven motion generation framework, which demonstrates several
desired properties over existing methods. 1) Probabilistic Mapping. Instead of
a deterministic language-motion mapping, MotionDiffuse generates motions
through a series of denoising steps in which variations are injected. 2)
Realistic Synthesis. MotionDiffuse excels at modeling complicated data
distribution and generating vivid motion sequences. 3) Multi-Level
Manipulation. MotionDiffuse responds to fine-grained instructions on body
parts, and arbitrary-length motion synthesis with time-varied text prompts. Our
experiments show MotionDiffuse outperforms existing SoTA methods by convincing
margins on text-driven motion generation and action-conditioned motion
generation. A qualitative analysis further demonstrates MotionDiffuse's
controllability for comprehensive motion generation. Homepage:
https://mingyuan-zhang.github.io/projects/MotionDiffuse.html"
Exploring Continuous Integrate-and-Fire for Adaptive Simultaneous Speech Translation,0.633786,"Simultaneous speech translation (SimulST) is a challenging task aiming to
translate streaming speech before the complete input is observed. A SimulST
system generally includes two components: the pre-decision that aggregates the
speech information and the policy that decides to read or write. While recent
works had proposed various strategies to improve the pre-decision, they mainly
adopt the fixed wait-k policy, leaving the adaptive policies rarely explored.
This paper proposes to model the adaptive policy by adapting the Continuous
Integrate-and-Fire (CIF). Compared with monotonic multihead attention (MMA),
our method has the advantage of simpler computation, superior quality at low
latency, and better generalization to long utterances. We conduct experiments
on the MuST-C V2 dataset and show the effectiveness of our approach."
End-to-End Visual Editing with a Generatively Pre-Trained Artist,0.113631,"We consider the targeted image editing problem: blending a region in a source
image with a driver image that specifies the desired change. Differently from
prior works, we solve this problem by learning a conditional probability
distribution of the edits, end-to-end. Training such a model requires
addressing a fundamental technical challenge: the lack of example edits for
training. To this end, we propose a self-supervised approach that simulates
edits by augmenting off-the-shelf images in a target domain. The benefits are
remarkable: implemented as a state-of-the-art auto-regressive transformer, our
approach is simple, sidesteps difficulties with previous methods based on
GAN-like priors, obtains significantly better edits, and is efficient.
Furthermore, we show that different blending effects can be learned by an
intuitive control of the augmentation process, with no other changes required
to the model architecture. We demonstrate the superiority of this approach
across several datasets in extensive quantitative and qualitative experiments,
including human studies, significantly outperforming prior work."
Fulfilling Formal Specifications ASAP by Model-free Reinforcement Learning,0.0587663,"We propose a model-free reinforcement learning solution, namely the ASAP-Phi
framework, to encourage an agent to fulfill a formal specification ASAP. The
framework leverages a piece-wise reward function that assigns quantitative
semantic reward to traces not satisfying the specification, and a high constant
reward to the remaining. Then, it trains an agent with an actor-critic-based
algorithm, such as soft actor-critic (SAC), or deep deterministic policy
gradient (DDPG). Moreover, we prove that ASAP-Phi produces policies that
prioritize fulfilling a specification ASAP. Extensive experiments are run,
including ablation studies, on state-of-the-art benchmarks. Results show that
our framework succeeds in finding sufficiently fast trajectories for up to 97\%
test cases and defeats baselines."
Probing Pre-Trained Language Models for Cross-Cultural Differences in Values,0.997702,"Language embeds information about social, cultural, and political values
people hold. Prior work has explored social and potentially harmful biases
encoded in Pre-Trained Language models (PTLMs). However, there has been no
systematic study investigating how values embedded in these models vary across
cultures. In this paper, we introduce probes to study which values across
cultures are embedded in these models, and whether they align with existing
theories and cross-cultural value surveys. We find that PTLMs capture
differences in values across cultures, but those only weakly align with
established value surveys. We discuss implications of using mis-aligned models
in cross-cultural settings, as well as ways of aligning PTLMs with value
surveys."
Controlling Extra-Textual Attributes about Dialogue Participants -- A Case Study of English-to-Polish Neural Machine Translation,0.137413,"Unlike English, morphologically rich languages can reveal characteristics of
speakers or their conversational partners, such as gender and number, via
pronouns, morphological endings of words and syntax. When translating from
English to such languages, a machine translation model needs to opt for a
certain interpretation of textual context, which may lead to serious
translation errors if extra-textual information is unavailable. We investigate
this challenge in the English-to-Polish language direction. We focus on the
underresearched problem of utilising external metadata in automatic translation
of TV dialogue, proposing a case study where a wide range of approaches for
controlling attributes in translation is employed in a multi-attribute
scenario. The best model achieves an improvement of +5.81 chrF++/+6.03 BLEU,
with other models achieving competitive performance. We additionally contribute
a novel attribute-annotated dataset of Polish TV dialogue and a morphological
analysis script used to evaluate attribute control in models."
Unfolding Local Growth Rate Estimates for (Almost) Perfect Adversarial Detection,0.418163,"Convolutional neural networks (CNN) define the state-of-the-art solution on
many perceptual tasks. However, current CNN approaches largely remain
vulnerable against adversarial perturbations of the input that have been
crafted specifically to fool the system while being quasi-imperceptible to the
human eye. In recent years, various approaches have been proposed to defend
CNNs against such attacks, for example by model hardening or by adding explicit
defence mechanisms. Thereby, a small ""detector"" is included in the network and
trained on the binary classification task of distinguishing genuine data from
data containing adversarial perturbations. In this work, we propose a simple
and light-weight detector, which leverages recent findings on the relation
between networks' local intrinsic dimensionality (LID) and adversarial attacks.
Based on a re-interpretation of the LID measure and several simple adaptations,
we surpass the state-of-the-art on adversarial detection by a significant
margin and reach almost perfect results in terms of F1-score for several
networks and datasets. Sources available at:
https://github.com/adverML/multiLID"
An Exploration of Hierarchical Attention Transformers for Efficient Long Document Classification,0.493819,"Non-hierarchical sparse attention Transformer-based models, such as
Longformer and Big Bird, are popular approaches to working with long documents.
There are clear benefits to these approaches compared to the original
Transformer in terms of efficiency, but Hierarchical Attention Transformer
(HAT) models are a vastly understudied alternative. We develop and release
fully pre-trained HAT models that use segment-wise followed by cross-segment
encoders and compare them with Longformer models and partially pre-trained
HATs. In several long document downstream classification tasks, our best HAT
model outperforms equally-sized Longformer models while using 10-20% less GPU
memory and processing documents 40-45% faster. In a series of ablation studies,
we find that HATs perform best with cross-segment contextualization throughout
the model than alternative configurations that implement either early or late
cross-segment contextualization. Our code is on GitHub:
https://github.com/coastalcph/hierarchical-transformers."
SoK: Cross-border Criminal Investigations and Digital Evidence,0.865552,"Digital evidence underpin the majority of crimes as their analysis is an
integral part of almost every criminal investigation. Even if we temporarily
disregard the numerous challenges in the collection and analysis of digital
evidence, the exchange of the evidence among the different stakeholders has
many thorny issues. Of specific interest are cross-border criminal
investigations as the complexity is significantly high due to the heterogeneity
of legal frameworks which beyond time bottlenecks can also become prohibiting.
The aim of this article is to analyse the current state of practice of
cross-border investigations considering the efficacy of current collaboration
protocols along with the challenges and drawbacks to be overcome. Further to
performing a legally-oriented research treatise, we recall all the challenges
raised in the literature and discuss them from a more practical yet global
perspective. Thus, this article paves the way to enabling practitioners and
stakeholders to leverage horizontal strategies to fill in the identified gaps
timely and accurately."
Combining Adversaries with Anti-adversaries in Training,0.202749,"Adversarial training is an effective learning technique to improve the
robustness of deep neural networks. In this study, the influence of adversarial
training on deep learning models in terms of fairness, robustness, and
generalization is theoretically investigated under more general perturbation
scope that different samples can have different perturbation directions (the
adversarial and anti-adversarial directions) and varied perturbation bounds.
Our theoretical explorations suggest that the combination of adversaries and
anti-adversaries (samples with anti-adversarial perturbations) in training can
be more effective in achieving better fairness between classes and a better
tradeoff between robustness and generalization in some typical learning
scenarios (e.g., noisy label learning and imbalance learning) compared with
standard adversarial training. On the basis of our theoretical findings, a more
general learning objective that combines adversaries and anti-adversaries with
varied bounds on each training sample is presented. Meta learning is utilized
to optimize the combination weights. Experiments on benchmark datasets under
different learning scenarios verify our theoretical findings and the
effectiveness of the proposed methodology."
Discovering Causality for Efficient Cooperation in Multi-Agent Environments,0.166109,"In cooperative Multi-Agent Reinforcement Learning (MARL) agents are required
to learn behaviours as a team to achieve a common goal. However, while learning
a task, some agents may end up learning sub-optimal policies, not contributing
to the objective of the team. Such agents are called lazy agents due to their
non-cooperative behaviours that may arise from failing to understand whether
they caused the rewards. As a consequence, we observe that the emergence of
cooperative behaviours is not necessarily a byproduct of being able to solve a
task as a team. In this paper, we investigate the applications of causality in
MARL and how it can be applied in MARL to penalise these lazy agents. We
observe that causality estimations can be used to improve the credit assignment
to the agents and show how it can be leveraged to improve independent learning
in MARL. Furthermore, we investigate how Amortized Causal Discovery can be used
to automate causality detection within MARL environments. The results
demonstrate that causality relations between individual observations and the
team reward can be used to detect and punish lazy agents, making them develop
more intelligent behaviours. This results in improvements not only in the
overall performances of the team but also in their individual capabilities. In
addition, results show that Amortized Causal Discovery can be used efficiently
to find causal relations in MARL."
ConsistTL: Modeling Consistency in Transfer Learning for Low-Resource Neural Machine Translation,0.263558,"Transfer learning is a simple and powerful method that can be used to boost
model performance of low-resource neural machine translation (NMT). Existing
transfer learning methods for NMT are static, which simply transfer knowledge
from a parent model to a child model once via parameter initialization. In this
paper, we propose a novel transfer learning method for NMT, namely ConsistTL,
which can continuously transfer knowledge from the parent model during the
training of the child model. Specifically, for each training instance of the
child model, ConsistTL constructs the semantically-equivalent instance for the
parent model and encourages prediction consistency between the parent and child
for this instance, which is equivalent to the child model learning each
instance under the guidance of the parent model. Experimental results on five
low-resource NMT tasks demonstrate that ConsistTL results in significant
improvements over strong transfer learning baselines, with a gain up to 1.7
BLEU over the existing back-translation model on the widely-used WMT17
Turkish-English benchmark. Further analysis reveals that ConsistTL can improve
the inference calibration of the child model. Code and scripts are freely
available at https://github.com/NLP2CT/ConsistTL."
Locality-aware Attention Network with Discriminative Dynamics Learning for Weakly Supervised Anomaly Detection,0.45271,"Video anomaly detection is recently formulated as a multiple instance
learning task under weak supervision, in which each video is treated as a bag
of snippets to be determined whether contains anomalies. Previous efforts
mainly focus on the discrimination of the snippet itself without modeling the
temporal dynamics, which refers to the variation of adjacent snippets.
Therefore, we propose a Discriminative Dynamics Learning (DDL) method with two
objective functions, i.e., dynamics ranking loss and dynamics alignment loss.
The former aims to enlarge the score dynamics gap between positive and negative
bags while the latter performs temporal alignment of the feature dynamics and
score dynamics within the bag. Moreover, a Locality-aware Attention Network
(LA-Net) is constructed to capture global correlations and re-calibrate the
location preference across snippets, followed by a multilayer perceptron with
causal convolution to obtain anomaly scores. Experimental results show that our
method achieves significant improvements on two challenging benchmarks, i.e.,
UCF-Crime and XD-Violence."
InitialGAN: A Language GAN with Completely Random Initialization,0.0289298,"Text generative models trained via Maximum Likelihood Estimation (MLE) suffer
from the notorious exposure bias problem, and Generative Adversarial Networks
(GANs) are shown to have potential to tackle this problem. Existing language
GANs adopt estimators like REINFORCE or continuous relaxations to model word
probabilities. The inherent limitations of such estimators lead current models
to rely on pre-training techniques (MLE pre-training or pre-trained
embeddings). Representation modeling methods which are free from those
limitations, however, are seldomly explored because of their poor performance
in previous attempts. Our analyses reveal that invalid sampling methods and
unhealthy gradients are the main contributors to such unsatisfactory
performance. In this work, we present two techniques to tackle these problems:
dropout sampling and fully normalized LSTM. Based on these two techniques, we
propose InitialGAN whose parameters are randomly initialized in full. Besides,
we introduce a new evaluation metric, Least Coverage Rate, to better evaluate
the quality of generated samples. The experimental results demonstrate that
InitialGAN outperforms both MLE and other compared models. To the best of our
knowledge, it is the first time a language GAN can outperform MLE without using
any pre-training techniques."
NeReF: Neural Refractive Field for Fluid Surface Reconstruction and Implicit Representation,0.45294,"Existing neural reconstruction schemes such as Neural Radiance Field (NeRF)
are largely focused on modeling opaque objects. We present a novel neural
refractive field(NeReF) to recover wavefront of transparent fluids by
simultaneously estimating the surface position and normal of the fluid front.
Unlike prior arts that treat the reconstruction target as a single layer of the
surface, NeReF is specifically formulated to recover a volumetric normal field
with its corresponding density field. A query ray will be refracted by NeReF
according to its accumulated refractive point and normal, and we employ the
correspondences and uniqueness of refracted ray for NeReF optimization. We show
NeReF, as a global optimization scheme, can more robustly tackle refraction
distortions detrimental to traditional methods for correspondence matching.
Furthermore, the continuous NeReF representation of wavefront enables view
synthesis as well as normal integration. We validate our approach on both
synthetic and real data and show it is particularly suitable for sparse
multi-view acquisition. We hence build a small light field array and experiment
on various surface shapes to demonstrate high fidelity NeReF reconstruction."
AutoDistil: Few-shot Task-agnostic Neural Architecture Search for Distilling Large Language Models,0.229715,"Knowledge distillation (KD) methods compress large models into smaller
students with manually-designed student architectures given pre-specified
computational cost. This requires several trials to find a viable student, and
further repeating the process for each student or computational budget change.
We use Neural Architecture Search (NAS) to automatically distill several
compressed students with variable cost from a large model. Current works train
a single SuperLM consisting of millions of subnetworks with weight-sharing,
resulting in interference between subnetworks of different sizes. Our framework
AutoDistil addresses above challenges with the following steps: (a)
Incorporates inductive bias and heuristics to partition Transformer search
space into K compact sub-spaces (K=3 for typical student sizes of base, small
and tiny); (b) Trains one SuperLM for each sub-space using task-agnostic
objective (e.g., self-attention distillation) with weight-sharing of students;
(c) Lightweight search for the optimal student without re-training. Fully
task-agnostic training and search allow students to be reused for fine-tuning
on any downstream task. Experiments on GLUE benchmark against state-of-the-art
KD and NAS methods demonstrate AutoDistil to outperform leading compression
techniques with upto 2.7x reduction in computational cost and negligible loss
in task performance."
Modality Adaption or Regularization? A Case Study on End-to-End Speech Translation,0.235767,"Pre-training and fine-tuning is a paradigm for alleviating the data scarcity
problem in end-to-end speech translation (E2E ST). The commonplace ""modality
gap"" between speech and text data often leads to inconsistent inputs between
pre-training and fine-tuning. However, we observe that this gap occurs in the
early stages of fine-tuning, but does not have a major impact on the final
performance. On the other hand, we find that there has another gap, which we
call the ""capacity gap"": high resource tasks (such as ASR and MT) always
require a large model to fit, when the model is reused for a low resource task
(E2E ST), it will get a sub-optimal performance due to the over-fitting. In a
case study, we find that the regularization plays a more important role than
the well-designed modality adaption method, which achieves 29.0 for en-de and
40.3 for en-fr on the MuST-C dataset. Code and models are available at
https://github.com/hannlp/TAB."
Mind the gap: Challenges of deep learning approaches to Theory of Mind,0.799068,"Theory of Mind is an essential ability of humans to infer the mental states
of others. Here we provide a coherent summary of the potential, current
progress, and problems of deep learning approaches to Theory of Mind. We
highlight that many current findings can be explained through shortcuts. These
shortcuts arise because the tasks used to investigate Theory of Mind in deep
learning systems have been too narrow. Thus, we encourage researchers to
investigate Theory of Mind in complex open-ended environments. Furthermore, to
inspire future deep learning systems we provide a concise overview of prior
work done in humans. We further argue that when studying Theory of Mind with
deep learning, the research's main focus and contribution ought to be opening
up the network's representations. We recommend researchers use tools from the
field of interpretability of AI to study the relationship between different
network components and aspects of Theory of Mind."
Towards Better Document-level Relation Extraction via Iterative Inference,0.609229,"Document-level relation extraction (RE) aims to extract the relations between
entities from the input document that usually containing many
difficultly-predicted entity pairs whose relations can only be predicted
through relational inference. Existing methods usually directly predict the
relations of all entity pairs of input document in a one-pass manner, ignoring
the fact that predictions of some entity pairs heavily depend on the predicted
results of other pairs. To deal with this issue, in this paper, we propose a
novel document-level RE model with iterative inference. Our model is mainly
composed of two modules: 1) a base module expected to provide preliminary
relation predictions on entity pairs; 2) an inference module introduced to
refine these preliminary predictions by iteratively dealing with
difficultly-predicted entity pairs depending on other pairs in an easy-to-hard
manner. Unlike previous methods which only consider feature information of
entity pairs, our inference module is equipped with two Extended Cross
Attention units, allowing it to exploit both feature information and previous
predictions of entity pairs during relational inference. Furthermore, we adopt
a two-stage strategy to train our model. At the first stage, we only train our
base module. During the second stage, we train the whole model, where
contrastive learning is introduced to enhance the training of inference module.
Experimental results on three commonly-used datasets show that our model
consistently outperforms other competitive baselines."
Justifiable Artificial Intelligence: Engineering Large Language Models for Legal Applications,0.315703,"In this work, I discuss how Large Language Models can be applied in the legal
domain, circumventing their current drawbacks. Despite their large success and
acceptance, their lack of explainability hinders legal experts to trust in
their output, and this happens rightfully so. However, in this paper, I argue
in favor of a new view, Justifiable Artificial Intelligence, instead of
focusing on Explainable Artificial Intelligence. I discuss in this paper how
gaining evidence for and against a Large Language Model's output may make their
generated texts more trustworthy - or hold them accountable for misinformation."
Recurrent Bilinear Optimization for Binary Neural Networks,0.731776,"Binary Neural Networks (BNNs) show great promise for real-world embedded
devices. As one of the critical steps to achieve a powerful BNN, the scale
factor calculation plays an essential role in reducing the performance gap to
their real-valued counterparts. However, existing BNNs neglect the intrinsic
bilinear relationship of real-valued weights and scale factors, resulting in a
sub-optimal model caused by an insufficient training process. To address this
issue, Recurrent Bilinear Optimization is proposed to improve the learning
process of BNNs (RBONNs) by associating the intrinsic bilinear variables in the
back propagation process. Our work is the first attempt to optimize BNNs from
the bilinear perspective. Specifically, we employ a recurrent optimization and
Density-ReLU to sequentially backtrack the sparse real-valued weight filters,
which will be sufficiently trained and reach their performance limits based on
a controllable learning process. We obtain robust RBONNs, which show impressive
performance over state-of-the-art BNNs on various models and datasets.
Particularly, on the task of object detection, RBONNs have great generalization
performance. Our code is open-sourced on https://github.com/SteveTsui/RBONN ."
Empirical study of the modulus as activation function in computer vision applications,0.509669,"In this work we propose a new non-monotonic activation function: the modulus.
The majority of the reported research on nonlinearities is focused on monotonic
functions. We empirically demonstrate how by using the modulus activation
function on computer vision tasks the models generalize better than with other
nonlinearities - up to a 15% accuracy increase in CIFAR100 and 4% in CIFAR10,
relative to the best of the benchmark activations tested. With the proposed
activation function the vanishing gradient and dying neurons problems
disappear, because the derivative of the activation function is always 1 or -1.
The simplicity of the proposed function and its derivative make this solution
specially suitable for TinyML and hardware applications."
Principal-Agent Reward Shaping in MDPs,0.342994,"Principal-agent problems arise when one party acts on behalf of another,
leading to conflicts of interest. The economic literature has extensively
studied principal-agent problems, and recent work has extended this to more
complex scenarios such as Markov Decision Processes (MDPs). In this paper, we
further explore this line of research by investigating how reward shaping under
budget constraints can improve the principal's utility. We study a two-player
Stackelberg game where the principal and the agent have different reward
functions, and the agent chooses an MDP policy for both players. The principal
offers an additional reward to the agent, and the agent picks their policy
selfishly to maximize their reward, which is the sum of the original and the
offered reward. Our results establish the NP-hardness of the problem and offer
polynomial approximation algorithms for two classes of instances: Stochastic
trees and deterministic decision processes with a finite horizon."
SynSciPass: detecting appropriate uses of scientific text generation,0.167,"Approaches to machine generated text detection tend to focus on binary
classification of human versus machine written text. In the scientific domain
where publishers might use these models to examine manuscripts under
submission, misclassification has the potential to cause harm to authors.
Additionally, authors may appropriately use text generation models such as with
the use of assistive technologies like translation tools. In this setting, a
binary classification scheme might be used to flag appropriate uses of
assistive text generation technology as simply machine generated which is a
cause of concern. In our work, we simulate this scenario by presenting a
state-of-the-art detector trained on the DAGPap22 with machine translated
passages from Scielo and find that the model performs at random. Given this
finding, we develop a framework for dataset development that provides a nuanced
approach to detecting machine generated text by having labels for the type of
technology used such as for translation or paraphrase resulting in the
construction of SynSciPass. By training the same model that performed well on
DAGPap22 on SynSciPass, we show that not only is the model more robust to
domain shifts but also is able to uncover the type of technology used for
machine generated text. Despite this, we conclude that current datasets are
neither comprehensive nor realistic enough to understand how these models would
perform in the wild where manuscript submissions can come from many unknown or
novel distributions, how they would perform on scientific full-texts rather
than small passages, and what might happen when there is a mix of appropriate
and inappropriate uses of natural language generation."
"Privacy in Large Language Models: Attacks, Defenses and Future Directions",0.850771,"The advancement of large language models (LLMs) has significantly enhanced
the ability to effectively tackle various downstream NLP tasks and unify these
tasks into generative pipelines. On the one hand, powerful language models,
trained on massive textual data, have brought unparalleled accessibility and
usability for both models and users. On the other hand, unrestricted access to
these models can also introduce potential malicious and unintentional privacy
risks. Despite ongoing efforts to address the safety and privacy concerns
associated with LLMs, the problem remains unresolved. In this paper, we provide
a comprehensive analysis of the current privacy attacks targeting LLMs and
categorize them according to the adversary's assumed capabilities to shed light
on the potential vulnerabilities present in LLMs. Then, we present a detailed
overview of prominent defense strategies that have been developed to counter
these privacy attacks. Beyond existing works, we identify upcoming privacy
concerns as LLMs evolve. Lastly, we point out several potential avenues for
future exploration."
Zero-shot Blind Image Denoising via Implicit Neural Representations,0.361606,"Recent denoising algorithms based on the ""blind-spot"" strategy show
impressive blind image denoising performances, without utilizing any external
dataset. While the methods excel in recovering highly contaminated images, we
observe that such algorithms are often less effective under a low-noise or real
noise regime. To address this gap, we propose an alternative denoising strategy
that leverages the architectural inductive bias of implicit neural
representations (INRs), based on our two findings: (1) INR tends to fit the
low-frequency clean image signal faster than the high-frequency noise, and (2)
INR layers that are closer to the output play more critical roles in fitting
higher-frequency parts. Building on these observations, we propose a denoising
algorithm that maximizes the innate denoising capability of INRs by penalizing
the growth of deeper layer weights. We show that our method outperforms
existing zero-shot denoising methods under an extensive set of low-noise or
real-noise scenarios."
Learning to Ignore Adversarial Attacks,0.0602004,"Despite the strong performance of current NLP models, they can be brittle
against adversarial attacks. To enable effective learning against adversarial
inputs, we introduce the use of rationale models that can explicitly learn to
ignore attack tokens. We find that the rationale models can successfully ignore
over 90% of attack tokens. This approach leads to consistent sizable
improvements ($\sim$10%) over baseline models in robustness on three datasets
for both BERT and RoBERTa, and also reliably outperforms data augmentation with
adversarial examples alone. In many cases, we find that our method is able to
close the gap between model performance on a clean test set and an attacked
test set and hence reduce the effect of adversarial attacks."
Does BERT really agree ? Fine-grained Analysis of Lexical Dependence on a Syntactic Task,0.676742,"Although transformer-based Neural Language Models demonstrate impressive
performance on a variety of tasks, their generalization abilities are not well
understood. They have been shown to perform strongly on subject-verb number
agreement in a wide array of settings, suggesting that they learned to track
syntactic dependencies during their training even without explicit supervision.
In this paper, we examine the extent to which BERT is able to perform
lexically-independent subject-verb number agreement (NA) on targeted syntactic
templates. To do so, we disrupt the lexical patterns found in naturally
occurring stimuli for each targeted structure in a novel fine-grained analysis
of BERT's behavior. Our results on nonce sentences suggest that the model
generalizes well for simple templates, but fails to perform
lexically-independent syntactic generalization when as little as one attractor
is present."
Visual Explanations from Deep Networks via Riemann-Stieltjes Integrated Gradient-based Localization,0.529856,"Neural networks are becoming increasingly better at tasks that involve
classifying and recognizing images. At the same time techniques intended to
explain the network output have been proposed. One such technique is the
Gradient-based Class Activation Map (Grad-CAM), which is able to locate
features of an input image at various levels of a convolutional neural network
(CNN), but is sensitive to the vanishing gradients problem. There are
techniques such as Integrated Gradients (IG), that are not affected by that
problem, but its use is limited to the input layer of a network. Here we
introduce a new technique to produce visual explanations for the predictions of
a CNN. Like Grad-CAM, our method can be applied to any layer of the network,
and like Integrated Gradients it is not affected by the problem of vanishing
gradients. For efficiency, gradient integration is performed numerically at the
layer level using a Riemann-Stieltjes sum approximation. Compared to Grad-CAM,
heatmaps produced by our algorithm are better focused in the areas of interest,
and their numerical computation is more stable. Our code is available at
https://github.com/mlerma54/RSIGradCAM"
UIT-ViCoV19QA: A Dataset for COVID-19 Community-based Question Answering on Vietnamese Language,0.642567,"For the last two years, from 2020 to 2021, COVID-19 has broken disease
prevention measures in many countries, including Vietnam, and negatively
impacted various aspects of human life and the social community. Besides, the
misleading information in the community and fake news about the pandemic are
also serious situations. Therefore, we present the first Vietnamese
community-based question answering dataset for developing question answering
systems for COVID-19 called UIT-ViCoV19QA. The dataset comprises 4,500
question-answer pairs collected from trusted medical sources, with at least one
answer and at most four unique paraphrased answers per question. Along with the
dataset, we set up various deep learning models as baseline to assess the
quality of our dataset and initiate the benchmark results for further research
through commonly used metrics such as BLEU, METEOR, and ROUGE-L. We also
illustrate the positive effects of having multiple paraphrased answers
experimented on these models, especially on Transformer - a dominant
architecture in the field of study."
JigsawHSI: a network for Hyperspectral Image classification,0.658321,"This article describes Jigsaw, a convolutional neural network (CNN) used in
geosciences and based on Inception but tailored for geoscientific analyses.
Introduces JigsawHSI (based on Jigsaw) and uses it on the land-use land-cover
(LULC) classification problem with the Indian Pines, Pavia University and
Salinas hyperspectral image data sets. The network is compared against
HybridSN, a spectral-spatial 3D-CNN followed by 2D-CNN that achieves
state-of-the-art results on the datasets. This short article proves that
JigsawHSI is able to meet or exceed HybridSN's performance in all three cases.
Additionally, the use of jigsaw in geosciences is highlighted, while the code
and toolkit are made available."
A Fused Gromov-Wasserstein Framework for Unsupervised Knowledge Graph Entity Alignment,0.957882,"Entity alignment is the task of identifying corresponding entities across
different knowledge graphs (KGs). Although recent embedding-based entity
alignment methods have shown significant advancements, they still struggle to
fully utilize KG structural information. In this paper, we introduce FGWEA, an
unsupervised entity alignment framework that leverages the Fused
Gromov-Wasserstein (FGW) distance, allowing for a comprehensive comparison of
entity semantics and KG structures within a joint optimization framework. To
address the computational challenges associated with optimizing FGW, we devise
a three-stage progressive optimization algorithm. It starts with a basic
semantic embedding matching, proceeds to approximate cross-KG structural and
relational similarity matching based on iterative updates of high-confidence
entity links, and ultimately culminates in a global structural comparison
between KGs. We perform extensive experiments on four entity alignment datasets
covering 14 distinct KGs across five languages. Without any supervision or
hyper-parameter tuning, FGWEA surpasses 21 competitive baselines, including
cutting-edge supervised entity alignment methods. Our code is available at
https://github.com/squareRoot3/FusedGW-Entity-Alignment."
Motion Robust High-Speed Light-Weighted Object Detection With Event Camera,0.403162,"In this work, we propose a motion robust and high-speed detection pipeline
which better leverages the event data. First, we design an event stream
representation called temporal active focus (TAF), which efficiently utilizes
the spatial-temporal asynchronous event stream, constructing event tensors
robust to object motions. Then, we propose a module called the bifurcated
folding module (BFM), which encodes the rich temporal information in the TAF
tensor at the input layer of the detector. Following this, we design a
high-speed lightweight detector called agile event detector (AED) plus a simple
but effective data augmentation method, to enhance the detection accuracy and
reduce the model's parameter. Experiments on two typical real-scene event
camera object detection datasets show that our method is competitive in terms
of accuracy, efficiency, and the number of parameters. By classifying objects
into multiple motion levels based on the optical flow density metric, we
further illustrated the robustness of our method for objects with different
velocities relative to the camera. The codes and trained models are available
at https://github.com/HarmoniaLeo/FRLW-EvD ."
UniT3D: A Unified Transformer for 3D Dense Captioning and Visual Grounding,0.927443,"Performing 3D dense captioning and visual grounding requires a common and
shared understanding of the underlying multimodal relationships. However,
despite some previous attempts on connecting these two related tasks with
highly task-specific neural modules, it remains understudied how to explicitly
depict their shared nature to learn them simultaneously. In this work, we
propose UniT3D, a simple yet effective fully unified transformer-based
architecture for jointly solving 3D visual grounding and dense captioning.
UniT3D enables learning a strong multimodal representation across the two tasks
through a supervised joint pre-training scheme with bidirectional and
seq-to-seq objectives. With a generic architecture design, UniT3D allows
expanding the pre-training scope to more various training sources such as the
synthesized data from 2D prior knowledge to benefit 3D vision-language tasks.
Extensive experiments and analysis demonstrate that UniT3D obtains significant
gains for 3D dense captioning and visual grounding."
Data Augmentation for Low-Resource Keyphrase Generation,0.0503036,"Keyphrase generation is the task of summarizing the contents of any given
article into a few salient phrases (or keyphrases). Existing works for the task
mostly rely on large-scale annotated datasets, which are not easy to acquire.
Very few works address the problem of keyphrase generation in low-resource
settings, but they still rely on a lot of additional unlabeled data for
pretraining and on automatic methods for pseudo-annotations. In this paper, we
present data augmentation strategies specifically to address keyphrase
generation in purely resource-constrained domains. We design techniques that
use the full text of the articles to improve both present and absent keyphrase
generation. We test our approach comprehensively on three datasets and show
that the data augmentation strategies consistently improve the state-of-the-art
performance. We release our source code at
https://github.com/kgarg8/kpgen-lowres-data-aug."
Training-Free Neural Matte Extraction for Visual Effects,0.0765659,"Alpha matting is widely used in video conferencing as well as in movies,
television, and social media sites. Deep learning approaches to the matte
extraction problem are well suited to video conferencing due to the consistent
subject matter (front-facing humans), however training-based approaches are
somewhat pointless for entertainment videos where varied subjects (spaceships,
monsters, etc.) may appear only a few times in a single movie -- if a method of
creating ground truth for training exists, just use that method to produce the
desired mattes. We introduce a training-free high quality neural matte
extraction approach that specifically targets the assumptions of visual effects
production. Our approach is based on the deep image prior, which optimizes a
deep neural network to fit a single image, thereby providing a deep encoding of
the particular image. We make use of the representations in the penultimate
layer to interpolate coarse and incomplete ""trimap"" constraints. Videos
processed with this approach are temporally consistent. The algorithm is both
very simple and surprisingly effective."
Perspective Fields for Single Image Camera Calibration,0.765401,"Geometric camera calibration is often required for applications that
understand the perspective of the image. We propose perspective fields as a
representation that models the local perspective properties of an image.
Perspective Fields contain per-pixel information about the camera view,
parameterized as an up vector and a latitude value. This representation has a
number of advantages as it makes minimal assumptions about the camera model and
is invariant or equivariant to common image editing operations like cropping,
warping, and rotation. It is also more interpretable and aligned with human
perception. We train a neural network to predict Perspective Fields and the
predicted Perspective Fields can be converted to calibration parameters easily.
We demonstrate the robustness of our approach under various scenarios compared
with camera calibration-based methods and show example applications in image
compositing."
On the Effectiveness of Compact Biomedical Transformers,0.664962,"Language models pre-trained on biomedical corpora, such as BioBERT, have
recently shown promising results on downstream biomedical tasks. Many existing
pre-trained models, on the other hand, are resource-intensive and
computationally heavy owing to factors such as embedding size, hidden
dimension, and number of layers. The natural language processing (NLP)
community has developed numerous strategies to compress these models utilising
techniques such as pruning, quantisation, and knowledge distillation, resulting
in models that are considerably faster, smaller, and subsequently easier to use
in practice. By the same token, in this paper we introduce six lightweight
models, namely, BioDistilBERT, BioTinyBERT, BioMobileBERT, DistilBioBERT,
TinyBioBERT, and CompactBioBERT which are obtained either by knowledge
distillation from a biomedical teacher or continual learning on the Pubmed
dataset via the Masked Language Modelling (MLM) objective. We evaluate all of
our models on three biomedical tasks and compare them with BioBERT-v1.1 to
create efficient lightweight models that perform on par with their larger
counterparts. All the models will be publicly available on our Huggingface
profile at https://huggingface.co/nlpie and the codes used to run the
experiments will be available at
https://github.com/nlpie-research/Compact-Biomedical-Transformers."
Neural Message Passing for Visual Relationship Detection,0.493548,"Visual relationship detection aims to detect the interactions between objects
in an image; however, this task suffers from combinatorial explosion due to the
variety of objects and interactions. Since the interactions associated with the
same object are dependent, we explore the dependency of interactions to reduce
the search space. We explicitly model objects and interactions by an
interaction graph and then propose a message-passing-style algorithm to
propagate the contextual information. We thus call the proposed method neural
message passing (NMP). We further integrate language priors and spatial cues to
rule out unrealistic interactions and capture spatial interactions.
Experimental results on two benchmark datasets demonstrate the superiority of
our proposed method. Our code is available at https://github.com/PhyllisH/NMP."
The Change that Matters in Discourse Parsing: Estimating the Impact of Domain Shift on Parser Error,0.441561,"Discourse analysis allows us to attain inferences of a text document that
extend beyond the sentence-level. The current performance of discourse models
is very low on texts outside of the training distribution's coverage,
diminishing the practical utility of existing models. There is need for a
measure that can inform us to what extent our model generalizes from the
training to the test sample when these samples may be drawn from distinct
distributions. While this can be estimated via distribution shift, we argue
that this does not directly correlate with change in the observed error of a
classifier (i.e. error-gap). Thus, we propose to use a statistic from the
theoretical domain adaptation literature which can be directly tied to
error-gap. We study the bias of this statistic as an estimator of error-gap
both theoretically and through a large-scale empirical study of over 2400
experiments on 6 discourse datasets from domains including, but not limited to:
news, biomedical texts, TED talks, Reddit posts, and fiction. Our results not
only motivate our proposal and help us to understand its limitations, but also
provide insight on the properties of discourse models and datasets which
improve performance in domain adaptation. For instance, we find that non-news
datasets are slightly easier to transfer to than news datasets when the
training and test sets are very different. Our code and an associated Python
package are available to allow practitioners to make more informed model and
dataset choices."
Progressive Prompts: Continual Learning for Language Models,0.987635,"We introduce Progressive Prompts - a simple and efficient approach for
continual learning in language models. Our method allows forward transfer and
resists catastrophic forgetting, without relying on data replay or a large
number of task-specific parameters. Progressive Prompts learns a new soft
prompt for each task and sequentially concatenates it with the previously
learned prompts, while keeping the base model frozen. Experiments on standard
continual learning benchmarks show that our approach outperforms
state-of-the-art methods, with an improvement >20% in average test accuracy
over the previous best-preforming method on T5 model. We also explore a more
challenging continual learning setup with longer sequences of tasks and show
that Progressive Prompts significantly outperforms prior methods."
Temporal Relation Extraction with a Graph-Based Deep Biaffine Attention Model,0.182722,"Temporal information extraction plays a critical role in natural language
understanding. Previous systems have incorporated advanced neural language
models and have successfully enhanced the accuracy of temporal information
extraction tasks. However, these systems have two major shortcomings. First,
they fail to make use of the two-sided nature of temporal relations in
prediction. Second, they involve non-parallelizable pipelines in inference
process that bring little performance gain. To this end, we propose a novel
temporal information extraction model based on deep biaffine attention to
extract temporal relationships between events in unstructured text efficiently
and accurately. Our model is performant because we perform relation extraction
tasks directly instead of considering event annotation as a prerequisite of
relation extraction. Moreover, our architecture uses Multilayer Perceptrons
(MLP) with biaffine attention to predict arcs and relation labels separately,
improving relation detecting accuracy by exploiting the two-sided nature of
temporal relationships. We experimentally demonstrate that our model achieves
state-of-the-art performance in temporal relation extraction."
Abstraction not Memory: BERT and the English Article System,0.236813,"Article prediction is a task that has long defied accurate linguistic
description. As such, this task is ideally suited to evaluate models on their
ability to emulate native-speaker intuition. To this end, we compare the
performance of native English speakers and pre-trained models on the task of
article prediction set up as a three way choice (a/an, the, zero). Our
experiments with BERT show that BERT outperforms humans on this task across all
articles. In particular, BERT is far superior to humans at detecting the zero
article, possibly because we insert them using rules that the deep neural model
can easily pick up. More interestingly, we find that BERT tends to agree more
with annotators than with the corpus when inter-annotator agreement is high but
switches to agreeing more with the corpus as inter-annotator agreement drops.
We contend that this alignment with annotators, despite being trained on the
corpus, suggests that BERT is not memorising article use, but captures a high
level generalisation of article use akin to human intuition."
DoE2Vec: Deep-learning Based Features for Exploratory Landscape Analysis,0.797644,"We propose DoE2Vec, a variational autoencoder (VAE)-based methodology to
learn optimization landscape characteristics for downstream meta-learning
tasks, e.g., automated selection of optimization algorithms. Principally, using
large training data sets generated with a random function generator, DoE2Vec
self-learns an informative latent representation for any design of experiments
(DoE). Unlike the classical exploratory landscape analysis (ELA) method, our
approach does not require any feature engineering and is easily applicable for
high dimensional search spaces. For validation, we inspect the quality of
latent reconstructions and analyze the latent representations using different
experiments. The latent representations not only show promising potentials in
identifying similar (cheap-to-evaluate) surrogate functions, but also can
significantly boost performances when being used complementary to the classical
ELA features in classification tasks."
Data Determines Distributional Robustness in Contrastive Language Image Pre-training (CLIP),0.983459,"Contrastively trained language-image models such as CLIP, ALIGN, and BASIC
have demonstrated unprecedented robustness to multiple challenging natural
distribution shifts. Since these language-image models differ from previous
training approaches in several ways, an important question is what causes the
large robustness gains. We answer this question via a systematic experimental
investigation. Concretely, we study five different possible causes for the
robustness gains: (i) the training set size, (ii) the training distribution,
(iii) language supervision at training time, (iv) language supervision at test
time, and (v) the contrastive loss function. Our experiments show that the more
diverse training distribution is the main cause for the robustness gains, with
the other factors contributing little to no robustness. Beyond our experimental
results, we also introduce ImageNet-Captions, a version of ImageNet with
original text annotations from Flickr, to enable further controlled experiments
of language-image training."
Adaptive Perturbation-Based Gradient Estimation for Discrete Latent Variable Models,0.446865,"The integration of discrete algorithmic components in deep learning
architectures has numerous applications. Recently, Implicit Maximum Likelihood
Estimation (IMLE, Niepert, Minervini, and Franceschi 2021), a class of gradient
estimators for discrete exponential family distributions, was proposed by
combining implicit differentiation through perturbation with the path-wise
gradient estimator. However, due to the finite difference approximation of the
gradients, it is especially sensitive to the choice of the finite difference
step size, which needs to be specified by the user. In this work, we present
Adaptive IMLE (AIMLE), the first adaptive gradient estimator for complex
discrete distributions: it adaptively identifies the target distribution for
IMLE by trading off the density of gradient information with the degree of bias
in the gradient estimates. We empirically evaluate our estimator on synthetic
examples, as well as on Learning to Explain, Discrete Variational
Auto-Encoders, and Neural Relational Inference tasks. In our experiments, we
show that our adaptive gradient estimator can produce faithful estimates while
requiring orders of magnitude fewer samples than other gradient estimators."
Trajectory Optimization for Physics-Based Reconstruction of 3d Human Pose from Monocular Video,0.82981,"We focus on the task of estimating a physically plausible articulated human
motion from monocular video. Existing approaches that do not consider physics
often produce temporally inconsistent output with motion artifacts, while
state-of-the-art physics-based approaches have either been shown to work only
in controlled laboratory conditions or consider simplified body-ground contact
limited to feet. This paper explores how these shortcomings can be addressed by
directly incorporating a fully-featured physics engine into the pose estimation
process. Given an uncontrolled, real-world scene as input, our approach
estimates the ground-plane location and the dimensions of the physical body
model. It then recovers the physical motion by performing trajectory
optimization. The advantage of our formulation is that it readily generalizes
to a variety of scenes that might have diverse ground properties and supports
any form of self-contact and contact between the articulated body and scene
geometry. We show that our approach achieves competitive results with respect
to existing physics-based methods on the Human3.6M benchmark, while being
directly applicable without re-training to more complex dynamic motions from
the AIST benchmark and to uncontrolled internet videos."
GeCoNeRF: Few-shot Neural Radiance Fields via Geometric Consistency,0.693178,"We present a novel framework to regularize Neural Radiance Field (NeRF) in a
few-shot setting with a geometry-aware consistency regularization. The proposed
approach leverages a rendered depth map at unobserved viewpoint to warp sparse
input images to the unobserved viewpoint and impose them as pseudo ground
truths to facilitate learning of NeRF. By encouraging such geometry-aware
consistency at a feature-level instead of using pixel-level reconstruction
loss, we regularize the NeRF at semantic and structural levels while allowing
for modeling view dependent radiance to account for color variations across
viewpoints. We also propose an effective method to filter out erroneous warped
solutions, along with training strategies to stabilize training during
optimization. We show that our model achieves competitive results compared to
state-of-the-art few-shot NeRF models. Project page is available at
https://ku-cvlab.github.io/GeCoNeRF/."
Reinforcement Learning with Large Action Spaces for Neural Machine Translation,0.265416,"Applying Reinforcement learning (RL) following maximum likelihood estimation
(MLE) pre-training is a versatile method for enhancing neural machine
translation (NMT) performance. However, recent work has argued that the gains
produced by RL for NMT are mostly due to promoting tokens that have already
received a fairly high probability in pre-training. We hypothesize that the
large action space is a main obstacle to RL's effectiveness in MT, and conduct
two sets of experiments that lend support to our hypothesis. First, we find
that reducing the size of the vocabulary improves RL's effectiveness. Second,
we find that effectively reducing the dimension of the action space without
changing the vocabulary also yields notable improvement as evaluated by BLEU,
semantic similarity, and human evaluation. Indeed, by initializing the
network's final fully connected layer (that maps the network's internal
dimension to the vocabulary dimension), with a layer that generalizes over
similar actions, we obtain a substantial improvement in RL performance: 1.5
BLEU points on average."
Local Attention Graph-based Transformer for Multi-target Genetic Alteration Prediction,0.80173,"Classical multiple instance learning (MIL) methods are often based on the
identical and independent distributed assumption between instances, hence
neglecting the potentially rich contextual information beyond individual
entities. On the other hand, Transformers with global self-attention modules
have been proposed to model the interdependencies among all instances. However,
in this paper we question: Is global relation modeling using self-attention
necessary, or can we appropriately restrict self-attention calculations to
local regimes in large-scale whole slide images (WSIs)? We propose a
general-purpose local attention graph-based Transformer for MIL (LA-MIL),
introducing an inductive bias by explicitly contextualizing instances in
adaptive local regimes of arbitrary size. Additionally, an efficiently adapted
loss function enables our approach to learn expressive WSI embeddings for the
joint analysis of multiple biomarkers. We demonstrate that LA-MIL achieves
state-of-the-art results in mutation prediction for gastrointestinal cancer,
outperforming existing models on important biomarkers such as microsatellite
instability for colorectal cancer. Our findings suggest that local
self-attention sufficiently models dependencies on par with global modules. Our
LA-MIL implementation is available at https://github.com/agentdr1/LA_MIL."
Discourse Structures Guided Fine-grained Propaganda Identification,0.375043,"Propaganda is a form of deceptive narratives that instigate or mislead the
public, usually with a political purpose. In this paper, we aim to identify
propaganda in political news at two fine-grained levels: sentence-level and
token-level. We observe that propaganda content is more likely to be embedded
in sentences that attribute causality or assert contrast to nearby sentences,
as well as seen in opinionated evaluation, speculation and discussions of
future expectation. Hence, we propose to incorporate both local and global
discourse structures for propaganda discovery and construct two teacher models
for identifying PDTB-style discourse relations between nearby sentences and
common discourse roles of sentences in a news article respectively. We further
devise two methods to incorporate the two types of discourse structures for
propaganda identification by either using teacher predicted probabilities as
additional features or soliciting guidance in a knowledge distillation
framework. Experiments on the benchmark dataset demonstrate that leveraging
guidance from discourse structures can significantly improve both precision and
recall of propaganda content identification."
Word-order typology in Multilingual BERT: A case study in subordinate-clause detection,0.608394,"The capabilities and limitations of BERT and similar models are still unclear
when it comes to learning syntactic abstractions, in particular across
languages. In this paper, we use the task of subordinate-clause detection
within and across languages to probe these properties. We show that this task
is deceptively simple, with easy gains offset by a long tail of harder cases,
and that BERT's zero-shot performance is dominated by word-order effects,
mirroring the SVO/VSO/SOV typology."
Asynchronous training of quantum reinforcement learning,0.612224,"The development of quantum machine learning (QML) has received a lot of
interest recently thanks to developments in both quantum computing (QC) and
machine learning (ML). One of the ML paradigms that can be utilized to address
challenging sequential decision-making issues is reinforcement learning (RL).
It has been demonstrated that classical RL can successfully complete many
difficult tasks. A leading method of building quantum RL agents relies on the
variational quantum circuits (VQC). However, training QRL algorithms with VQCs
requires significant amount of computational resources. This issue hurdles the
exploration of various QRL applications. In this paper, we approach this
challenge through asynchronous training QRL agents. Specifically, we choose the
asynchronous training of advantage actor-critic variational quantum policies.
We demonstrate the results via numerical simulations that within the tasks
considered, the asynchronous training of QRL agents can reach performance
comparable to or superior than classical agents with similar model sizes and
architectures."
Learnable human mesh triangulation for 3D human pose and shape estimation,0.640774,"Compared to joint position, the accuracy of joint rotation and shape
estimation has received relatively little attention in the skinned multi-person
linear model (SMPL)-based human mesh reconstruction from multi-view images. The
work in this field is broadly classified into two categories. The first
approach performs joint estimation and then produces SMPL parameters by fitting
SMPL to resultant joints. The second approach regresses SMPL parameters
directly from the input images through a convolutional neural network
(CNN)-based model. However, these approaches suffer from the lack of
information for resolving the ambiguity of joint rotation and shape
reconstruction and the difficulty of network learning. To solve the
aforementioned problems, we propose a two-stage method. The proposed method
first estimates the coordinates of mesh vertices through a CNN-based model from
input images, and acquires SMPL parameters by fitting the SMPL model to the
estimated vertices. Estimated mesh vertices provide sufficient information for
determining joint rotation and shape, and are easier to learn than SMPL
parameters. According to experiments using Human3.6M and MPI-INF-3DHP datasets,
the proposed method significantly outperforms the previous works in terms of
joint rotation and shape estimation, and achieves competitive performance in
terms of joint location estimation."
FAIR principles for AI models with a practical application for accelerated high energy diffraction microscopy,0.711453,"A concise and measurable set of FAIR (Findable, Accessible, Interoperable and
Reusable) principles for scientific data is transforming the state-of-practice
for data management and stewardship, supporting and enabling discovery and
innovation. Learning from this initiative, and acknowledging the impact of
artificial intelligence (AI) in the practice of science and engineering, we
introduce a set of practical, concise, and measurable FAIR principles for AI
models. We showcase how to create and share FAIR data and AI models within a
unified computational framework combining the following elements: the Advanced
Photon Source at Argonne National Laboratory, the Materials Data Facility, the
Data and Learning Hub for Science, and funcX, and the Argonne Leadership
Computing Facility (ALCF), in particular the ThetaGPU supercomputer and the
SambaNova DataScale system at the ALCF AI Testbed. We describe how this
domain-agnostic computational framework may be harnessed to enable autonomous
AI-driven discovery."
FUN with Fisher: Improving Generalization of Adapter-Based Cross-lingual Transfer with Scheduled Unfreezing,0.333432,"Standard fine-tuning of language models typically performs well on
in-distribution data, but suffers with generalization to distribution shifts.
In this work, we aim to improve the generalization of adapter-based
cross-lingual task transfer where such cross-language distribution shifts are
imminent. We investigate scheduled unfreezing algorithms -- originally proposed
to mitigate catastrophic forgetting in transfer learning -- for fine-tuning
task adapters. Our experiments show that scheduled unfreezing methods close the
gap to full fine-tuning and achieve stronger cross-lingual transfer
performance, suggesting that these methods can go beyond just mitigating
catastrophic forgetting. Next, aiming to understand these empirical findings,
we investigate the learning dynamics of scheduled unfreezing using Fisher
Information. Our experiments reveal that scheduled unfreezing induces different
learning dynamics compared to standard fine-tuning, and provide evidence that
the dynamics of Fisher Information during training correlate with cross-lingual
generalization performance. We additionally propose a general scheduled
unfreezing algorithm that achieves an average of 2 points improvement over four
datasets compared to standard fine-tuning and provides empirical evidence for a
theory-based justification of the heuristic unfreezing schedule for adapter
training."
What can a cook in Italy teach a mechanic in India? Action Recognition Generalisation Over Scenarios and Locations,0.755915,"We propose and address a new generalisation problem: can a model trained for
action recognition successfully classify actions when they are performed within
a previously unseen scenario and in a previously unseen location? To answer
this question, we introduce the Action Recognition Generalisation Over
scenarios and locations dataset (ARGO1M), which contains 1.1M video clips from
the large-scale Ego4D dataset, across 10 scenarios and 13 locations. We
demonstrate recognition models struggle to generalise over 10 proposed test
splits, each of an unseen scenario in an unseen location. We thus propose CIR,
a method to represent each video as a Cross-Instance Reconstruction of videos
from other domains. Reconstructions are paired with text narrations to guide
the learning of a domain generalisable representation. We provide extensive
analysis and ablations on ARGO1M that show CIR outperforms prior domain
generalisation works on all test splits. Code and data:
https://chiaraplizz.github.io/what-can-a-cook/."
Temporal and cross-modal attention for audio-visual zero-shot learning,0.355967,"Audio-visual generalised zero-shot learning for video classification requires
understanding the relations between the audio and visual information in order
to be able to recognise samples from novel, previously unseen classes at test
time. The natural semantic and temporal alignment between audio and visual data
in video data can be exploited to learn powerful representations that
generalise to unseen classes at test time. We propose a multi-modal and
Temporal Cross-attention Framework (\modelName) for audio-visual generalised
zero-shot learning. Its inputs are temporally aligned audio and visual features
that are obtained from pre-trained networks. Encouraging the framework to focus
on cross-modal correspondence across time instead of self-attention within the
modalities boosts the performance significantly. We show that our proposed
framework that ingests temporal features yields state-of-the-art performance on
the \ucf, \vgg, and \activity benchmarks for (generalised) zero-shot learning.
Code for reproducing all results is available at
\url{https://github.com/ExplainableML/TCAF-GZSL}."
Octuplet Loss: Make Face Recognition Robust to Image Resolution,0.536783,"Image resolution, or in general, image quality, plays an essential role in
the performance of today's face recognition systems. To address this problem,
we propose a novel combination of the popular triplet loss to improve
robustness against image resolution via fine-tuning of existing face
recognition models. With octuplet loss, we leverage the relationship between
high-resolution images and their synthetically down-sampled variants jointly
with their identity labels. Fine-tuning several state-of-the-art approaches
with our method proves that we can significantly boost performance for
cross-resolution (high-to-low resolution) face verification on various datasets
without meaningfully exacerbating the performance on high-to-high resolution
images. Our method applied on the FaceTransformer network achieves 95.12% face
verification accuracy on the challenging XQLFW dataset while reaching 99.73% on
the LFW database. Moreover, the low-to-low face verification accuracy benefits
from our method. We release our code to allow seamless integration of the
octuplet loss into existing frameworks."
Probabilistic Adaptation of Text-to-Video Models,0.626257,"Large text-to-video models trained on internet-scale data have demonstrated
exceptional capabilities in generating high-fidelity videos from arbitrary
textual descriptions. However, adapting these models to tasks with limited
domain-specific data, such as animation or robotics videos, poses a significant
computational challenge, since finetuning a pretrained large model can be
prohibitively expensive. Inspired by how a small modifiable component (e.g.,
prompts, prefix-tuning) can adapt a large language model to perform new tasks
without requiring access to the model weights, we investigate how to adapt a
large pretrained text-to-video model to a variety of downstream domains and
tasks without finetuning. In answering this question, we propose Video Adapter,
which leverages the score function of a large pretrained video diffusion model
as a probabilistic prior to guide the generation of a task-specific small video
model. Our experiments show that Video Adapter is capable of incorporating the
broad knowledge and preserving the high fidelity of a large pretrained video
model in a task-specific small video model that is able to generate
high-quality yet specialized videos on a variety of tasks such as animation,
egocentric modeling, and modeling of simulated and real-world robotics data.
More videos can be found on the website https://video-adapter.github.io/."
A Spiking Neural Network based on Neural Manifold for Augmenting Intracortical Brain-Computer Interface Data,0.126923,"Brain-computer interfaces (BCIs), transform neural signals in the brain into
in-structions to control external devices. However, obtaining sufficient
training data is difficult as well as limited. With the advent of advanced
machine learning methods, the capability of brain-computer interfaces has been
enhanced like never before, however, these methods require a large amount of
data for training and thus require data augmentation of the limited data
available. Here, we use spiking neural networks (SNN) as data generators. It is
touted as the next-generation neu-ral network and is considered as one of the
algorithms oriented to general artifi-cial intelligence because it borrows the
neural information processing from bio-logical neurons. We use the SNN to
generate neural spike information that is bio-interpretable and conforms to the
intrinsic patterns in the original neural data. Ex-periments show that the
model can directly synthesize new spike trains, which in turn improves the
generalization ability of the BCI decoder. Both the input and output of the
spiking neural model are spike information, which is a brain-inspired
intelligence approach that can be better integrated with BCI in the future."
Atari-5: Distilling the Arcade Learning Environment down to Five Games,0.791756,"The Arcade Learning Environment (ALE) has become an essential benchmark for
assessing the performance of reinforcement learning algorithms. However, the
computational cost of generating results on the entire 57-game dataset limits
ALE's use and makes the reproducibility of many results infeasible. We propose
a novel solution to this problem in the form of a principled methodology for
selecting small but representative subsets of environments within a benchmark
suite. We applied our method to identify a subset of five ALE games, called
Atari-5, which produces 57-game median score estimates within 10% of their true
values. Extending the subset to 10-games recovers 80% of the variance for
log-scores for all games within the 57-game set. We show this level of
compression is possible due to a high degree of correlation between many of the
games in ALE."
Joint Dense-Point Representation for Contour-Aware Graph Segmentation,0.0767834,"We present a novel methodology that combines graph and dense segmentation
techniques by jointly learning both point and pixel contour representations,
thereby leveraging the benefits of each approach. This addresses deficiencies
in typical graph segmentation methods where misaligned objectives restrict the
network from learning discriminative vertex and contour features. Our joint
learning strategy allows for rich and diverse semantic features to be encoded,
while alleviating common contour stability issues in dense-based approaches,
where pixel-level objectives can lead to anatomically implausible topologies.
In addition, we identify scenarios where correct predictions that fall on the
contour boundary are penalised and address this with a novel hybrid contour
distance loss. Our approach is validated on several Chest X-ray datasets,
demonstrating clear improvements in segmentation stability and accuracy against
a variety of dense- and point-based methods. Our source code is freely
available at: www.github.com/kitbransby/Joint_Graph_Segmentation"
Quantitative AI Risk Assessments: Opportunities and Challenges,0.768873,"Although AI-based systems are increasingly being leveraged to provide value
to organizations, individuals, and society, significant attendant risks have
been identified. These risks have led to proposed regulations, litigation, and
general societal concerns.
  As with any promising technology, organizations want to benefit from the
positive capabilities of AI technology while reducing the risks. The best way
to reduce risks is to implement comprehensive AI lifecycle governance where
policies and procedures are described and enforced during the design,
development, deployment, and monitoring of an AI system. While support for
comprehensive governance is beginning to emerge, organizations often need to
identify the risks of deploying an already-built model without knowledge of how
it was constructed or access to its original developers.
  Such an assessment will quantitatively assess the risks of an existing model
in a manner analogous to how a home inspector might assess the energy
efficiency of an already-built home or a physician might assess overall patient
health based on a battery of tests. This paper explores the concept of a
quantitative AI Risk Assessment, exploring the opportunities, challenges, and
potential impacts of such an approach, and discussing how it might improve AI
regulations."
NFTVis: Visual Analysis of NFT Performance,0.0590804,"A non-fungible token (NFT) is a data unit stored on the blockchain. Nowadays,
more and more investors and collectors (NFT traders), who participate in
transactions of NFTs, have an urgent need to assess the performance of NFTs.
However, there are two challenges for NFT traders when analyzing the
performance of NFT. First, the current rarity models have flaws and are
sometimes not convincing. In addition, NFT performance is dependent on multiple
factors, such as images (high-dimensional data), history transactions
(network), and market evolution (time series). It is difficult to take
comprehensive consideration and analyze NFT performance efficiently. To address
these challenges, we propose NFTVis, a visual analysis system that facilitates
assessing individual NFT performance. A new NFT rarity model is proposed to
quantify NFTs with images. Four well-coordinated views are designed to
represent the various factors affecting the performance of the NFT. Finally, we
evaluate the usefulness and effectiveness of our system using two case studies
and user studies."
Enhancing Low-resolution Face Recognition with Feature Similarity Knowledge Distillation,0.233339,"In this study, we introduce a feature knowledge distillation framework to
improve low-resolution (LR) face recognition performance using knowledge
obtained from high-resolution (HR) images. The proposed framework transfers
informative features from an HR-trained network to an LR-trained network by
reducing the distance between them. A cosine similarity measure was employed as
a distance metric to effectively align the HR and LR features. This approach
differs from conventional knowledge distillation frameworks, which use the L_p
distance metrics and offer the advantage of converging well when reducing the
distance between features of different resolutions. Our framework achieved a 3%
improvement over the previous state-of-the-art method on the AgeDB-30 benchmark
without bells and whistles, while maintaining a strong performance on HR
images. The effectiveness of cosine similarity as a distance metric was
validated through statistical analysis, making our approach a promising
solution for real-world applications in which LR images are frequently
encountered. The code and pretrained models are publicly available on
https://github.com/gist-ailab/feature-similarity-KD."
Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets,0.493145,"Natural language processing models often exploit spurious correlations
between task-independent features and labels in datasets to perform well only
within the distributions they are trained on, while not generalising to
different task distributions. We propose to tackle this problem by generating a
debiased version of a dataset, which can then be used to train a debiased,
off-the-shelf model, by simply replacing its training data. Our approach
consists of 1) a method for training data generators to generate high-quality,
label-consistent data samples; and 2) a filtering mechanism for removing data
points that contribute to spurious correlations, measured in terms of
z-statistics. We generate debiased versions of the SNLI and MNLI datasets, and
we evaluate on a large suite of debiased, out-of-distribution, and adversarial
test sets. Results show that models trained on our debiased datasets generalise
better than those trained on the original datasets in all settings. On the
majority of the datasets, our method outperforms or performs comparably to
previous state-of-the-art debiasing strategies, and when combined with an
orthogonal technique, product-of-experts, it improves further and outperforms
previous best results of SNLI-hard and MNLI-hard."
Speaker adaptation for Wav2vec2 based dysarthric ASR,0.622052,"Dysarthric speech recognition has posed major challenges due to lack of
training data and heavy mismatch in speaker characteristics. Recent ASR systems
have benefited from readily available pretrained models such as wav2vec2 to
improve the recognition performance. Speaker adaptation using fMLLR and
xvectors have provided major gains for dysarthric speech with very little
adaptation data. However, integration of wav2vec2 with fMLLR features or
xvectors during wav2vec2 finetuning is yet to be explored. In this work, we
propose a simple adaptation network for fine-tuning wav2vec2 using fMLLR
features. The adaptation network is also flexible to handle other speaker
adaptive features such as xvectors. Experimental analysis show steady
improvements using our proposed approach across all impairment severity levels
and attains 57.72\% WER for high severity in UASpeech dataset. We also
performed experiments on German dataset to substantiate the consistency of our
proposed approach across diverse domains."
Facial Tic Detection in Untrimmed Videos of Tourette Syndrome Patients,0.0449186,"Tourette Syndrome (TS) is a behavior disorder that onsets in childhood and is
characterized by the expression of involuntary movements and sounds commonly
referred to as tics. Behavioral therapy is the first-line treatment for
patients with TS, and it helps patients raise awareness about tic occurrence as
well as develop tic inhibition strategies. However, the limited availability of
therapists and the difficulties for in-home follow up work limits its
effectiveness. An automatic tic detection system that is easy to deploy could
alleviate the difficulties of home-therapy by providing feedback to the
patients while exercising tic awareness. In this work, we propose a novel
architecture (T-Net) for automatic tic detection and classification from
untrimmed videos. T-Net combines temporal detection and segmentation and
operates on features that are interpretable to a clinician. We compare T-Net to
several state-of-the-art systems working on deep features extracted from the
raw videos and T-Net achieves comparable performance in terms of average
precision while relying on interpretable features needed in clinical practice."
The Theory of Artificial Immutability: Protecting Algorithmic Groups Under Anti-Discrimination Law,0.6479,"Artificial Intelligence (AI) is increasingly used to make important decisions
about people. While issues of AI bias and proxy discrimination are well
explored, less focus has been paid to the harms created by profiling based on
groups that do not map to or correlate with legally protected groups such as
sex or ethnicity. This raises a question: are existing equality laws able to
protect against emergent AI-driven inequality? This article examines the legal
status of algorithmic groups in North American and European non-discrimination
doctrine, law, and jurisprudence and will show that algorithmic groups are not
comparable to traditional protected groups. Nonetheless, these new groups are
worthy of protection. I propose a new theory of harm - ""the theory of
artificial immutability"" - that aims to bring AI groups within the scope of the
law. My theory describes how algorithmic groups act as de facto immutable
characteristics in practice that limit people's autonomy and prevent them from
achieving important goals."
Depth and Representation in Vision Models,0.0252384,"Deep learning models develop successive representations of their input in
sequential layers, the last of which maps the final representation to the
output. Here we investigate the informational content of these representations
by observing the ability of convolutional image classification models to
autoencode the model's input using embeddings existing in various layers. We
find that the deeper the layer, the less accurate that layer's representation
of the input is before training. Inaccurate representation results from
non-uniqueness in which various distinct inputs give approximately the same
embedding. Non-unique representation is a consequence of both exact and
approximate non-invertibility of transformations present in the forward pass.
Learning to classify natural images leads to an increase in representation
clarity for early but not late layers, which instead form abstract images.
Rather than simply selecting for features present in the input necessary for
classification, deep layer representations are found to transform the input so
that it matches representations of the training data such that arbitrary inputs
are mapped to manifolds learned during training. This work provides support for
the theory that the tasks of image recognition and input generation are
inseparable even for models trained exclusively to classify."
Neural Surface Reconstruction of Dynamic Scenes with Monocular RGB-D Camera,0.846612,"We propose Neural-DynamicReconstruction (NDR), a template-free method to
recover high-fidelity geometry and motions of a dynamic scene from a monocular
RGB-D camera. In NDR, we adopt the neural implicit function for surface
representation and rendering such that the captured color and depth can be
fully utilized to jointly optimize the surface and deformations. To represent
and constrain the non-rigid deformations, we propose a novel neural invertible
deforming network such that the cycle consistency between arbitrary two frames
is automatically satisfied. Considering that the surface topology of dynamic
scene might change over time, we employ a topology-aware strategy to construct
the topology-variant correspondence for the fused frames. NDR also further
refines the camera poses in a global optimization manner. Experiments on public
datasets and our collected dataset demonstrate that NDR outperforms existing
monocular dynamic reconstruction methods."
Global Semantic Descriptors for Zero-Shot Action Recognition,0.0751823,"The success of Zero-shot Action Recognition (ZSAR) methods is intrinsically
related to the nature of semantic side information used to transfer knowledge,
although this aspect has not been primarily investigated in the literature.
This work introduces a new ZSAR method based on the relationships of
actions-objects and actions-descriptive sentences. We demonstrate that
representing all object classes using descriptive sentences generates an
accurate object-action affinity estimation when a paraphrase estimation method
is used as an embedder. We also show how to estimate probabilities over the set
of action classes based only on a set of sentences without hard human labeling.
In our method, the probabilities from these two global classifiers (i.e., which
use features computed over the entire video) are combined, producing an
efficient transfer knowledge model for action classification. Our results are
state-of-the-art in the Kinetics-400 dataset and are competitive on UCF-101
under the ZSAR evaluation. Our code is available at
https://github.com/valterlej/objsentzsar"
Financial data analysis application via multi-strategy text processing,0.47965,"Maintaining financial system stability is critical to economic development,
and early identification of risks and opportunities is essential. The financial
industry contains a wide variety of data, such as financial statements,
customer information, stock trading data, news, etc. Massive heterogeneous data
calls for intelligent algorithms for machines to process and understand. This
paper mainly focuses on the stock trading data and news about China A-share
companies. We present a financial data analysis application, Financial Quotient
Porter, designed to combine textual and numerical data by using a
multi-strategy data mining approach. Additionally, we present our efforts and
plans in deep learning financial text processing application scenarios using
natural language processing (NLP) and knowledge graph (KG) technologies. Based
on KG technology, risks and opportunities can be identified from heterogeneous
data. NLP technology can be used to extract entities, relations, and events
from unstructured text, and analyze market sentiment. Experimental results show
market sentiments towards a company and an industry, as well as news-level
associations between companies."
HyPe: Better Pre-trained Language Model Fine-tuning with Hidden Representation Perturbation,0.835253,"Language models with the Transformers structure have shown great performance
in natural language processing. However, there still poses problems when
fine-tuning pre-trained language models on downstream tasks, such as
over-fitting or representation collapse. In this work, we propose HyPe, a
simple yet effective fine-tuning technique to alleviate such problems by
perturbing hidden representations of Transformers layers. Unlike previous works
that only add noise to inputs or parameters, we argue that the hidden
representations of Transformers layers convey more diverse and meaningful
language information. Therefore, making the Transformers layers more robust to
hidden representation perturbations can further benefit the fine-tuning of PLMs
en bloc. We conduct extensive experiments and analyses on GLUE and other
natural language inference datasets. Results demonstrate that HyPe outperforms
vanilla fine-tuning and enhances generalization of hidden representations from
different layers. In addition, HyPe acquires negligible computational
overheads, and is better than and compatible with previous state-of-the-art
fine-tuning techniques."
Unified Fourier-based Kernel and Nonlinearity Design for Equivariant Networks on Homogeneous Spaces,0.57126,"We introduce a unified framework for group equivariant networks on
homogeneous spaces derived from a Fourier perspective. We consider
tensor-valued feature fields, before and after a convolutional layer. We
present a unified derivation of kernels via the Fourier domain by leveraging
the sparsity of Fourier coefficients of the lifted feature fields. The sparsity
emerges when the stabilizer subgroup of the homogeneous space is a compact Lie
group. We further introduce a nonlinear activation, via an elementwise
nonlinearity on the regular representation after lifting and projecting back to
the field through an equivariant convolution. We show that other methods
treating features as the Fourier coefficients in the stabilizer subgroup are
special cases of our activation. Experiments on $SO(3)$ and $SE(3)$ show
state-of-the-art performance in spherical vector field regression, point cloud
classification, and molecular completion."
Evaluating ChatGPT's Performance for Multilingual and Emoji-based Hate Speech Detection,0.735778,"Hate speech is a severe issue that affects many online platforms. So far,
several studies have been performed to develop robust hate speech detection
systems. Large language models like ChatGPT have recently shown a great promise
in performing several tasks, including hate speech detection. However, it is
crucial to comprehend the limitations of these models to build robust hate
speech detection systems. To bridge this gap, our study aims to evaluate the
strengths and weaknesses of the ChatGPT model in detecting hate speech at a
granular level across 11 languages. Our evaluation employs a series of
functionality tests that reveals various intricate failures of the model which
the aggregate metrics like macro F1 or accuracy are not able to unfold. In
addition, we investigate the influence of complex emotions, such as the use of
emojis in hate speech, on the performance of the ChatGPT model. Our analysis
highlights the shortcomings of the generative models in detecting certain types
of hate speech and highlighting the need for further research and improvements
in the workings of these models."
An Architecture for Deploying Reinforcement Learning in Industrial Environments,0.127867,"Industry 4.0 is driven by demands like shorter time-to-market, mass
customization of products, and batch size one production. Reinforcement
Learning (RL), a machine learning paradigm shown to possess a great potential
in improving and surpassing human level performance in numerous complex tasks,
allows coping with the mentioned demands. In this paper, we present an OPC UA
based Operational Technology (OT)-aware RL architecture, which extends the
standard RL setting, combining it with the setting of digital twins. Moreover,
we define an OPC UA information model allowing for a generalized plug-and-play
like approach for exchanging the RL agent used. In conclusion, we demonstrate
and evaluate the architecture, by creating a proof of concept. By means of
solving a toy example, we show that this architecture can be used to determine
the optimal policy using a real control system."
Changing the Representation: Examining Language Representation for Neural Sign Language Production,0.636322,"Neural Sign Language Production (SLP) aims to automatically translate from
spoken language sentences to sign language videos. Historically the SLP task
has been broken into two steps; Firstly, translating from a spoken language
sentence to a gloss sequence and secondly, producing a sign language video
given a sequence of glosses. In this paper we apply Natural Language Processing
techniques to the first step of the SLP pipeline. We use language models such
as BERT and Word2Vec to create better sentence level embeddings, and apply
several tokenization techniques, demonstrating how these improve performance on
the low resource translation task of Text to Gloss. We introduce Text to
HamNoSys (T2H) translation, and show the advantages of using a phonetic
representation for sign language translation rather than a sign level gloss
representation. Furthermore, we use HamNoSys to extract the hand shape of a
sign and use this as additional supervision during training, further increasing
the performance on T2H. Assembling best practise, we achieve a BLEU-4 score of
26.99 on the MineDGS dataset and 25.09 on PHOENIX14T, two new state-of-the-art
baselines."
Hierarchical Point Cloud Encoding and Decoding with Lightweight Self-Attention based Model,0.141317,"In this paper we present SA-CNN, a hierarchical and lightweight
self-attention based encoding and decoding architecture for representation
learning of point cloud data. The proposed SA-CNN introduces convolution and
transposed convolution stacks to capture and generate contextual information
among unordered 3D points. Following conventional hierarchical pipeline, the
encoding process extracts feature in local-to-global manner, while the decoding
process generates feature and point cloud in coarse-to-fine, multi-resolution
stages. We demonstrate that SA-CNN is capable of a wide range of applications,
namely classification, part segmentation, reconstruction, shape retrieval, and
unsupervised classification. While achieving the state-of-the-art or comparable
performance in the benchmarks, SA-CNN maintains its model complexity several
order of magnitude lower than the others. In term of qualitative results, we
visualize the multi-stage point cloud reconstructions and latent walks on rigid
objects as well as deformable non-rigid human and robot models."
CAMS: CAnonicalized Manipulation Spaces for Category-Level Functional Hand-Object Manipulation Synthesis,0.947794,"In this work, we focus on a novel task of category-level functional
hand-object manipulation synthesis covering both rigid and articulated object
categories. Given an object geometry, an initial human hand pose as well as a
sparse control sequence of object poses, our goal is to generate a physically
reasonable hand-object manipulation sequence that performs like human beings.
To address such a challenge, we first design CAnonicalized Manipulation Spaces
(CAMS), a two-level space hierarchy that canonicalizes the hand poses in an
object-centric and contact-centric view. Benefiting from the representation
capability of CAMS, we then present a two-stage framework for synthesizing
human-like manipulation animations. Our framework achieves state-of-the-art
performance for both rigid and articulated categories with impressive visual
effects. Codes and video results can be found at our project homepage:
https://cams-hoi.github.io/"
Incremental Transformer Structure Enhanced Image Inpainting with Masking Positional Encoding,0.932486,"Image inpainting has made significant advances in recent years. However, it
is still challenging to recover corrupted images with both vivid textures and
reasonable structures. Some specific methods only tackle regular textures while
losing holistic structures due to the limited receptive fields of convolutional
neural networks (CNNs). On the other hand, attention-based models can learn
better long-range dependency for the structure recovery, but they are limited
by the heavy computation for inference with large image sizes. To address these
issues, we propose to leverage an additional structure restorer to facilitate
the image inpainting incrementally. The proposed model restores holistic image
structures with a powerful attention-based transformer model in a fixed
low-resolution sketch space. Such a grayscale space is easy to be upsampled to
larger scales to convey correct structural information. Our structure restorer
can be integrated with other pretrained inpainting models efficiently with the
zero-initialized residual addition. Furthermore, a masking positional encoding
strategy is utilized to improve the performance with large irregular masks.
Extensive experiments on various datasets validate the efficacy of our model
compared with other competitors. Our codes are released in
https://github.com/DQiaole/ZITS_inpainting."
Similarity-weighted Construction of Contextualized Commonsense Knowledge Graphs for Knowledge-intense Argumentation Tasks,0.882324,"Arguments often do not make explicit how a conclusion follows from its
premises. To compensate for this lack, we enrich arguments with structured
background knowledge to support knowledge-intense argumentation tasks. We
present a new unsupervised method for constructing Contextualized Commonsense
Knowledge Graphs (CCKGs) that selects contextually relevant knowledge from
large knowledge graphs (KGs) efficiently and at high quality. Our work goes
beyond context-insensitive knowledge extraction heuristics by computing
semantic similarity between KG triplets and textual arguments. Using these
triplet similarities as weights, we extract contextualized knowledge paths that
connect a conclusion to its premise, while maximizing similarity to the
argument. We combine multiple paths into a CCKG that we optionally prune to
reduce noise and raise precision. Intrinsic evaluation of the quality of our
graphs shows that our method is effective for (re)constructing human
explanation graphs. Manual evaluations in a large-scale knowledge selection
setup confirm high recall and precision of implicit CSK in the CCKGs. Finally,
we demonstrate the effectiveness of CCKGs in a knowledge-insensitive argument
quality rating task, outperforming strong baselines and rivaling a GPT-3 based
system."
eCDANs: Efficient Temporal Causal Discovery from Autocorrelated and Non-stationary Data (Student Abstract),0.328659,"Conventional temporal causal discovery (CD) methods suffer from high
dimensionality, fail to identify lagged causal relationships, and often ignore
dynamics in relations. In this study, we present a novel constraint-based CD
approach for autocorrelated and non-stationary time series data (eCDANs)
capable of detecting lagged and contemporaneous causal relationships along with
temporal changes. eCDANs addresses high dimensionality by optimizing the
conditioning sets while conducting conditional independence (CI) tests and
identifies the changes in causal relations by introducing a surrogate variable
to represent time dependency. Experiments on synthetic and real-world data show
that eCDANs can identify time influence and outperform the baselines."
Atmospheric Turbulence Correction via Variational Deep Diffusion,0.612773,"Atmospheric Turbulence (AT) correction is a challenging restoration task as
it consists of two distortions: geometric distortion and spatially variant
blur. Diffusion models have shown impressive accomplishments in photo-realistic
image synthesis and beyond. In this paper, we propose a novel deep conditional
diffusion model under a variational inference framework to solve the AT
correction problem. We use this framework to improve performance by learning
latent prior information from the input and degradation processes. We use the
learned information to further condition the diffusion model. Experiments are
conducted in a comprehensive synthetic AT dataset. We show that the proposed
framework achieves good quantitative and qualitative results."
PromptBoosting: Black-Box Text Classification with Ten Forward Passes,0.715876,"We describe PromptBoosting, a query-efficient procedure for building a text
classifier from a neural language model (LM) without access to the LM's
parameters, gradients, or hidden representations. This form of ""black-box""
classifier training has become increasingly important as the cost of training
and inference in large-scale LMs grows. But existing black-box LM classifier
learning approaches are themselves computationally inefficient, typically
specializing LMs to the target task by searching in a large space of (discrete
or continuous) prompts using zeroth-order optimization methods. Instead of
directly optimizing in prompt space, PromptBoosting obtains a small pool of
prompts via a gradient-free approach and then constructs a large pool of weak
learners by pairing these prompts with different elements of the LM's output
distribution. These weak learners are then ensembled using the AdaBoost
algorithm. The entire learning process requires only a small number of forward
passes and no backward pass. Experiments show that PromptBoosting achieves
state-of-the-art performance in multiple black-box few-shot classification
tasks, and matches or outperforms full fine-tuning in both few-shot and
standard learning paradigms, while training 10x faster than existing black-box
methods."
MarsEclipse at SemEval-2023 Task 3: Multi-Lingual and Multi-Label Framing Detection with Contrastive Learning,0.719917,"This paper describes our system for SemEval-2023 Task 3 Subtask 2 on Framing
Detection. We used a multi-label contrastive loss for fine-tuning large
pre-trained language models in a multi-lingual setting, achieving very
competitive results: our system was ranked first on the official test set and
on the official shared task leaderboard for five of the six languages for which
we had training data and for which we could perform fine-tuning. Here, we
describe our experimental setup, as well as various ablation studies. The code
of our system is available at https://github.com/QishengL/SemEval2023"
IGLU 2022: Interactive Grounded Language Understanding in a Collaborative Environment at NeurIPS 2022,0.697186,"Human intelligence has the remarkable ability to adapt to new tasks and
environments quickly. Starting from a very young age, humans acquire new skills
and learn how to solve new tasks either by imitating the behavior of others or
by following provided natural language instructions. To facilitate research in
this direction, we propose IGLU: Interactive Grounded Language Understanding in
a Collaborative Environment. The primary goal of the competition is to approach
the problem of how to develop interactive embodied agents that learn to solve a
task while provided with grounded natural language instructions in a
collaborative environment. Understanding the complexity of the challenge, we
split it into sub-tasks to make it feasible for participants.
  This research challenge is naturally related, but not limited, to two fields
of study that are highly relevant to the NeurIPS community: Natural Language
Understanding and Generation (NLU/G) and Reinforcement Learning (RL).
Therefore, the suggested challenge can bring two communities together to
approach one of the crucial challenges in AI. Another critical aspect of the
challenge is the dedication to perform a human-in-the-loop evaluation as a
final evaluation for the agents developed by contestants."
ImFace: A Nonlinear 3D Morphable Face Model with Implicit Neural Representations,0.70853,"Precise representations of 3D faces are beneficial to various computer vision
and graphics applications. Due to the data discretization and model linearity,
however, it remains challenging to capture accurate identity and expression
clues in current studies. This paper presents a novel 3D morphable face model,
namely ImFace, to learn a nonlinear and continuous space with implicit neural
representations. It builds two explicitly disentangled deformation fields to
model complex shapes associated with identities and expressions, respectively,
and designs an improved learning strategy to extend embeddings of expressions
to allow more diverse changes. We further introduce a Neural Blend-Field to
learn sophisticated details by adaptively blending a series of local fields. In
addition to ImFace, an effective preprocessing pipeline is proposed to address
the issue of watertight input requirement in implicit representations, enabling
them to work with common facial surfaces for the first time. Extensive
experiments are performed to demonstrate the superiority of ImFace."
Generating Faithful Synthetic Data with Large Language Models: A Case Study in Computational Social Science,0.986305,"Large Language Models (LLMs) have democratized synthetic data generation,
which in turn has the potential to simplify and broaden a wide gamut of NLP
tasks. Here, we tackle a pervasive problem in synthetic data generation: its
generative distribution often differs from the distribution of real-world data
researchers care about (in other words, it is unfaithful). In a case study on
sarcasm detection, we study three strategies to increase the faithfulness of
synthetic data: grounding, filtering, and taxonomy-based generation. We
evaluate these strategies using the performance of classifiers trained with
generated synthetic data on real-world data. While all three strategies improve
the performance of classifiers, we find that grounding works best for the task
at hand. As synthetic data generation plays an ever-increasing role in NLP
research, we expect this work to be a stepping stone in improving its utility.
We conclude this paper with some recommendations on how to generate
high(er)-fidelity synthetic data for specific tasks."
FairStyle: Debiasing StyleGAN2 with Style Channel Manipulations,0.487823,"Recent advances in generative adversarial networks have shown that it is
possible to generate high-resolution and hyperrealistic images. However, the
images produced by GANs are only as fair and representative as the datasets on
which they are trained. In this paper, we propose a method for directly
modifying a pre-trained StyleGAN2 model that can be used to generate a balanced
set of images with respect to one (e.g., eyeglasses) or more attributes (e.g.,
gender and eyeglasses). Our method takes advantage of the style space of the
StyleGAN2 model to perform disentangled control of the target attributes to be
debiased. Our method does not require training additional models and directly
debiases the GAN model, paving the way for its use in various downstream
applications. Our experiments show that our method successfully debiases the
GAN model within a few minutes without compromising the quality of the
generated images. To promote fair generative models, we share the code and
debiased models at http://catlab-team.github.io/fairstyle."
From One to Many: Dynamic Cross Attention Networks for LiDAR and Camera Fusion,0.251838,"LiDAR and cameras are two complementary sensors for 3D perception in
autonomous driving. LiDAR point clouds have accurate spatial and geometry
information, while RGB images provide textural and color data for context
reasoning. To exploit LiDAR and cameras jointly, existing fusion methods tend
to align each 3D point to only one projected image pixel based on calibration,
namely one-to-one mapping. However, the performance of these approaches highly
relies on the calibration quality, which is sensitive to the temporal and
spatial synchronization of sensors. Therefore, we propose a Dynamic Cross
Attention (DCA) module with a novel one-to-many cross-modality mapping that
learns multiple offsets from the initial projection towards the neighborhood
and thus develops tolerance to calibration error. Moreover, a \textit{dynamic
query enhancement} is proposed to perceive the model-independent calibration,
which further strengthens DCA's tolerance to the initial misalignment. The
whole fusion architecture named Dynamic Cross Attention Network (DCAN) exploits
multi-level image features and adapts to multiple representations of point
clouds, which allows DCA to serve as a plug-in fusion module. Extensive
experiments on nuScenes and KITTI prove DCA's effectiveness. The proposed DCAN
outperforms state-of-the-art methods on the nuScenes detection challenge."
Parameter-efficient Modularised Bias Mitigation via AdapterFusion,0.857569,"Large pre-trained language models contain societal biases and carry along
these biases to downstream tasks. Current in-processing bias mitigation
approaches (like adversarial training) impose debiasing by updating a model's
parameters, effectively transferring the model to a new, irreversible debiased
state. In this work, we propose a novel approach to develop stand-alone
debiasing functionalities separate from the model, which can be integrated into
the model on-demand, while keeping the core model untouched. Drawing from the
concept of AdapterFusion in multi-task learning, we introduce DAM (Debiasing
with Adapter Modules) - a debiasing approach to first encapsulate arbitrary
bias mitigation functionalities into separate adapters, and then add them to
the model on-demand in order to deliver fairness qualities. We conduct a large
set of experiments on three classification tasks with gender, race, and age as
protected attributes. Our results show that DAM improves or maintains the
effectiveness of bias mitigation, avoids catastrophic forgetting in a
multi-attribute scenario, and maintains on-par task performance, while granting
parameter-efficiency and easy switching between the original and debiased
models."
Dependency-based Mixture Language Models,0.0631962,"Various models have been proposed to incorporate knowledge of syntactic
structures into neural language models. However, previous works have relied
heavily on elaborate components for a specific language model, usually
recurrent neural network (RNN), which makes themselves unwieldy in practice to
fit into other neural language models, such as Transformer and GPT-2. In this
paper, we introduce the Dependency-based Mixture Language Models. In detail, we
first train neural language models with a novel dependency modeling objective
to learn the probability distribution of future dependent tokens given context.
We then formulate the next-token probability by mixing the previous dependency
modeling probability distributions with self-attention. Extensive experiments
and human evaluations show that our method can be easily and effectively
applied to different neural language models while improving neural text
generation on various tasks."
Compressed Heterogeneous Graph for Abstractive Multi-Document Summarization,0.65134,"Multi-document summarization (MDS) aims to generate a summary for a number of
related documents. We propose HGSUM, an MDS model that extends an
encoder-decoder architecture, to incorporate a heterogeneous graph to represent
different semantic units (e.g., words and sentences) of the documents. This
contrasts with existing MDS models which do not consider different edge types
of graphs and as such do not capture the diversity of relationships in the
documents. To preserve only key information and relationships of the documents
in the heterogeneous graph, HGSUM uses graph pooling to compress the input
graph. And to guide HGSUM to learn compression, we introduce an additional
objective that maximizes the similarity between the compressed graph and the
graph constructed from the ground-truth summary during training. HGSUM is
trained end-to-end with graph similarity and standard cross-entropy objectives.
Experimental results over MULTI-NEWS, WCEP-100, and ARXIV show that HGSUM
outperforms state-of-the-art MDS models. The code for our model and experiments
is available at: https://github.com/oaimli/HGSum."
Battle royale optimizer with a new movement strategy,0.155686,"Gamed-based is a new stochastic metaheuristics optimization category that is
inspired by traditional or digital game genres. Unlike SI-based algorithms,
in-dividuals do not work together with the goal of defeating other individuals
and winning the game. Battle royale optimizer (BRO) is a Gamed-based
me-taheuristic optimization algorithm that has been recently proposed for the
task of continuous problems. This paper proposes a modified BRO (M-BRO) in
order to improve balance between exploration and exploitation. For this matter,
an additional movement operator has been used in the movement strategy.
Moreover, no extra parameters are required for the proposed ap-proach.
Furthermore, the complexity of this modified algorithm is the same as the
original one. Experiments are performed on a set of 19 (unimodal and
multimodal) benchmark functions (CEC 2010). The proposed method has been
compared with the original BRO alongside six well-known/recently proposed
optimization algorithms. The results show that BRO with additional movement
operator performs well to solve complex numerical optimization problems
compared to the original BRO and other competitors."
FECANet: Boosting Few-Shot Semantic Segmentation with Feature-Enhanced Context-Aware Network,0.878276,"Few-shot semantic segmentation is the task of learning to locate each pixel
of the novel class in the query image with only a few annotated support images.
The current correlation-based methods construct pair-wise feature correlations
to establish the many-to-many matching because the typical prototype-based
approaches cannot learn fine-grained correspondence relations. However, the
existing methods still suffer from the noise contained in naive correlations
and the lack of context semantic information in correlations. To alleviate
these problems mentioned above, we propose a Feature-Enhanced Context-Aware
Network (FECANet). Specifically, a feature enhancement module is proposed to
suppress the matching noise caused by inter-class local similarity and enhance
the intra-class relevance in the naive correlation. In addition, we propose a
novel correlation reconstruction module that encodes extra correspondence
relations between foreground and background and multi-scale context semantic
features, significantly boosting the encoder to capture a reliable matching
pattern. Experiments on PASCAL-$5^i$ and COCO-$20^i$ datasets demonstrate that
our proposed FECANet leads to remarkable improvement compared to previous
state-of-the-arts, demonstrating its effectiveness."
Word Order Matters when you Increase Masking,0.523553,"Word order, an essential property of natural languages, is injected in
Transformer-based neural language models using position encoding. However,
recent experiments have shown that explicit position encoding is not always
useful, since some models without such feature managed to achieve state-of-the
art performance on some tasks. To understand better this phenomenon, we examine
the effect of removing position encodings on the pre-training objective itself
(i.e., masked language modelling), to test whether models can reconstruct
position information from co-occurrences alone. We do so by controlling the
amount of masked tokens in the input sentence, as a proxy to affect the
importance of position information for the task. We find that the necessity of
position information increases with the amount of masking, and that masked
language models without position encodings are not able to reconstruct this
information on the task. These findings point towards a direct relationship
between the amount of masking and the ability of Transformers to capture
order-sensitive aspects of language using position encoding."
SVIT: Scaling up Visual Instruction Tuning,0.834127,"Thanks to the emerging of foundation models, the large language and vision
models are integrated to acquire the multimodal ability of visual captioning,
question answering, etc. Although existing multimodal models present impressive
performance of visual understanding and reasoning, their limits are still
largely under-explored due to the scarcity of high-quality instruction tuning
data. To push the limits of multimodal capability, we Scale up Visual
Instruction Tuning (SVIT) by constructing a dataset of 4.2 million visual
instruction tuning data including 1.6M conversation question-answer (QA) pairs,
1.6M complex reasoning QA pairs, 1.0M referring QA pairs and 106K detailed
image descriptions. Besides the volume, the proposed dataset is also featured
by the high quality and rich diversity, which is generated by prompting GPT-4
with the abundant manual annotations of images. We also propose a new data
recipe to select subset with better diversity and balance, which evokes model's
superior capabilities. Extensive experiments verify that SVIT-v1.5, trained on
the proposed dataset, outperforms state-of-the-art Multimodal Large Language
Models on popular benchmarks. The data and code are publicly available at
https://github.com/BAAI-DCAI/Visual-Instruction-Tuning."
DualCam: A Novel Benchmark Dataset for Fine-grained Real-time Traffic Light Detection,0.0624595,"Traffic light detection is essential for self-driving cars to navigate safely
in urban areas. Publicly available traffic light datasets are inadequate for
the development of algorithms for detecting distant traffic lights that provide
important navigation information. We introduce a novel benchmark traffic light
dataset captured using a synchronized pair of narrow-angle and wide-angle
cameras covering urban and semi-urban roads. We provide 1032 images for
training and 813 synchronized image pairs for testing. Additionally, we provide
synchronized video pairs for qualitative analysis. The dataset includes images
of resolution 1920$\times$1080 covering 10 different classes. Furthermore, we
propose a post-processing algorithm for combining outputs from the two cameras.
Results show that our technique can strike a balance between speed and
accuracy, compared to the conventional approach of using a single camera frame."
Transforming Sequence Tagging Into A Seq2Seq Task,0.247697,"Pretrained, large, generative language models (LMs) have had great success in
a wide range of sequence tagging and structured prediction tasks. Casting a
sequence tagging task as a Seq2Seq one requires deciding the formats of the
input and output sequences. However, we lack a principled understanding of the
trade-offs associated with these formats (such as the effect on model accuracy,
sequence length, multilingual generalization, hallucination). In this paper, we
rigorously study different formats one could use for casting input text
sentences and their output labels into the input and target (i.e., output) of a
Seq2Seq model. Along the way, we introduce a new format, which we show to to be
both simpler and more effective. Additionally the new format demonstrates
significant gains in the multilingual settings -- both zero-shot transfer
learning and joint training. Lastly, we find that the new format is more robust
and almost completely devoid of hallucination -- an issue we find common in
existing formats. With well over a 1000 experiments studying 14 different
formats, over 7 diverse public benchmarks -- including 3 multilingual datasets
spanning 7 languages -- we believe our findings provide a strong empirical
basis in understanding how we should tackle sequence tagging tasks."
A Diachronic Perspective on User Trust in AI under Uncertainty,0.534309,"In a human-AI collaboration, users build a mental model of the AI system
based on its reliability and how it presents its decision, e.g. its
presentation of system confidence and an explanation of the output. Modern NLP
systems are often uncalibrated, resulting in confidently incorrect predictions
that undermine user trust. In order to build trustworthy AI, we must understand
how user trust is developed and how it can be regained after potential
trust-eroding events. We study the evolution of user trust in response to these
trust-eroding events using a betting game. We find that even a few incorrect
instances with inaccurate confidence estimates damage user trust and
performance, with very slow recovery. We also show that this degradation in
trust reduces the success of human-AI collaboration and that different types of
miscalibration -- unconfidently correct and confidently incorrect -- have
different negative effects on user trust. Our findings highlight the importance
of calibration in user-facing AI applications and shed light on what aspects
help users decide whether to trust the AI system."
Image-based material analysis of ancient historical documents,0.257449,"Researchers continually perform corroborative tests to classify ancient
historical documents based on the physical materials of their writing surfaces.
However, these tests, often performed on-site, requires actual access to the
manuscript objects. The procedures involve a considerable amount of time and
cost, and can damage the manuscripts. Developing a technique to classify such
documents using only digital images can be very useful and efficient. In order
to tackle this problem, this study uses images of a famous historical
collection, the Dead Sea Scrolls, to propose a novel method to classify the
materials of the manuscripts. The proposed classifier uses the two-dimensional
Fourier Transform to identify patterns within the manuscript surfaces.
Combining a binary classification system employing the transform with a
majority voting process is shown to be effective for this classification task.
This pilot study shows a successful classification percentage of up to 97% for
a confined amount of manuscripts produced from either parchment or papyrus
material. Feature vectors based on Fourier-space grid representation
outperformed a concentric Fourier-space format."
Robust face anti-spoofing framework with Convolutional Vision Transformer,0.85237,"Owing to the advances in image processing technology and large-scale
datasets, companies have implemented facial authentication processes, thereby
stimulating increased focus on face anti-spoofing (FAS) against realistic
presentation attacks. Recently, various attempts have been made to improve face
recognition performance using both global and local learning on face images;
however, to the best of our knowledge, this is the first study to investigate
whether the robustness of FAS against domain shifts is improved by considering
global information and local cues in face images captured using self-attention
and convolutional layers. This study proposes a convolutional vision
transformer-based framework that achieves robust performance for various unseen
domain data. Our model resulted in 7.3%$p$ and 12.9%$p$ increases in FAS
performance compared to models using only a convolutional neural network or
vision transformer, respectively. It also shows the highest average rank in
sub-protocols of cross-dataset setting over the other nine benchmark models for
domain generalization."
Using Multiple Self-Supervised Tasks Improves Model Robustness,0.0885585,"Deep networks achieve state-of-the-art performance on computer vision tasks,
yet they fail under adversarial attacks that are imperceptible to humans. In
this paper, we propose a novel defense that can dynamically adapt the input
using the intrinsic structure from multiple self-supervised tasks. By
simultaneously using many self-supervised tasks, our defense avoids
over-fitting the adapted image to one specific self-supervised task and
restores more intrinsic structure in the image compared to a single
self-supervised task approach. Our approach further improves robustness and
clean accuracy significantly compared to the state-of-the-art single task
self-supervised defense. Our work is the first to connect multiple
self-supervised tasks to robustness, and suggests that we can achieve better
robustness with more intrinsic signal from visual data."
Neural-Hidden-CRF: A Robust Weakly-Supervised Sequence Labeler,0.236994,"We propose a neuralized undirected graphical model called Neural-Hidden-CRF
to solve the weakly-supervised sequence labeling problem. Under the umbrella of
probabilistic undirected graph theory, the proposed Neural-Hidden-CRF embedded
with a hidden CRF layer models the variables of word sequence, latent ground
truth sequence, and weak label sequence with the global perspective that
undirected graphical models particularly enjoy. In Neural-Hidden-CRF, we can
capitalize on the powerful language model BERT or other deep models to provide
rich contextual semantic knowledge to the latent ground truth sequence, and use
the hidden CRF layer to capture the internal label dependencies.
Neural-Hidden-CRF is conceptually simple and empirically powerful. It obtains
new state-of-the-art results on one crowdsourcing benchmark and three
weak-supervision benchmarks, including outperforming the recent advanced model
CHMM by 2.80 F1 points and 2.23 F1 points in average generalization and
inference performance, respectively."
Investigating Reasons for Disagreement in Natural Language Inference,0.526118,"We investigate how disagreement in natural language inference (NLI)
annotation arises. We developed a taxonomy of disagreement sources with 10
categories spanning 3 high-level classes. We found that some disagreements are
due to uncertainty in the sentence meaning, others to annotator biases and task
artifacts, leading to different interpretations of the label distribution. We
explore two modeling approaches for detecting items with potential
disagreement: a 4-way classification with a ""Complicated"" label in addition to
the three standard NLI labels, and a multilabel classification approach. We
found that the multilabel classification is more expressive and gives better
recall of the possible interpretations in the data."
Probabilities of the third type: Statistical Relational Learning and Reasoning with Relative Frequencies,0.042327,"Dependencies on the relative frequency of a state in the domain are common
when modelling probabilistic dependencies on relational data. For instance, the
likelihood of a school closure during an epidemic might depend on the
proportion of infected pupils exceeding a threshold. Often, rather than
depending on discrete thresholds, dependencies are continuous: for instance,
the likelihood of any one mosquito bite transmitting an illness depends on the
proportion of carrier mosquitoes. Current approaches usually only consider
probabilities over possible worlds rather than over domain elements themselves.
An exception are the recently introduced Lifted Bayesian Networks for
Conditional Probability Logic, which express discrete dependencies on
probabilistic data. We introduce functional lifted Bayesian networks, a
formalism that explicitly incorporates continuous dependencies on relative
frequencies into statistical relational artificial intelligence. and compare
and contrast them with ifted Bayesian Networks for Conditional Probability
Logic. Incorporating relative frequencies is not only beneficial to modelling;
it also provides a more rigorous approach to learning problems where training
and test or application domains have different sizes. To this end, we provide a
representation of the asymptotic probability distributions induced by
functional lifted Bayesian networks on domains of increasing sizes. Since that
representation has well-understood scaling behaviour across domain sizes, it
can be used to estimate parameters for a large domain consistently from
randomly sampled subpopulations. Furthermore, we show that in parametric
families of FLBN, convergence is uniform in the parameters, which ensures a
meaningful dependence of the asymptotic probabilities on the parameters of the
model."
Entity Set Co-Expansion in StackOverflow,0.441699,"Given a few seed entities of a certain type (e.g., Software or Programming
Language), entity set expansion aims to discover an extensive set of entities
that share the same type as the seeds. Entity set expansion in software-related
domains such as StackOverflow can benefit many downstream tasks (e.g., software
knowledge graph construction) and facilitate better IT operations and service
management. Meanwhile, existing approaches are less concerned with two
problems: (1) How to deal with multiple types of seed entities simultaneously?
(2) How to leverage the power of pre-trained language models (PLMs)? Being
aware of these two problems, in this paper, we study the entity set
co-expansion task in StackOverflow, which extracts Library, OS, Application,
and Language entities from StackOverflow question-answer threads. During the
co-expansion process, we use PLMs to derive embeddings of candidate entities
for calculating similarities between entities. Experimental results show that
our proposed SECoExpan framework outperforms previous approaches significantly."
Human-Inspired Framework to Accelerate Reinforcement Learning,0.0849902,"Reinforcement learning (RL) is crucial for data science decision-making but
suffers from sample inefficiency, particularly in real-world scenarios with
costly physical interactions. This paper introduces a novel human-inspired
framework to enhance RL algorithm sample efficiency. It achieves this by
initially exposing the learning agent to simpler tasks that progressively
increase in complexity, ultimately leading to the main task. This method
requires no pre-training and involves learning simpler tasks for just one
iteration. The resulting knowledge can facilitate various transfer learning
approaches, such as value and policy transfer, without increasing computational
complexity. It can be applied across different goals, environments, and RL
algorithms, including value-based, policy-based, tabular, and deep RL methods.
Experimental evaluations demonstrate the framework's effectiveness in enhancing
sample efficiency, especially in challenging main tasks, demonstrated through
both a simple Random Walk and more complex optimal control problems with
constraints."
Weakly Supervised Headline Dependency Parsing,0.30715,"English news headlines form a register with unique syntactic properties that
have been documented in linguistics literature since the 1930s. However,
headlines have received surprisingly little attention from the NLP syntactic
parsing community. We aim to bridge this gap by providing the first news
headline corpus of Universal Dependencies annotated syntactic dependency trees,
which enables us to evaluate existing state-of-the-art dependency parsers on
news headlines. To improve English news headline parsing accuracies, we develop
a projection method to bootstrap silver training data from unlabeled news
headline-article lead sentence pairs. Models trained on silver headline parses
demonstrate significant improvements in performance over models trained solely
on gold-annotated long-form texts. Ultimately, we find that, although projected
silver training data improves parser performance across different news outlets,
the improvement is moderated by constructions idiosyncratic to outlet."
BAD-NeRF: Bundle Adjusted Deblur Neural Radiance Fields,0.612397,"Neural Radiance Fields (NeRF) have received considerable attention recently,
due to its impressive capability in photo-realistic 3D reconstruction and novel
view synthesis, given a set of posed camera images. Earlier work usually
assumes the input images are of good quality. However, image degradation (e.g.
image motion blur in low-light conditions) can easily happen in real-world
scenarios, which would further affect the rendering quality of NeRF. In this
paper, we present a novel bundle adjusted deblur Neural Radiance Fields
(BAD-NeRF), which can be robust to severe motion blurred images and inaccurate
camera poses. Our approach models the physical image formation process of a
motion blurred image, and jointly learns the parameters of NeRF and recovers
the camera motion trajectories during exposure time. In experiments, we show
that by directly modeling the real physical image formation process, BAD-NeRF
achieves superior performance over prior works on both synthetic and real
datasets. Code and data are available at https://github.com/WU-CVGL/BAD-NeRF."
DynamicDet: A Unified Dynamic Architecture for Object Detection,0.406882,"Dynamic neural network is an emerging research topic in deep learning. With
adaptive inference, dynamic models can achieve remarkable accuracy and
computational efficiency. However, it is challenging to design a powerful
dynamic detector, because of no suitable dynamic architecture and exiting
criterion for object detection. To tackle these difficulties, we propose a
dynamic framework for object detection, named DynamicDet. Firstly, we carefully
design a dynamic architecture based on the nature of the object detection task.
Then, we propose an adaptive router to analyze the multi-scale information and
to decide the inference route automatically. We also present a novel
optimization strategy with an exiting criterion based on the detection losses
for our dynamic detectors. Last, we present a variable-speed inference
strategy, which helps to realize a wide range of accuracy-speed trade-offs with
only one dynamic detector. Extensive experiments conducted on the COCO
benchmark demonstrate that the proposed DynamicDet achieves new
state-of-the-art accuracy-speed trade-offs. For instance, with comparable
accuracy, the inference speed of our dynamic detector Dy-YOLOv7-W6 surpasses
YOLOv7-E6 by 12%, YOLOv7-D6 by 17%, and YOLOv7-E6E by 39%. The code is
available at https://github.com/VDIGPKU/DynamicDet."
Contrastive Learning of Sentence Embeddings from Scratch,0.436229,"Contrastive learning has been the dominant approach to train state-of-the-art
sentence embeddings. Previous studies have typically learned sentence
embeddings either through the use of human-annotated natural language inference
(NLI) data or via large-scale unlabeled sentences in an unsupervised manner.
However, even in the case of unlabeled data, their acquisition presents
challenges in certain domains due to various reasons. To address these issues,
we present SynCSE, a contrastive learning framework that trains sentence
embeddings with synthesized data. Specifically, we explore utilizing large
language models to synthesize the required data samples for contrastive
learning, including (1) producing positive and negative annotations given
unlabeled sentences (SynCSE-partial), and (2) generating sentences along with
their corresponding annotations from scratch (SynCSE-scratch). Experimental
results on sentence similarity and reranking tasks indicate that both
SynCSE-partial and SynCSE-scratch greatly outperform unsupervised baselines,
and SynCSE-partial even achieves comparable performance to the supervised
models in most settings."
Unpaired Translation from Semantic Label Maps to Images by Leveraging Domain-Specific Simulations,0.0903188,"Photorealistic image generation from simulated label maps are necessitated in
several contexts, such as for medical training in virtual reality. With
conventional deep learning methods, this task requires images that are paired
with semantic annotations, which typically are unavailable. We introduce a
contrastive learning framework for generating photorealistic images from
simulated label maps, by learning from unpaired sets of both. Due to
potentially large scene differences between real images and label maps,
existing unpaired image translation methods lead to artifacts of scene
modification in synthesized images. We utilize simulated images as surrogate
targets for a contrastive loss, while ensuring consistency by utilizing
features from a reverse translation network. Our method enables bidirectional
label-image translations, which is demonstrated in a variety of scenarios and
datasets, including laparoscopy, ultrasound, and driving scenes. By comparing
with state-of-the-art unpaired translation methods, our proposed method is
shown to generate realistic and scene-accurate translations."
Understanding Adverse Biological Effect Predictions Using Knowledge Graphs,0.187366,"Extrapolation of adverse biological (toxic) effects of chemicals is an
important contribution to expand available hazard data in (eco)toxicology
without the use of animals in laboratory experiments. In this work, we
extrapolate effects based on a knowledge graph (KG) consisting of the most
relevant effect data as domain-specific background knowledge. An effect
prediction model, with and without background knowledge, was used to predict
mean adverse biological effect concentration of chemicals as a prototypical
type of stressors. The background knowledge improves the model prediction
performance by up to 40\% in terms of $R^2$ (\ie coefficient of determination).
We use the KG and KG embeddings to provide quantitative and qualitative
insights into the predictions. These insights are expected to improve the
confidence in effect prediction. Larger scale implementation of such
extrapolation models should be expected to support hazard and risk assessment,
by simplifying and reducing testing needs."
Break It Down: Evidence for Structural Compositionality in Neural Networks,0.718099,"Though modern neural networks have achieved impressive performance in both
vision and language tasks, we know little about the functions that they
implement. One possibility is that neural networks implicitly break down
complex tasks into subroutines, implement modular solutions to these
subroutines, and compose them into an overall solution to a task - a property
we term structural compositionality. Another possibility is that they may
simply learn to match new inputs to learned templates, eliding task
decomposition entirely. Here, we leverage model pruning techniques to
investigate this question in both vision and language across a variety of
architectures, tasks, and pretraining regimens. Our results demonstrate that
models often implement solutions to subroutines via modular subnetworks, which
can be ablated while maintaining the functionality of other subnetworks. This
suggests that neural networks may be able to learn compositionality, obviating
the need for specialized symbolic mechanisms."
Cross-lingual Inference with A Chinese Entailment Graph,0.103101,"Predicate entailment detection is a crucial task for question-answering from
text, where previous work has explored unsupervised learning of entailment
graphs from typed open relation triples. In this paper, we present the first
pipeline for building Chinese entailment graphs, which involves a novel
high-recall open relation extraction (ORE) method and the first Chinese
fine-grained entity typing dataset under the FIGER type ontology. Through
experiments on the Levy-Holt dataset, we verify the strength of our Chinese
entailment graph, and reveal the cross-lingual complementarity: on the parallel
Levy-Holt dataset, an ensemble of Chinese and English entailment graphs
outperforms both monolingual graphs, and raises unsupervised SOTA by 4.7 AUC
points."
Deep Learning Hyperparameter Optimization for Breast Mass Detection in Mammograms,0.0996438,"Accurate breast cancer diagnosis through mammography has the potential to
save millions of lives around the world. Deep learning (DL) methods have shown
to be very effective for mass detection in mammograms. Additional improvements
of current DL models will further improve the effectiveness of these methods. A
critical issue in this context is how to pick the right hyperparameters for DL
models. In this paper, we present GA-E2E, a new approach for tuning the
hyperparameters of DL models for brest cancer detection using Genetic
Algorithms (GAs). Our findings reveal that differences in parameter values can
considerably alter the area under the curve (AUC), which is used to determine a
classifier's performance."
FANToM: A Benchmark for Stress-testing Machine Theory of Mind in Interactions,0.999985,"Theory of mind (ToM) evaluations currently focus on testing models using
passive narratives that inherently lack interactivity. We introduce FANToM, a
new benchmark designed to stress-test ToM within information-asymmetric
conversational contexts via question answering. Our benchmark draws upon
important theoretical requisites from psychology and necessary empirical
considerations when evaluating large language models (LLMs). In particular, we
formulate multiple types of questions that demand the same underlying reasoning
to identify illusory or false sense of ToM capabilities in LLMs. We show that
FANToM is challenging for state-of-the-art LLMs, which perform significantly
worse than humans even with chain-of-thought reasoning or fine-tuning."
Generate rather than Retrieve: Large Language Models are Strong Context Generators,0.815401,"Knowledge-intensive tasks, such as open-domain question answering (QA),
require access to a large amount of world or domain knowledge. A common
approach for knowledge-intensive tasks is to employ a retrieve-then-read
pipeline that first retrieves a handful of relevant contextual documents from
an external corpus such as Wikipedia and then predicts an answer conditioned on
the retrieved documents. In this paper, we present a novel perspective for
solving knowledge-intensive tasks by replacing document retrievers with large
language model generators. We call our method generate-then-read (GenRead),
which first prompts a large language model to generate contextutal documents
based on a given question, and then reads the generated documents to produce
the final answer. Furthermore, we propose a novel clustering-based prompting
method that selects distinct prompts, resulting in the generated documents that
cover different perspectives, leading to better recall over acceptable answers.
We conduct extensive experiments on three different knowledge-intensive tasks,
including open-domain QA, fact checking, and dialogue system. Notably, GenRead
achieves 71.6 and 54.4 exact match scores on TriviaQA and WebQ, significantly
outperforming the state-of-the-art retrieve-then-read pipeline DPR-FiD by +4.0
and +3.9, without retrieving any documents from any external knowledge source.
Lastly, we demonstrate the model performance can be further improved by
combining retrieval and generation. Our code and generated documents can be
found at https://github.com/wyu97/GenRead."
HyperPrompt: Prompt-based Task-Conditioning of Transformers,0.835895,"Prompt-Tuning is a new paradigm for finetuning pre-trained language models in
a parameter-efficient way. Here, we explore the use of HyperNetworks to
generate hyper-prompts: we propose HyperPrompt, a novel architecture for
prompt-based task-conditioning of self-attention in Transformers. The
hyper-prompts are end-to-end learnable via generation by a HyperNetwork.
HyperPrompt allows the network to learn task-specific feature maps where the
hyper-prompts serve as task global memories for the queries to attend to, at
the same time enabling flexible information sharing among tasks. We show that
HyperPrompt is competitive against strong multi-task learning baselines with as
few as $0.14\%$ of additional task-conditioning parameters, achieving great
parameter and computational efficiency. Through extensive empirical
experiments, we demonstrate that HyperPrompt can achieve superior performances
over strong T5 multi-task learning baselines and parameter-efficient adapter
variants including Prompt-Tuning and HyperFormer++ on Natural Language
Understanding benchmarks of GLUE and SuperGLUE across many model sizes."
GAM : Gradient Attention Module of Optimization for Point Clouds Analysis,0.646464,"In point cloud analysis tasks, the existing local feature aggregation
descriptors (LFAD) are unable to fully utilize information in the neighborhood
of central points. Previous methods rely solely on Euclidean distance to
constrain the local aggregation process, which can be easily affected by
abnormal points and cannot adequately fit with the original geometry of the
point cloud. We believe that fine-grained geometric information (FGGI) is
significant for the aggregation of local features. Therefore, we propose a
gradient-based local attention module, termed as Gradient Attention Module
(GAM), to address the aforementioned problem. Our proposed GAM simplifies the
process that extracts gradient information in the neighborhood and uses the
Zenith Angle matrix and Azimuth Angle matrix as explicit representation, which
accelerates the module by 35X. Comprehensive experiments were conducted on five
benchmark datasets to demonstrate the effectiveness and generalization
capability of the proposed GAM for 3D point cloud analysis. Especially on S3DIS
dataset, GAM achieves the best performance among current point-based models
with mIoU/OA/mAcc of 74.4%/90.6%/83.2%, respectively."
A Self-Paced Mixed Distillation Method for Non-Autoregressive Generation,0.0437336,"Non-Autoregressive generation is a sequence generation paradigm, which
removes the dependency between target tokens. It could efficiently reduce the
text generation latency with parallel decoding in place of token-by-token
sequential decoding. However, due to the known multi-modality problem,
Non-Autoregressive (NAR) models significantly under-perform Auto-regressive
(AR) models on various language generation tasks. Among the NAR models, BANG is
the first large-scale pre-training model on English un-labeled raw text corpus.
It considers different generation paradigms as its pre-training tasks including
Auto-regressive (AR), Non-Autoregressive (NAR), and semi-Non-Autoregressive
(semi-NAR) information flow with multi-stream strategy. It achieves
state-of-the-art performance without any distillation techniques. However, AR
distillation has been shown to be a very effective solution for improving NAR
performance. In this paper, we propose a novel self-paced mixed distillation
method to further improve the generation quality of BANG. Firstly, we propose
the mixed distillation strategy based on the AR stream knowledge. Secondly, we
encourage the model to focus on the samples with the same modality by
self-paced learning. The proposed self-paced mixed distillation algorithm
improves the generation quality and has no influence on the inference latency.
We carry out extensive experiments on summarization and question generation
tasks to validate the effectiveness. To further illustrate the commercial value
of our approach, we conduct experiments on three generation tasks in real-world
advertisements applications. Experimental results on commercial data show the
effectiveness of the proposed model. Compared with BANG, it achieves
significant BLEU score improvement. On the other hand, compared with
auto-regressive generation method, it achieves more than 7x speedup."
Fine-grained Semantic Alignment Network for Weakly Supervised Temporal Language Grounding,0.573411,"Temporal language grounding (TLG) aims to localize a video segment in an
untrimmed video based on a natural language description. To alleviate the
expensive cost of manual annotations for temporal boundary labels, we are
dedicated to the weakly supervised setting, where only video-level descriptions
are provided for training. Most of the existing weakly supervised methods
generate a candidate segment set and learn cross-modal alignment through a
MIL-based framework. However, the temporal structure of the video as well as
the complicated semantics in the sentence are lost during the learning. In this
work, we propose a novel candidate-free framework: Fine-grained Semantic
Alignment Network (FSAN), for weakly supervised TLG. Instead of view the
sentence and candidate moments as a whole, FSAN learns token-by-clip
cross-modal semantic alignment by an iterative cross-modal interaction module,
generates a fine-grained cross-modal semantic alignment map, and performs
grounding directly on top of the map. Extensive experiments are conducted on
two widely-used benchmarks: ActivityNet-Captions, and DiDeMo, where our FSAN
achieves state-of-the-art performance."
Facial Action Unit Recognition Based on Transfer Learning,0.480554,"Facial action unit recognition is an important task for facial analysis.
Owing to the complex collection environment, facial action unit recognition in
the wild is still challenging. The 3rd competition on affective behavior
analysis in-the-wild (ABAW) has provided large amount of facial images with
facial action unit annotations. In this paper, we introduce a facial action
unit recognition method based on transfer learning. We first use available
facial images with expression labels to train the feature extraction network.
Then we fine-tune the network for facial action unit recognition."
Asynchronous Distributed Bilevel Optimization,0.503241,"Bilevel optimization plays an essential role in many machine learning tasks,
ranging from hyperparameter optimization to meta-learning. Existing studies on
bilevel optimization, however, focus on either centralized or synchronous
distributed setting. The centralized bilevel optimization approaches require
collecting massive amount of data to a single server, which inevitably incur
significant communication expenses and may give rise to data privacy risks.
Synchronous distributed bilevel optimization algorithms, on the other hand,
often face the straggler problem and will immediately stop working if a few
workers fail to respond. As a remedy, we propose Asynchronous Distributed
Bilevel Optimization (ADBO) algorithm. The proposed ADBO can tackle bilevel
optimization problems with both nonconvex upper-level and lower-level objective
functions, and its convergence is theoretically guaranteed. Furthermore, it is
revealed through theoretic analysis that the iteration complexity of ADBO to
obtain the $\epsilon$-stationary point is upper bounded by
$\mathcal{O}(\frac{1}{{{\epsilon ^2}}})$. Thorough empirical studies on public
datasets have been conducted to elucidate the effectiveness and efficiency of
the proposed ADBO."
Don't Lose Yourself! Empathetic Response Generation via Explicit Self-Other Awareness,0.837473,"As a critical step to achieve human-like chatbots, empathetic response
generation has attained increasing interests. Previous attempts are incomplete
and not sufficient enough to elicit empathy because they only focus on the
initial aspect of empathy to automatically mimic the feelings and thoughts of
the user via other-awareness. However, they ignore to maintain and take the own
views of the system into account, which is a crucial process to achieve the
empathy called self-other awareness. To this end, we propose to generate
Empathetic response with explicit Self-Other Awareness (EmpSOA). Specifically,
three stages, self-other differentiation, self-other modulation and self-other
generation, are devised to clearly maintain, regulate and inject the self-other
aware information into the process of empathetic response generation. Both
automatic and human evaluations on the benchmark dataset demonstrate the
superiority of EmpSOA to generate more empathetic responses."
Defects of Convolutional Decoder Networks in Frequency Representation,0.712266,"In this paper, we prove the representation defects of a cascaded
convolutional decoder network, considering the capacity of representing
different frequency components of an input sample. We conduct the discrete
Fourier transform on each channel of the feature map in an intermediate layer
of the decoder network. Then, we extend the 2D circular convolution theorem to
represent the forward and backward propagations through convolutional layers in
the frequency domain. Based on this, we prove three defects in representing
feature spectrums. First, we prove that the convolution operation, the
zero-padding operation, and a set of other settings all make a convolutional
decoder network more likely to weaken high-frequency components. Second, we
prove that the upsampling operation generates a feature spectrum, in which
strong signals repetitively appear at certain frequencies. Third, we prove that
if the frequency components in the input sample and frequency components in the
target output for regression have a small shift, then the decoder usually
cannot be effectively learned."
Multiagent Inverse Reinforcement Learning via Theory of Mind Reasoning,0.687686,"We approach the problem of understanding how people interact with each other
in collaborative settings, especially when individuals know little about their
teammates, via Multiagent Inverse Reinforcement Learning (MIRL), where the goal
is to infer the reward functions guiding the behavior of each individual given
trajectories of a team's behavior during some task. Unlike current MIRL
approaches, we do not assume that team members know each other's goals a
priori; rather, that they collaborate by adapting to the goals of others
perceived by observing their behavior, all while jointly performing a task. To
address this problem, we propose a novel approach to MIRL via Theory of Mind
(MIRL-ToM). For each agent, we first use ToM reasoning to estimate a posterior
distribution over baseline reward profiles given their demonstrated behavior.
We then perform MIRL via decentralized equilibrium by employing single-agent
Maximum Entropy IRL to infer a reward function for each agent, where we
simulate the behavior of other teammates according to the time-varying
distribution over profiles. We evaluate our approach in a simulated 2-player
search-and-rescue operation where the goal of the agents, playing different
roles, is to search for and evacuate victims in the environment. Our results
show that the choice of baseline profiles is paramount to the recovery of the
ground-truth rewards, and that MIRL-ToM is able to recover the rewards used by
agents interacting both with known and unknown teammates."
Considerations for meaningful sign language machine translation based on glosses,0.678136,"Automatic sign language processing is gaining popularity in Natural Language
Processing (NLP) research (Yin et al., 2021). In machine translation (MT) in
particular, sign language translation based on glosses is a prominent approach.
In this paper, we review recent works on neural gloss translation. We find that
limitations of glosses in general and limitations of specific datasets are not
discussed in a transparent manner and that there is no common standard for
evaluation.
  To address these issues, we put forward concrete recommendations for future
research on gloss translation. Our suggestions advocate awareness of the
inherent limitations of gloss-based approaches, realistic datasets, stronger
baselines and convincing evaluation."
Multilingual Multimodal Learning with Machine Translated Text,0.269376,"Most vision-and-language pretraining research focuses on English tasks.
However, the creation of multilingual multimodal evaluation datasets (e.g.
Multi30K, xGQA, XVNLI, and MaRVL) poses a new challenge in finding high-quality
training data that is both multilingual and multimodal. In this paper, we
investigate whether machine translating English multimodal data can be an
effective proxy for the lack of readily available multilingual data. We call
this framework TD-MML: Translated Data for Multilingual Multimodal Learning,
and it can be applied to any multimodal dataset and model. We apply it to both
pretraining and fine-tuning data with a state-of-the-art model. In order to
prevent models from learning from low-quality translated text, we propose two
metrics for automatically removing such translations from the resulting
datasets. In experiments on five tasks across 20 languages in the IGLUE
benchmark, we show that translated data can provide a useful signal for
multilingual multimodal learning, both at pretraining and fine-tuning."
On the detection of morphing attacks generated by GANs,0.315371,"Recent works have demonstrated the feasibility of GAN-based morphing attacks
that reach similar success rates as more traditional landmark-based methods.
This new type of ""deep"" morphs might require the development of new adequate
detectors to protect face recognition systems. We explore simple deep morph
detection baselines based on spectral features and LBP histograms features, as
well as on CNN models, both in the intra-dataset and cross-dataset case. We
observe that simple LBP-based systems are already quite accurate in the
intra-dataset setting, but struggle with generalization, a phenomenon that is
partially mitigated by fusing together several of those systems at score-level.
We conclude that a pretrained ResNet effective for GAN image detection is the
most effective overall, reaching close to perfect accuracy. We note however
that LBP-based systems maintain a level of interest : additionally to their
lower computational requirements and increased interpretability with respect to
CNNs, LBP+ResNet fusions sometimes also showcase increased performance versus
ResNet-only, hinting that LBP-based systems can focus on meaningful signal that
is not necessarily picked up by the CNN detector."
T2I-CompBench: A Comprehensive Benchmark for Open-world Compositional Text-to-image Generation,0.90464,"Despite the stunning ability to generate high-quality images by recent
text-to-image models, current approaches often struggle to effectively compose
objects with different attributes and relationships into a complex and coherent
scene. We propose T2I-CompBench, a comprehensive benchmark for open-world
compositional text-to-image generation, consisting of 6,000 compositional text
prompts from 3 categories (attribute binding, object relationships, and complex
compositions) and 6 sub-categories (color binding, shape binding, texture
binding, spatial relationships, non-spatial relationships, and complex
compositions). We further propose several evaluation metrics specifically
designed to evaluate compositional text-to-image generation and explore the
potential and limitations of multimodal LLMs for evaluation. We introduce a new
approach, Generative mOdel fine-tuning with Reward-driven Sample selection
(GORS), to boost the compositional text-to-image generation abilities of
pretrained text-to-image models. Extensive experiments and evaluations are
conducted to benchmark previous methods on T2I-CompBench, and to validate the
effectiveness of our proposed evaluation metrics and GORS approach. Project
page is available at https://karine-h.github.io/T2I-CompBench/."
Parameter-Efficient Fine-Tuning of LLaMA for the Clinical Domain,0.826762,"Adapting pretrained language models to novel domains, such as clinical
applications, traditionally involves retraining their entire set of parameters.
Parameter-Efficient Fine-Tuning (PEFT) techniques for fine-tuning language
models significantly reduce computational requirements by selectively
fine-tuning small subsets of parameters. In this study, we propose a two-step
PEFT framework and evaluate it in the clinical domain. Our approach combines a
specialised PEFT adapter layer designed for clinical domain adaptation with
another adapter specialised for downstream tasks. We evaluate the framework on
multiple clinical outcome prediction datasets, comparing it to clinically
trained language models. Our framework achieves a better AUROC score averaged
across all clinical downstream tasks compared to clinical language models. In
particular, we observe large improvements of 4-5% AUROC in large-scale
multilabel classification tasks, such as diagnoses and procedures
classification. To our knowledge, this study is the first to provide an
extensive empirical analysis of the interplay between PEFT techniques and
domain adaptation in an important real-world domain of clinical applications."
Efficient Off-Policy Reinforcement Learning via Brain-Inspired Computing,0.184333,"Reinforcement Learning (RL) has opened up new opportunities to enhance
existing smart systems that generally include a complex decision-making
process. However, modern RL algorithms, e.g., Deep Q-Networks (DQN), are based
on deep neural networks, resulting in high computational costs. In this paper,
we propose QHD, an off-policy value-based Hyperdimensional Reinforcement
Learning, that mimics brain properties toward robust and real-time learning.
QHD relies on a lightweight brain-inspired model to learn an optimal policy in
an unknown environment. On both desktop and power-limited embedded platforms,
QHD achieves significantly better overall efficiency than DQN while providing
higher or comparable rewards. QHD is also suitable for highly-efficient
reinforcement learning with great potential for online and real-time learning.
Our solution supports a small experience replay batch size that provides 12.3
times speedup compared to DQN while ensuring minimal quality loss. Our
evaluation shows QHD capability for real-time learning, providing 34.6 times
speedup and significantly better quality of learning than DQN."
Learning Structure-Guided Diffusion Model for 2D Human Pose Estimation,0.797734,"One of the mainstream schemes for 2D human pose estimation (HPE) is learning
keypoints heatmaps by a neural network. Existing methods typically improve the
quality of heatmaps by customized architectures, such as high-resolution
representation and vision Transformers. In this paper, we propose
\textbf{DiffusionPose}, a new scheme that formulates 2D HPE as a keypoints
heatmaps generation problem from noised heatmaps. During training, the
keypoints are diffused to random distribution by adding noises and the
diffusion model learns to recover ground-truth heatmaps from noised heatmaps
with respect to conditions constructed by image feature. During inference, the
diffusion model generates heatmaps from initialized heatmaps in a progressive
denoising way. Moreover, we further explore improving the performance of
DiffusionPose with conditions from human structural information. Extensive
experiments show the prowess of our DiffusionPose, with improvements of 1.6,
1.2, and 1.2 mAP on widely-used COCO, CrowdPose, and AI Challenge datasets,
respectively."
Unseen Object Instance Segmentation with Fully Test-time RGB-D Embeddings Adaptation,0.367886,"Segmenting unseen objects is a crucial ability for the robot since it may
encounter new environments during the operation. Recently, a popular solution
is leveraging RGB-D features of large-scale synthetic data and directly
applying the model to unseen real-world scenarios. However, the domain shift
caused by the sim2real gap is inevitable, posing a crucial challenge to the
segmentation model. In this paper, we emphasize the adaptation process across
sim2real domains and model it as a learning problem on the BatchNorm parameters
of a simulation-trained model. Specifically, we propose a novel non-parametric
entropy objective, which formulates the learning objective for the test-time
adaptation in an open-world manner. Then, a cross-modality knowledge
distillation objective is further designed to encourage the test-time knowledge
transfer for feature enhancement. Our approach can be efficiently implemented
with only test images, without requiring annotations or revisiting the
large-scale synthetic training data. Besides significant time savings, the
proposed method consistently improves segmentation results on the overlap and
boundary metrics, achieving state-of-the-art performance on unseen object
instance segmentation."
Exploiting Social Media Content for Self-Supervised Style Transfer,0.270401,"Recent research on style transfer takes inspiration from unsupervised neural
machine translation (UNMT), learning from large amounts of non-parallel data by
exploiting cycle consistency loss, back-translation, and denoising
autoencoders. By contrast, the use of self-supervised NMT (SSNMT), which
leverages (near) parallel instances hidden in non-parallel data more
efficiently than UNMT, has not yet been explored for style transfer. In this
paper we present a novel Self-Supervised Style Transfer (3ST) model, which
augments SSNMT with UNMT methods in order to identify and efficiently exploit
supervisory signals in non-parallel social media posts. We compare 3ST with
state-of-the-art (SOTA) style transfer models across civil rephrasing,
formality and polarity tasks. We show that 3ST is able to balance the three
major objectives (fluency, content preservation, attribute transfer accuracy)
the best, outperforming SOTA models on averaged performance across their tested
tasks in automatic and human evaluation."
A Unified Framework for Attention-Based Few-Shot Object Detection,0.0906256,"Few-Shot Object Detection (FSOD) is a rapidly growing field in computer
vision. It consists in finding all occurrences of a given set of classes with
only a few annotated examples for each class. Numerous methods have been
proposed to address this challenge and most of them are based on attention
mechanisms. However, the great variety of classic object detection frameworks
and training strategies makes performance comparison between methods difficult.
In particular, for attention-based FSOD methods, it is laborious to compare the
impact of the different attention mechanisms on performance. This paper aims at
filling this shortcoming. To do so, a flexible framework is proposed to allow
the implementation of most of the attention techniques available in the
literature. To properly introduce such a framework, a detailed review of the
existing FSOD methods is firstly provided. Some different attention mechanisms
are then reimplemented within the framework and compared with all other
parameters fixed."
A Tutorial on Adversarial Learning Attacks and Countermeasures,0.47297,"Machine learning algorithms are used to construct a mathematical model for a
system based on training data. Such a model is capable of making highly
accurate predictions without being explicitly programmed to do so. These
techniques have a great many applications in all areas of the modern digital
economy and artificial intelligence. More importantly, these methods are
essential for a rapidly increasing number of safety-critical applications such
as autonomous vehicles and intelligent defense systems. However, emerging
adversarial learning attacks pose a serious security threat that greatly
undermines further such systems. The latter are classified into four types,
evasion (manipulating data to avoid detection), poisoning (injection malicious
training samples to disrupt retraining), model stealing (extraction), and
inference (leveraging over-generalization on training data). Understanding this
type of attacks is a crucial first step for the development of effective
countermeasures. The paper provides a detailed tutorial on the principles of
adversarial machining learning, explains the different attack scenarios, and
gives an in-depth insight into the state-of-art defense mechanisms against this
rising threat ."
RICO: Regularizing the Unobservable for Indoor Compositional Reconstruction,0.676627,"Recently, neural implicit surfaces have become popular for multi-view
reconstruction. To facilitate practical applications like scene editing and
manipulation, some works extend the framework with semantic masks input for the
object-compositional reconstruction rather than the holistic perspective.
Though achieving plausible disentanglement, the performance drops significantly
when processing the indoor scenes where objects are usually partially observed.
We propose RICO to address this by regularizing the unobservable regions for
indoor compositional reconstruction. Our key idea is to first regularize the
smoothness of the occluded background, which then in turn guides the foreground
object reconstruction in unobservable regions based on the object-background
relationship. Particularly, we regularize the geometry smoothness of occluded
background patches. With the improved background surface, the signed distance
function and the reversedly rendered depth of objects can be optimized to bound
them within the background range. Extensive experiments show our method
outperforms other methods on synthetic and real-world indoor scenes and prove
the effectiveness of proposed regularizations. The code is available at
https://github.com/kyleleey/RICO."
FactMix: Using a Few Labeled In-domain Examples to Generalize to Cross-domain Named Entity Recognition,0.696472,"Few-shot Named Entity Recognition (NER) is imperative for entity tagging in
limited resource domains and thus received proper attention in recent years.
Existing approaches for few-shot NER are evaluated mainly under in-domain
settings. In contrast, little is known about how these inherently faithful
models perform in cross-domain NER using a few labeled in-domain examples. This
paper proposes a two-step rationale-centric data augmentation method to improve
the model's generalization ability. Results on several datasets show that our
model-agnostic method significantly improves the performance of cross-domain
NER tasks compared to previous state-of-the-art methods, including the data
augmentation and prompt-tuning methods. Our codes are available at
https://github.com/lifan-yuan/FactMix."
Towards a Deep Multi-layered Dialectal Language Analysis: A Case Study of African-American English,0.0823328,"Currently, natural language processing (NLP) models proliferate language
discrimination leading to potentially harmful societal impacts as a result of
biased outcomes. For example, part-of-speech taggers trained on Mainstream
American English (MAE) produce non-interpretable results when applied to
African American English (AAE) as a result of language features not seen during
training. In this work, we incorporate a human-in-the-loop paradigm to gain a
better understanding of AAE speakers' behavior and their language use, and
highlight the need for dialectal language inclusivity so that native AAE
speakers can extensively interact with NLP systems while reducing feelings of
disenfranchisement."
"Interventions, Where and How? Experimental Design for Causal Models at Scale",0.738378,"Causal discovery from observational and interventional data is challenging
due to limited data and non-identifiability: factors that introduce uncertainty
in estimating the underlying structural causal model (SCM). Selecting
experiments (interventions) based on the uncertainty arising from both factors
can expedite the identification of the SCM. Existing methods in experimental
design for causal discovery from limited data either rely on linear assumptions
for the SCM or select only the intervention target. This work incorporates
recent advances in Bayesian causal discovery into the Bayesian optimal
experimental design framework, allowing for active causal discovery of large,
nonlinear SCMs while selecting both the interventional target and the value. We
demonstrate the performance of the proposed method on synthetic graphs
(Erdos-R\`enyi, Scale Free) for both linear and nonlinear SCMs as well as on
the \emph{in-silico} single-cell gene regulatory network dataset, DREAM."
Ontology Revision based on Pre-trained Language Models,0.42607,"Ontology revision aims to seamlessly incorporate a new ontology into an
existing ontology and plays a crucial role in tasks such as ontology evolution,
ontology maintenance, and ontology alignment. Similar to repair single
ontologies, resolving logical incoherence in the task of ontology revision is
also important and meaningful, because incoherence is a main potential factor
to cause inconsistency and reasoning with an inconsistent ontology will obtain
meaningless answers.To deal with this problem, various ontology revision
approaches have been proposed to define revision operators and design ranking
strategies for axioms in an ontology. However, they rarely consider axiom
semantics which provides important information to differentiate axioms. In
addition, pre-trained models can be utilized to encode axiom semantics, and
have been widely applied in many natural language processing tasks and
ontology-related ones in recent years.Therefore, in this paper, we study how to
apply pre-trained models to revise ontologies. We first define four scoring
functions to rank axioms based on a pre-trained model by considering various
information from an ontology. Based on the functions, an ontology revision
algorithm is then proposed to deal with unsatisfiable concepts at once. To
improve efficiency, an adapted revision algorithm is designed to deal with
unsatisfiable concepts group by group. We conduct experiments over 19 ontology
pairs and compare our algorithms and scoring functions with existing ones.
According to the experiments, our algorithms could achieve promising
performance."
Improving Mandarin End-to-End Speech Recognition with Word N-gram Language Model,0.683645,"Despite the rapid progress of end-to-end (E2E) automatic speech recognition
(ASR), it has been shown that incorporating external language models (LMs) into
the decoding can further improve the recognition performance of E2E ASR
systems. To align with the modeling units adopted in E2E ASR systems,
subword-level (e.g., characters, BPE) LMs are usually used to cooperate with
current E2E ASR systems. However, the use of subword-level LMs will ignore the
word-level information, which may limit the strength of the external LMs in E2E
ASR. Although several methods have been proposed to incorporate word-level
external LMs in E2E ASR, these methods are mainly designed for languages with
clear word boundaries such as English and cannot be directly applied to
languages like Mandarin, in which each character sequence can have multiple
corresponding word sequences. To this end, we propose a novel decoding
algorithm where a word-level lattice is constructed on-the-fly to consider all
possible word sequences for each partial hypothesis. Then, the LM score of the
hypothesis is obtained by intersecting the generated lattice with an external
word N-gram LM. The proposed method is examined on both Attention-based
Encoder-Decoder (AED) and Neural Transducer (NT) frameworks. Experiments
suggest that our method consistently outperforms subword-level LMs, including
N-gram LM and neural network LM. We achieve state-of-the-art results on both
Aishell-1 (CER 4.18%) and Aishell-2 (CER 5.06%) datasets and reduce CER by
14.8% relatively on a 21K-hour Mandarin dataset."
Understanding Time Variations of DNN Inference in Autonomous Driving,0.431552,"Deep neural networks (DNNs) are widely used in autonomous driving due to
their high accuracy for perception, decision, and control. In safety-critical
systems like autonomous driving, executing tasks like sensing and perception in
real-time is vital to the vehicle's safety, which requires the application's
execution time to be predictable. However, non-negligible time variations are
observed in DNN inference. Current DNN inference studies either ignore the time
variation issue or rely on the scheduler to handle it. None of the current work
explains the root causes of DNN inference time variations. Understanding the
time variations of the DNN inference becomes a fundamental challenge in
real-time scheduling for autonomous driving. In this work, we analyze the time
variation in DNN inference in fine granularity from six perspectives: data,
I/O, model, runtime, hardware, and end-to-end perception system. Six insights
are derived in understanding the time variations for DNN inference."
Analogy Generation by Prompting Large Language Models: A Case Study of InstructGPT,0.23994,"We propose a novel application of prompting Pre-trained Language Models
(PLMs) to generate analogies and study how to design effective prompts for two
task settings: generating a source concept analogous to a given target concept
(aka Analogous Concept Generation or ACG), and generating an explanation of the
similarity between a given pair of target concept and source concept (aka
Analogous Explanation Generation or AEG). We found that it is feasible to
prompt InstructGPT to generate meaningful analogies and the best prompts tend
to be precise imperative statements especially with a low temperature setting.
We also systematically analyzed the sensitivity of the InstructGPT model to
prompt design, temperature, and injected spelling errors, and found that the
model is particularly sensitive to certain variations (e.g., questions vs.
imperative statements). Further, we conducted human evaluation on 1.4k of the
generated analogies and found that the quality of generations varies
substantially by model size. The largest InstructGPT model can achieve
human-level performance at generating meaningful analogies for a given target
while there is still room for improvement on the AEG task."
All you need is feedback: Communication with block attention feedback codes,0.398667,"Deep learning based channel code designs have recently gained interest as an
alternative to conventional coding algorithms, particularly for channels for
which existing codes do not provide effective solutions. Communication over a
feedback channel is one such problem, for which promising results have recently
been obtained by employing various deep learning architectures. In this paper,
we introduce a novel learning-aided code design for feedback channels, called
generalized block attention feedback (GBAF) codes, which i) employs a modular
architecture that can be implemented using different neural network
architectures; ii) provides order-of-magnitude improvements in the probability
of error compared to existing designs; and iii) can transmit at desired code
rates."
QAmeleon: Multilingual QA with Only 5 Examples,0.353511,"The availability of large, high-quality datasets has been one of the main
drivers of recent progress in question answering (QA). Such annotated datasets
however are difficult and costly to collect, and rarely exist in languages
other than English, rendering QA technology inaccessible to underrepresented
languages. An alternative to building large monolingual training datasets is to
leverage pre-trained language models (PLMs) under a few-shot learning setting.
Our approach, QAmeleon, uses a PLM to automatically generate multilingual data
upon which QA models are trained, thus avoiding costly annotation. Prompt
tuning the PLM for data synthesis with only five examples per language delivers
accuracy superior to translation-based baselines, bridges nearly 60% of the gap
between an English-only baseline and a fully supervised upper bound trained on
almost 50,000 hand labeled examples, and always leads to substantial
improvements compared to fine-tuning a QA model directly on labeled examples in
low resource settings. Experiments on the TyDiQA-GoldP and MLQA benchmarks show
that few-shot prompt tuning for data synthesis scales across languages and is a
viable alternative to large-scale annotation."
WebQAmGaze: A Multilingual Webcam Eye-Tracking-While-Reading Dataset,0.487612,"We present WebQAmGaze, a multilingual low-cost eye-tracking-while-reading
dataset, designed as the first webcam-based eye-tracking corpus of reading to
support the development of explainable computational language processing
models. WebQAmGaze includes webcam eye-tracking data from 600 participants of a
wide age range naturally reading English, German, Spanish, and Turkish texts.
Each participant performs two reading tasks composed of five texts each, a
normal reading and an information-seeking task, followed by a comprehension
question. We compare the collected webcam data to high-quality eye-tracking
recordings. The results show a moderate to strong correlation between the eye
movement measures obtained with the webcam compared to those obtained with a
commercial eye-tracking device. When validating the data, we find that higher
fixation duration on relevant text spans accurately indicates correctness when
answering the corresponding questions. This dataset advances webcam-based
reading studies and opens avenues to low-cost and diverse data collection.
WebQAmGaze is beneficial to learn about the cognitive processes behind
question-answering and to apply these insights to computational models of
language understanding."
Information-Theoretic Odometry Learning,0.0558926,"In this paper, we propose a unified information theoretic framework for
learning-motivated methods aimed at odometry estimation, a crucial component of
many robotics and vision tasks such as navigation and virtual reality where
relative camera poses are required in real time. We formulate this problem as
optimizing a variational information bottleneck objective function, which
eliminates pose-irrelevant information from the latent representation. The
proposed framework provides an elegant tool for performance evaluation and
understanding in information-theoretic language. Specifically, we bound the
generalization errors of the deep information bottleneck framework and the
predictability of the latent representation. These provide not only a
performance guarantee but also practical guidance for model design, sample
collection, and sensor selection. Furthermore, the stochastic latent
representation provides a natural uncertainty measure without the needs for
extra structures or computations. Experiments on two well-known odometry
datasets demonstrate the effectiveness of our method."
PAL: Persona-Augmented Emotional Support Conversation Generation,0.951647,"Due to the lack of human resources for mental health support, there is an
increasing demand for employing conversational agents for support. Recent work
has demonstrated the effectiveness of dialogue models in providing emotional
support. As previous studies have demonstrated that seekers' persona is an
important factor for effective support, we investigate whether there are
benefits to modeling such information in dialogue models for support. In this
paper, our empirical analysis verifies that persona has an important impact on
emotional support. Therefore, we propose a framework for dynamically inferring
and modeling seekers' persona. We first train a model for inferring the
seeker's persona from the conversation history. Accordingly, we propose PAL, a
model that leverages persona information and, in conjunction with our
strategy-based controllable generation method, provides personalized emotional
support. Automatic and manual evaluations demonstrate that PAL achieves
state-of-the-art results, outperforming the baselines on the studied benchmark.
Our code and data are publicly available at https://github.com/chengjl19/PAL."
Knowledge Infused Decoding,0.686248,"Pre-trained language models (LMs) have been shown to memorize a substantial
amount of knowledge from the pre-training corpora; however, they are still
limited in recalling factually correct knowledge given a certain context.
Hence, they tend to suffer from counterfactual or hallucinatory generation when
used in knowledge-intensive natural language generation (NLG) tasks. Recent
remedies to this problem focus on modifying either the pre-training or task
fine-tuning objectives to incorporate knowledge, which normally require
additional costly training or architecture modification of LMs for practical
applications. We present Knowledge Infused Decoding (KID) -- a novel decoding
algorithm for generative LMs, which dynamically infuses external knowledge into
each step of the LM decoding. Specifically, we maintain a local knowledge
memory based on the current context, interacting with a dynamically created
external knowledge trie, and continuously update the local memory as a
knowledge-aware constraint to guide decoding via reinforcement learning. On six
diverse knowledge-intensive NLG tasks, task-agnostic LMs (e.g., GPT-2 and BART)
armed with KID outperform many task-optimized state-of-the-art models, and show
particularly strong performance in few-shot scenarios over seven related
knowledge-infusion techniques. Human evaluation confirms KID's ability to
generate more relevant and factual language for the input context when compared
with multiple baselines. Finally, KID also alleviates exposure bias and
provides stable generation quality when generating longer sequences. Code for
KID is available at https://github.com/microsoft/KID."
Mutually Guided Few-shot Learning for Relational Triple Extraction,0.373273,"Knowledge graphs (KGs), containing many entity-relation-entity triples,
provide rich information for downstream applications. Although extracting
triples from unstructured texts has been widely explored, most of them require
a large number of labeled instances. The performance will drop dramatically
when only few labeled data are available. To tackle this problem, we propose
the Mutually Guided Few-shot learning framework for Relational Triple
Extraction (MG-FTE). Specifically, our method consists of an entity-guided
relation proto-decoder to classify the relations firstly and a relation-guided
entity proto-decoder to extract entities based on the classified relations. To
draw the connection between entity and relation, we design a proto-level fusion
module to boost the performance of both entity extraction and relation
classification. Moreover, a new cross-domain few-shot triple extraction task is
introduced. Extensive experiments show that our method outperforms many
state-of-the-art methods by 12.6 F1 score on FewRel 1.0 (single-domain) and
20.5 F1 score on FewRel 2.0 (cross-domain)."
SCOTCH and SODA: A Transformer Video Shadow Detection Framework,0.456441,"Shadows in videos are difficult to detect because of the large shadow
deformation between frames. In this work, we argue that accounting for shadow
deformation is essential when designing a video shadow detection method. To
this end, we introduce the shadow deformation attention trajectory (SODA), a
new type of video self-attention module, specially designed to handle the large
shadow deformations in videos. Moreover, we present a new shadow contrastive
learning mechanism (SCOTCH) which aims at guiding the network to learn a
unified shadow representation from massive positive shadow pairs across
different videos. We demonstrate empirically the effectiveness of our two
contributions in an ablation study. Furthermore, we show that SCOTCH and SODA
significantly outperforms existing techniques for video shadow detection. Code
is available at the project page:
https://lihaoliu-cambridge.github.io/scotch_and_soda/"
Bridging between LegalRuleML and TPTP for Automated Normative Reasoning (extended version),0.0206831,"LegalRuleML is a comprehensive XML-based representation framework for
modeling and exchanging normative rules. The TPTP input and output formats, on
the other hand, are general-purpose standards for the interaction with
automated reasoning systems. In this paper we provide a bridge between the two
communities by (i) defining a logic-pluralistic normative reasoning language
based on the TPTP format, (ii) providing a translation scheme between relevant
fragments of LegalRuleML and this language, and (iii) proposing a flexible
architecture for automated normative reasoning based on this translation. We
exemplarily instantiate and demonstrate the approach with three different
normative logics."
Open-domain Question Answering via Chain of Reasoning over Heterogeneous Knowledge,0.39421,"We propose a novel open-domain question answering (ODQA) framework for
answering single/multi-hop questions across heterogeneous knowledge sources.
The key novelty of our method is the introduction of the intermediary modules
into the current retriever-reader pipeline. Unlike previous methods that solely
rely on the retriever for gathering all evidence in isolation, our intermediary
performs a chain of reasoning over the retrieved set. Specifically, our method
links the retrieved evidence with its related global context into graphs and
organizes them into a candidate list of evidence chains. Built upon pretrained
language models, our system achieves competitive performance on two ODQA
datasets, OTT-QA and NQ, against tables and passages from Wikipedia. In
particular, our model substantially outperforms the previous state-of-the-art
on OTT-QA with an exact match score of 47.3 (45 % relative gain)."
A Deep CNN Architecture with Novel Pooling Layer Applied to Two Sudanese Arabic Sentiment Datasets,0.164008,"Arabic sentiment analysis has become an important research field in recent
years. Initially, work focused on Modern Standard Arabic (MSA), which is the
most widely-used form. Since then, work has been carried out on several
different dialects, including Egyptian, Levantine and Moroccan. Moreover, a
number of datasets have been created to support such work. However, up until
now, less work has been carried out on Sudanese Arabic, a dialect which has 32
million speakers. In this paper, two new publicly available datasets are
introduced, the 2-Class Sudanese Sentiment Dataset (SudSenti2) and the 3-Class
Sudanese Sentiment Dataset (SudSenti3). Furthermore, a CNN architecture, SCM,
is proposed, comprising five CNN layers together with a novel pooling layer,
MMA, to extract the best features. This SCM+MMA model is applied to SudSenti2
and SudSenti3 with accuracies of 92.75% and 84.39%. Next, the model is compared
to other deep learning classifiers and shown to be superior on these new
datasets. Finally, the proposed model is applied to the existing Saudi
Sentiment Dataset and to the MSA Hotel Arabic Review Dataset with accuracies
85.55% and 90.01%."
Differentially Private Decoding in Large Language Models,0.898162,"Recent large-scale natural language processing (NLP) systems use a
pre-trained Large Language Model (LLM) on massive and diverse corpora as a
headstart. In practice, the pre-trained model is adapted to a wide array of
tasks via fine-tuning on task-specific datasets. LLMs, while effective, have
been shown to memorize instances of training data thereby potentially revealing
private information processed during pre-training. The potential leakage might
further propagate to the downstream tasks for which LLMs are fine-tuned. On the
other hand, privacy-preserving algorithms usually involve retraining from
scratch, which is prohibitively expensive for LLMs. In this work, we propose a
simple, easy to interpret, and computationally lightweight perturbation
mechanism to be applied to an already trained model at the decoding stage. Our
perturbation mechanism is model-agnostic and can be used in conjunction with
any LLM. We provide theoretical analysis showing that the proposed mechanism is
differentially private, and experimental results showing a privacy-utility
trade-off."
Generalizability of Adversarial Robustness Under Distribution Shifts,0.296147,"Recent progress in empirical and certified robustness promises to deliver
reliable and deployable Deep Neural Networks (DNNs). Despite that success, most
existing evaluations of DNN robustness have been done on images sampled from
the same distribution on which the model was trained. However, in the real
world, DNNs may be deployed in dynamic environments that exhibit significant
distribution shifts. In this work, we take a first step towards thoroughly
investigating the interplay between empirical and certified adversarial
robustness on one hand and domain generalization on another. To do so, we train
robust models on multiple domains and evaluate their accuracy and robustness on
an unseen domain. We observe that: (1) both empirical and certified robustness
generalize to unseen domains, and (2) the level of generalizability does not
correlate well with input visual similarity, measured by the FID between source
and target domains. We also extend our study to cover a real-world medical
application, in which adversarial augmentation significantly boosts the
generalization of robustness with minimal effect on clean data accuracy."
Enhancing Portuguese Sign Language Animation with Dynamic Timing and Mouthing,0.26753,"Current signing avatars are often described as unnatural as they cannot
accurately reproduce all the subtleties of synchronized body behaviors of a
human signer. In this paper, we propose a new dynamic approach for transitions
between signs, focusing on mouthing animations for Portuguese Sign Language.
Although native signers preferred animations with dynamic transitions, we did
not find significant differences in comprehension and perceived naturalness
scores. On the other hand, we show that including mouthing behaviors improved
comprehension and perceived naturalness for novice sign language learners.
Results have implications in computational linguistics, human-computer
interaction, and synthetic animation of signing avatars."
Tuning computer vision models with task rewards,0.522967,"Misalignment between model predictions and intended usage can be detrimental
for the deployment of computer vision models. The issue is exacerbated when the
task involves complex structured outputs, as it becomes harder to design
procedures which address this misalignment. In natural language processing,
this is often addressed using reinforcement learning techniques that align
models with a task reward. We adopt this approach and show its surprising
effectiveness across multiple computer vision tasks, such as object detection,
panoptic segmentation, colorization and image captioning. We believe this
approach has the potential to be widely useful for better aligning models with
a diverse range of computer vision tasks."
"One Model, Any CSP: Graph Neural Networks as Fast Global Search Heuristics for Constraint Satisfaction",0.309732,"We propose a universal Graph Neural Network architecture which can be trained
as an end-2-end search heuristic for any Constraint Satisfaction Problem (CSP).
Our architecture can be trained unsupervised with policy gradient descent to
generate problem specific heuristics for any CSP in a purely data driven
manner. The approach is based on a novel graph representation for CSPs that is
both generic and compact and enables us to process every possible CSP instance
with one GNN, regardless of constraint arity, relations or domain size. Unlike
previous RL-based methods, we operate on a global search action space and allow
our GNN to modify any number of variables in every step of the stochastic
search. This enables our method to properly leverage the inherent parallelism
of GNNs. We perform a thorough empirical evaluation where we learn heuristics
for well known and important CSPs from random data, including graph coloring,
MaxCut, 3-SAT and MAX-k-SAT. Our approach outperforms prior approaches for
neural combinatorial optimization by a substantial margin. It can compete with,
and even improve upon, conventional search heuristics on test instances that
are several orders of magnitude larger and structurally more complex than those
seen during training."
KGEx: Explaining Knowledge Graph Embeddings via Subgraph Sampling and Knowledge Distillation,0.280163,"Despite being the go-to choice for link prediction on knowledge graphs,
research on interpretability of knowledge graph embeddings (KGE) has been
relatively unexplored. We present KGEx, a novel post-hoc method that explains
individual link predictions by drawing inspiration from surrogate models
research. Given a target triple to predict, KGEx trains surrogate KGE models
that we use to identify important training triples. To gauge the impact of a
training triple, we sample random portions of the target triple neighborhood
and we train multiple surrogate KGE models on each of them. To ensure
faithfulness, each surrogate is trained by distilling knowledge from the
original KGE model. We then assess how well surrogates predict the target
triple being explained, the intuition being that those leading to faithful
predictions have been trained on impactful neighborhood samples. Under this
assumption, we then harvest triples that appear frequently across impactful
neighborhoods. We conduct extensive experiments on two publicly available
datasets, to demonstrate that KGEx is capable of providing explanations
faithful to the black-box model."
Divert More Attention to Vision-Language Tracking,0.38206,"Relying on Transformer for complex visual feature learning, object tracking
has witnessed the new standard for state-of-the-arts (SOTAs). However, this
advancement accompanies by larger training data and longer training period,
making tracking increasingly expensive. In this paper, we demonstrate that the
Transformer-reliance is not necessary and the pure ConvNets are still
competitive and even better yet more economical and friendly in achieving SOTA
tracking. Our solution is to unleash the power of multimodal vision-language
(VL) tracking, simply using ConvNets. The essence lies in learning novel
unified-adaptive VL representations with our modality mixer (ModaMixer) and
asymmetrical ConvNet search. We show that our unified-adaptive VL
representation, learned purely with the ConvNets, is a simple yet strong
alternative to Transformer visual features, by unbelievably improving a
CNN-based Siamese tracker by 14.5% in SUC on challenging LaSOT (50.7% > 65.2%),
even outperforming several Transformer-based SOTA trackers. Besides empirical
results, we theoretically analyze our approach to evidence its effectiveness.
By revealing the potential of VL representation, we expect the community to
divert more attention to VL tracking and hope to open more possibilities for
future tracking beyond Transformer. Code and models will be released at
https://github.com/JudasDie/SOTS."
Bridging the Granularity Gap for Acoustic Modeling,0.325915,"While Transformer has become the de-facto standard for speech, modeling upon
the fine-grained frame-level features remains an open challenge of capturing
long-distance dependencies and distributing the attention weights. We propose
\textit{Progressive Down-Sampling} (PDS) which gradually compresses the
acoustic features into coarser-grained units containing more complete semantic
information, like text-level representation. In addition, we develop a
representation fusion method to alleviate information loss that occurs
inevitably during high compression. In this way, we compress the acoustic
features into 1/32 of the initial length while achieving better or comparable
performances on the speech recognition task. And as a bonus, it yields
inference speedups ranging from 1.20$\times$ to 1.47$\times$. By reducing the
modeling burden, we also achieve competitive results when training on the more
challenging speech translation task."
Multielement polynomial chaos Kriging-based metamodelling for Bayesian inference of non-smooth systems,0.695532,"This paper presents a surrogate modelling technique based on domain
partitioning for Bayesian parameter inference of highly nonlinear engineering
models. In order to alleviate the computational burden typically involved in
Bayesian inference applications, a multielement Polynomial Chaos Expansion
based Kriging metamodel is proposed. The developed surrogate model combines in
a piecewise function an array of local Polynomial Chaos based Kriging
metamodels constructed on a finite set of non-overlapping subdomains of the
stochastic input space. Therewith, the presence of non-smoothness in the
response of the forward model (e.g.~ nonlinearities and sparseness) can be
reproduced by the proposed metamodel with minimum computational costs owing to
its local adaptation capabilities. The model parameter inference is conducted
through a Markov chain Monte Carlo approach comprising adaptive exploration and
delayed rejection. The efficiency and accuracy of the proposed approach are
validated through two case studies, including an analytical benchmark and a
numerical case study. The latter relates the partial differential equation
governing the hydrogen diffusion phenomenon of metallic materials in Thermal
Desorption Spectroscopy tests."
MedMine: Examining Pre-trained Language Models on Medication Mining,0.474115,"Automatic medication mining from clinical and biomedical text has become a
popular topic due to its real impact on healthcare applications and the recent
development of powerful language models (LMs). However, fully-automatic
extraction models still face obstacles to be overcome such that they can be
deployed directly into clinical practice for better impacts. Such obstacles
include their imbalanced performances on different entity types and clinical
events. In this work, we examine current state-of-the-art pre-trained language
models (PLMs) on such tasks, via fine-tuning including the monolingual model
Med7 and multilingual large language model (LLM) XLM-RoBERTa. We compare their
advantages and drawbacks using historical medication mining shared task data
sets from n2c2-2018 challenges. We report the findings we get from these
fine-tuning experiments such that they can facilitate future research on
addressing them, for instance, how to combine their outputs, merge such models,
or improve their overall accuracy by ensemble learning and data augmentation.
MedMine is part of the M3 Initiative \url{https://github.com/HECTA-UoM/M3}"
FEED PETs: Further Experimentation and Expansion on the Disambiguation of Potentially Euphemistic Terms,0.696679,"Transformers have been shown to work well for the task of English euphemism
disambiguation, in which a potentially euphemistic term (PET) is classified as
euphemistic or non-euphemistic in a particular context. In this study, we
expand on the task in two ways. First, we annotate PETs for vagueness, a
linguistic property associated with euphemisms, and find that transformers are
generally better at classifying vague PETs, suggesting linguistic differences
in the data that impact performance. Second, we present novel euphemism corpora
in three different languages: Yoruba, Spanish, and Mandarin Chinese. We perform
euphemism disambiguation experiments in each language using multilingual
transformer models mBERT and XLM-RoBERTa, establishing preliminary results from
which to launch future work."
DoNet: Deep De-overlapping Network for Cytology Instance Segmentation,0.514231,"Cell instance segmentation in cytology images has significant importance for
biology analysis and cancer screening, while remains challenging due to 1) the
extensive overlapping translucent cell clusters that cause the ambiguous
boundaries, and 2) the confusion of mimics and debris as nuclei. In this work,
we proposed a De-overlapping Network (DoNet) in a decompose-and-recombined
strategy. A Dual-path Region Segmentation Module (DRM) explicitly decomposes
the cell clusters into intersection and complement regions, followed by a
Semantic Consistency-guided Recombination Module (CRM) for integration. To
further introduce the containment relationship of the nucleus in the cytoplasm,
we design a Mask-guided Region Proposal Strategy (MRP) that integrates the cell
attention maps for inner-cell instance prediction. We validate the proposed
approach on ISBI2014 and CPS datasets. Experiments show that our proposed DoNet
significantly outperforms other state-of-the-art (SOTA) cell instance
segmentation methods. The code is available at
https://github.com/DeepDoNet/DoNet."
The Pipeline for the Continuous Development of Artificial Intelligence Models -- Current State of Research and Practice,0.617448,"Companies struggle to continuously develop and deploy AI models to complex
production systems due to AI characteristics while assuring quality. To ease
the development process, continuous pipelines for AI have become an active
research area where consolidated and in-depth analysis regarding the
terminology, triggers, tasks, and challenges is required. This paper includes a
Multivocal Literature Review where we consolidated 151 relevant formal and
informal sources. In addition, nine-semi structured interviews with
participants from academia and industry verified and extended the obtained
information. Based on these sources, this paper provides and compares
terminologies for DevOps and CI/CD for AI, MLOps, (end-to-end) lifecycle
management, and CD4ML. Furthermore, the paper provides an aggregated list of
potential triggers for reiterating the pipeline, such as alert systems or
schedules. In addition, this work uses a taxonomy creation strategy to present
a consolidated pipeline comprising tasks regarding the continuous development
of AI. This pipeline consists of four stages: Data Handling, Model Learning,
Software Development and System Operations. Moreover, we map challenges
regarding pipeline implementation, adaption, and usage for the continuous
development of AI to these four stages."
Facial Expression Recognition and Image Description Generation in Vietnamese,0.147465,"This paper discusses a facial expression recognition model and a description
generation model to build descriptive sentences for images and facial
expressions of people in images. Our study shows that YOLOv5 achieves better
results than a traditional CNN for all emotions on the KDEF dataset. In
particular, the accuracies of the CNN and YOLOv5 models for emotion recognition
are 0.853 and 0.938, respectively. A model for generating descriptions for
images based on a merged architecture is proposed using VGG16 with the
descriptions encoded over an LSTM model. YOLOv5 is also used to recognize
dominant colors of objects in the images and correct the color words in the
descriptions generated if it is necessary. If the description contains words
referring to a person, we recognize the emotion of the person in the image.
Finally, we combine the results of all models to create sentences that describe
the visual content and the human emotions in the images. Experimental results
on the Flickr8k dataset in Vietnamese achieve BLEU-1, BLEU-2, BLEU-3, BLEU-4
scores of 0.628; 0.425; 0.280; and 0.174, respectively."
Prompt Consistency for Zero-Shot Task Generalization,0.569058,"One of the most impressive results of recent NLP history is the ability of
pre-trained language models to solve new tasks in a zero-shot setting. To
achieve this, NLP tasks are framed as natural language prompts, generating a
response indicating the predicted output. Nonetheless, the performance in such
settings often lags far behind its supervised counterpart, suggesting a large
space for potential improvement. In this paper, we explore methods to utilize
unlabeled data to improve zero-shot performance. Specifically, we take
advantage of the fact that multiple prompts can be used to specify a single
task, and propose to regularize prompt consistency, encouraging consistent
predictions over this diverse set of prompts. Our method makes it possible to
fine-tune the model either with extra unlabeled training data, or directly on
test input at inference time in an unsupervised manner. In experiments, our
approach outperforms the state-of-the-art zero-shot learner, T0 (Sanh et al.,
2022), on 9 out of 11 datasets across 4 NLP tasks by up to 10.6 absolute points
in terms of accuracy. The gains are often attained with a small number of
unlabeled examples."
Free Lunch for Efficient Textual Commonsense Integration in Language Models,0.118557,"Recent years have witnessed the emergence of textual commonsense knowledge
bases, aimed at providing more nuanced and context-rich knowledge. The
integration of external commonsense into language models has been shown to be a
key enabler in advancing the state-of-the-art for a wide range of NLP tasks.
However, incorporating textual commonsense descriptions is computationally
expensive, as compared to encoding conventional symbolic knowledge. In this
paper, we propose a method to improve its efficiency without modifying the
model. We group training samples with similar commonsense descriptions into a
single batch, thus reusing the encoded description across multiple samples. One
key observation is that the upper bound of batch partitioning can be reduced to
the classic {\it graph k-cut problem}. Consequently, we propose a spectral
clustering-based algorithm to solve this problem. Extensive experiments
illustrate that the proposed batch partitioning approach effectively reduces
the computational cost while preserving performance. The efficiency improvement
is more pronounced on larger datasets and on devices with more memory capacity,
attesting to its practical utility for large-scale applications."
Multi-View Document Representation Learning for Open-Domain Dense Retrieval,0.783766,"Dense retrieval has achieved impressive advances in first-stage retrieval
from a large-scale document collection, which is built on bi-encoder
architecture to produce single vector representation of query and document.
However, a document can usually answer multiple potential queries from
different views. So the single vector representation of a document is hard to
match with multi-view queries, and faces a semantic mismatch problem. This
paper proposes a multi-view document representation learning framework, aiming
to produce multi-view embeddings to represent documents and enforce them to
align with different queries. First, we propose a simple yet effective method
of generating multiple embeddings through viewers. Second, to prevent
multi-view embeddings from collapsing to the same one, we further propose a
global-local loss with annealed temperature to encourage the multiple viewers
to better align with different potential queries. Experiments show our method
outperforms recent works and achieves state-of-the-art results."
Recurrent Memory Transformer,0.940889,"Transformer-based models show their effectiveness across multiple domains and
tasks. The self-attention allows to combine information from all sequence
elements into context-aware representations. However, global and local
information has to be stored mostly in the same element-wise representations.
Moreover, the length of an input sequence is limited by quadratic computational
complexity of self-attention.
  In this work, we propose and study a memory-augmented segment-level recurrent
Transformer (RMT). Memory allows to store and process local and global
information as well as to pass information between segments of the long
sequence with the help of recurrence.
  We implement a memory mechanism with no changes to Transformer model by
adding special memory tokens to the input or output sequence. Then the model is
trained to control both memory operations and sequence representations
processing.
  Results of experiments show that RMT performs on par with the Transformer-XL
on language modeling for smaller memory sizes and outperforms it for tasks that
require longer sequence processing. We show that adding memory tokens to Tr-XL
is able to improve its performance. This makes Recurrent Memory Transformer a
promising architecture for applications that require learning of long-term
dependencies and general purpose in memory processing, such as algorithmic
tasks and reasoning."
VectorFusion: Text-to-SVG by Abstracting Pixel-Based Diffusion Models,0.974183,"Diffusion models have shown impressive results in text-to-image synthesis.
Using massive datasets of captioned images, diffusion models learn to generate
raster images of highly diverse objects and scenes. However, designers
frequently use vector representations of images like Scalable Vector Graphics
(SVGs) for digital icons or art. Vector graphics can be scaled to any size, and
are compact. We show that a text-conditioned diffusion model trained on pixel
representations of images can be used to generate SVG-exportable vector
graphics. We do so without access to large datasets of captioned SVGs. By
optimizing a differentiable vector graphics rasterizer, our method,
VectorFusion, distills abstract semantic knowledge out of a pretrained
diffusion model. Inspired by recent text-to-3D work, we learn an SVG consistent
with a caption using Score Distillation Sampling. To accelerate generation and
improve fidelity, VectorFusion also initializes from an image sample.
Experiments show greater quality than prior work, and demonstrate a range of
styles including pixel art and sketches. See our project webpage at
https://ajayj.com/vectorfusion ."
FERMAT: An Alternative to Accuracy for Numerical Reasoning,0.0502051,"While pre-trained language models achieve impressive performance on various
NLP benchmarks, they still struggle with tasks that require numerical
reasoning. Recent advances in improving numerical reasoning are mostly achieved
using very large language models that contain billions of parameters and are
not accessible to everyone. In addition, numerical reasoning is measured using
a single score on existing datasets. As a result, we do not have a clear
understanding of the strengths and shortcomings of existing models on different
numerical reasoning aspects and therefore, potential ways to improve them apart
from scaling them up. Inspired by CheckList (Ribeiro et al., 2020), we
introduce a multi-view evaluation set for numerical reasoning in English,
called FERMAT. Instead of reporting a single score on a whole dataset, FERMAT
evaluates models on various key numerical reasoning aspects such as number
understanding, mathematical operations, and training dependency. Apart from
providing a comprehensive evaluation of models on different numerical reasoning
aspects, FERMAT enables a systematic and automated generation of an arbitrarily
large training or evaluation set for each aspect.The datasets and codes are
publicly available to generate further multi-view data for ulterior tasks and
languages."
Bayes risk CTC: Controllable CTC alignment in Sequence-to-Sequence tasks,0.793711,"Sequence-to-Sequence (seq2seq) tasks transcribe the input sequence to a
target sequence. The Connectionist Temporal Classification (CTC) criterion is
widely used in multiple seq2seq tasks. Besides predicting the target sequence,
a side product of CTC is to predict the alignment, which is the most probable
input-long sequence that specifies a hard aligning relationship between the
input and target units. As there are multiple potential aligning sequences
(called paths) that are equally considered in CTC formulation, the choice of
which path will be most probable and become the predicted alignment is always
uncertain. In addition, it is usually observed that the alignment predicted by
vanilla CTC will drift compared with its reference and rarely provides
practical functionalities. Thus, the motivation of this work is to make the CTC
alignment prediction controllable and thus equip CTC with extra
functionalities. The Bayes risk CTC (BRCTC) criterion is then proposed in this
work, in which a customizable Bayes risk function is adopted to enforce the
desired characteristics of the predicted alignment. With the risk function, the
BRCTC is a general framework to adopt some customizable preference over the
paths in order to concentrate the posterior into a particular subset of the
paths. In applications, we explore one particular preference which yields
models with the down-sampling ability and reduced inference costs. By using
BRCTC with another preference for early emissions, we obtain an improved
performance-latency trade-off for online models. Experimentally, the proposed
BRCTC reduces the inference cost of offline models by up to 47% without
performance degradation and cuts down the overall latency of online systems to
an unseen level."
Limits for Learning with Language Models,0.211659,"With the advent of large language models (LLMs), the trend in NLP has been to
train LLMs on vast amounts of data to solve diverse language understanding and
generation tasks. The list of LLM successes is long and varied. Nevertheless,
several recent papers provide empirical evidence that LLMs fail to capture
important aspects of linguistic meaning. Focusing on universal quantification,
we provide a theoretical foundation for these empirical findings by proving
that LLMs cannot learn certain fundamental semantic properties including
semantic entailment and consistency as they are defined in formal semantics.
More generally, we show that LLMs are unable to learn concepts beyond the first
level of the Borel Hierarchy, which imposes severe limits on the ability of
LMs, both large and small, to capture many aspects of linguistic meaning. This
means that LLMs will continue to operate without formal guarantees on tasks
that require entailments and deep linguistic understanding."
Do Transformer Models Show Similar Attention Patterns to Task-Specific Human Gaze?,0.792602,"Learned self-attention functions in state-of-the-art NLP models often
correlate with human attention. We investigate whether self-attention in
large-scale pre-trained language models is as predictive of human eye fixation
patterns during task-reading as classical cognitive models of human attention.
We compare attention functions across two task-specific reading datasets for
sentiment analysis and relation extraction. We find the predictiveness of
large-scale pre-trained self-attention for human attention depends on `what is
in the tail', e.g., the syntactic nature of rare contexts. Further, we observe
that task-specific fine-tuning does not increase the correlation with human
task-specific reading. Through an input reduction experiment we give
complementary insights on the sparsity and fidelity trade-off, showing that
lower-entropy attention vectors are more faithful."
Defending Black-box Skeleton-based Human Activity Classifiers,0.62166,"Skeletal motions have been heavily replied upon for human activity
recognition (HAR). Recently, a universal vulnerability of skeleton-based HAR
has been identified across a variety of classifiers and data, calling for
mitigation. To this end, we propose the first black-box defense method for
skeleton-based HAR to our best knowledge. Our method is featured by full
Bayesian treatments of the clean data, the adversaries and the classifier,
leading to (1) a new Bayesian Energy-based formulation of robust discriminative
classifiers, (2) a new adversary sampling scheme based on natural motion
manifolds, and (3) a new post-train Bayesian strategy for black-box defense. We
name our framework Bayesian Energy-based Adversarial Training or BEAT. BEAT is
straightforward but elegant, which turns vulnerable black-box classifiers into
robust ones without sacrificing accuracy. It demonstrates surprising and
universal effectiveness across a wide range of skeletal HAR classifiers and
datasets, under various attacks. Code is available at
https://github.com/realcrane/RobustActionRecogniser."
"A Stable, Fast, and Fully Automatic Learning Algorithm for Predictive Coding Networks",0.229217,"Predictive coding networks are neuroscience-inspired models with roots in
both Bayesian statistics and neuroscience. Training such models, however, is
quite inefficient and unstable. In this work, we show how by simply changing
the temporal scheduling of the update rule for the synaptic weights leads to an
algorithm that is much more efficient and stable than the original one, and has
theoretical guarantees in terms of convergence. The proposed algorithm, that we
call incremental predictive coding (iPC) is also more biologically plausible
than the original one, as it it fully automatic. In an extensive set of
experiments, we show that iPC constantly performs better than the original
formulation on a large number of benchmarks for image classification, as well
as for the training of both conditional and masked language models, in terms of
test accuracy, efficiency, and convergence with respect to a large set of
hyperparameters."
Mind the Gap: Offline Policy Optimization for Imperfect Rewards,0.299024,"Reward function is essential in reinforcement learning (RL), serving as the
guiding signal to incentivize agents to solve given tasks, however, is also
notoriously difficult to design. In many cases, only imperfect rewards are
available, which inflicts substantial performance loss for RL agents. In this
study, we propose a unified offline policy optimization approach, \textit{RGM
(Reward Gap Minimization)}, which can smartly handle diverse types of imperfect
rewards. RGM is formulated as a bi-level optimization problem: the upper layer
optimizes a reward correction term that performs visitation distribution
matching w.r.t. some expert data; the lower layer solves a pessimistic RL
problem with the corrected rewards. By exploiting the duality of the lower
layer, we derive a tractable algorithm that enables sampled-based learning
without any online interactions. Comprehensive experiments demonstrate that RGM
achieves superior performance to existing methods under diverse settings of
imperfect rewards. Further, RGM can effectively correct wrong or inconsistent
rewards against expert preference and retrieve useful information from biased
rewards."
MIA 2022 Shared Task: Evaluating Cross-lingual Open-Retrieval Question Answering for 16 Diverse Languages,0.424825,"We present the results of the Workshop on Multilingual Information Access
(MIA) 2022 Shared Task, evaluating cross-lingual open-retrieval question
answering (QA) systems in 16 typologically diverse languages. In this task, we
adapted two large-scale cross-lingual open-retrieval QA datasets in 14
typologically diverse languages, and newly annotated open-retrieval QA data in
2 underrepresented languages: Tagalog and Tamil. Four teams submitted their
systems. The best system leveraging iteratively mined diverse negative examples
and larger pretrained models achieves 32.2 F1, outperforming our baseline by
4.5 points. The second best system uses entity-aware contextualized
representations for document retrieval, and achieves significant improvements
in Tamil (20.8 F1), whereas most of the other systems yield nearly zero scores."
Open- and Closed-Loop Neural Network Verification using Polynomial Zonotopes,0.727531,"We present a novel approach to efficiently compute tight non-convex
enclosures of the image through neural networks with ReLU, sigmoid, or
hyperbolic tangent activation functions. In particular, we abstract the
input-output relation of each neuron by a polynomial approximation, which is
evaluated in a set-based manner using polynomial zonotopes. While our approach
can also can be beneficial for open-loop neural network verification, our main
application is reachability analysis of neural network controlled systems,
where polynomial zonotopes are able to capture the non-convexity caused by the
neural network as well as the system dynamics. This results in a superior
performance compared to other methods, as we demonstrate on various benchmarks."
Will we run out of data? An analysis of the limits of scaling datasets in Machine Learning,0.708538,"We analyze the growth of dataset sizes used in machine learning for natural
language processing and computer vision, and extrapolate these using two
methods; using the historical growth rate and estimating the compute-optimal
dataset size for future predicted compute budgets. We investigate the growth in
data usage by estimating the total stock of unlabeled data available on the
internet over the coming decades. Our analysis indicates that the stock of
high-quality language data will be exhausted soon; likely before 2026. By
contrast, the stock of low-quality language data and image data will be
exhausted only much later; between 2030 and 2050 (for low-quality language) and
between 2030 and 2060 (for images). Our work suggests that the current trend of
ever-growing ML models that rely on enormous datasets might slow down if data
efficiency is not drastically improved or new sources of data become available."
Adapting Pre-trained Language Models to African Languages via Multilingual Adaptive Fine-Tuning,0.990294,"Multilingual pre-trained language models (PLMs) have demonstrated impressive
performance on several downstream tasks for both high-resourced and
low-resourced languages. However, there is still a large performance drop for
languages unseen during pre-training, especially African languages. One of the
most effective approaches to adapt to a new language is \textit{language
adaptive fine-tuning} (LAFT) -- fine-tuning a multilingual PLM on monolingual
texts of a language using the pre-training objective. However, adapting to a
target language individually takes a large disk space and limits the
cross-lingual transfer abilities of the resulting models because they have been
specialized for a single language. In this paper, we perform
\textit{multilingual adaptive fine-tuning} on 17 most-resourced African
languages and three other high-resource languages widely spoken on the African
continent to encourage cross-lingual transfer learning. To further specialize
the multilingual PLM, we removed vocabulary tokens from the embedding layer
that corresponds to non-African writing scripts before MAFT, thus reducing the
model size by around 50%. Our evaluation on two multilingual PLMs (AfriBERTa
and XLM-R) and three NLP tasks (NER, news topic classification, and sentiment
classification) shows that our approach is competitive to applying LAFT on
individual languages while requiring significantly less disk space.
Additionally, we show that our adapted PLM also improves the zero-shot
cross-lingual transfer abilities of parameter efficient fine-tuning methods."
"Geodesics, Non-linearities and the Archive of Novelty Search",0.21338,"The Novelty Search (NS) algorithm was proposed more than a decade ago.
However, the mechanisms behind its empirical success are still not well
formalized/understood. This short note focuses on the effects of the archive on
exploration. Experimental evidence from a few application domains suggests that
archive-based NS performs in general better than when Novelty is solely
computed with respect to the population. An argument that is often encountered
in the literature is that the archive prevents exploration from backtracking or
cycling, i.e. from revisiting previously encountered areas in the behavior
space. We argue that this is not a complete or accurate explanation as
backtracking - beside often being desirable - can actually be enabled by the
archive. Through low-dimensional/analytical examples, we show that a key effect
of the archive is that it counterbalances the exploration biases that result,
among other factors, from the use of inadequate behavior metrics and the
non-linearities of the behavior mapping. Our observations seem to hint that
attributing a more active role to the archive in sampling can be beneficial."
The Sound of Bounding-Boxes,0.0958485,"In the task of audio-visual sound source separation, which leverages visual
information for sound source separation, identifying objects in an image is a
crucial step prior to separating the sound source. However, existing methods
that assign sound on detected bounding boxes suffer from a problem that their
approach heavily relies on pre-trained object detectors. Specifically, when
using these existing methods, it is required to predetermine all the possible
categories of objects that can produce sound and use an object detector
applicable to all such categories. To tackle this problem, we propose a fully
unsupervised method that learns to detect objects in an image and separate
sound source simultaneously. As our method does not rely on any pre-trained
detector, our method is applicable to arbitrary categories without any
additional annotation. Furthermore, although being fully unsupervised, we found
that our method performs comparably in separation accuracy."
Generalization Analogies: A Testbed for Generalizing AI Oversight to Hard-To-Measure Domains,0.511877,"As AI systems become more intelligent and their behavior becomes more
challenging to assess, they may learn to game the flaws of human feedback
instead of genuinely striving to follow instructions; however, this risk can be
mitigated by controlling how LLMs generalize human feedback to situations where
it is unreliable. To better understand how reward models generalize, we craft
69 distribution shifts spanning 8 categories. We find that reward models do not
learn to evaluate `instruction-following' by default and instead favor personas
that resemble internet text. Techniques for interpreting reward models'
internal representations achieve better generalization than standard
fine-tuning, but still frequently fail to distinguish instruction-following
from conflated behaviors. We consolidate the 15 most challenging distribution
shifts into the GENeralization analogIES (GENIES) benchmark, which we hope will
enable progress toward controlling reward model generalization."
Interpretable Low-Resource Legal Decision Making,0.27162,"Over the past several years, legal applications of deep learning have been on
the rise. However, as with other high-stakes decision making areas, the
requirement for interpretability is of crucial importance. Current models
utilized by legal practitioners are more of the conventional machine learning
type, wherein they are inherently interpretable, yet unable to harness the
performance capabilities of data-driven deep learning models. In this work, we
utilize deep learning models in the area of trademark law to shed light on the
issue of likelihood of confusion between trademarks. Specifically, we introduce
a model-agnostic interpretable intermediate layer, a technique which proves to
be effective for legal documents. Furthermore, we utilize weakly supervised
learning by means of a curriculum learning strategy, effectively demonstrating
the improved performance of a deep learning model. This is in contrast to the
conventional models which are only able to utilize the limited number of
expensive manually-annotated samples by legal experts. Although the methods
presented in this work tackles the task of risk of confusion for trademarks, it
is straightforward to extend them to other fields of law, or more generally, to
other similar high-stakes application scenarios."
Exhaustivity and anti-exhaustivity in the RSA framework: Testing the effect of prior beliefs,0.318134,"During communication, the interpretation of utterances is sensitive to a
listener's probabilistic prior beliefs, something which is captured by one
currently influential model of pragmatics, the Rational Speech Act (RSA)
framework. In this paper we focus on cases when this sensitivity to priors
leads to counterintuitive predictions of the framework. Our domain of interest
is exhaustivity effects, whereby a sentence such as ""Mary came"" is understood
to mean that only Mary came. We show that in the baseline RSA model, under
certain conditions, anti-exhaustive readings are predicted (e.g., ""Mary came""
would be used to convey that both Mary and Peter came). The specific question
we ask is the following: should exhaustive interpretations be derived as purely
pragmatic inferences (as in the classical Gricean view, endorsed in the
baseline RSA model), or should they rather be generated by an encapsulated
semantic mechanism (as argued in some of the recent formal literature)? To
answer this question, we provide a detailed theoretical analysis of different
RSA models and evaluate them against data obtained in a new study which tested
the effects of prior beliefs on both production and comprehension, improving on
previous empirical work. We found no anti-exhaustivity effects, but observed
that message choice is sensitive to priors, as predicted by the RSA framework
overall. The best models turn out to be those which include an encapsulated
exhaustivity mechanism (as other studies concluded on the basis of very
different data). We conclude that, on the one hand, in the division of labor
between semantics and pragmatics, semantics plays a larger role than is often
thought, but, on the other hand, the tradeoff between informativity and cost
which characterizes all RSA models does play a central role for genuine
pragmatic effects."
Gradient-Guided Importance Sampling for Learning Binary Energy-Based Models,0.864665,"Learning energy-based models (EBMs) is known to be difficult especially on
discrete data where gradient-based learning strategies cannot be applied
directly. Although ratio matching is a sound method to learn discrete EBMs, it
suffers from expensive computation and excessive memory requirements, thereby
resulting in difficulties in learning EBMs on high-dimensional data. Motivated
by these limitations, in this study, we propose ratio matching with
gradient-guided importance sampling (RMwGGIS). Particularly, we use the
gradient of the energy function w.r.t. the discrete data space to approximately
construct the provably optimal proposal distribution, which is subsequently
used by importance sampling to efficiently estimate the original ratio matching
objective. We perform experiments on density modeling over synthetic discrete
data, graph generation, and training Ising models to evaluate our proposed
method. The experimental results demonstrate that our method can significantly
alleviate the limitations of ratio matching, perform more effectively in
practice, and scale to high-dimensional problems. Our implementation is
available at https://github.com/divelab/RMwGGIS."
Deep Surrogate Assisted Generation of Environments,0.795734,"Recent progress in reinforcement learning (RL) has started producing
generally capable agents that can solve a distribution of complex environments.
These agents are typically tested on fixed, human-authored environments. On the
other hand, quality diversity (QD) optimization has been proven to be an
effective component of environment generation algorithms, which can generate
collections of high-quality environments that are diverse in the resulting
agent behaviors. However, these algorithms require potentially expensive
simulations of agents on newly generated environments. We propose Deep
Surrogate Assisted Generation of Environments (DSAGE), a sample-efficient QD
environment generation algorithm that maintains a deep surrogate model for
predicting agent behaviors in new environments. Results in two benchmark
domains show that DSAGE significantly outperforms existing QD environment
generation algorithms in discovering collections of environments that elicit
diverse behaviors of a state-of-the-art RL agent and a planning agent. Our
source code and videos are available at https://dsagepaper.github.io/."
CHEF: A Pilot Chinese Dataset for Evidence-Based Fact-Checking,0.969913,"The explosion of misinformation spreading in the media ecosystem urges for
automated fact-checking. While misinformation spans both geographic and
linguistic boundaries, most work in the field has focused on English. Datasets
and tools available in other languages, such as Chinese, are limited. In order
to bridge this gap, we construct CHEF, the first CHinese Evidence-based
Fact-checking dataset of 10K real-world claims. The dataset covers multiple
domains, ranging from politics to public health, and provides annotated
evidence retrieved from the Internet. Further, we develop established baselines
and a novel approach that is able to model the evidence retrieval as a latent
variable, allowing jointly training with the veracity prediction model in an
end-to-end fashion. Extensive experiments show that CHEF will provide a
challenging testbed for the development of fact-checking systems designed to
retrieve and reason over non-English claims."
"Better Datastore, Better Translation: Generating Datastores from Pre-Trained Models for Nearest Neural Machine Translation",0.259453,"Nearest Neighbor Machine Translation (kNNMT) is a simple and effective method
of augmenting neural machine translation (NMT) with a token-level nearest
neighbor retrieval mechanism. The effectiveness of kNNMT directly depends on
the quality of retrieved neighbors. However, original kNNMT builds datastores
based on representations from NMT models, which would result in poor retrieval
accuracy when NMT models are not good enough, leading to sub-optimal
translation performance. In this paper, we propose PRED, a framework that
leverages Pre-trained models for Datastores in kNN-MT. Better representations
from pre-trained models allow us to build datastores of better quality. We also
design a novel contrastive alignment objective to mitigate the representation
gap between the NMT model and pre-trained models, enabling the NMT model to
retrieve from better datastores. We conduct extensive experiments on both
bilingual and multilingual translation benchmarks, including WMT17 English
$\leftrightarrow$ Chinese, WMT14 English $\leftrightarrow$ German, IWSLT14
German $\leftrightarrow$ English, and IWSLT14 multilingual datasets. Empirical
results demonstrate the effectiveness of PRED."
Deep Learning in Healthcare: An In-Depth Analysis,0.0362029,"Deep learning (DL) along with never-ending advancements in computational
processing and cloud technologies have bestowed us powerful analyzing tools and
techniques in the past decade and enabled us to use and apply them in various
fields of study. Health informatics is not an exception, and conversely, is the
discipline that generates the most amount of data in today's era and can
benefit from DL the most. Extracting features and finding complex patterns from
a huge amount of raw data and transforming them into knowledge is a challenging
task. Besides, various DL architectures have been proposed by researchers
throughout the years to tackle different problems. In this paper, we provide a
review of DL models and their broad application in bioinformatics and
healthcare categorized by their architecture. In addition, we also go over some
of the key challenges that still exist and can show up while conducting DL
research."
ReCo: Reliable Causal Chain Reasoning via Structural Causal Recurrent Neural Networks,0.0419964,"Causal chain reasoning (CCR) is an essential ability for many decision-making
AI systems, which requires the model to build reliable causal chains by
connecting causal pairs. However, CCR suffers from two main transitive
problems: threshold effect and scene drift. In other words, the causal pairs to
be spliced may have a conflicting threshold boundary or scenario. To address
these issues, we propose a novel Reliable Causal chain reasoning
framework~(ReCo), which introduces exogenous variables to represent the
threshold and scene factors of each causal pair within the causal chain, and
estimates the threshold and scene contradictions across exogenous variables via
structural causal recurrent neural networks~(SRNN). Experiments show that ReCo
outperforms a series of strong baselines on both Chinese and English CCR
datasets. Moreover, by injecting reliable causal chain knowledge distilled by
ReCo, BERT can achieve better performances on four downstream causal-related
tasks than BERT models enhanced by other kinds of knowledge."
A case for using rotation invariant features in state of the art feature matchers,0.893859,"The aim of this paper is to demonstrate that a state of the art feature
matcher (LoFTR) can be made more robust to rotations by simply replacing the
backbone CNN with a steerable CNN which is equivariant to translations and
image rotations. It is experimentally shown that this boost is obtained without
reducing performance on ordinary illumination and viewpoint matching sequences."
SA-BEV: Generating Semantic-Aware Bird's-Eye-View Feature for Multi-view 3D Object Detection,0.820325,"Recently, the pure camera-based Bird's-Eye-View (BEV) perception provides a
feasible solution for economical autonomous driving. However, the existing
BEV-based multi-view 3D detectors generally transform all image features into
BEV features, without considering the problem that the large proportion of
background information may submerge the object information. In this paper, we
propose Semantic-Aware BEV Pooling (SA-BEVPool), which can filter out
background information according to the semantic segmentation of image features
and transform image features into semantic-aware BEV features. Accordingly, we
propose BEV-Paste, an effective data augmentation strategy that closely matches
with semantic-aware BEV feature. In addition, we design a Multi-Scale
Cross-Task (MSCT) head, which combines task-specific and cross-task information
to predict depth distribution and semantic segmentation more accurately,
further improving the quality of semantic-aware BEV feature. Finally, we
integrate the above modules into a novel multi-view 3D object detection
framework, namely SA-BEV. Experiments on nuScenes show that SA-BEV achieves
state-of-the-art performance. Code has been available at
https://github.com/mengtan00/SA-BEV.git."
RuBioRoBERTa: a pre-trained biomedical language model for Russian language biomedical text mining,0.0980527,"This paper presents several BERT-based models for Russian language biomedical
text mining (RuBioBERT, RuBioRoBERTa). The models are pre-trained on a corpus
of freely available texts in the Russian biomedical domain. With this
pre-training, our models demonstrate state-of-the-art results on RuMedBench -
Russian medical language understanding benchmark that covers a diverse set of
tasks, including text classification, question answering, natural language
inference, and named entity recognition."
Harnessing Pre-Trained Sentence Transformers for Offensive Language Detection in Indian Languages,0.0869597,"In our increasingly interconnected digital world, social media platforms have
emerged as powerful channels for the dissemination of hate speech and offensive
content. This work delves into the domain of hate speech detection, placing
specific emphasis on three low-resource Indian languages: Bengali, Assamese,
and Gujarati. The challenge is framed as a text classification task, aimed at
discerning whether a tweet contains offensive or non-offensive content.
Leveraging the HASOC 2023 datasets, we fine-tuned pre-trained BERT and SBERT
models to evaluate their effectiveness in identifying hate speech. Our findings
underscore the superiority of monolingual sentence-BERT models, particularly in
the Bengali language, where we achieved the highest ranking. However, the
performance in Assamese and Gujarati languages signifies ongoing opportunities
for enhancement. Our goal is to foster inclusive online spaces by countering
hate speech proliferation."
Track Anything: Segment Anything Meets Videos,1.0,"Recently, the Segment Anything Model (SAM) gains lots of attention rapidly
due to its impressive segmentation performance on images. Regarding its strong
ability on image segmentation and high interactivity with different prompts, we
found that it performs poorly on consistent segmentation in videos. Therefore,
in this report, we propose Track Anything Model (TAM), which achieves
high-performance interactive tracking and segmentation in videos. To be
detailed, given a video sequence, only with very little human participation,
i.e., several clicks, people can track anything they are interested in, and get
satisfactory results in one-pass inference. Without additional training, such
an interactive design performs impressively on video object tracking and
segmentation. All resources are available on
{https://github.com/gaomingqi/Track-Anything}. We hope this work can facilitate
related research."
Symbolic music generation conditioned on continuous-valued emotions,0.915957,"In this paper we present a new approach for the generation of
multi-instrument symbolic music driven by musical emotion. The principal
novelty of our approach centres on conditioning a state-of-the-art transformer
based on continuous-valued valence and arousal labels. In addition, we provide
a new large-scale dataset of symbolic music paired with emotion labels in terms
of valence and arousal. We evaluate our approach in a quantitative manner in
two ways, first by measuring its note prediction accuracy, and second via a
regression task in the valence-arousal plane. Our results demonstrate that our
proposed approaches outperform conditioning using control tokens which is
representative of the current state of the art."
Real-Time Driver Monitoring Systems through Modality and View Analysis,0.327655,"Driver distractions are known to be the dominant cause of road accidents.
While monitoring systems can detect non-driving-related activities and
facilitate reducing the risks, they must be accurate and efficient to be
applicable. Unfortunately, state-of-the-art methods prioritize accuracy while
ignoring latency because they leverage cross-view and multimodal videos in
which consecutive frames are highly similar. Thus, in this paper, we pursue
time-effective detection models by neglecting the temporal relation between
video frames and investigate the importance of each sensing modality in
detecting drives' activities. Experiments demonstrate that 1) our proposed
algorithms are real-time and can achieve similar performances (97.5\% AUC-PR)
with significantly reduced computation compared with video-based models; 2) the
top view with the infrared channel is more informative than any other single
modality. Furthermore, we enhance the DAD dataset by manually annotating its
test set to enable multiclassification. We also thoroughly analyze the
influence of visual sensor types and their placements on the prediction of each
class. The code and the new labels will be released."
Statistical guarantees for sparse deep learning,0.53075,"Neural networks are becoming increasingly popular in applications, but our
mathematical understanding of their potential and limitations is still limited.
In this paper, we further this understanding by developing statistical
guarantees for sparse deep learning. In contrast to previous work, we consider
different types of sparsity, such as few active connections, few active nodes,
and other norm-based types of sparsity. Moreover, our theories cover important
aspects that previous theories have neglected, such as multiple outputs,
regularization, and l2-loss. The guarantees have a mild dependence on network
widths and depths, which means that they support the application of sparse but
wide and deep networks from a statistical perspective. Some of the concepts and
tools that we use in our derivations are uncommon in deep learning and, hence,
might be of additional interest."
Query-based Instance Discrimination Network for Relational Triple Extraction,0.779479,"Joint entity and relation extraction has been a core task in the field of
information extraction. Recent approaches usually consider the extraction of
relational triples from a stereoscopic perspective, either learning a
relation-specific tagger or separate classifiers for each relation type.
However, they still suffer from error propagation, relation redundancy and lack
of high-level connections between triples. To address these issues, we propose
a novel query-based approach to construct instance-level representations for
relational triples. By metric-based comparison between query embeddings and
token embeddings, we can extract all types of triples in one step, thus
eliminating the error propagation problem. In addition, we learn the
instance-level representation of relational triples via contrastive learning.
In this way, relational triples can not only enclose rich class-level semantics
but also access to high-order global connections. Experimental results show
that our proposed method achieves the state of the art on five widely used
benchmarks."
Conv2Former: A Simple Transformer-Style ConvNet for Visual Recognition,0.798104,"This paper does not attempt to design a state-of-the-art method for visual
recognition but investigates a more efficient way to make use of convolutions
to encode spatial features. By comparing the design principles of the recent
convolutional neural networks ConvNets) and Vision Transformers, we propose to
simplify the self-attention by leveraging a convolutional modulation operation.
We show that such a simple approach can better take advantage of the large
kernels (>=7x7) nested in convolutional layers. We build a family of
hierarchical ConvNets using the proposed convolutional modulation, termed
Conv2Former. Our network is simple and easy to follow. Experiments show that
our Conv2Former outperforms existent popular ConvNets and vision Transformers,
like Swin Transformer and ConvNeXt in all ImageNet classification, COCO object
detection and ADE20k semantic segmentation."
CoAnnotating: Uncertainty-Guided Work Allocation between Human and Large Language Models for Data Annotation,0.587348,"Annotated data plays a critical role in Natural Language Processing (NLP) in
training models and evaluating their performance. Given recent developments in
Large Language Models (LLMs), models such as ChatGPT demonstrate zero-shot
capability on many text-annotation tasks, comparable with or even exceeding
human annotators. Such LLMs can serve as alternatives for manual annotation,
due to lower costs and higher scalability. However, limited work has leveraged
LLMs as complementary annotators, nor explored how annotation work is best
allocated among humans and LLMs to achieve both quality and cost objectives. We
propose CoAnnotating, a novel paradigm for Human-LLM co-annotation of
unstructured texts at scale. Under this framework, we utilize uncertainty to
estimate LLMs' annotation capability. Our empirical study shows CoAnnotating to
be an effective means to allocate work from results on different datasets, with
up to 21% performance improvement over random baseline. For code
implementation, see https://github.com/SALT-NLP/CoAnnotating."
MEIM: Multi-partition Embedding Interaction Beyond Block Term Format for Efficient and Expressive Link Prediction,0.644615,"Knowledge graph embedding aims to predict the missing relations between
entities in knowledge graphs. Tensor-decomposition-based models, such as
ComplEx, provide a good trade-off between efficiency and expressiveness, that
is crucial because of the large size of real world knowledge graphs. The recent
multi-partition embedding interaction (MEI) model subsumes these models by
using the block term tensor format and provides a systematic solution for the
trade-off. However, MEI has several drawbacks, some of which carried from its
subsumed tensor-decomposition-based models. In this paper, we address these
drawbacks and introduce the Multi-partition Embedding Interaction iMproved
beyond block term format (MEIM) model, with independent core tensor for
ensemble effects and soft orthogonality for max-rank mapping, in addition to
multi-partition embedding. MEIM improves expressiveness while still being
highly efficient, helping it to outperform strong baselines and achieve
state-of-the-art results on difficult link prediction benchmarks using fairly
small embedding sizes. The source code is released at
https://github.com/tranhungnghiep/MEIM-KGE."
Interactive Segmentation of Radiance Fields,0.837679,"Radiance Fields (RF) are popular to represent casually-captured scenes for
new view synthesis and several applications beyond it. Mixed reality on
personal spaces needs understanding and manipulating scenes represented as RFs,
with semantic segmentation of objects as an important step. Prior segmentation
efforts show promise but don't scale to complex objects with diverse
appearance. We present the ISRF method to interactively segment objects with
fine structure and appearance. Nearest neighbor feature matching using
distilled semantic features identifies high-confidence seed regions. Bilateral
search in a joint spatio-semantic space grows the region to recover accurate
segmentation. We show state-of-the-art results of segmenting objects from RFs
and compositing them to another scene, changing appearance, etc., and an
interactive segmentation tool that others can use.
  Project Page: https://rahul-goel.github.io/isrf/"
Can language models handle recursively nested grammatical structures? A case study on comparing models and humans,0.997492,"How should we compare the capabilities of language models (LMs) and humans? I
draw inspiration from comparative psychology to highlight some challenges. In
particular, I consider a case study: processing of recursively nested
grammatical structures. Prior work suggests that LMs cannot handle these
structures as reliably as humans can. However, the humans were provided with
instructions and training, while the LMs were evaluated zero-shot. I therefore
match the evaluation more closely. Providing large LMs with a simple prompt --
substantially less content than the human training -- allows the LMs to
consistently outperform the human results, and even to extrapolate to more
deeply nested conditions than were tested with humans. Further, reanalyzing the
prior human data suggests that the humans may not perform above chance at the
difficult structures initially. Thus, large LMs may indeed process recursively
nested grammatical structures as reliably as humans. This case study highlights
how discrepancies in the evaluation can confound comparisons of language models
and humans. I therefore reflect on the broader challenge of comparing human and
model capabilities, and highlight an important difference between evaluating
cognitive models and foundation models."
HumSet: Dataset of Multilingual Information Extraction and Classification for Humanitarian Crisis Response,0.42079,"Timely and effective response to humanitarian crises requires quick and
accurate analysis of large amounts of text data - a process that can highly
benefit from expert-assisted NLP systems trained on validated and annotated
data in the humanitarian response domain. To enable creation of such NLP
systems, we introduce and release HumSet, a novel and rich multilingual dataset
of humanitarian response documents annotated by experts in the humanitarian
response community. The dataset provides documents in three languages (English,
French, Spanish) and covers a variety of humanitarian crises from 2018 to 2021
across the globe. For each document, HUMSET provides selected snippets
(entries) as well as assigned classes to each entry annotated using common
humanitarian information analysis frameworks. HUMSET also provides novel and
challenging entry extraction and multi-label entry classification tasks. In
this paper, we take a first step towards approaching these tasks and conduct a
set of experiments on Pre-trained Language Models (PLM) to establish strong
baselines for future research in this domain. The dataset is available at
https://blog.thedeep.io/humset/."
Emergent Visual Sensors for Autonomous Vehicles,0.27962,"Autonomous vehicles rely on perception systems to understand their
surroundings for further navigation missions. Cameras are essential for
perception systems due to the advantages of object detection and recognition
provided by modern computer vision algorithms, comparing to other sensors, such
as LiDARs and radars. However, limited by its inherent imaging principle, a
standard RGB camera may perform poorly in a variety of adverse scenarios,
including but not limited to: low illumination, high contrast, bad weather such
as fog/rain/snow, etc. Meanwhile, estimating the 3D information from the 2D
image detection is generally more difficult when compared to LiDARs or radars.
Several new sensing technologies have emerged in recent years to address the
limitations of conventional RGB cameras. In this paper, we review the
principles of four novel image sensors: infrared cameras, range-gated cameras,
polarization cameras, and event cameras. Their comparative advantages, existing
or potential applications, and corresponding data processing algorithms are all
presented in a systematic manner. We expect that this study will assist
practitioners in the autonomous driving society with new perspectives and
insights."
Subgraph Neighboring Relations Infomax for Inductive Link Prediction on Knowledge Graphs,0.910693,"Inductive link prediction for knowledge graph aims at predicting missing
links between unseen entities, those not shown in training stage. Most previous
works learn entity-specific embeddings of entities, which cannot handle unseen
entities. Recent several methods utilize enclosing subgraph to obtain inductive
ability. However, all these works only consider the enclosing part of subgraph
without complete neighboring relations, which leads to the issue that partial
neighboring relations are neglected, and sparse subgraphs are hard to be
handled. To address that, we propose Subgraph Neighboring Relations Infomax,
SNRI, which sufficiently exploits complete neighboring relations from two
aspects: neighboring relational feature for node feature and neighboring
relational path for sparse subgraph. To further model neighboring relations in
a global way, we innovatively apply mutual information (MI) maximization for
knowledge graph. Experiments show that SNRI outperforms existing state-of-art
methods by a large margin on inductive link prediction task, and verify the
effectiveness of exploring complete neighboring relations in a global way to
characterize node features and reason on sparse subgraphs."
Conditional Generation of Audio from Video via Foley Analogies,0.437592,"The sound effects that designers add to videos are designed to convey a
particular artistic effect and, thus, may be quite different from a scene's
true sound. Inspired by the challenges of creating a soundtrack for a video
that differs from its true sound, but that nonetheless matches the actions
occurring on screen, we propose the problem of conditional Foley. We present
the following contributions to address this problem. First, we propose a
pretext task for training our model to predict sound for an input video clip
using a conditional audio-visual clip sampled from another time within the same
source video. Second, we propose a model for generating a soundtrack for a
silent input video, given a user-supplied example that specifies what the video
should ""sound like"". We show through human studies and automated evaluation
metrics that our model successfully generates sound from video, while varying
its output according to the content of a supplied example. Project site:
https://xypb.github.io/CondFoleyGen/"
Learning Attention as Disentangler for Compositional Zero-shot Learning,0.309626,"Compositional zero-shot learning (CZSL) aims at learning visual concepts
(i.e., attributes and objects) from seen compositions and combining concept
knowledge into unseen compositions. The key to CZSL is learning the
disentanglement of the attribute-object composition. To this end, we propose to
exploit cross-attentions as compositional disentanglers to learn disentangled
concept embeddings. For example, if we want to recognize an unseen composition
""yellow flower"", we can learn the attribute concept ""yellow"" and object concept
""flower"" from different yellow objects and different flowers respectively. To
further constrain the disentanglers to learn the concept of interest, we employ
a regularization at the attention level. Specifically, we adapt the earth
mover's distance (EMD) as a feature similarity metric in the cross-attention
module. Moreover, benefiting from concept disentanglement, we improve the
inference process and tune the prediction score by combining multiple concept
probabilities. Comprehensive experiments on three CZSL benchmark datasets
demonstrate that our method significantly outperforms previous works in both
closed- and open-world settings, establishing a new state-of-the-art."
MVP: Robust Multi-View Practice for Driving Action Localization,0.235166,"Distracted driving causes thousands of deaths per year, and how to apply
deep-learning methods to prevent these tragedies has become a crucial problem.
In Track3 of the 6th AI City Challenge, researchers provide a high-quality
video dataset with densely action annotations. Due to the small data scale and
unclear action boundary, the dataset presents a unique challenge to precisely
localize all the different actions and classify their categories. In this
paper, we make good use of the multi-view synchronization among videos, and
conduct robust Multi-View Practice (MVP) for driving action localization. To
avoid overfitting, we fine-tune SlowFast with Kinetics-700 pre-training as the
feature extractor. Then the features of different views are passed to
ActionFormer to generate candidate action proposals. For precisely localizing
all the actions, we design elaborate post-processing, including model voting,
threshold filtering and duplication removal. The results show that our MVP is
robust for driving action localization, which achieves 28.49% F1-score in the
Track3 test set."
Construction of English Resume Corpus and Test with Pre-trained Language Models,0.031063,"Information extraction(IE) has always been one of the essential tasks of NLP.
Moreover, one of the most critical application scenarios of information
extraction is the information extraction of resumes. Constructed text is
obtained by classifying each part of the resume. It is convenient to store
these texts for later search and analysis. Furthermore, the constructed resume
data can also be used in the AI resume screening system. Significantly reduce
the labor cost of HR. This study aims to transform the information extraction
task of resumes into a simple sentence classification task. Based on the
English resume dataset produced by the prior study. The classification rules
are improved to create a larger and more fine-grained classification dataset of
resumes. This corpus is also used to test some current mainstream Pre-training
language models (PLMs) performance.Furthermore, in order to explore the
relationship between the number of training samples and the correctness rate of
the resume dataset, we also performed comparison experiments with training sets
of different train set sizes.The final multiple experimental results show that
the resume dataset with improved annotation rules and increased sample size of
the dataset improves the accuracy of the original resume dataset."
SMTCE: A Social Media Text Classification Evaluation Benchmark and BERTology Models for Vietnamese,0.501323,"Text classification is a typical natural language processing or computational
linguistics task with various interesting applications. As the number of users
on social media platforms increases, data acceleration promotes emerging
studies on Social Media Text Classification (SMTC) or social media text mining
on these valuable resources. In contrast to English, Vietnamese, one of the
low-resource languages, is still not concentrated on and exploited thoroughly.
Inspired by the success of the GLUE, we introduce the Social Media Text
Classification Evaluation (SMTCE) benchmark, as a collection of datasets and
models across a diverse set of SMTC tasks. With the proposed benchmark, we
implement and analyze the effectiveness of a variety of multilingual BERT-based
models (mBERT, XLM-R, and DistilmBERT) and monolingual BERT-based models
(PhoBERT, viBERT, vELECTRA, and viBERT4news) for tasks in the SMTCE benchmark.
Monolingual models outperform multilingual models and achieve state-of-the-art
results on all text classification tasks. It provides an objective assessment
of multilingual and monolingual BERT-based models on the benchmark, which will
benefit future studies about BERTology in the Vietnamese language."
Model Attribution of Face-swap Deepfake Videos,0.222591,"AI-created face-swap videos, commonly known as Deepfakes, have attracted wide
attention as powerful impersonation attacks. Existing research on Deepfakes
mostly focuses on binary detection to distinguish between real and fake videos.
However, it is also important to determine the specific generation model for a
fake video, which can help attribute it to the source for forensic
investigation. In this paper, we fill this gap by studying the model
attribution problem of Deepfake videos. We first introduce a new dataset with
DeepFakes from Different Models (DFDM) based on several Autoencoder models.
Specifically, five generation models with variations in encoder, decoder,
intermediate layer, input resolution, and compression ratio have been used to
generate a total of 6,450 Deepfake videos based on the same input. Then we take
Deepfakes model attribution as a multiclass classification task and propose a
spatial and temporal attention based method to explore the differences among
Deepfakes in the new dataset. Experimental evaluation shows that most existing
Deepfakes detection methods failed in Deepfakes model attribution, while the
proposed method achieved over 70% accuracy on the high-quality DFDM dataset."
Learning Cross-view Geo-localization Embeddings via Dynamic Weighted Decorrelation Regularization,0.816313,"Cross-view geo-localization aims to spot images of the same location shot
from two platforms, e.g., the drone platform and the satellite platform.
Existing methods usually focus on optimizing the distance between one embedding
with others in the feature space, while neglecting the redundancy of the
embedding itself. In this paper, we argue that the low redundancy is also of
importance, which motivates the model to mine more diverse patterns. To verify
this point, we introduce a simple yet effective regularization, i.e., Dynamic
Weighted Decorrelation Regularization (DWDR), to explicitly encourage networks
to learn independent embedding channels. As the name implies, DWDR regresses
the embedding correlation coefficient matrix to a sparse matrix, i.e., the
identity matrix, with dynamic weights. The dynamic weights are applied to focus
on still correlated channels during training. Besides, we propose a cross-view
symmetric sampling strategy, which keeps the example balance between different
platforms. Albeit simple, the proposed method has achieved competitive results
on three large-scale benchmarks, i.e., University-1652, CVUSA and CVACT.
Moreover, under the harsh circumstance, e.g., the extremely short feature of 64
dimensions, the proposed method surpasses the baseline model by a clear margin."
Learning to Compress Prompts with Gist Tokens,0.774314,"Prompting is the primary way to utilize the multitask capabilities of
language models (LMs), but prompts occupy valuable space in the input context
window, and repeatedly encoding the same prompt is computationally inefficient.
Finetuning and distillation methods allow for specialization of LMs without
prompting, but require retraining the model for each task. To avoid this
trade-off entirely, we present gisting, which trains an LM to compress prompts
into smaller sets of ""gist"" tokens which can be cached and reused for compute
efficiency. Gist models can be trained with no additional cost over standard
instruction finetuning by simply modifying Transformer attention masks to
encourage prompt compression. On decoder (LLaMA-7B) and encoder-decoder
(FLAN-T5-XXL) LMs, gisting enables up to 26x compression of prompts, resulting
in up to 40% FLOPs reductions, 4.2% wall time speedups, and storage savings,
all with minimal loss in output quality."
MeetEval: A Toolkit for Computation of Word Error Rates for Meeting Transcription Systems,0.736872,"MeetEval is an open-source toolkit to evaluate all kinds of meeting
transcription systems. It provides a unified interface for the computation of
commonly used Word Error Rates (WERs), specifically cpWER, ORC-WER and MIMO-WER
along other WER definitions. We extend the cpWER computation by a temporal
constraint to ensure that only words are identified as correct when the
temporal alignment is plausible. This leads to a better quality of the matching
of the hypothesis string to the reference string that more closely resembles
the actual transcription quality, and a system is penalized if it provides poor
time annotations. Since word-level timing information is often not available,
we present a way to approximate exact word-level timings from segment-level
timings (e.g., a sentence) and show that the approximation leads to a similar
WER as a matching with exact word-level annotations. At the same time, the time
constraint leads to a speedup of the matching algorithm, which outweighs the
additional overhead caused by processing the time stamps."
A New Generation of Perspective API: Efficient Multilingual Character-level Transformers,0.997785,"On the world wide web, toxic content detectors are a crucial line of defense
against potentially hateful and offensive messages. As such, building highly
effective classifiers that enable a safer internet is an important research
area. Moreover, the web is a highly multilingual, cross-cultural community that
develops its own lingo over time. As such, it is crucial to develop models that
are effective across a diverse range of languages, usages, and styles. In this
paper, we present the fundamentals behind the next version of the Perspective
API from Google Jigsaw. At the heart of the approach is a single multilingual
token-free Charformer model that is applicable across a range of languages,
domains, and tasks. We demonstrate that by forgoing static vocabularies, we
gain flexibility across a variety of settings. We additionally outline the
techniques employed to make such a byte-level model efficient and feasible for
productionization. Through extensive experiments on multilingual toxic comment
classification benchmarks derived from real API traffic and evaluation on an
array of code-switching, covert toxicity, emoji-based hate, human-readable
obfuscation, distribution shift, and bias evaluation settings, we show that our
proposed approach outperforms strong baselines. Finally, we present our
findings from deploying this system in production."
Apple of Sodom: Hidden Backdoors in Superior Sentence Embeddings via Contrastive Learning,0.0352784,"This paper finds that contrastive learning can produce superior sentence
embeddings for pre-trained models but is also vulnerable to backdoor attacks.
We present the first backdoor attack framework, BadCSE, for state-of-the-art
sentence embeddings under supervised and unsupervised learning settings. The
attack manipulates the construction of positive and negative pairs so that the
backdoored samples have a similar embedding with the target sample (targeted
attack) or the negative embedding of its clean version (non-targeted attack).
By injecting the backdoor in sentence embeddings, BadCSE is resistant against
downstream fine-tuning. We evaluate BadCSE on both STS tasks and other
downstream tasks. The supervised non-targeted attack obtains a performance
degradation of 194.86%, and the targeted attack maps the backdoored samples to
the target embedding with a 97.70% success rate while maintaining the model
utility."
TransLog: A Unified Transformer-based Framework for Log Anomaly Detection,0.483908,"Log anomaly detection is a key component in the field of artificial
intelligence for IT operations (AIOps). Considering log data of variant
domains, retraining the whole network for unknown domains is inefficient in
real industrial scenarios especially for low-resource domains. However,
previous deep models merely focused on extracting the semantics of log sequence
in the same domain, leading to poor generalization on multi-domain logs.
Therefore, we propose a unified Transformer-based framework for log anomaly
detection (\ourmethod{}), which is comprised of the pretraining and
adapter-based tuning stage. Our model is first pretrained on the source domain
to obtain shared semantic knowledge of log data. Then, we transfer the
pretrained model to the target domain via the adapter-based tuning. The
proposed method is evaluated on three public datasets including one source
domain and two target domains. The experimental results demonstrate that our
simple yet efficient approach, with fewer trainable parameters and lower
training costs in the target domain, achieves state-of-the-art performance on
three benchmarks."
Large Language Models as Topological Structure Enhancers for Text-Attributed Graphs,0.607936,"The latest advancements in large language models (LLMs) have revolutionized
the field of natural language processing (NLP). Inspired by the success of LLMs
in NLP tasks, some recent work has begun investigating the potential of
applying LLMs in graph learning tasks. However, most of the existing work
focuses on utilizing LLMs as powerful node feature augmenters, leaving
employing LLMs to enhance graph topological structures an understudied problem.
In this work, we explore how to leverage the information retrieval and text
generation capabilities of LLMs to refine/enhance the topological structure of
text-attributed graphs (TAGs) under the node classification setting. First, we
propose using LLMs to help remove unreliable edges and add reliable ones in the
TAG. Specifically, we first let the LLM output the semantic similarity between
node attributes through delicate prompt designs, and then perform edge deletion
and edge addition based on the similarity. Second, we propose using
pseudo-labels generated by the LLM to improve graph topology, that is, we
introduce the pseudo-label propagation as a regularization to guide the graph
neural network (GNN) in learning proper edge weights. Finally, we incorporate
the two aforementioned LLM-based methods for graph topological refinement into
the process of GNN training, and perform extensive experiments on four
real-world datasets. The experimental results demonstrate the effectiveness of
LLM-based graph topology refinement (achieving a 0.15%--2.47% performance gain
on public benchmarks)."
Relational Message Passing for Fully Inductive Knowledge Graph Completion,0.93954,"In knowledge graph completion (KGC), predicting triples involving emerging
entities and/or relations, which are unseen when the KG embeddings are learned,
has become a critical challenge. Subgraph reasoning with message passing is a
promising and popular solution. Some recent methods have achieved good
performance, but they (i) usually can only predict triples involving unseen
entities alone, failing to address more realistic fully inductive situations
with both unseen entities and unseen relations, and (ii) often conduct message
passing over the entities with the relation patterns not fully utilized. In
this study, we propose a new method named RMPI which uses a novel Relational
Message Passing network for fully Inductive KGC. It passes messages directly
between relations to make full use of the relation patterns for subgraph
reasoning with new techniques on graph transformation, graph pruning,
relation-aware neighborhood attention, addressing empty subgraphs, etc., and
can utilize the relation semantics defined in the ontological schema of KG.
Extensive evaluation on multiple benchmarks has shown the effectiveness of
techniques involved in RMPI and its better performance compared with the
existing methods that support fully inductive KGC. RMPI is also comparable to
the state-of-the-art partially inductive KGC methods with very promising
results achieved. Our codes and data are available at
https://github.com/zjukg/RMPI."
Adaptive Local-Component-aware Graph Convolutional Network for One-shot Skeleton-based Action Recognition,0.721547,"Skeleton-based action recognition receives increasing attention because the
skeleton representations reduce the amount of training data by eliminating
visual information irrelevant to actions. To further improve the sample
efficiency, meta-learning-based one-shot learning solutions were developed for
skeleton-based action recognition. These methods find the nearest neighbor
according to the similarity between instance-level global average embedding.
However, such measurement holds unstable representativity due to inadequate
generalized learning on local invariant and noisy features, while intuitively,
more fine-grained recognition usually relies on determining key local body
movements. To address this limitation, we present the Adaptive
Local-Component-aware Graph Convolutional Network, which replaces the
comparison metric with a focused sum of similarity measurements on aligned
local embedding of action-critical spatial/temporal segments. Comprehensive
one-shot experiments on the public benchmark of NTU-RGB+D 120 indicate that our
method provides a stronger representation than the global embedding and helps
our model reach state-of-the-art."
Synthehicle: Multi-Vehicle Multi-Camera Tracking in Virtual Cities,0.820029,"Smart City applications such as intelligent traffic routing or accident
prevention rely on computer vision methods for exact vehicle localization and
tracking. Due to the scarcity of accurately labeled data, detecting and
tracking vehicles in 3D from multiple cameras proves challenging to explore. We
present a massive synthetic dataset for multiple vehicle tracking and
segmentation in multiple overlapping and non-overlapping camera views. Unlike
existing datasets, which only provide tracking ground truth for 2D bounding
boxes, our dataset additionally contains perfect labels for 3D bounding boxes
in camera- and world coordinates, depth estimation, and instance, semantic and
panoptic segmentation. The dataset consists of 17 hours of labeled video
material, recorded from 340 cameras in 64 diverse day, rain, dawn, and night
scenes, making it the most extensive dataset for multi-target multi-camera
tracking so far. We provide baselines for detection, vehicle re-identification,
and single- and multi-camera tracking. Code and data are publicly available."
Deconstructing deep active inference,0.108445,"Active inference is a theory of perception, learning and decision making,
which can be applied to neuroscience, robotics, and machine learning. Recently,
reasearch has been taking place to scale up this framework using Monte-Carlo
tree search and deep learning. The goal of this activity is to solve more
complicated tasks using deep active inference. First, we review the existing
literature, then, we progresively build a deep active inference agent. For two
agents, we have experimented with five definitions of the expected free energy
and three different action selection strategies. According to our experiments,
the models able to solve the dSprites environment are the ones that maximise
rewards. Finally, we compare the similarity of the representation learned by
the layers of various agents using centered kernel alignment. Importantly, the
agent maximising reward and the agent minimising expected free energy learn
very similar representations except for the last layer of the critic network
(reflecting the difference in learning objective), and the variance layers of
the transition and encoder networks. We found that the reward maximising agent
is a lot more certain than the agent minimising expected free energy. This is
because the agent minimising expected free energy always picks the action down,
and does not gather enough data for the other actions. In contrast, the agent
maximising reward, keeps on selecting the actions left and right, enabling it
to successfully solve the task. The only difference between those two agents is
the epistemic value, which aims to make the outputs of the transition and
encoder networks as close as possible. Thus, the agent minimising expected free
energy picks a single action (down), and becomes an expert at predicting the
future when selecting this action. This makes the KL divergence between the
output of the transition and encoder networks small."
DFormer: Diffusion-guided Transformer for Universal Image Segmentation,0.318751,"This paper introduces an approach, named DFormer, for universal image
segmentation. The proposed DFormer views universal image segmentation task as a
denoising process using a diffusion model. DFormer first adds various levels of
Gaussian noise to ground-truth masks, and then learns a model to predict
denoising masks from corrupted masks. Specifically, we take deep pixel-level
features along with the noisy masks as inputs to generate mask features and
attention masks, employing diffusion-based decoder to perform mask prediction
gradually. At inference, our DFormer directly predicts the masks and
corresponding categories from a set of randomly-generated masks. Extensive
experiments reveal the merits of our proposed contributions on different image
segmentation tasks: panoptic segmentation, instance segmentation, and semantic
segmentation. Our DFormer outperforms the recent diffusion-based panoptic
segmentation method Pix2Seq-D with a gain of 3.6% on MS COCO val2017 set.
Further, DFormer achieves promising semantic segmentation performance
outperforming the recent diffusion-based method by 2.2% on ADE20K val set. Our
source code and models will be publicly on https://github.com/cp3wan/DFormer"
Learning Universal Policies via Text-Guided Video Generation,0.975186,"A goal of artificial intelligence is to construct an agent that can solve a
wide variety of tasks. Recent progress in text-guided image synthesis has
yielded models with an impressive ability to generate complex novel images,
exhibiting combinatorial generalization across domains. Motivated by this
success, we investigate whether such tools can be used to construct more
general-purpose agents. Specifically, we cast the sequential decision making
problem as a text-conditioned video generation problem, where, given a
text-encoded specification of a desired goal, a planner synthesizes a set of
future frames depicting its planned actions in the future, after which control
actions are extracted from the generated video. By leveraging text as the
underlying goal specification, we are able to naturally and combinatorially
generalize to novel goals. The proposed policy-as-video formulation can further
represent environments with different state and action spaces in a unified
space of images, which, for example, enables learning and generalization across
a variety of robot manipulation tasks. Finally, by leveraging pretrained
language embeddings and widely available videos from the internet, the approach
enables knowledge transfer through predicting highly realistic video plans for
real robots."
FinVis-GPT: A Multimodal Large Language Model for Financial Chart Analysis,0.666602,"In this paper, we propose FinVis-GPT, a novel multimodal large language model
(LLM) specifically designed for financial chart analysis. By leveraging the
power of LLMs and incorporating instruction tuning and multimodal capabilities,
FinVis-GPT is capable of interpreting financial charts and providing valuable
analysis. To train FinVis-GPT, a financial task oriented dataset was generated
for pre-training alignment and instruction tuning, comprising various types of
financial charts and their corresponding descriptions. We evaluate the model
performance via several case studies due to the time limit, and the promising
results demonstrated that FinVis-GPT is superior in various financial chart
related tasks, including generating descriptions, answering questions and
predicting future market trends, surpassing existing state-of-the-art
multimodal LLMs. The proposed FinVis-GPT serves as a pioneering effort in
utilizing multimodal LLMs in the finance domain and our generated dataset will
be release for public use in the near future to speedup related research."
Local Directional Gradient Pattern: A Local Descriptor for Face Recognition,0.915713,"In this paper a local pattern descriptor in high order derivative space is
proposed for face recognition. The proposed local directional gradient pattern
(LDGP) is a 1D local micropattern computed by encoding the relationships
between the higher order derivatives of the reference pixel in four distinct
directions. The proposed descriptor identifies the relationship between the
high order derivatives of the referenced pixel in four different directions to
compute the micropattern which corresponds to the local feature. Proposed
descriptor considerably reduces the length of the micropattern which
consequently reduces the extraction time and matching time while maintaining
the recognition rate. Results of the extensive experiments conducted on
benchmark databases AT&T, Extended Yale B and CMU-PIE show that the proposed
descriptor significantly reduces the extraction as well as matching time while
the recognition rate is almost similar to the existing state of the art
methods."
PlanBench: An Extensible Benchmark for Evaluating Large Language Models on Planning and Reasoning about Change,0.999292,"Generating plans of action, and reasoning about change have long been
considered a core competence of intelligent agents. It is thus no surprise that
evaluating the planning and reasoning capabilities of large language models
(LLMs) has become a hot topic of research. Most claims about LLM planning
capabilities are however based on common sense tasks-where it becomes hard to
tell whether LLMs are planning or merely retrieving from their vast world
knowledge. There is a strong need for systematic and extensible planning
benchmarks with sufficient diversity to evaluate whether LLMs have innate
planning capabilities. Motivated by this, we propose PlanBench, an extensible
benchmark suite based on the kinds of domains used in the automated planning
community, especially in the International Planning Competition, to test the
capabilities of LLMs in planning or reasoning about actions and change.
PlanBench provides sufficient diversity in both the task domains and the
specific planning capabilities. Our studies also show that on many critical
capabilities-including plan generation-LLM performance falls quite short, even
with the SOTA models. PlanBench can thus function as a useful marker of
progress of LLMs in planning and reasoning."
Maze Learning using a Hyperdimensional Predictive Processing Cognitive Architecture,0.399824,"We present the COGnitive Neural GENerative system (CogNGen), a cognitive
architecture that combines two neurobiologically-plausible, computational
models: predictive processing and hyperdimensional/vector-symbolic models. We
draw inspiration from architectures such as ACT-R and Spaun/Nengo. CogNGen is
in broad agreement with these, providing a level of detail between ACT-R's
high-level symbolic description of human cognition and Spaun's low-level
neurobiological description, furthermore creating the groundwork for designing
agents that learn continually from diverse tasks and model human performance at
larger scales than what is possible with current systems. We test CogNGen on
four maze-learning tasks, including those that test memory and planning, and
find that CogNGen matches performance of deep reinforcement learning models and
exceeds on a task designed to test memory."
Image Masking for Robust Self-Supervised Monocular Depth Estimation,0.521766,"Self-supervised monocular depth estimation is a salient task for 3D scene
understanding. Learned jointly with monocular ego-motion estimation, several
methods have been proposed to predict accurate pixel-wise depth without using
labeled data. Nevertheless, these methods focus on improving performance under
ideal conditions without natural or digital corruptions. The general absence of
occlusions is assumed even for object-specific depth estimation. These methods
are also vulnerable to adversarial attacks, which is a pertinent concern for
their reliable deployment in robots and autonomous driving systems. We propose
MIMDepth, a method that adapts masked image modeling (MIM) for self-supervised
monocular depth estimation. While MIM has been used to learn generalizable
features during pre-training, we show how it could be adapted for direct
training of monocular depth estimation. Our experiments show that MIMDepth is
more robust to noise, blur, weather conditions, digital artifacts, occlusions,
as well as untargeted and targeted adversarial attacks."
Summarizing a virtual robot's past actions in natural language,0.229636,"We propose and demonstrate the task of giving natural language summaries of
the actions of a robotic agent in a virtual environment. We explain why such a
task is important, what makes it difficult, and discuss how it might be
addressed. To encourage others to work on this, we show how a popular existing
dataset that matches robot actions with natural language descriptions designed
for an instruction following task can be repurposed to serve as a training
ground for robot action summarization work. We propose and test several methods
of learning to generate such summaries, starting from either egocentric video
frames of the robot taking actions or intermediate text representations of the
actions used by an automatic planner. We provide quantitative and qualitative
evaluations of our results, which can serve as a baseline for future work."
Fast Point Cloud Generation with Straight Flows,0.708762,"Diffusion models have emerged as a powerful tool for point cloud generation.
A key component that drives the impressive performance for generating
high-quality samples from noise is iteratively denoise for thousands of steps.
While beneficial, the complexity of learning steps has limited its applications
to many 3D real-world. To address this limitation, we propose Point Straight
Flow (PSF), a model that exhibits impressive performance using one step. Our
idea is based on the reformulation of the standard diffusion model, which
optimizes the curvy learning trajectory into a straight path. Further, we
develop a distillation strategy to shorten the straight path into one step
without a performance loss, enabling applications to 3D real-world with latency
constraints. We perform evaluations on multiple 3D tasks and find that our PSF
performs comparably to the standard diffusion model, outperforming other
efficient 3D point cloud generation methods. On real-world applications such as
point cloud completion and training-free text-guided generation in a
low-latency setup, PSF performs favorably."
Structure Extraction in Task-Oriented Dialogues with Slot Clustering,0.28447,"Extracting structure information from dialogue data can help us better
understand user and system behaviors. In task-oriented dialogues, dialogue
structure has often been considered as transition graphs among dialogue states.
However, annotating dialogue states manually is expensive and time-consuming.
In this paper, we propose a simple yet effective approach for structure
extraction in task-oriented dialogues. We first detect and cluster possible
slot tokens with a pre-trained model to approximate dialogue ontology for a
target domain. Then we track the status of each identified token group and
derive a state transition structure. Empirical results show that our approach
outperforms unsupervised baseline models by far in dialogue structure
extraction. In addition, we show that data augmentation based on extracted
structures enriches the surface formats of training data and can achieve a
significant performance boost in dialogue response generation."
Boosting 3D Adversarial Attacks with Attacking On Frequency,0.648193,"Deep neural networks (DNNs) have been shown to be vulnerable to adversarial
attacks. Recently, 3D adversarial attacks, especially adversarial attacks on
point clouds, have elicited mounting interest. However, adversarial point
clouds obtained by previous methods show weak transferability and are easy to
defend. To address these problems, in this paper we propose a novel point cloud
attack (dubbed AOF) that pays more attention on the low-frequency component of
point clouds. We combine the losses from point cloud and its low-frequency
component to craft adversarial samples. Extensive experiments validate that AOF
can improve the transferability significantly compared to state-of-the-art
(SOTA) attacks, and is more robust to SOTA 3D defense methods. Otherwise,
compared to clean point clouds, adversarial point clouds obtained by AOF
contain more deformation than outlier."
Cost-Effective Online Contextual Model Selection,0.583542,"How can we collect the most useful labels to learn a model selection policy,
when presented with arbitrary heterogeneous data streams? In this paper, we
formulate this task as an online contextual active model selection problem,
where at each round the learner receives an unlabeled data point along with a
context. The goal is to output the best model for any given context without
obtaining an excessive amount of labels. In particular, we focus on the task of
selecting pre-trained classifiers, and propose a contextual active model
selection algorithm (CAMS), which relies on a novel uncertainty sampling query
criterion defined on a given policy class for adaptive model selection. In
comparison to prior art, our algorithm does not assume a globally optimal
model. We provide rigorous theoretical analysis for the regret and query
complexity under both adversarial and stochastic settings. Our experiments on
several benchmark classification datasets demonstrate the algorithm's
effectiveness in terms of both regret and query complexity. Notably, to achieve
the same accuracy, CAMS incurs less than 10% of the label cost when compared to
the best online model selection baselines on CIFAR10."
Does Corpus Quality Really Matter for Low-Resource Languages?,0.326311,"The vast majority of non-English corpora are derived from automatically
filtered versions of CommonCrawl. While prior work has identified major issues
on the quality of these datasets (Kreutzer et al., 2021), it is not clear how
this impacts downstream performance. Taking representation learning in Basque
as a case study, we explore tailored crawling (manually identifying and
scraping websites with high-quality content) as an alternative to filtering
CommonCrawl. Our new corpus, called EusCrawl, is similar in size to the Basque
portion of popular multilingual corpora like CC100 and mC4, yet it has a much
higher quality according to native annotators. For instance, 66% of documents
are rated as high-quality for EusCrawl, in contrast with <33% for both mC4 and
CC100. Nevertheless, we obtain similar results on downstream NLU tasks
regardless of the corpus used for pre-training. Our work suggests that NLU
performance in low-resource languages is not primarily constrained by the
quality of the data, and other factors like corpus size and domain coverage can
play a more important role."
MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models,0.98973,"Large language models (LLMs) have achieved remarkable performance in natural
language understanding and generation tasks. However, they often suffer from
limitations such as difficulty in incorporating new knowledge, generating
hallucinations, and explaining their reasoning process. To address these
challenges, we propose a novel prompting pipeline, named \method, that
leverages knowledge graphs (KGs) to enhance LLMs' inference and transparency.
Our method enables LLMs to comprehend KG inputs and infer with a combination of
implicit and external knowledge. Moreover, our method elicits the mind map of
LLMs, which reveals their reasoning pathways based on the ontology of
knowledge. We evaluate our method on diverse question \& answering tasks,
especially in medical domains, and show significant improvements over
baselines. We also introduce a new hallucination evaluation benchmark and
analyze the effects of different components of our method. Our results
demonstrate the effectiveness and robustness of our method in merging knowledge
from LLMs and KGs for combined inference. To reproduce our results and extend
the framework further, we make our codebase available at
https://github.com/wyl-willing/MindMap."
Emotionally Enhanced Talking Face Generation,0.609572,"Several works have developed end-to-end pipelines for generating lip-synced
talking faces with various real-world applications, such as teaching and
language translation in videos. However, these prior works fail to create
realistic-looking videos since they focus little on people's expressions and
emotions. Moreover, these methods' effectiveness largely depends on the faces
in the training dataset, which means they may not perform well on unseen faces.
To mitigate this, we build a talking face generation framework conditioned on a
categorical emotion to generate videos with appropriate expressions, making
them more realistic and convincing. With a broad range of six emotions, i.e.,
\emph{happiness}, \emph{sadness}, \emph{fear}, \emph{anger}, \emph{disgust},
and \emph{neutral}, we show that our model can adapt to arbitrary identities,
emotions, and languages. Our proposed framework is equipped with a
user-friendly web interface with a real-time experience for talking face
generation with emotions. We also conduct a user study for subjective
evaluation of our interface's usability, design, and functionality. Project
page: https://midas.iiitd.edu.in/emo/"
MEKER: Memory Efficient Knowledge Embedding Representation for Link Prediction and Question Answering,0.398163,"Knowledge Graphs (KGs) are symbolically structured storages of facts. The KG
embedding contains concise data used in NLP tasks requiring implicit
information about the real world. Furthermore, the size of KGs that may be
useful in actual NLP assignments is enormous, and creating embedding over it
has memory cost issues. We represent KG as a 3rd-order binary tensor and move
beyond the standard CP decomposition by using a data-specific generalized
version of it. The generalization of the standard CP-ALS algorithm allows
obtaining optimization gradients without a backpropagation mechanism. It
reduces the memory needed in training while providing computational benefits.
We propose a MEKER, a memory-efficient KG embedding model, which yields
SOTA-comparable performance on link prediction tasks and KG-based Question
Answering."
Practice Makes a Solver Perfect: Data Augmentation for Math Word Problem Solvers,0.588761,"Existing Math Word Problem (MWP) solvers have achieved high accuracy on
benchmark datasets. However, prior works have shown that such solvers do not
generalize well and rely on superficial cues to achieve high performance. In
this paper, we first conduct experiments to showcase that this behaviour is
mainly associated with the limited size and diversity present in existing MWP
datasets. Next, we propose several data augmentation techniques broadly
categorized into Substitution and Paraphrasing based methods. By deploying
these methods we increase the size of existing datasets by five folds.
Extensive experiments on two benchmark datasets across three state-of-the-art
MWP solvers show that proposed methods increase the generalization and
robustness of existing solvers. On average, proposed methods significantly
increase the state-of-the-art results by over five percentage points on
benchmark datasets. Further, the solvers trained on the augmented dataset
perform comparatively better on the challenge test set. We also show the
effectiveness of proposed techniques through ablation studies and verify the
quality of augmented samples through human evaluation."
Differentiable Dynamics for Articulated 3d Human Motion Reconstruction,0.879224,"We introduce DiffPhy, a differentiable physics-based model for articulated 3d
human motion reconstruction from video. Applications of physics-based reasoning
in human motion analysis have so far been limited, both by the complexity of
constructing adequate physical models of articulated human motion, and by the
formidable challenges of performing stable and efficient inference with physics
in the loop. We jointly address such modeling and inference challenges by
proposing an approach that combines a physically plausible body representation
with anatomical joint limits, a differentiable physics simulator, and
optimization techniques that ensure good performance and robustness to
suboptimal local optima. In contrast to several recent methods, our approach
readily supports full-body contact including interactions with objects in the
scene. Most importantly, our model connects end-to-end with images, thus
supporting direct gradient-based physics optimization by means of image-based
loss functions. We validate the model by demonstrating that it can accurately
reconstruct physically plausible 3d human motion from monocular video, both on
public benchmarks with available 3d ground-truth, and on videos from the
internet."
"Expository Text Generation: Imitate, Retrieve, Paraphrase",0.0573156,"Expository documents are vital resources for conveying complex information to
readers. Despite their usefulness, writing expository text by hand is a
challenging process that requires careful content planning, obtaining facts
from multiple sources, and the ability to clearly synthesize these facts. To
ease these burdens, we propose the task of expository text generation, which
seeks to automatically generate an accurate and stylistically consistent
expository text for a topic by intelligently searching a knowledge source. We
solve our task by developing IRP, a framework that overcomes the limitations of
retrieval-augmented models and iteratively performs content planning, fact
retrieval, and rephrasing. Through experiments on three diverse,
newly-collected datasets, we show that IRP produces factual and organized
expository texts that accurately inform readers."
Continuous diffusion for categorical data,0.57931,"Diffusion models have quickly become the go-to paradigm for generative
modelling of perceptual signals (such as images and sound) through iterative
refinement. Their success hinges on the fact that the underlying physical
phenomena are continuous. For inherently discrete and categorical data such as
language, various diffusion-inspired alternatives have been proposed. However,
the continuous nature of diffusion models conveys many benefits, and in this
work we endeavour to preserve it. We propose CDCD, a framework for modelling
categorical data with diffusion models that are continuous both in time and
input space. We demonstrate its efficacy on several language modelling tasks."
Artificial Intelligence and Auction Design,0.94418,"Motivated by online advertising auctions, we study auction design in repeated
auctions played by simple Artificial Intelligence algorithms (Q-learning). We
find that first-price auctions with no additional feedback lead to
tacit-collusive outcomes (bids lower than values), while second-price auctions
do not. We show that the difference is driven by the incentive in first-price
auctions to outbid opponents by just one bid increment. This facilitates
re-coordination on low bids after a phase of experimentation. We also show that
providing information about lowest bid to win, as introduced by Google at the
time of switch to first-price auctions, increases competitiveness of auctions."
Humanoid Agents: Platform for Simulating Human-like Generative Agents,0.697962,"Just as computational simulations of atoms, molecules and cells have shaped
the way we study the sciences, true-to-life simulations of human-like agents
can be valuable tools for studying human behavior. We propose Humanoid Agents,
a system that guides Generative Agents to behave more like humans by
introducing three elements of System 1 processing: Basic needs (e.g. hunger,
health and energy), Emotion and Closeness in Relationships. Humanoid Agents are
able to use these dynamic elements to adapt their daily activities and
conversations with other agents, as supported with empirical experiments. Our
system is designed to be extensible to various settings, three of which we
demonstrate, as well as to other elements influencing human behavior (e.g.
empathy, moral values and cultural background). Our platform also includes a
Unity WebGL game interface for visualization and an interactive analytics
dashboard to show agent statuses over time. Our platform is available on
https://www.humanoidagents.com/ and code is on
https://github.com/HumanoidAgents/HumanoidAgents"
From Unstructured Text to Causal Knowledge Graphs: A Transformer-Based Approach,0.302162,"Qualitative causal relationships compactly express the direction, dependency,
temporal constraints, and monotonicity constraints of discrete or continuous
interactions in the world. In everyday or academic language, we may express
interactions between quantities (e.g., sleep decreases stress), between
discrete events or entities (e.g., a protein inhibits another protein's
transcription), or between intentional or functional factors (e.g., hospital
patients pray to relieve their pain). Extracting and representing these diverse
causal relations are critical for cognitive systems that operate in domains
spanning from scientific discovery to social science. This paper presents a
transformer-based NLP architecture that jointly extracts knowledge graphs
including (1) variables or factors described in language, (2) qualitative
causal relationships over these variables, (3) qualifiers and magnitudes that
constrain these causal relationships, and (4) word senses to localize each
extracted node within a large ontology. We do not claim that our
transformer-based architecture is itself a cognitive system; however, we
provide evidence of its accurate knowledge graph extraction in real-world
domains and the practicality of its resulting knowledge graphs for cognitive
systems that perform graph-based reasoning. We demonstrate this approach and
include promising results in two use cases, processing textual inputs from
academic publications, news articles, and social media."
SemDeDup: Data-efficient learning at web-scale through semantic deduplication,0.951353,"Progress in machine learning has been driven in large part by massive
increases in data. However, large web-scale datasets such as LAION are largely
uncurated beyond searches for exact duplicates, potentially leaving much
redundancy. Here, we introduce SemDeDup, a method which leverages embeddings
from pre-trained models to identify and remove semantic duplicates: data pairs
which are semantically similar, but not exactly identical. Removing semantic
duplicates preserves performance and speeds up learning. Analyzing a subset of
LAION, we show that SemDeDup can remove 50% of the data with minimal
performance loss, effectively halving training time. Moreover, performance
increases out of distribution. Also, analyzing language models trained on C4, a
partially curated dataset, we show that SemDeDup improves over prior approaches
while providing efficiency gains. SemDeDup provides an example of how simple
ways of leveraging quality embeddings can be used to make models learn faster
with less data."
Eight Things to Know about Large Language Models,0.410348,"The widespread public deployment of large language models (LLMs) in recent
months has prompted a wave of new attention and engagement from advocates,
policymakers, and scholars from many fields. This attention is a timely
response to the many urgent questions that this technology raises, but it can
sometimes miss important considerations. This paper surveys the evidence for
eight potentially surprising such points:
  1. LLMs predictably get more capable with increasing investment, even without
targeted innovation.
  2. Many important LLM behaviors emerge unpredictably as a byproduct of
increasing investment.
  3. LLMs often appear to learn and use representations of the outside world.
  4. There are no reliable techniques for steering the behavior of LLMs.
  5. Experts are not yet able to interpret the inner workings of LLMs.
  6. Human performance on a task isn't an upper bound on LLM performance.
  7. LLMs need not express the values of their creators nor the values encoded
in web text.
  8. Brief interactions with LLMs are often misleading."
Rotation-Invariant Completion Network,0.408424,"Real-world point clouds usually suffer from incompleteness and display
different poses. While current point cloud completion methods excel in
reproducing complete point clouds with consistent poses as seen in the training
set, their performance tends to be unsatisfactory when handling point clouds
with diverse poses. We propose a network named Rotation-Invariant Completion
Network (RICNet), which consists of two parts: a Dual Pipeline Completion
Network (DPCNet) and an enhancing module. Firstly, DPCNet generates a coarse
complete point cloud. The feature extraction module of DPCNet can extract
consistent features, no matter if the input point cloud has undergone rotation
or translation. Subsequently, the enhancing module refines the fine-grained
details of the final generated point cloud. RICNet achieves better rotation
invariance in feature extraction and incorporates structural relationships in
man-made objects. To assess the performance of RICNet and existing methods on
point clouds with various poses, we applied random transformations to the point
clouds in the MVP dataset and conducted experiments on them. Our experiments
demonstrate that RICNet exhibits superior completion performance compared to
existing methods."
Can CNNs Be More Robust Than Transformers?,0.907319,"The recent success of Vision Transformers is shaking the long dominance of
Convolutional Neural Networks (CNNs) in image recognition for a decade.
Specifically, in terms of robustness on out-of-distribution samples, recent
research finds that Transformers are inherently more robust than CNNs,
regardless of different training setups. Moreover, it is believed that such
superiority of Transformers should largely be credited to their
self-attention-like architectures per se. In this paper, we question that
belief by closely examining the design of Transformers. Our findings lead to
three highly effective architecture designs for boosting robustness, yet simple
enough to be implemented in several lines of code, namely a) patchifying input
images, b) enlarging kernel size, and c) reducing activation layers and
normalization layers. Bringing these components together, we are able to build
pure CNN architectures without any attention-like operations that are as robust
as, or even more robust than, Transformers. We hope this work can help the
community better understand the design of robust neural architectures. The code
is publicly available at https://github.com/UCSC-VLAA/RobustCNN."
Face2Text revisited: Improved data set and baseline results,0.065329,"Current image description generation models do not transfer well to the task
of describing human faces. To encourage the development of more human-focused
descriptions, we developed a new data set of facial descriptions based on the
CelebA image data set. We describe the properties of this data set, and present
results from a face description generator trained on it, which explores the
feasibility of using transfer learning from VGGFace/ResNet CNNs. Comparisons
are drawn through both automated metrics and human evaluation by 76
English-speaking participants. The descriptions generated by the VGGFace-LSTM +
Attention model are closest to the ground truth according to human evaluation
whilst the ResNet-LSTM + Attention model obtained the highest CIDEr and CIDEr-D
results (1.252 and 0.686 respectively). Together, the new data set and these
experimental results provide data and baselines for future work in this area."
Differentiable Logics for Neural Network Training and Verification,0.115972,"The rising popularity of neural networks (NNs) in recent years and their
increasing prevalence in real-world applications have drawn attention to the
importance of their verification. While verification is known to be
computationally difficult theoretically, many techniques have been proposed for
solving it in practice. It has been observed in the literature that by default
neural networks rarely satisfy logical constraints that we want to verify. A
good course of action is to train the given NN to satisfy said constraint prior
to verifying them. This idea is sometimes referred to as continuous
verification, referring to the loop between training and verification. Usually
training with constraints is implemented by specifying a translation for a
given formal logic language into loss functions. These loss functions are then
used to train neural networks. Because for training purposes these functions
need to be differentiable, these translations are called differentiable logics
(DL). This raises several research questions. What kind of differentiable
logics are possible? What difference does a specific choice of DL make in the
context of continuous verification? What are the desirable criteria for a DL
viewed from the point of view of the resulting loss function? In this extended
abstract we will discuss and answer these questions."
Neural Token Segmentation for High Token-Internal Complexity,0.0658888,"Tokenizing raw texts into word units is an essential pre-processing step for
critical tasks in the NLP pipeline such as tagging, parsing, named entity
recognition, and more. For most languages, this tokenization step
straightforward. However, for languages with high token-internal complexity,
further token-to-word segmentation is required. Previous canonical segmentation
studies were based on character-level frameworks, with no contextualised
representation involved. Contextualized vectors a la BERT show remarkable
results in many applications, but were not shown to improve performance on
linguistic segmentation per se. Here we propose a novel neural segmentation
model which combines the best of both worlds, contextualised token
representation and char-level decoding, which is particularly effective for
languages with high token-internal complexity and extreme morphological
ambiguity. Our model shows substantial improvements in segmentation accuracy on
Hebrew and Arabic compared to the state-of-the-art, and leads to further
improvements on downstream tasks such as Part-of-Speech Tagging, Dependency
Parsing and Named-Entity Recognition, over existing pipelines. When comparing
our segmentation-first pipeline with joint segmentation and labeling in the
same settings, we show that, contrary to pre-neural studies, the pipeline
performance is superior."
BERT on a Data Diet: Finding Important Examples by Gradient-Based Pruning,0.700646,"Current pre-trained language models rely on large datasets for achieving
state-of-the-art performance. However, past research has shown that not all
examples in a dataset are equally important during training. In fact, it is
sometimes possible to prune a considerable fraction of the training set while
maintaining the test performance. Established on standard vision benchmarks,
two gradient-based scoring metrics for finding important examples are GraNd and
its estimated version, EL2N. In this work, we employ these two metrics for the
first time in NLP. We demonstrate that these metrics need to be computed after
at least one epoch of fine-tuning and they are not reliable in early steps.
Furthermore, we show that by pruning a small portion of the examples with the
highest GraNd/EL2N scores, we can not only preserve the test accuracy, but also
surpass it. This paper details adjustments and implementation choices which
enable GraNd and EL2N to be applied to NLP."
NLP Workbench: Efficient and Extensible Integration of State-of-the-art Text Mining Tools,0.120631,"NLP Workbench is a web-based platform for text mining that allows non-expert
users to obtain semantic understanding of large-scale corpora using
state-of-the-art text mining models. The platform is built upon latest
pre-trained models and open source systems from academia that provide semantic
analysis functionalities, including but not limited to entity linking,
sentiment analysis, semantic parsing, and relation extraction. Its extensible
design enables researchers and developers to smoothly replace an existing model
or integrate a new one. To improve efficiency, we employ a microservice
architecture that facilitates allocation of acceleration hardware and
parallelization of computation. This paper presents the architecture of NLP
Workbench and discusses the challenges we faced in designing it. We also
discuss diverse use cases of NLP Workbench and the benefits of using it over
other approaches. The platform is under active development, with its source
code released under the MIT license. A website and a short video demonstrating
our platform are also available."
Reinforcement Learning in Presence of Discrete Markovian Context Evolution,0.161475,"We consider a context-dependent Reinforcement Learning (RL) setting, which is
characterized by: a) an unknown finite number of not directly observable
contexts; b) abrupt (discontinuous) context changes occurring during an
episode; and c) Markovian context evolution. We argue that this challenging
case is often met in applications and we tackle it using a Bayesian approach
and variational inference. We adapt a sticky Hierarchical Dirichlet Process
(HDP) prior for model learning, which is arguably best-suited for Markov
process modeling. We then derive a context distillation procedure, which
identifies and removes spurious contexts in an unsupervised fashion. We argue
that the combination of these two components allows to infer the number of
contexts from data thus dealing with the context cardinality assumption. We
then find the representation of the optimal policy enabling efficient policy
learning using off-the-shelf RL algorithms. Finally, we demonstrate empirically
(using gym environments cart-pole swing-up, drone, intersection) that our
approach succeeds where state-of-the-art methods of other frameworks fail and
elaborate on the reasons for such failures."
Graph-based Asynchronous Event Processing for Rapid Object Recognition,0.976846,"Different from traditional video cameras, event cameras capture asynchronous
events stream in which each event encodes pixel location, trigger time, and the
polarity of the brightness changes. In this paper, we introduce a novel
graph-based framework for event cameras, namely SlideGCN. Unlike some recent
graph-based methods that use groups of events as input, our approach can
efficiently process data event-by-event, unlock the low latency nature of
events data while still maintaining the graph's structure internally. For fast
graph construction, we develop a radius search algorithm, which better exploits
the partial regular structure of event cloud against k-d tree based generic
methods. Experiments show that our method reduces the computational complexity
up to 100 times with respect to current graph-based methods while keeping
state-of-the-art performance on object recognition. Moreover, we verify the
superiority of event-wise processing with our method. When the state becomes
stable, we can give a prediction with high confidence, thus making an early
recognition. Project page: \url{https://zju3dv.github.io/slide_gcn/}."
Point2Vec for Self-Supervised Representation Learning on Point Clouds,0.554849,"Recently, the self-supervised learning framework data2vec has shown inspiring
performance for various modalities using a masked student-teacher approach.
However, it remains open whether such a framework generalizes to the unique
challenges of 3D point clouds. To answer this question, we extend data2vec to
the point cloud domain and report encouraging results on several downstream
tasks. In an in-depth analysis, we discover that the leakage of positional
information reveals the overall object shape to the student even under heavy
masking and thus hampers data2vec to learn strong representations for point
clouds. We address this 3D-specific shortcoming by proposing point2vec, which
unleashes the full potential of data2vec-like pre-training on point clouds. Our
experiments show that point2vec outperforms other self-supervised methods on
shape classification and few-shot learning on ModelNet40 and ScanObjectNN,
while achieving competitive results on part segmentation on ShapeNetParts.
These results suggest that the learned representations are strong and
transferable, highlighting point2vec as a promising direction for
self-supervised learning of point cloud representations."
Soda: An Object-Oriented Functional Language for Specifying Human-Centered Problems,0.809944,"We present Soda (Symbolic Objective Descriptive Analysis), a language that
helps to treat qualities and quantities in a natural way and greatly simplifies
the task of checking their correctness. We present key properties for the
language motivated by the design of a descriptive language to encode complex
requirements on computer systems, and we explain how these key properties must
be addressed to model these requirements with simple definitions. We give an
overview of a tool that helps to describe problems in an easy way that we
consider more transparent and less error-prone."
Learning Customized Visual Models with Retrieval-Augmented Knowledge,0.660302,"Image-text contrastive learning models such as CLIP have demonstrated strong
task transfer ability. The high generality and usability of these visual models
is achieved via a web-scale data collection process to ensure broad concept
coverage, followed by expensive pre-training to feed all the knowledge into
model weights. Alternatively, we propose REACT, REtrieval-Augmented
CusTomization, a framework to acquire the relevant web knowledge to build
customized visual models for target domains. We retrieve the most relevant
image-text pairs (~3% of CLIP pre-training data) from the web-scale database as
external knowledge, and propose to customize the model by only training new
modualized blocks while freezing all the original weights. The effectiveness of
REACT is demonstrated via extensive experiments on classification, retrieval,
detection and segmentation tasks, including zero, few, and full-shot settings.
Particularly, on the zero-shot classification task, compared with CLIP, it
achieves up to 5.4% improvement on ImageNet and 3.7% on the ELEVATER benchmark
(20 datasets)."
Computer sciences and synthesis: retrospective and perspective,0.040168,"The problem of synthesis in computer sciences, including cybernetics,
artificial intelligence and system analysis, is analyzed. Main methods of
realization this problem are discussed. Ways of search universal method of
creation universal synthetic science are represented. As example of such
universal method polymetric analysis is given. Perspective of further
development of this research, including application polymetric method for the
resolution main problems of computer sciences, is analyzed too."
Mechanism Design for Ad Auctions with Display Prices,0.0976414,"In many applications, ads are displayed together with the prices, so as to
provide a direct comparison among similar products or services. The
price-displaying feature not only influences the consumers' decisions, but also
affects the advertisers' bidding behaviors. In this paper, we study ad auctions
with display prices from the perspective of mechanism design, in which
advertisers are asked to submit both the costs and prices of their products. We
provide a characterization for all incentive compatible auctions with display
prices, and use it to design auctions under two scenarios. In the former
scenario, the display prices are assumed to be exogenously determined. For this
setting, we derive the welfare-maximizing and revenue-maximizing auctions for
any realization of the price profile. In the latter, advertisers are allowed to
strategize display prices in their own interests. We investigate two families
of allocation policies within the scenario and identify the equilibrium prices
accordingly. Our results reveal that the display prices do affect the design of
ad auctions and the platform can leverage such information to optimize the
performance of ad delivery."
Deep Learning and Artificial General Intelligence: Still a Long Way to Go,0.0707658,"In recent years, deep learning using neural network architecture, i.e. deep
neural networks, has been on the frontier of computer science research. It has
even lead to superhuman performance in some problems, e.g., in computer vision,
games and biology, and as a result the term deep learning revolution was
coined. The undisputed success and rapid growth of deep learning suggests that,
in future, it might become an enabler for Artificial General Intelligence
(AGI). In this article, we approach this statement critically showing five
major reasons of why deep neural networks, as of the current state, are not
ready to be the technique of choice for reaching AGI."
Entropy-based Active Learning for Object Detection with Progressive Diversity Constraint,0.805876,"Active learning is a promising alternative to alleviate the issue of high
annotation cost in the computer vision tasks by consciously selecting more
informative samples to label. Active learning for object detection is more
challenging and existing efforts on it are relatively rare. In this paper, we
propose a novel hybrid approach to address this problem, where the
instance-level uncertainty and diversity are jointly considered in a bottom-up
manner. To balance the computational complexity, the proposed approach is
designed as a two-stage procedure. At the first stage, an Entropy-based
Non-Maximum Suppression (ENMS) is presented to estimate the uncertainty of
every image, which performs NMS according to the entropy in the feature space
to remove predictions with redundant information gains. At the second stage, a
diverse prototype (DivProto) strategy is explored to ensure the diversity
across images by progressively converting it into the intra-class and
inter-class diversities of the entropy-based class-specific prototypes.
Extensive experiments are conducted on MS COCO and Pascal VOC, and the proposed
approach achieves state of the art results and significantly outperforms the
other counterparts, highlighting its superiority."
TabLib: A Dataset of 627M Tables with Context,0.607764,"It is well-established that large, diverse datasets play a pivotal role in
the performance of modern AI systems for text and image modalities. However,
there are no datasets for tabular data of comparable size and diversity to
those available for text and images. Thus we present ""TabLib'', a compilation
of 627 million tables totaling 69 TiB, along with 867B tokens of context.
TabLib was extracted from numerous file formats, including CSV, HTML, SQLite,
PDF, Excel, and others, sourced from GitHub and Common Crawl. The size and
diversity of TabLib offer considerable promise in the table modality,
reminiscent of the original promise of foundational datasets for text and
images, such as The Pile and LAION."
KL-Divergence Guided Temperature Sampling,0.124823,"Temperature sampling is a conventional approach to diversify large language
model predictions. As temperature increases, the prediction becomes diverse but
also vulnerable to hallucinations -- generating tokens that are sensible but
not factual. One common approach to mitigate hallucinations is to provide
source/grounding documents and the model is trained to produce predictions that
bind to and are attributable to the provided source. It appears that there is a
trade-off between diversity and attribution. To mitigate any such trade-off, we
propose to relax the constraint of having a fixed temperature over decoding
steps, and a mechanism to guide the dynamic temperature according to its
relevance to the source through KL-divergence. Our experiments justifies the
trade-off, and shows that our sampling algorithm outperforms the conventional
top-k and top-p algorithms in conversational question-answering and
summarization tasks."
Color Image Inpainting via Robust Pure Quaternion Matrix Completion: Error Bound and Weighted Loss,0.626417,"In this paper, we study color image inpainting as a pure quaternion matrix
completion problem. In the literature, the theoretical guarantee for quaternion
matrix completion is not well-established. Our main aim is to propose a new
minimization problem with an objective combining nuclear norm and a quadratic
loss weighted among three channels. To fill the theoretical vacancy, we obtain
the error bound in both clean and corrupted regimes, which relies on some new
results of quaternion matrices. A general Gaussian noise is considered in
robust completion where all observations are corrupted. Motivated by the error
bound, we propose to handle unbalanced or correlated noise via a cross-channel
weight in the quadratic loss, with the main purpose of rebalancing noise level,
or removing noise correlation. Extensive experimental results on synthetic and
color image data are presented to confirm and demonstrate our theoretical
findings."
Multi Task Learning For Zero Shot Performance Prediction of Multilingual Models,0.342084,"Massively Multilingual Transformer based Language Models have been observed
to be surprisingly effective on zero-shot transfer across languages, though the
performance varies from language to language depending on the pivot language(s)
used for fine-tuning. In this work, we build upon some of the existing
techniques for predicting the zero-shot performance on a task, by modeling it
as a multi-task learning problem. We jointly train predictive models for
different tasks which helps us build more accurate predictors for tasks where
we have test data in very few languages to measure the actual performance of
the model. Our approach also lends us the ability to perform a much more robust
feature selection and identify a common set of features that influence
zero-shot performance across a variety of tasks."
RDMNet: Reliable Dense Matching Based Point Cloud Registration for Autonomous Driving,0.368171,"Point cloud registration is an important task in robotics and autonomous
driving to estimate the ego-motion of the vehicle. Recent advances following
the coarse-to-fine manner show promising potential in point cloud registration.
However, existing methods rely on good superpoint correspondences, which are
hard to be obtained reliably and efficiently, thus resulting in less robust and
accurate point cloud registration. In this paper, we propose a novel network,
named RDMNet, to find dense point correspondences coarse-to-fine and improve
final pose estimation based on such reliable correspondences. Our RDMNet uses a
devised 3D-RoFormer mechanism to first extract distinctive superpoints and
generates reliable superpoints matches between two point clouds. The proposed
3D-RoFormer fuses 3D position information into the transformer network,
efficiently exploiting point clouds' contextual and geometric information to
generate robust superpoint correspondences. RDMNet then propagates the sparse
superpoints matches to dense point matches using the neighborhood information
for accurate point cloud registration. We extensively evaluate our method on
multiple datasets from different environments. The experimental results
demonstrate that our method outperforms existing state-of-the-art approaches in
all tested datasets with a strong generalization ability."
Shrinking the Inductive Programming Search Space with Instruction Subsets,0.0771148,"Inductive programming frequently relies on some form of search in order to
identify candidate solutions. However, the size of the search space limits the
use of inductive programming to the production of relatively small programs. If
we could somehow correctly predict the subset of instructions required for a
given problem then inductive programming would be more tractable. We will show
that this can be achieved in a high percentage of cases. This paper presents a
novel model of programming language instruction co-occurrence that was built to
support search space partitioning in the Zoea distributed inductive programming
system. This consists of a collection of intersecting instruction subsets
derived from a large sample of open source code. Using the approach different
parts of the search space can be explored in parallel. The number of subsets
required does not grow linearly with the quantity of code used to produce them
and a manageable number of subsets is sufficient to cover a high percentage of
unseen code. This approach also significantly reduces the overall size of the
search space - often by many orders of magnitude."
Domain Adaptation of Machine Translation with Crowdworkers,0.119174,"Although a machine translation model trained with a large in-domain parallel
corpus achieves remarkable results, it still works poorly when no in-domain
data are available. This situation restricts the applicability of machine
translation when the target domain's data are limited. However, there is great
demand for high-quality domain-specific machine translation models for many
domains. We propose a framework that efficiently and effectively collects
parallel sentences in a target domain from the web with the help of
crowdworkers. With the collected parallel data, we can quickly adapt a machine
translation model to the target domain. Our experiments show that the proposed
method can collect target-domain parallel data over a few days at a reasonable
cost. We tested it with five domains, and the domain-adapted model improved the
BLEU scores to +19.7 by an average of +7.8 points compared to a general-purpose
translation model."
Connections between Operator-splitting Methods and Deep Neural Networks with Applications in Image Segmentation,0.0683112,"Deep neural network is a powerful tool for many tasks. Understanding why it
is so successful and providing a mathematical explanation is an important
problem and has been one popular research direction in past years. In the
literature of mathematical analysis of deep neural networks, a lot of works is
dedicated to establishing representation theories. How to make connections
between deep neural networks and mathematical algorithms is still under
development. In this paper, we give an algorithmic explanation for deep neural
networks, especially in their connections with operator splitting. We show that
with certain splitting strategies, operator-splitting methods have the same
structure as networks. Utilizing this connection and the Potts model for image
segmentation, two networks inspired by operator-splitting methods are proposed.
The two networks are essentially two operator-splitting algorithms solving the
Potts model. Numerical experiments are presented to demonstrate the
effectiveness of the proposed networks."
Perspective (In)consistency of Paint by Text,0.433369,"Type ""a sea otter with a pearl earring by Johannes Vermeer"" or ""a photo of a
teddy bear on a skateboard in Times Square"" into OpenAI's DALL-E-2
paint-by-text synthesis engine and you will not be disappointed by the
delightful and eerily pertinent results. The ability to synthesize highly
realistic images -- with seemingly no limitation other than our imagination --
is sure to yield many exciting and creative applications. These images are also
likely to pose new challenges to the photo-forensic community. Motivated by the
fact that paint by text is not based on explicit geometric modeling, and the
human visual system's often obliviousness to even glaring geometric
inconsistencies, we provide an initial exploration of the perspective
consistency of DALL-E-2 synthesized images to determine if geometric-based
forensic analyses will prove fruitful in detecting this new breed of synthetic
media."
Unsupervised Symbolic Music Segmentation using Ensemble Temporal Prediction Errors,0.319818,"Symbolic music segmentation is the process of dividing symbolic melodies into
smaller meaningful groups, such as melodic phrases. We proposed an unsupervised
method for segmenting symbolic music. The proposed model is based on an
ensemble of temporal prediction error models. During training, each model
predicts the next token to identify musical phrase changes. While at test time,
we perform a peak detection algorithm to select segment candidates. Finally, we
aggregate the predictions of each of the models participating in the ensemble
to predict the final segmentation. Results suggest the proposed method reaches
state-of-the-art performance on the Essen Folksong dataset under the
unsupervised setting when considering F-Score and R-value. We additionally
provide an ablation study to better assess the contribution of each of the
model components to the final results. As expected, the proposed method is
inferior to the supervised setting, which leaves room for improvement in future
research considering closing the gap between unsupervised and supervised
methods."
Online Easy Example Mining for Weakly-supervised Gland Segmentation from Histology Images,0.580896,"Developing an AI-assisted gland segmentation method from histology images is
critical for automatic cancer diagnosis and prognosis; however, the high cost
of pixel-level annotations hinders its applications to broader diseases.
Existing weakly-supervised semantic segmentation methods in computer vision
achieve degenerative results for gland segmentation, since the characteristics
and problems of glandular datasets are different from general object datasets.
We observe that, unlike natural images, the key problem with histology images
is the confusion of classes owning to morphological homogeneity and low color
contrast among different tissues. To this end, we propose a novel method Online
Easy Example Mining (OEEM) that encourages the network to focus on credible
supervision signals rather than noisy signals, therefore mitigating the
influence of inevitable false predictions in pseudo-masks. According to the
characteristics of glandular datasets, we design a strong framework for gland
segmentation. Our results exceed many fully-supervised methods and
weakly-supervised methods for gland segmentation over 4.4% and 6.04% at mIoU,
respectively. Code is available at https://github.com/xmed-lab/OEEM."
ZeroPose: CAD-Model-based Zero-Shot Pose Estimation,0.540853,"In this paper, we present a CAD model-based zero-shot pose estimation
pipeline called ZeroPose. Existing pose estimation methods remain to require
expensive training when applied to an unseen object, which greatly hinders
their scalability in the practical application of industry. In contrast, the
proposed method enables the accurate estimation of pose parameters for
previously unseen objects without the need for training. Specifically, we
design a two-step pipeline consisting of CAD model-based zero-shot instance
segmentation and a zero-shot pose estimator. For the first step, there is a
simple but effective way to leverage CAD models and visual foundation models
SAM and Imagebind to segment the interest unseen object at the instance level.
For the second step, we based on the intensive geometric information in the CAD
model of the rigid object to propose a lightweight hierarchical geometric
structure matching mechanism achieving zero-shot pose estimation. Extensive
experimental results on the seven core datasets on the BOP challenge show that
the proposed zero-shot instance segmentation methods achieve comparable
performance with supervised MaskRCNN and the zero-shot pose estimation results
outperform the SOTA pose estimators with better efficiency."
Knowledge Removal in Sampling-based Bayesian Inference,0.903963,"The right to be forgotten has been legislated in many countries, but its
enforcement in the AI industry would cause unbearable costs. When single data
deletion requests come, companies may need to delete the whole models learned
with massive resources. Existing works propose methods to remove knowledge
learned from data for explicitly parameterized models, which however are not
appliable to the sampling-based Bayesian inference, i.e., Markov chain Monte
Carlo (MCMC), as MCMC can only infer implicit distributions. In this paper, we
propose the first machine unlearning algorithm for MCMC. We first convert the
MCMC unlearning problem into an explicit optimization problem. Based on this
problem conversion, an {\it MCMC influence function} is designed to provably
characterize the learned knowledge from data, which then delivers the MCMC
unlearning algorithm. Theoretical analysis shows that MCMC unlearning would not
compromise the generalizability of the MCMC models. Experiments on Gaussian
mixture models and Bayesian neural networks confirm the effectiveness of the
proposed algorithm. The code is available at
\url{https://github.com/fshp971/mcmc-unlearning}."
GFNet: Geometric Flow Network for 3D Point Cloud Semantic Segmentation,0.696843,"Point cloud semantic segmentation from projected views, such as range-view
(RV) and bird's-eye-view (BEV), has been intensively investigated. Different
views capture different information of point clouds and thus are complementary
to each other. However, recent projection-based methods for point cloud
semantic segmentation usually utilize a vanilla late fusion strategy for the
predictions of different views, failing to explore the complementary
information from a geometric perspective during the representation learning. In
this paper, we introduce a geometric flow network (GFNet) to explore the
geometric correspondence between different views in an align-before-fuse
manner. Specifically, we devise a novel geometric flow module (GFM) to
bidirectionally align and propagate the complementary information across
different views according to geometric relationships under the end-to-end
learning scheme. We perform extensive experiments on two widely used benchmark
datasets, SemanticKITTI and nuScenes, to demonstrate the effectiveness of our
GFNet for project-based point cloud semantic segmentation. Concretely, GFNet
not only significantly boosts the performance of each individual view but also
achieves state-of-the-art results over all existing projection-based models.
Code is available at \url{https://github.com/haibo-qiu/GFNet}."
TTIDA: Controllable Generative Data Augmentation via Text-to-Text and Text-to-Image Models,0.65292,"Data augmentation has been established as an efficacious approach to
supplement useful information for low-resource datasets. Traditional
augmentation techniques such as noise injection and image transformations have
been widely used. In addition, generative data augmentation (GDA) has been
shown to produce more diverse and flexible data. While generative adversarial
networks (GANs) have been frequently used for GDA, they lack diversity and
controllability compared to text-to-image diffusion models. In this paper, we
propose TTIDA (Text-to-Text-to-Image Data Augmentation) to leverage the
capabilities of large-scale pre-trained Text-to-Text (T2T) and Text-to-Image
(T2I) generative models for data augmentation. By conditioning the T2I model on
detailed descriptions produced by T2T models, we are able to generate
photo-realistic labeled images in a flexible and controllable manner.
Experiments on in-domain classification, cross-domain classification, and image
captioning tasks show consistent improvements over other data augmentation
baselines. Analytical studies in varied settings, including few-shot,
long-tail, and adversarial, further reinforce the effectiveness of TTIDA in
enhancing performance and increasing robustness."
"An Ensemble Approach to Question Classification: Integrating Electra Transformer, GloVe, and LSTM",0.184367,"Natural Language Processing (NLP) has emerged as a crucial technology for
understanding and generating human language, playing an essential role in tasks
such as machine translation, sentiment analysis, and more pertinently, question
classification. As a subfield within NLP, question classification focuses on
determining the type of information being sought, a fundamental step for
downstream applications like question answering systems. This study presents an
innovative ensemble approach for question classification, combining the
strengths of Electra, GloVe, and LSTM models. Rigorously tested on the
well-regarded TREC dataset, the model demonstrates how the integration of these
disparate technologies can lead to superior results. Electra brings in its
transformer-based capabilities for complex language understanding, GloVe offers
global vector representations for capturing word-level semantics, and LSTM
contributes its sequence learning abilities to model long-term dependencies. By
fusing these elements strategically, our ensemble model delivers a robust and
efficient solution for the complex task of question classification. Through
rigorous comparisons with well-known models like BERT, RoBERTa, and DistilBERT,
the ensemble approach verifies its effectiveness by attaining an 80% accuracy
score on the test dataset."
In-Context Impersonation Reveals Large Language Models' Strengths and Biases,0.424797,"In everyday conversations, humans can take on different roles and adapt their
vocabulary to their chosen roles. We explore whether LLMs can take on, that is
impersonate, different roles when they generate text in-context. We ask LLMs to
assume different personas before solving vision and language tasks. We do this
by prefixing the prompt with a persona that is associated either with a social
identity or domain expertise. In a multi-armed bandit task, we find that LLMs
pretending to be children of different ages recover human-like developmental
stages of exploration. In a language-based reasoning task, we find that LLMs
impersonating domain experts perform better than LLMs impersonating non-domain
experts. Finally, we test whether LLMs' impersonations are complementary to
visual information when describing different categories. We find that
impersonation can improve performance: an LLM prompted to be a bird expert
describes birds better than one prompted to be a car expert. However,
impersonation can also uncover LLMs' biases: an LLM prompted to be a man
describes cars better than one prompted to be a woman. These findings
demonstrate that LLMs are capable of taking on diverse roles and that this
in-context impersonation can be used to uncover their hidden strengths and
biases."
Adaptive Anytime Multi-Agent Path Finding Using Bandit-Based Large Neighborhood Search,0.56061,"Anytime multi-agent path finding (MAPF) is a promising approach to scalable
path optimization in large-scale multi-agent systems. State-of-the-art anytime
MAPF is based on Large Neighborhood Search (LNS), where a fast initial solution
is iteratively optimized by destroying and repairing a fixed number of parts,
i.e., the neighborhood, of the solution, using randomized destroy heuristics
and prioritized planning. Despite their recent success in various MAPF
instances, current LNS-based approaches lack exploration and flexibility due to
greedy optimization with a fixed neighborhood size which can lead to low
quality solutions in general. So far, these limitations have been addressed
with extensive prior effort in tuning or offline machine learning beyond actual
planning. In this paper, we focus on online learning in LNS and propose
Bandit-based Adaptive LArge Neighborhood search Combined with Exploration
(BALANCE). BALANCE uses a bi-level multi-armed bandit scheme to adapt the
selection of destroy heuristics and neighborhood sizes on the fly during
search. We evaluate BALANCE on multiple maps from the MAPF benchmark set and
empirically demonstrate cost improvements of at least 50% compared to
state-of-the-art anytime MAPF in large-scale scenarios. We find that Thompson
Sampling performs particularly well compared to alternative multi-armed bandit
algorithms."
Pixel-Level Equalized Matching for Video Object Segmentation,0.0701702,"Feature similarity matching, which transfers the information of the reference
frame to the query frame, is a key component in semi-supervised video object
segmentation. If surjective matching is adopted, background distractors can
easily occur and degrade the performance. Bijective matching mechanisms try to
prevent this by restricting the amount of information being transferred to the
query frame, but have two limitations: 1) surjective matching cannot be fully
leveraged as it is transformed to bijective matching at test time; and 2)
test-time manual tuning is required for searching the optimal hyper-parameters.
To overcome these limitations while ensuring reliable information transfer, we
introduce an equalized matching mechanism. To prevent the reference frame
information from being overly referenced, the potential contribution to the
query frame is equalized by simply applying a softmax operation along with the
query. On public benchmark datasets, our proposed approach achieves a
comparable performance to state-of-the-art methods."
Fast Few-shot Debugging for NLU Test Suites,0.0460248,"We study few-shot debugging of transformer based natural language
understanding models, using recently popularized test suites to not just
diagnose but correct a problem. Given a few debugging examples of a certain
phenomenon, and a held-out test set of the same phenomenon, we aim to maximize
accuracy on the phenomenon at a minimal cost of accuracy on the original test
set. We examine several methods that are faster than full epoch retraining. We
introduce a new fast method, which samples a few in-danger examples from the
original training set. Compared to fast methods using parameter distance
constraints or Kullback-Leibler divergence, we achieve superior original
accuracy for comparable debugging accuracy."
Near-Optimal Multi-Agent Learning for Safe Coverage Control,0.836703,"In multi-agent coverage control problems, agents navigate their environment
to reach locations that maximize the coverage of some density. In practice, the
density is rarely known $\textit{a priori}$, further complicating the original
NP-hard problem. Moreover, in many applications, agents cannot visit arbitrary
locations due to $\textit{a priori}$ unknown safety constraints. In this paper,
we aim to efficiently learn the density to approximately solve the coverage
problem while preserving the agents' safety. We first propose a conditionally
linear submodular coverage function that facilitates theoretical analysis.
Utilizing this structure, we develop MacOpt, a novel algorithm that efficiently
trades off the exploration-exploitation dilemma due to partial observability,
and show that it achieves sublinear regret. Next, we extend results on
single-agent safe exploration to our multi-agent setting and propose SafeMac
for safe coverage and exploration. We analyze SafeMac and give first of its
kind results: near optimal coverage in finite time while provably guaranteeing
safety. We extensively evaluate our algorithms on synthetic and real problems,
including a bio-diversity monitoring task under safety constraints, where
SafeMac outperforms competing methods."
Individual Topology Structure of Eye Movement Trajectories,0.249477,"Traditionally, extracting patterns from eye movement data relies on
statistics of different macro-events such as fixations and saccades. This
requires an additional preprocessing step to separate the eye movement
subtypes, often with a number of parameters on which the classification results
depend. Besides that, definitions of such macro events are formulated in
different ways by different researchers.
  We propose an application of a new class of features to the quantitative
analysis of personal eye movement trajectories structure. This new class of
features based on algebraic topology allows extracting patterns from different
modalities of gaze such as time series of coordinates and amplitudes, heatmaps,
and point clouds in a unified way at all scales from micro to macro. We
experimentally demonstrate the competitiveness of the new class of features
with the traditional ones and their significant synergy while being used
together for the person authentication task on the recently published eye
movement trajectories dataset."
Improving Empathetic Dialogue Generation by Dynamically Infusing Commonsense Knowledge,0.546039,"In empathetic conversations, individuals express their empathy towards
others. Previous work has mainly focused on generating empathetic responses by
utilizing the speaker's emotion. Besides, external commonsense knowledge has
been applied to enhance the system's understandings of the speaker's situation.
However, given an event, commonsense knowledge base contains various relations,
potentially leading to confusion for the dialogue system. Consequently,
inconsistencies arise among the emotion, generated response and speaker's
contextual information. To this end, we propose a novel approach for empathetic
response generation, which incorporates an adaptive module for commonsense
knowledge selection to ensure consistency between the generated empathetic
responses and the speaker's situation. This selected knowledge is used to
refine the commonsense cognition and empathy expression for generated
responses. Experimental results show that our approach significantly
outperforms baseline models in both automatic and human evaluations, exhibiting
the generation of more coherent and empathetic responses. Moreover, case
studies highlight the interpretability of knowledge selection in the responses
and the effectiveness of adaptive module in our model. Code:
https://github.com/Hanscal/DCKS."
Multimodal Contrastive Learning with LIMoE: the Language-Image Mixture of Experts,0.941467,"Large sparsely-activated models have obtained excellent performance in
multiple domains. However, such models are typically trained on a single
modality at a time. We present the Language-Image MoE, LIMoE, a sparse mixture
of experts model capable of multimodal learning. LIMoE accepts both images and
text simultaneously, while being trained using a contrastive loss. MoEs are a
natural fit for a multimodal backbone, since expert layers can learn an
appropriate partitioning of modalities. However, new challenges arise; in
particular, training stability and balanced expert utilization, for which we
propose an entropy-based regularization scheme. Across multiple scales, we
demonstrate remarkable performance improvement over dense models of equivalent
computational cost. LIMoE-L/16 trained comparably to CLIP-L/14 achieves 78.6%
zero-shot ImageNet accuracy (vs. 76.2%), and when further scaled to H/14 (with
additional data) it achieves 84.1%, comparable to state-of-the-art methods
which use larger custom per-modality backbones and pre-training schemes. We
analyse the quantitative and qualitative behavior of LIMoE, and demonstrate
phenomena such as differing treatment of the modalities and the organic
emergence of modality-specific experts."
Meet-in-the-middle: Multi-scale upsampling and matching for cross-resolution face recognition,0.318799,"In this paper, we aim to address the large domain gap between high-resolution
face images, e.g., from professional portrait photography, and low-quality
surveillance images, e.g., from security cameras. Establishing an identity
match between disparate sources like this is a classical surveillance face
identification scenario, which continues to be a challenging problem for modern
face recognition techniques. To that end, we propose a method that combines
face super-resolution, resolution matching, and multi-scale template
accumulation to reliably recognize faces from long-range surveillance footage,
including from low quality sources. The proposed approach does not require
training or fine-tuning on the target dataset of real surveillance images.
Extensive experiments show that our proposed method is able to outperform even
existing methods fine-tuned to the SCFace dataset."
AutoSTL: Automated Spatio-Temporal Multi-Task Learning,0.785725,"Spatio-Temporal prediction plays a critical role in smart city construction.
Jointly modeling multiple spatio-temporal tasks can further promote an
intelligent city life by integrating their inseparable relationship. However,
existing studies fail to address this joint learning problem well, which
generally solve tasks individually or a fixed task combination. The challenges
lie in the tangled relation between different properties, the demand for
supporting flexible combinations of tasks and the complex spatio-temporal
dependency. To cope with the problems above, we propose an Automated
Spatio-Temporal multi-task Learning (AutoSTL) method to handle multiple
spatio-temporal tasks jointly. Firstly, we propose a scalable architecture
consisting of advanced spatio-temporal operations to exploit the complicated
dependency. Shared modules and feature fusion mechanism are incorporated to
further capture the intrinsic relationship between tasks. Furthermore, our
model automatically allocates the operations and fusion weight. Extensive
experiments on benchmark datasets verified that our model achieves
state-of-the-art performance. As we can know, AutoSTL is the first automated
spatio-temporal multi-task learning method."
Distributionally Robust Optimization and Invariant Representation Learning for Addressing Subgroup Underrepresentation: Mechanisms and Limitations,0.137489,"Spurious correlation caused by subgroup underrepresentation has received
increasing attention as a source of bias that can be perpetuated by deep neural
networks (DNNs). Distributionally robust optimization has shown success in
addressing this bias, although the underlying working mechanism mostly relies
on upweighting under-performing samples as surrogates for those
underrepresented in data. At the same time, while invariant representation
learning has been a powerful choice for removing nuisance-sensitive features,
it has been little considered in settings where spurious correlations are
caused by significant underrepresentation of subgroups. In this paper, we take
the first step to better understand and improve the mechanisms for debiasing
spurious correlation due to subgroup underrepresentation in medical image
classification. Through a comprehensive evaluation study, we first show that 1)
generalized reweighting of under-performing samples can be problematic when
bias is not the only cause for poor performance, while 2) naive invariant
representation learning suffers from spurious correlations itself. We then
present a novel approach that leverages robust optimization to facilitate the
learning of invariant representations at the presence of spurious correlations.
Finetuned classifiers utilizing such representation demonstrated improved
abilities to reduce subgroup performance disparity, while maintaining high
average and worst-group performance."
SecureBERT: A Domain-Specific Language Model for Cybersecurity,0.424602,"Natural Language Processing (NLP) has recently gained wide attention in
cybersecurity, particularly in Cyber Threat Intelligence (CTI) and cyber
automation. Increased connection and automation have revolutionized the world's
economic and cultural infrastructures, while they have introduced risks in
terms of cyber attacks. CTI is information that helps cybersecurity analysts
make intelligent security decisions, that is often delivered in the form of
natural language text, which must be transformed to machine readable format
through an automated procedure before it can be used for automated security
measures.
  This paper proposes SecureBERT, a cybersecurity language model capable of
capturing text connotations in cybersecurity text (e.g., CTI) and therefore
successful in automation for many critical cybersecurity tasks that would
otherwise rely on human expertise and time-consuming manual efforts. SecureBERT
has been trained using a large corpus of cybersecurity text.To make SecureBERT
effective not just in retaining general English understanding, but also when
applied to text with cybersecurity implications, we developed a customized
tokenizer as well as a method to alter pre-trained weights. The SecureBERT is
evaluated using the standard Masked Language Model (MLM) test as well as two
additional standard NLP tasks. Our evaluation studies show that
SecureBERT\footnote{\url{https://github.com/ehsanaghaei/SecureBERT}}
outperforms existing similar models, confirming its capability for solving
crucial NLP tasks in cybersecurity."
Character-LLM: A Trainable Agent for Role-Playing,0.982278,"Large language models (LLMs) can be used to serve as agents to simulate human
behaviors, given the powerful ability to understand human instructions and
provide high-quality generated texts. Such ability stimulates us to wonder
whether LLMs can simulate a person in a higher form than simple human
behaviors. Therefore, we aim to train an agent with the profile, experience,
and emotional states of a specific person instead of using limited prompts to
instruct ChatGPT API. In this work, we introduce Character-LLM that teach LLMs
to act as specific people such as Beethoven, Queen Cleopatra, Julius Caesar,
etc. Our method focuses on editing profiles as experiences of a certain
character and training models to be personal simulacra with these experiences.
To assess the effectiveness of our approach, we build a test playground that
interviews trained agents and evaluates whether the agents \textit{memorize}
their characters and experiences. Experimental results show interesting
observations that help build future simulacra of humankind."
PUPS: Point Cloud Unified Panoptic Segmentation,0.805893,"Point cloud panoptic segmentation is a challenging task that seeks a holistic
solution for both semantic and instance segmentation to predict groupings of
coherent points. Previous approaches treat semantic and instance segmentation
as surrogate tasks, and they either use clustering methods or bounding boxes to
gather instance groupings with costly computation and hand-crafted designs in
the instance segmentation task. In this paper, we propose a simple but
effective point cloud unified panoptic segmentation (PUPS) framework, which use
a set of point-level classifiers to directly predict semantic and instance
groupings in an end-to-end manner. To realize PUPS, we introduce bipartite
matching to our training pipeline so that our classifiers are able to
exclusively predict groupings of instances, getting rid of hand-crafted
designs, e.g. anchors and Non-Maximum Suppression (NMS). In order to achieve
better grouping results, we utilize a transformer decoder to iteratively refine
the point classifiers and develop a context-aware CutMix augmentation to
overcome the class imbalance problem. As a result, PUPS achieves 1st place on
the leader board of SemanticKITTI panoptic segmentation task and
state-of-the-art results on nuScenes."
ZooPFL: Exploring Black-box Foundation Models for Personalized Federated Learning,0.638877,"When personalized federated learning (FL) meets large foundation models, new
challenges arise from various limitations in resources. In addition to typical
limitations such as data, computation, and communication costs, access to the
models is also often limited. This paper endeavors to solve both the challenges
of limited resources and personalization. i.e., distribution shifts between
clients. To do so, we propose a method named ZOOPFL that uses Zeroth-Order
Optimization for Personalized Federated Learning. ZOOPFL avoids direct
interference with the foundation models and instead learns to adapt its inputs
through zeroth-order optimization. In addition, we employ simple yet effective
linear projections to remap its predictions for personalization. To reduce the
computation costs and enhance personalization, we propose input surgery to
incorporate an auto-encoder with low-dimensional and client-specific
embeddings. We provide theoretical support for ZOOPFL to analyze its
convergence. Extensive empirical experiments on computer vision and natural
language processing tasks using popular foundation models demonstrate its
effectiveness for FL on black-box foundation models."
CLRerNet: Improving Confidence of Lane Detection with LaneIoU,0.478081,"Lane marker detection is a crucial component of the autonomous driving and
driver assistance systems. Modern deep lane detection methods with row-based
lane representation exhibit excellent performance on lane detection benchmarks.
Through preliminary oracle experiments, we firstly disentangle the lane
representation components to determine the direction of our approach. We show
that correct lane positions are already among the predictions of an existing
row-based detector, and the confidence scores that accurately represent
intersection-over-union (IoU) with ground truths are the most beneficial. Based
on the finding, we propose LaneIoU that better correlates with the metric, by
taking the local lane angles into consideration. We develop a novel detector
coined CLRerNet featuring LaneIoU for the target assignment cost and loss
functions aiming at the improved quality of confidence scores. Through careful
and fair benchmark including cross validation, we demonstrate that CLRerNet
outperforms the state-of-the-art by a large margin - enjoying F1 score of
81.43% compared with 80.47% of the existing method on CULane, and 86.47%
compared with 86.10% on CurveLanes."
SEAT: Stable and Explainable Attention,0.3239,"Currently, attention mechanism becomes a standard fixture in most
state-of-the-art natural language processing (NLP) models, not only due to
outstanding performance it could gain, but also due to plausible innate
explanation for the behaviors of neural architectures it provides, which is
notoriously difficult to analyze. However, recent studies show that attention
is unstable against randomness and perturbations during training or testing,
such as random seeds and slight perturbation of embedding vectors, which
impedes it from becoming a faithful explanation tool. Thus, a natural question
is whether we can find some substitute of the current attention which is more
stable and could keep the most important characteristics on explanation and
prediction of attention. In this paper, to resolve the problem, we provide a
first rigorous definition of such alternate namely SEAT (Stable and Explainable
Attention). Specifically, a SEAT should has the following three properties: (1)
Its prediction distribution is enforced to be close to the distribution based
on the vanilla attention; (2) Its top-k indices have large overlaps with those
of the vanilla attention; (3) It is robust w.r.t perturbations, i.e., any
slight perturbation on SEAT will not change the prediction distribution too
much, which implicitly indicates that it is stable to randomness and
perturbations. Finally, through intensive experiments on various datasets, we
compare our SEAT with other baseline methods using RNN, BiLSTM and BERT
architectures via six different evaluation metrics for model interpretation,
stability and accuracy. Results show that SEAT is more stable against different
perturbations and randomness while also keeps the explainability of attention,
which indicates it is a more faithful explanation. Moreover, compared with
vanilla attention, there is almost no utility (accuracy) degradation for SEAT."
Depth-Adapted CNNs for RGB-D Semantic Segmentation,0.64054,"Recent RGB-D semantic segmentation has motivated research interest thanks to
the accessibility of complementary modalities from the input side. Existing
works often adopt a two-stream architecture that processes photometric and
geometric information in parallel, with few methods explicitly leveraging the
contribution of depth cues to adjust the sampling position on RGB images. In
this paper, we propose a novel framework to incorporate the depth information
in the RGB convolutional neural network (CNN), termed Z-ACN (Depth-Adapted
CNN). Specifically, our Z-ACN generates a 2D depth-adapted offset which is
fully constrained by low-level features to guide the feature extraction on RGB
images. With the generated offset, we introduce two intuitive and effective
operations to replace basic CNN operators: depth-adapted convolution and
depth-adapted average pooling. Extensive experiments on both indoor and outdoor
semantic segmentation tasks demonstrate the effectiveness of our approach."
Coreference Resolution through a seq2seq Transition-Based System,0.508337,"Most recent coreference resolution systems use search algorithms over
possible spans to identify mentions and resolve coreference. We instead present
a coreference resolution system that uses a text-to-text (seq2seq) paradigm to
predict mentions and links jointly. We implement the coreference system as a
transition system and use multilingual T5 as an underlying language model. We
obtain state-of-the-art accuracy on the CoNLL-2012 datasets with 83.3 F1-score
for English (a 2.3 higher F1-score than previous work (Dobrovolskii, 2021))
using only CoNLL data for training, 68.5 F1-score for Arabic (+4.1 higher than
previous work) and 74.3 F1-score for Chinese (+5.3). In addition we use the
SemEval-2010 data sets for experiments in the zero-shot setting, a few-shot
setting, and supervised setting using all available training data. We get
substantially higher zero-shot F1-scores for 3 out of 4 languages than previous
approaches and significantly exceed previous supervised state-of-the-art
results for all five tested languages."
LEGO-Prover: Neural Theorem Proving with Growing Libraries,0.999444,"Despite the success of large language models (LLMs), the task of theorem
proving still remains one of the hardest reasoning tasks that is far from being
fully solved. Prior methods using language models have demonstrated promising
results, but they still struggle to prove even middle school level theorems.
One common limitation of these methods is that they assume a fixed theorem
library during the whole theorem proving process. However, as we all know,
creating new useful theorems or even new theories is not only helpful but
crucial and necessary for advancing mathematics and proving harder and deeper
results. In this work, we present LEGO-Prover, which employs a growing skill
library containing verified lemmas as skills to augment the capability of LLMs
used in theorem proving. By constructing the proof modularly, LEGO-Prover
enables LLMs to utilize existing skills retrieved from the library and to
create new skills during the proving process. These skills are further evolved
(by prompting an LLM) to enrich the library on another scale. Modular and
reusable skills are constantly added to the library to enable tackling
increasingly intricate mathematical problems. Moreover, the learned library
further bridges the gap between human proofs and formal proofs by making it
easier to impute missing steps. LEGO-Prover advances the state-of-the-art pass
rate on miniF2F-valid (48.0% to 57.0%) and miniF2F-test (45.5% to 47.1%).
During the proving process, LEGO-Prover also manages to generate over 20,000
skills (theorems/lemmas) and adds them to the growing library. Our ablation
study indicates that these newly added skills are indeed helpful for proving
theorems, resulting in an improvement from a success rate of 47.1% to 50.4%. We
also release our code and all the generated skills."
DARER: Dual-task Temporal Relational Recurrent Reasoning Network for Joint Dialog Sentiment Classification and Act Recognition,0.827567,"The task of joint dialog sentiment classification (DSC) and act recognition
(DAR) aims to simultaneously predict the sentiment label and act label for each
utterance in a dialog. In this paper, we put forward a new framework which
models the explicit dependencies via integrating \textit{prediction-level
interactions} other than semantics-level interactions, more consistent with
human intuition. Besides, we propose a speaker-aware temporal graph (SATG) and
a dual-task relational temporal graph (DRTG) to introduce \textit{temporal
relations} into dialog understanding and dual-task reasoning. To implement our
framework, we propose a novel model dubbed DARER, which first generates the
context-, speaker- and temporal-sensitive utterance representations via
modeling SATG, then conducts recurrent dual-task relational reasoning on DRTG,
in which process the estimated label distributions act as key clues in
prediction-level interactions. Experiment results show that DARER outperforms
existing models by large margins while requiring much less computation resource
and costing less training time. Remarkably, on DSC task in Mastodon, DARER
gains a relative improvement of about 25% over previous best model in terms of
F1, with less than 50% parameters and about only 60% required GPU memory."
Capturing Failures of Large Language Models via Human Cognitive Biases,0.946232,"Large language models generate complex, open-ended outputs: instead of
outputting a class label they write summaries, generate dialogue, or produce
working code. In order to asses the reliability of these open-ended generation
systems, we aim to identify qualitative categories of erroneous behavior,
beyond identifying individual errors. To hypothesize and test for such
qualitative errors, we draw inspiration from human cognitive biases --
systematic patterns of deviation from rational judgement. Specifically, we use
cognitive biases as motivation to (i) generate hypotheses for problems that
models may have, and (ii) develop experiments that elicit these problems. Using
code generation as a case study, we find that OpenAI's Codex errs predictably
based on how the input prompt is framed, adjusts outputs towards anchors, and
is biased towards outputs that mimic frequent training examples. We then use
our framework to elicit high-impact errors such as incorrectly deleting files.
Our results indicate that experimental methodology from cognitive science can
help characterize how machine learning systems behave."
Empirical Analysis of the Strengths and Weaknesses of PEFT Techniques for LLMs,0.45925,"As foundation models continue to exponentially scale in size, efficient
methods of adaptation become increasingly critical. Parameter-efficient
fine-tuning (PEFT), a recent class of techniques that require only modifying a
small percentage of the model parameters, is currently the most popular method
for adapting large language models (LLMs). Several PEFT techniques have
recently been proposed with varying tradeoffs. We provide a comprehensive and
uniform benchmark of various PEFT techniques across a representative LLM, the
FLAN-T5 model, and evaluate model performance across different data scales of
classification and generation datasets. Based on this, we provide a framework
for choosing the optimal fine-tuning techniques given the task type and data
availability. Contrary to popular belief, we also empirically prove that PEFT
techniques converge slower than full tuning in low data scenarios, and posit
the amount of data required for PEFT methods to both perform well and converge
efficiently. Lastly, we further optimize these PEFT techniques by selectively
choosing which parts of the model to train, and find that these techniques can
be applied with significantly fewer parameters while maintaining and even
improving performance."
Improving Covariance Conditioning of the SVD Meta-layer by Orthogonality,0.195817,"Inserting an SVD meta-layer into neural networks is prone to make the
covariance ill-conditioned, which could harm the model in the training
stability and generalization abilities. In this paper, we systematically study
how to improve the covariance conditioning by enforcing orthogonality to the
Pre-SVD layer. Existing orthogonal treatments on the weights are first
investigated. However, these techniques can improve the conditioning but would
hurt the performance. To avoid such a side effect, we propose the Nearest
Orthogonal Gradient (NOG) and Optimal Learning Rate (OLR). The effectiveness of
our methods is validated in two applications: decorrelated Batch Normalization
(BN) and Global Covariance Pooling (GCP). Extensive experiments on visual
recognition demonstrate that our methods can simultaneously improve the
covariance conditioning and generalization. Moreover, the combinations with
orthogonal weight can further boost the performances."
LoftQ: LoRA-Fine-Tuning-Aware Quantization for Large Language Models,0.423243,"Quantization is an indispensable technique for serving Large Language Models
(LLMs) and has recently found its way into LoRA fine-tuning. In this work we
focus on the scenario where quantization and LoRA fine-tuning are applied
together on a pre-trained model. In such cases it is common to observe a
consistent gap in the performance on downstream tasks between full fine-tuning
and quantization plus LoRA fine-tuning approach. In response, we propose LoftQ
(LoRA-Fine-Tuning-aware Quantization), a novel quantization framework that
simultaneously quantizes an LLM and finds a proper low-rank initialization for
LoRA fine-tuning. Such an initialization alleviates the discrepancy between the
quantized and full-precision model and significantly improves generalization in
downstream tasks. We evaluate our method on natural language understanding,
question answering, summarization, and natural language generation tasks.
Experiments show that our method is highly effective and outperforms existing
quantization methods, especially in the challenging 2-bit and 2/4-bit mixed
precision regimes. The code is available on https://github.com/yxli2123/LoftQ."
Minimum Bayes' Risk Decoding for System Combination of Grammatical Error Correction Systems,0.24883,"For sequence-to-sequence tasks it is challenging to combine individual system
outputs. Further, there is also often a mismatch between the decoding criterion
and the one used for assessment. Minimum Bayes' Risk (MBR) decoding can be used
to combine system outputs in a manner that encourages better alignment with the
final assessment criterion. This paper examines MBR decoding for Grammatical
Error Correction (GEC) systems, where performance is usually evaluated in terms
of edits and an associated F-score. Hence, we propose a novel MBR loss function
directly linked to this form of criterion. Furthermore, an approach to expand
the possible set of candidate sentences is described. This builds on a current
max-voting combination scheme, as well as individual edit-level selection.
Experiments on three popular GEC datasets and with state-of-the-art GEC systems
demonstrate the efficacy of the proposed MBR approach. Additionally, the paper
highlights how varying reward metrics within the MBR decoding framework can
provide control over precision, recall, and the F-score in combined GEC
systems."
On Projectivity in Markov Logic Networks,0.113739,"Markov Logic Networks (MLNs) define a probability distribution on relational
structures over varying domain sizes. Many works have noticed that MLNs, like
many other relational models, do not admit consistent marginal inference over
varying domain sizes. Furthermore, MLNs learnt on a certain domain do not
generalize to new domains of varied sizes. In recent works, connections have
emerged between domain size dependence, lifted inference and learning from
sub-sampled domains. The central idea to these works is the notion of
projectivity. The probability distributions ascribed by projective models
render the marginal probabilities of sub-structures independent of the domain
cardinality. Hence, projective models admit efficient marginal inference,
removing any dependence on the domain size. Furthermore, projective models
potentially allow efficient and consistent parameter learning from sub-sampled
domains. In this paper, we characterize the necessary and sufficient conditions
for a two-variable MLN to be projective. We then isolate a special model in
this class of MLNs, namely Relational Block Model (RBM). We show that, in terms
of data likelihood maximization, RBM is the best possible projective MLN in the
two-variable fragment. Finally, we show that RBMs also admit consistent
parameter learning over sub-sampled domains."
RSFDM-Net: Real-time Spatial and Frequency Domains Modulation Network for Underwater Image Enhancement,0.582375,"Underwater images typically experience mixed degradations of brightness and
structure caused by the absorption and scattering of light by suspended
particles. To address this issue, we propose a Real-time Spatial and Frequency
Domains Modulation Network (RSFDM-Net) for the efficient enhancement of colors
and details in underwater images. Specifically, our proposed conditional
network is designed with Adaptive Fourier Gating Mechanism (AFGM) and
Multiscale Convolutional Attention Module (MCAM) to generate vectors carrying
low-frequency background information and high-frequency detail features, which
effectively promote the network to model global background information and
local texture details. To more precisely correct the color cast and low
saturation of the image, we introduce a Three-branch Feature Extraction (TFE)
block in the primary net that processes images pixel by pixel to integrate the
color information extended by the same channel (R, G, or B). This block
consists of three small branches, each of which has its own weights. Extensive
experiments demonstrate that our network significantly outperforms over
state-of-the-art methods in both visual quality and quantitative metrics."
LingMess: Linguistically Informed Multi Expert Scorers for Coreference Resolution,0.882429,"While coreference resolution typically involves various linguistic
challenges, recent models are based on a single pairwise scorer for all types
of pairs. We present LingMess, a new coreference model that defines different
categories of coreference cases and optimize multiple pairwise scorers, where
each scorer learns a specific set of linguistic challenges. Our model
substantially improves pairwise scores for most categories and outperforms
cluster-level performance on Ontonotes and 5 additional datasets. Our model is
available in https://github.com/shon-otmazgin/lingmess-coref"
"CounterGeDi: A controllable approach to generate polite, detoxified and emotional counterspeech",0.787466,"Recently, many studies have tried to create generation models to assist
counter speakers by providing counterspeech suggestions for combating the
explosive proliferation of online hate. However, since these suggestions are
from a vanilla generation model, they might not include the appropriate
properties required to counter a particular hate speech instance. In this
paper, we propose CounterGeDi - an ensemble of generative discriminators (GeDi)
to guide the generation of a DialoGPT model toward more polite, detoxified, and
emotionally laden counterspeech. We generate counterspeech using three datasets
and observe significant improvement across different attribute scores. The
politeness and detoxification scores increased by around 15% and 6%
respectively, while the emotion in the counterspeech increased by at least 10%
across all the datasets. We also experiment with triple-attribute control and
observe significant improvement over single attribute results when combining
complementing attributes, e.g., politeness, joyfulness and detoxification. In
all these experiments, the relevancy of the generated text does not deteriorate
due to the application of these controls"
Implicit Neural Head Synthesis via Controllable Local Deformation Fields,0.524946,"High-quality reconstruction of controllable 3D head avatars from 2D videos is
highly desirable for virtual human applications in movies, games, and
telepresence. Neural implicit fields provide a powerful representation to model
3D head avatars with personalized shape, expressions, and facial parts, e.g.,
hair and mouth interior, that go beyond the linear 3D morphable model (3DMM).
However, existing methods do not model faces with fine-scale facial features,
or local control of facial parts that extrapolate asymmetric expressions from
monocular videos. Further, most condition only on 3DMM parameters with poor(er)
locality, and resolve local features with a global neural field. We build on
part-based implicit shape models that decompose a global deformation field into
local ones. Our novel formulation models multiple implicit deformation fields
with local semantic rig-like control via 3DMM-based parameters, and
representative facial landmarks. Further, we propose a local control loss and
attention mask mechanism that promote sparsity of each learned deformation
field. Our formulation renders sharper locally controllable nonlinear
deformations than previous implicit monocular approaches, especially mouth
interior, asymmetric expressions, and facial details."
Back to the Roots: Reconstructing Large and Complex Cranial Defects using an Image-based Statistical Shape Model,0.366961,"Designing implants for large and complex cranial defects is a challenging
task, even for professional designers. Current efforts on automating the design
process focused mainly on convolutional neural networks (CNN), which have
produced state-of-the-art results on reconstructing synthetic defects. However,
existing CNN-based methods have been difficult to translate to clinical
practice in cranioplasty, as their performance on complex and irregular cranial
defects remains unsatisfactory. In this paper, a statistical shape model (SSM)
built directly on the segmentation masks of the skulls is presented. We
evaluate the SSM on several cranial implant design tasks, and the results show
that, while the SSM performs suboptimally on synthetic defects compared to
CNN-based approaches, it is capable of reconstructing large and complex defects
with only minor manual corrections. The quality of the resulting implants is
examined and assured by experienced neurosurgeons. In contrast, CNN-based
approaches, even with massive data augmentation, fail or produce
less-than-satisfactory implants for these cases. Codes are publicly available
at https://github.com/Jianningli/ssm"
Semantic Line Detection Using Mirror Attention and Comparative Ranking and Matching,0.576186,"A novel algorithm to detect semantic lines is proposed in this paper. We
develop three networks: detection network with mirror attention (D-Net) and
comparative ranking and matching networks (R-Net and M-Net). D-Net extracts
semantic lines by exploiting rich contextual information. To this end, we
design the mirror attention module. Then, through pairwise comparisons of
extracted semantic lines, we iteratively select the most semantic line and
remove redundant ones overlapping with the selected one. For the pairwise
comparisons, we develop R-Net and M-Net in the Siamese architecture.
Experiments demonstrate that the proposed algorithm outperforms the
conventional semantic line detector significantly. Moreover, we apply the
proposed algorithm to detect two important kinds of semantic lines
successfully: dominant parallel lines and reflection symmetry axes. Our codes
are available at https://github.com/dongkwonjin/Semantic-Line-DRM."
Simulated Contextual Bandits for Personalization Tasks from Recommendation Datasets,0.0511081,"We propose a method for generating simulated contextual bandit environments
for personalization tasks from recommendation datasets like MovieLens, Netflix,
Last.fm, Million Song, etc. This allows for personalization environments to be
developed based on real-life data to reflect the nuanced nature of real-world
user interactions. The obtained environments can be used to develop methods for
solving personalization tasks, algorithm benchmarking, model simulation, and
more. We demonstrate our approach with numerical examples on MovieLens and IMDb
datasets."
Unsupervised Hebbian Learning on Point Sets in StarCraft II,0.0802377,"Learning the evolution of real-time strategy (RTS) game is a challenging
problem in artificial intelligent (AI) system. In this paper, we present a
novel Hebbian learning method to extract the global feature of point sets in
StarCraft II game units, and its application to predict the movement of the
points. Our model includes encoder, LSTM, and decoder, and we train the encoder
with the unsupervised learning method. We introduce the concept of neuron
activity aware learning combined with k-Winner-Takes-All. The optimal value of
neuron activity is mathematically derived, and experiments support the
effectiveness of the concept over the downstream task. Our Hebbian learning
rule benefits the prediction with lower loss compared to self-supervised
learning. Also, our model significantly saves the computational cost such as
activations and FLOPs compared to a frame-based approach."
Identifying Adversarial Attacks on Text Classifiers,0.401003,"The landscape of adversarial attacks against text classifiers continues to
grow, with new attacks developed every year and many of them available in
standard toolkits, such as TextAttack and OpenAttack. In response, there is a
growing body of work on robust learning, which reduces vulnerability to these
attacks, though sometimes at a high cost in compute time or accuracy. In this
paper, we take an alternate approach -- we attempt to understand the attacker
by analyzing adversarial text to determine which methods were used to create
it. Our first contribution is an extensive dataset for attack detection and
labeling: 1.5~million attack instances, generated by twelve adversarial attacks
targeting three classifiers trained on six source datasets for sentiment
analysis and abuse detection in English. As our second contribution, we use
this dataset to develop and benchmark a number of classifiers for attack
identification -- determining if a given text has been adversarially
manipulated and by which attack. As a third contribution, we demonstrate the
effectiveness of three classes of features for these tasks: text properties,
capturing content and presentation of text; language model properties,
determining which tokens are more or less probable throughout the input; and
target model properties, representing how the text classifier is influenced by
the attack, including internal node activations. Overall, this represents a
first step towards forensics for adversarial attacks against text classifiers."
Robust Object Detection With Inaccurate Bounding Boxes,0.761333,"Learning accurate object detectors often requires large-scale training data
with precise object bounding boxes. However, labeling such data is expensive
and time-consuming. As the crowd-sourcing labeling process and the ambiguities
of the objects may raise noisy bounding box annotations, the object detectors
will suffer from the degenerated training data. In this work, we aim to address
the challenge of learning robust object detectors with inaccurate bounding
boxes. Inspired by the fact that localization precision suffers significantly
from inaccurate bounding boxes while classification accuracy is less affected,
we propose leveraging classification as a guidance signal for refining
localization results. Specifically, by treating an object as a bag of
instances, we introduce an Object-Aware Multiple Instance Learning approach
(OA-MIL), featured with object-aware instance selection and object-aware
instance extension. The former aims to select accurate instances for training,
instead of directly using inaccurate box annotations. The latter focuses on
generating high-quality instances for selection. Extensive experiments on
synthetic noisy datasets (i.e., noisy PASCAL VOC and MS-COCO) and a real noisy
wheat head dataset demonstrate the effectiveness of our OA-MIL. Code is
available at https://github.com/cxliu0/OA-MIL."
Overview of Test Coverage Criteria for Test Case Generation from Finite State Machines Modelled as Directed Graphs,0.210364,"Test Coverage criteria are an essential concept for test engineers when
generating the test cases from a System Under Test model. They are routinely
used in test case generation for user interfaces, middleware, and back-end
system parts for software, electronics, or Internet of Things (IoT) systems.
Test Coverage criteria define the number of actions or combinations by which a
system is tested, informally determining a potential ""strength"" of a test set.
As no previous study summarized all commonly used test coverage criteria for
Finite State Machines and comprehensively discussed them regarding their
subsumption, equivalence, or non-comparability, this paper provides this
overview. In this study, 14 most common test coverage criteria and seven of
their synonyms for Finite State Machines defined via a directed graph are
summarized and compared. The results give researchers and industry testing
engineers a helpful overview when setting a software-based or IoT system test
strategy."
Hand Geometry Based Recognition with a MLP Classifier,0.0420242,"This paper presents a biometric recognition system based on hand geometry. We
describe a database specially collected for research purposes, which consists
of 50 people and 10 different acquisitions of the right hand. This database can
be freely downloaded. In addition, we describe a feature extraction procedure
and we obtain experimental results using different classification strategies
based on Multi Layer Perceptrons (MLP). We have evaluated identification rates
and Detection Cost Function (DCF) values for verification applications.
Experimental results reveal up to 100% identification and 0% DCF"
Understanding Text Classification Data and Models Using Aggregated Input Salience,0.0517587,"Realizing when a model is right for a wrong reason is not trivial and
requires a significant effort by model developers. In some cases an input
salience method, which highlights the most important parts of the input, may
reveal problematic reasoning. But scrutinizing highlights over many data
instances is tedious and often infeasible. Furthermore, analyzing examples in
isolation does not reveal general patterns in the data or in the model's
behavior. In this paper we aim to address these issues and go from
understanding single examples to understanding entire datasets and models. The
methodology we propose is based on aggregated salience maps, to which we apply
clustering, nearest neighbor search and visualizations. Using this methodology
we address multiple distinct but common model developer needs by showing how
problematic data and model behavior can be identified and explained -- a
necessary first step for improving the model."
FSOINet: Feature-Space Optimization-Inspired Network for Image Compressive Sensing,0.662062,"In recent years, deep learning-based image compressive sensing (ICS) methods
have achieved brilliant success. Many optimization-inspired networks have been
proposed to bring the insights of optimization algorithms into the network
structure design and have achieved excellent reconstruction quality with low
computational complexity. But they keep the information flow in pixel space as
traditional algorithms by updating and transferring the image in pixel space,
which does not fully use the information in the image features. In this paper,
we propose the idea of achieving information flow phase by phase in feature
space and design a Feature-Space Optimization-Inspired Network (dubbed FSOINet)
to implement it by mapping both steps of proximal gradient descent algorithm
from pixel space to feature space. Moreover, the sampling matrix is learned
end-to-end with other network parameters. Experiments show that the proposed
FSOINet outperforms the existing state-of-the-art methods by a large margin
both quantitatively and qualitatively. The source code is available on
https://github.com/cwjjun/FSOINet."
Privacy-Friendly Peer-to-Peer Energy Trading: A Game Theoretical Approach,0.362125,"In this paper, we propose a decentralized, privacy-friendly energy trading
platform (PFET) based on game theoretical approach - specifically Stackelberg
competition. Unlike existing trading schemes, PFET provides a competitive
market in which prices and demands are determined based on competition, and
computations are performed in a decentralized manner which does not rely on
trusted third parties. It uses homomorphic encryption cryptosystem to encrypt
sensitive information of buyers and sellers such as sellers$'$ prices and
buyers$'$ demands. Buyers calculate total demand on particular seller using an
encrypted data and sensitive buyer profile data is hidden from sellers. Hence,
privacy of both sellers and buyers is preserved. Through privacy analysis and
performance evaluation, we show that PFET preserves users$'$ privacy in an
efficient manner."
Detect Any Deepfakes: Segment Anything Meets Face Forgery Detection and Localization,0.563211,"The rapid advancements in computer vision have stimulated remarkable progress
in face forgery techniques, capturing the dedicated attention of researchers
committed to detecting forgeries and precisely localizing manipulated areas.
Nonetheless, with limited fine-grained pixel-wise supervision labels, deepfake
detection models perform unsatisfactorily on precise forgery detection and
localization. To address this challenge, we introduce the well-trained vision
segmentation foundation model, i.e., Segment Anything Model (SAM) in face
forgery detection and localization. Based on SAM, we propose the Detect Any
Deepfakes (DADF) framework with the Multiscale Adapter, which can capture
short- and long-range forgery contexts for efficient fine-tuning. Moreover, to
better identify forged traces and augment the model's sensitivity towards
forgery regions, Reconstruction Guided Attention (RGA) module is proposed. The
proposed framework seamlessly integrates end-to-end forgery localization and
detection optimization. Extensive experiments on three benchmark datasets
demonstrate the superiority of our approach for both forgery detection and
localization. The codes will be released soon at
https://github.com/laiyingxin2/DADF."
SD-Conv: Towards the Parameter-Efficiency of Dynamic Convolution,0.20924,"Dynamic convolution achieves better performance for efficient CNNs at the
cost of negligible FLOPs increase. However, the performance increase can not
match the significantly expanded number of parameters, which is the main
bottleneck in real-world applications. Contrastively, mask-based unstructured
pruning obtains a lightweight network by removing redundancy in the heavy
network. In this paper, we propose a new framework, \textbf{Sparse Dynamic
Convolution} (\textsc{SD-Conv}), to naturally integrate these two paths such
that it can inherit the advantage of dynamic mechanism and sparsity. We first
design a binary mask derived from a learnable threshold to prune static
kernels, significantly reducing the parameters and computational cost but
achieving higher performance in Imagenet-1K. We further transfer pretrained
models into a variety of downstream tasks, showing consistently better results
than baselines. We hope our SD-Conv could be an efficient alternative to
conventional dynamic convolutions."
YFACC: A Yorb speech-image dataset for cross-lingual keyword localisation through visual grounding,0.459567,"Visually grounded speech (VGS) models are trained on images paired with
unlabelled spoken captions. Such models could be used to build speech systems
in settings where it is impossible to get labelled data, e.g. for documenting
unwritten languages. However, most VGS studies are in English or other
high-resource languages. This paper attempts to address this shortcoming. We
collect and release a new single-speaker dataset of audio captions for 6k
Flickr images in Yor\`ub\'a -- a real low-resource language spoken in Nigeria.
We train an attention-based VGS model where images are automatically tagged
with English visual labels and paired with Yor\`ub\'a utterances. This enables
cross-lingual keyword localisation: a written English query is detected and
located in Yor\`ub\'a speech. To quantify the effect of the smaller dataset, we
compare to English systems trained on similar and more data. We hope that this
new dataset will stimulate research in the use of VGS models for real
low-resource languages."
From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models,0.949464,"Language models (LMs) are pretrained on diverse data sources, including news,
discussion forums, books, and online encyclopedias. A significant portion of
this data includes opinions and perspectives which, on one hand, celebrate
democracy and diversity of ideas, and on the other hand are inherently socially
biased. Our work develops new methods to (1) measure political biases in LMs
trained on such corpora, along social and economic axes, and (2) measure the
fairness of downstream NLP models trained on top of politically biased LMs. We
focus on hate speech and misinformation detection, aiming to empirically
quantify the effects of political (social, economic) biases in pretraining data
on the fairness of high-stakes social-oriented tasks. Our findings reveal that
pretrained LMs do have political leanings that reinforce the polarization
present in pretraining corpora, propagating social biases into hate speech
predictions and misinformation detectors. We discuss the implications of our
findings for NLP research and propose future directions to mitigate unfairness."
Market Making with Scaled Beta Policies,0.629701,"This paper introduces a new representation for the actions of a market maker
in an order-driven market. This representation uses scaled beta distributions,
and generalises three approaches taken in the artificial intelligence for
market making literature: single price-level selection, ladder strategies and
""market making at the touch"". Ladder strategies place uniform volume across an
interval of contiguous prices. Scaled beta distribution based policies
generalise these, allowing volume to be skewed across the price interval. We
demonstrate that this flexibility is useful for inventory management, one of
the key challenges faced by a market maker.
  In this paper, we conduct three main experiments: first, we compare our more
flexible beta-based actions with the special case of ladder strategies; then,
we investigate the performance of simple fixed distributions; and finally, we
devise and evaluate a simple and intuitive dynamic control policy that adjusts
actions in a continuous manner depending on the signed inventory that the
market maker has acquired. All empirical evaluations use a high-fidelity limit
order book simulator based on historical data with 50 levels on each side."
Transformers and CNNs both Beat Humans on SBIR,0.028346,"Sketch-based image retrieval (SBIR) is the task of retrieving natural images
(photos) that match the semantics and the spatial configuration of hand-drawn
sketch queries. The universality of sketches extends the scope of possible
applications and increases the demand for efficient SBIR solutions. In this
paper, we study classic triplet-based SBIR solutions and show that a persistent
invariance to horizontal flip (even after model finetuning) is harming
performance. To overcome this limitation, we propose several approaches and
evaluate in depth each of them to check their effectiveness. Our main
contributions are twofold: We propose and evaluate several intuitive
modifications to build SBIR solutions with better flip equivariance. We show
that vision transformers are more suited for the SBIR task, and that they
outperform CNNs with a large margin. We carried out numerous experiments and
introduce the first models to outperform human performance on a large-scale
SBIR benchmark (Sketchy). Our best model achieves a recall of 62.25% (at k = 1)
on the sketchy benchmark compared to previous state-of-the-art methods 46.2%."
Can We Revitalize Interventional Healthcare with AI-XR Surgical Metaverses?,0.19339,"Recent advancements in technology, particularly in machine learning (ML),
deep learning (DL), and the metaverse, offer great potential for
revolutionizing surgical science. The combination of artificial intelligence
and extended reality (AI-XR) technologies has the potential to create a
surgical metaverse, a virtual environment where surgeries can be planned and
performed. This paper aims to provide insight into the various potential
applications of an AI-XR surgical metaverse and the challenges that must be
addressed to bring its full potential to fruition. It is important for the
community to focus on these challenges to fully realize the potential of the
AI-XR surgical metaverses. Furthermore, to emphasize the need for secure and
robust AI-XR surgical metaverses and to demonstrate the real-world implications
of security threats to the AI-XR surgical metaverses, we present a case study
in which the ``an immersive surgical attack'' on incision point localization is
performed in the context of preoperative planning in a surgical metaverse."
MMDialog: A Large-scale Multi-turn Dialogue Dataset Towards Multi-modal Open-domain Conversation,0.657132,"Responding with multi-modal content has been recognized as an essential
capability for an intelligent conversational agent. In this paper, we introduce
the MMDialog dataset to better facilitate multi-modal conversation. MMDialog is
composed of a curated set of 1.08 million real-world dialogues with 1.53
million unique images across 4,184 topics. MMDialog has two main and unique
advantages. First, it is the largest multi-modal conversation dataset by the
number of dialogues by 88x. Second, it contains massive topics to generalize
the open-domain. To build engaging dialogue system with this dataset, we
propose and normalize two response producing tasks based on retrieval and
generative scenarios. In addition, we build two baselines for above tasks with
state-of-the-art techniques and report their experimental performance. We also
propose a novel evaluation metric MM-Relevance to measure the multi-modal
responses. Our dataset and scripts are available in
https://github.com/victorsungo/MMDialog."
Bidding Agent Design in the LinkedIn Ad Marketplace,0.459246,"We establish a general optimization framework for the design of automated
bidding agent in dynamic online marketplaces. It optimizes solely for the
buyer's interest and is agnostic to the auction mechanism imposed by the
seller. As a result, the framework allows, for instance, the joint optimization
of a group of ads across multiple platforms each running its own auction
format. Bidding strategy derived from this framework automatically guarantees
the optimality of budget allocation across ad units and platforms. Common
constraints such as budget delivery schedule, return on investments and
guaranteed results, directly translates to additional parameters in the bidding
formula. We share practical learnings of the deployed bidding system in the
LinkedIn ad marketplace based on this framework."
Fine-Grained Scene Graph Generation with Data Transfer,0.914471,"Scene graph generation (SGG) is designed to extract (subject, predicate,
object) triplets in images. Recent works have made a steady progress on SGG,
and provide useful tools for high-level vision and language understanding.
However, due to the data distribution problems including long-tail distribution
and semantic ambiguity, the predictions of current SGG models tend to collapse
to several frequent but uninformative predicates (e.g., on, at), which limits
practical application of these models in downstream tasks. To deal with the
problems above, we propose a novel Internal and External Data Transfer
(IETrans) method, which can be applied in a plug-and-play fashion and expanded
to large SGG with 1,807 predicate classes. Our IETrans tries to relieve the
data distribution problem by automatically creating an enhanced dataset that
provides more sufficient and coherent annotations for all predicates. By
training on the enhanced dataset, a Neural Motif model doubles the macro
performance while maintaining competitive micro performance. The code and data
are publicly available at https://github.com/waxnkw/IETrans-SGG.pytorch."
Do it Like the Doctor: How We Can Design a Model That Uses Domain Knowledge to Diagnose Pneumothorax,0.030559,"Computer-aided diagnosis for medical imaging is a well-studied field that
aims to provide real-time decision support systems for physicians. These
systems attempt to detect and diagnose a plethora of medical conditions across
a variety of image diagnostic technologies including ultrasound, x-ray, MRI,
and CT. When designing AI models for these systems, we are often limited by
little training data, and for rare medical conditions, positive examples are
difficult to obtain. These issues often cause models to perform poorly, so we
needed a way to design an AI model in light of these limitations. Thus, our
approach was to incorporate expert domain knowledge into the design of an AI
model. We conducted two qualitative think-aloud studies with doctors trained in
the interpretation of lung ultrasound diagnosis to extract relevant domain
knowledge for the condition Pneumothorax. We extracted knowledge of key
features and procedures used to make a diagnosis. With this knowledge, we
employed knowledge engineering concepts to make recommendations for an AI model
design to automatically diagnose Pneumothorax."
Adapting Pretrained Text-to-Text Models for Long Text Sequences,0.758419,"We present an empirical study of adapting an existing pretrained text-to-text
model for long-sequence inputs. Through a comprehensive study along three axes
of the pretraining pipeline -- model architecture, optimization objective, and
pretraining corpus, we propose an effective recipe to build long-context models
from existing short-context models. Specifically, we replace the full attention
in transformers with pooling-augmented blockwise attention, and pretrain the
model with a masked-span prediction task with spans of varying length. In terms
of the pretraining corpus, we find that using randomly concatenated
short-documents from a large open-domain corpus results in better performance
than using existing long document corpora which are typically limited in their
domain coverage. With these findings, we build a long-context model that
achieves competitive performance on long-text QA tasks and establishes the new
state of the art on five long-text summarization datasets, often outperforming
previous methods with larger model sizes. Our code has been released at
https://github.com/facebookresearch/bart_ls."
CSP: Self-Supervised Contrastive Spatial Pre-Training for Geospatial-Visual Representations,0.910751,"Geo-tagged images are publicly available in large quantities, whereas labels
such as object classes are rather scarce and expensive to collect. Meanwhile,
contrastive learning has achieved tremendous success in various natural image
and language tasks with limited labeled data. However, existing methods fail to
fully leverage geospatial information, which can be paramount to distinguishing
objects that are visually similar. To directly leverage the abundant geospatial
information associated with images in pre-training, fine-tuning, and inference
stages, we present Contrastive Spatial Pre-Training (CSP), a self-supervised
learning framework for geo-tagged images. We use a dual-encoder to separately
encode the images and their corresponding geo-locations, and use contrastive
objectives to learn effective location representations from images, which can
be transferred to downstream supervised tasks such as image classification.
Experiments show that CSP can improve model performance on both iNat2018 and
fMoW datasets. Especially, on iNat2018, CSP significantly boosts the model
performance with 10-34% relative improvement with various labeled training data
sampling ratios."
An Application of a Runtime Epistemic Probabilistic Event Calculus to Decision-making in e-Health Systems,0.424044,"We present and discuss a runtime architecture that integrates sensorial data
and classifiers with a logic-based decision-making system in the context of an
e-Health system for the rehabilitation of children with neuromotor disorders.
In this application, children perform a rehabilitation task in the form of
games. The main aim of the system is to derive a set of parameters the child's
current level of cognitive and behavioral performance (e.g., engagement,
attention, task accuracy) from the available sensors and classifiers (e.g., eye
trackers, motion sensors, emotion recognition techniques) and take decisions
accordingly. These decisions are typically aimed at improving the child's
performance by triggering appropriate re-engagement stimuli when their
attention is low, by changing the game or making it more difficult when the
child is losing interest in the task as it is too easy. Alongside
state-of-the-art techniques for emotion recognition and head pose estimation,
we use a runtime variant of a probabilistic and epistemic logic programming
dialect of the Event Calculus, known as the Epistemic Probabilistic Event
Calculus. In particular, the probabilistic component of this symbolic framework
allows for a natural interface with the machine learning techniques. We
overview the architecture and its components, and show some of its
characteristics through a discussion of a running example and experiments.
Under consideration for publication in Theory and Practice of Logic Programming
(TPLP)."
ezCoref: Towards Unifying Annotation Guidelines for Coreference Resolution,0.130874,"Large-scale, high-quality corpora are critical for advancing research in
coreference resolution. However, existing datasets vary in their definition of
coreferences and have been collected via complex and lengthy guidelines that
are curated for linguistic experts. These concerns have sparked a growing
interest among researchers to curate a unified set of guidelines suitable for
annotators with various backgrounds. In this work, we develop a
crowdsourcing-friendly coreference annotation methodology, ezCoref, consisting
of an annotation tool and an interactive tutorial. We use ezCoref to
re-annotate 240 passages from seven existing English coreference datasets
(spanning fiction, news, and multiple other domains) while teaching annotators
only cases that are treated similarly across these datasets. Surprisingly, we
find that reasonable quality annotations were already achievable (>90%
agreement between the crowd and expert annotations) even without extensive
training. On carefully analyzing the remaining disagreements, we identify the
presence of linguistic cases that our annotators unanimously agree upon but
lack unified treatments (e.g., generic pronouns, appositives) in existing
datasets. We propose the research community should revisit these phenomena when
curating future unified annotation guidelines."
Generalized Quantifiers as a Source of Error in Multilingual NLU Benchmarks,0.199169,"Logical approaches to representing language have developed and evaluated
computational models of quantifier words since the 19th century, but today's
NLU models still struggle to capture their semantics. We rely on Generalized
Quantifier Theory for language-independent representations of the semantics of
quantifier words, to quantify their contribution to the errors of NLU models.
We find that quantifiers are pervasive in NLU benchmarks, and their occurrence
at test time is associated with performance drops. Multilingual models also
exhibit unsatisfying quantifier reasoning abilities, but not necessarily worse
for non-English languages. To facilitate directly-targeted probing, we present
an adversarial generalized quantifier NLI task (GQNLI) and show that
pre-trained language models have a clear lack of robustness in generalized
quantifier reasoning."
Photorealistic Monocular 3D Reconstruction of Humans Wearing Clothing,0.987249,"We present PHORHUM, a novel, end-to-end trainable, deep neural network
methodology for photorealistic 3D human reconstruction given just a monocular
RGB image. Our pixel-aligned method estimates detailed 3D geometry and, for the
first time, the unshaded surface color together with the scene illumination.
Observing that 3D supervision alone is not sufficient for high fidelity color
reconstruction, we introduce patch-based rendering losses that enable reliable
color reconstruction on visible parts of the human, and detailed and plausible
color estimation for the non-visible parts. Moreover, our method specifically
addresses methodological and practical limitations of prior work in terms of
representing geometry, albedo, and illumination effects, in an end-to-end model
where factors can be effectively disentangled. In extensive experiments, we
demonstrate the versatility and robustness of our approach. Our
state-of-the-art results validate the method qualitatively and for different
metrics, for both geometric and color reconstruction."
PolyBuilding: Polygon Transformer for End-to-End Building Extraction,0.406055,"We present PolyBuilding, a fully end-to-end polygon Transformer for building
extraction. PolyBuilding direct predicts vector representation of buildings
from remote sensing images. It builds upon an encoder-decoder transformer
architecture and simultaneously outputs building bounding boxes and polygons.
Given a set of polygon queries, the model learns the relations among them and
encodes context information from the image to predict the final set of building
polygons with fixed vertex numbers. Corner classification is performed to
distinguish the building corners from the sampled points, which can be used to
remove redundant vertices along the building walls during inference. A 1-d
non-maximum suppression (NMS) is further applied to reduce vertex redundancy
near the building corners. With the refinement operations, polygons with
regular shapes and low complexity can be effectively obtained. Comprehensive
experiments are conducted on the CrowdAI dataset. Quantitative and qualitative
results show that our approach outperforms prior polygonal building extraction
methods by a large margin. It also achieves a new state-of-the-art in terms of
pixel-level coverage, instance-level precision and recall, and geometry-level
properties (including contour regularity and polygon complexity)."
Leveraging Visual Knowledge in Language Tasks: An Empirical Study on Intermediate Pre-training for Cross-modal Knowledge Transfer,0.388518,"Pre-trained language models are still far from human performance in tasks
that need understanding of properties (e.g. appearance, measurable quantity)
and affordances of everyday objects in the real world since the text lacks such
information due to reporting bias. In this work, we study whether integrating
visual knowledge into a language model can fill the gap. We investigate two
types of knowledge transfer: (1) text knowledge transfer using image captions
that may contain enriched visual knowledge and (2) cross-modal knowledge
transfer using both images and captions with vision-language training
objectives. On 5 downstream tasks that may need visual knowledge to solve the
problem, we perform extensive empirical comparisons over the presented
objectives. Our experiments show that visual knowledge transfer can improve
performance in both low-resource and fully supervised settings."
UncLe-SLAM: Uncertainty Learning for Dense Neural SLAM,0.868616,"We present an uncertainty learning framework for dense neural simultaneous
localization and mapping (SLAM). Estimating pixel-wise uncertainties for the
depth input of dense SLAM methods allows re-weighing the tracking and mapping
losses towards image regions that contain more suitable information that is
more reliable for SLAM. To this end, we propose an online framework for sensor
uncertainty estimation that can be trained in a self-supervised manner from
only 2D input data. We further discuss the advantages of the uncertainty
learning for the case of multi-sensor input. Extensive analysis,
experimentation, and ablations show that our proposed modeling paradigm
improves both mapping and tracking accuracy and often performs better than
alternatives that require ground truth depth or 3D. Our experiments show that
we achieve a 38\% and 27\% lower absolute trajectory tracking error (ATE) on
the 7-Scenes and TUM-RGBD datasets respectively. On the popular Replica dataset
using two types of depth sensors, we report an 11\% F1-score improvement on
RGBD SLAM compared to the recent state-of-the-art neural implicit approaches.
Source code: https://github.com/kev-in-ta/UncLe-SLAM."
Generating Training Data with Language Models: Towards Zero-Shot Language Understanding,0.892512,"Pretrained language models (PLMs) have demonstrated remarkable performance in
various natural language processing tasks: Unidirectional PLMs (e.g., GPT) are
well known for their superior text generation capabilities; bidirectional PLMs
(e.g., BERT) have been the prominent choice for natural language understanding
(NLU) tasks. While both types of models have achieved promising few-shot
learning performance, their potential for zero-shot learning has been
underexplored. In this paper, we present a simple approach that uses both types
of PLMs for fully zero-shot learning of NLU tasks without requiring any
task-specific data: A unidirectional PLM generates class-conditioned texts
guided by prompts, which are used as the training data for fine-tuning a
bidirectional PLM. With quality training data selected based on the generation
probability and regularization techniques (label smoothing and temporal
ensembling) applied to the fine-tuning stage for better generalization and
stability, our approach demonstrates strong performance across seven
classification tasks of the GLUE benchmark (e.g., 72.3/73.8 on MNLI-m/mm and
92.8 on SST-2), significantly outperforming zero-shot prompting methods and
achieving even comparable results to strong few-shot approaches using 32
training samples per class."
Anomaly localization for copy detection patterns through print estimations,0.223598,"Copy detection patterns (CDP) are recent technologies for protecting products
from counterfeiting. However, in contrast to traditional copy fakes, deep
learning-based fakes have shown to be hardly distinguishable from originals by
traditional authentication systems. Systems based on classical supervised
learning and digital templates assume knowledge of fake CDP at training time
and cannot generalize to unseen types of fakes. Authentication based on printed
copies of originals is an alternative that yields better results even for
unseen fakes and simple authentication metrics but comes at the impractical
cost of acquisition and storage of printed copies. In this work, to overcome
these shortcomings, we design a machine learning (ML) based authentication
system that only requires digital templates and printed original CDP for
training, whereas authentication is based solely on digital templates, which
are used to estimate original printed codes. The obtained results show that the
proposed system can efficiently authenticate original and detect fake CDP by
accurately locating the anomalies in the fake CDP. The empirical evaluation of
the authentication system under investigation is performed on the original and
ML-based fakes CDP printed on two industrial printers."
Privacy-Preserving Image Classification Using Vision Transformer,0.864702,"In this paper, we propose a privacy-preserving image classification method
that is based on the combined use of encrypted images and the vision
transformer (ViT). The proposed method allows us not only to apply images
without visual information to ViT models for both training and testing but to
also maintain a high classification accuracy. ViT utilizes patch embedding and
position embedding for image patches, so this architecture is shown to reduce
the influence of block-wise image transformation. In an experiment, the
proposed method for privacy-preserving image classification is demonstrated to
outperform state-of-the-art methods in terms of classification accuracy and
robustness against various attacks."
Generalizing to the Future: Mitigating Entity Bias in Fake News Detection,0.722496,"The wide dissemination of fake news is increasingly threatening both
individuals and society. Fake news detection aims to train a model on the past
news and detect fake news of the future. Though great efforts have been made,
existing fake news detection methods overlooked the unintended entity bias in
the real-world data, which seriously influences models' generalization ability
to future data. For example, 97\% of news pieces in 2010-2017 containing the
entity `Donald Trump' are real in our data, but the percentage falls down to
merely 33\% in 2018. This would lead the model trained on the former set to
hardly generalize to the latter, as it tends to predict news pieces about
`Donald Trump' as real for lower training loss. In this paper, we propose an
entity debiasing framework (\textbf{ENDEF}) which generalizes fake news
detection models to the future data by mitigating entity bias from a
cause-effect perspective. Based on the causal graph among entities, news
contents, and news veracity, we separately model the contribution of each cause
(entities and contents) during training. In the inference stage, we remove the
direct effect of the entities to mitigate entity bias. Extensive offline
experiments on the English and Chinese datasets demonstrate that the proposed
framework can largely improve the performance of base fake news detectors, and
online tests verify its superiority in practice. To the best of our knowledge,
this is the first work to explicitly improve the generalization ability of fake
news detection models to the future data. The code has been released at
https://github.com/ICTMCG/ENDEF-SIGIR2022."
CILIATE: Towards Fairer Class-based Incremental Learning by Dataset and Training Refinement,0.21618,"Due to the model aging problem, Deep Neural Networks (DNNs) need updates to
adjust them to new data distributions. The common practice leverages
incremental learning (IL), e.g., Class-based Incremental Learning (CIL) that
updates output labels, to update the model with new data and a limited number
of old data. This avoids heavyweight training (from scratch) using conventional
methods and saves storage space by reducing the number of old data to store.
But it also leads to poor performance in fairness. In this paper, we show that
CIL suffers both dataset and algorithm bias problems, and existing solutions
can only partially solve the problem. We propose a novel framework, CILIATE,
that fixes both dataset and algorithm bias in CIL. It features a novel
differential analysis guided dataset and training refinement process that
identifies unique and important samples overlooked by existing CIL and enforces
the model to learn from them. Through this process, CILIATE improves the
fairness of CIL by 17.03%, 22.46%, and 31.79% compared to state-of-the-art
methods, iCaRL, BiC, and WA, respectively, based on our evaluation on three
popular datasets and widely used ResNet models."
Parameter-Efficient Tuning with Special Token Adaptation,0.215621,"Parameter-efficient tuning aims at updating only a small subset of parameters
when adapting a pretrained model to downstream tasks. In this work, we
introduce PASTA, in which we only modify the special token representations
(e.g., [SEP] and [CLS] in BERT) before the self-attention module at each layer
in Transformer-based models. PASTA achieves comparable performance to full
finetuning in natural language understanding tasks including text
classification and NER with up to only 0.029% of total parameters trained. Our
work not only provides a simple yet effective way of parameter-efficient
tuning, which has a wide range of practical applications when deploying
finetuned models for multiple tasks, but also demonstrates the pivotal role of
special tokens in pretrained language models"
"AI Technical Considerations: Data Storage, Cloud usage and AI Pipeline",0.111827,"Artificial intelligence (AI), especially deep learning, requires vast amounts
of data for training, testing, and validation. Collecting these data and the
corresponding annotations requires the implementation of imaging biobanks that
provide access to these data in a standardized way. This requires careful
design and implementation based on the current standards and guidelines and
complying with the current legal restrictions. However, the realization of
proper imaging data collections is not sufficient to train, validate and deploy
AI as resource demands are high and require a careful hybrid implementation of
AI pipelines both on-premise and in the cloud. This chapter aims to help the
reader when technical considerations have to be made about the AI environment
by providing a technical background of different concepts and implementation
aspects involved in data storage, cloud usage, and AI pipelines."
"System identification of neural systems: If we got it right, would we know?",0.671737,"Artificial neural networks are being proposed as models of parts of the
brain. The networks are compared to recordings of biological neurons, and good
performance in reproducing neural responses is considered to support the
model's validity. A key question is how much this system identification
approach tells us about brain computation. Does it validate one model
architecture over another? We evaluate the most commonly used comparison
techniques, such as a linear encoding model and centered kernel alignment, to
correctly identify a model by replacing brain recordings with known ground
truth models. System identification performance is quite variable; it also
depends significantly on factors independent of the ground truth architecture,
such as stimuli images. In addition, we show the limitations of using
functional similarity scores in identifying higher-level architectural motifs."
uChecker: Masked Pretrained Language Models as Unsupervised Chinese Spelling Checkers,0.750648,"The task of Chinese Spelling Check (CSC) is aiming to detect and correct
spelling errors that can be found in the text. While manually annotating a
high-quality dataset is expensive and time-consuming, thus the scale of the
training dataset is usually very small (e.g., SIGHAN15 only contains 2339
samples for training), therefore supervised-learning based models usually
suffer the data sparsity limitation and over-fitting issue, especially in the
era of big language models. In this paper, we are dedicated to investigating
the \textbf{unsupervised} paradigm to address the CSC problem and we propose a
framework named \textbf{uChecker} to conduct unsupervised spelling error
detection and correction. Masked pretrained language models such as BERT are
introduced as the backbone model considering their powerful language diagnosis
capability. Benefiting from the various and flexible MASKing operations, we
propose a Confusionset-guided masking strategy to fine-train the masked
language model to further improve the performance of unsupervised detection and
correction. Experimental results on standard datasets demonstrate the
effectiveness of our proposed model uChecker in terms of character-level and
sentence-level Accuracy, Precision, Recall, and F1-Measure on tasks of spelling
error detection and correction respectively."
Neighborhood Contrastive Learning for Scientific Document Representations with Citation Embeddings,0.783728,"Learning scientific document representations can be substantially improved
through contrastive learning objectives, where the challenge lies in creating
positive and negative training samples that encode the desired similarity
semantics. Prior work relies on discrete citation relations to generate
contrast samples. However, discrete citations enforce a hard cut-off to
similarity. This is counter-intuitive to similarity-based learning, and ignores
that scientific papers can be very similar despite lacking a direct citation -
a core problem of finding related research. Instead, we use controlled nearest
neighbor sampling over citation graph embeddings for contrastive learning. This
control allows us to learn continuous similarity, to sample hard-to-learn
negatives and positives, and also to avoid collisions between negative and
positive samples by controlling the sampling margin between them. The resulting
method SciNCL outperforms the state-of-the-art on the SciDocs benchmark.
Furthermore, we demonstrate that it can train (or tune) models
sample-efficiently, and that it can be combined with recent training-efficient
methods. Perhaps surprisingly, even training a general-domain language model
this way outperforms baselines pretrained in-domain."
"The $(1+(,))$ Global SEMO Algorithm",0.455936,"The $(1+(\lambda,\lambda))$ genetic algorithm is a recently proposed
single-objective evolutionary algorithm with several interesting properties. We
show that its main working principle, mutation with a high rate and crossover
as repair mechanism, can be transported also to multi-objective evolutionary
computation. We define the $(1+(\lambda,\lambda))$ global SEMO algorithm, a
variant of the classic global SEMO algorithm, and prove that it optimizes the
OneMinMax benchmark asymptotically faster than the global SEMO. Following the
single-objective example, we design a one-fifth rule inspired dynamic parameter
setting (to the best of our knowledge for the first time in discrete
multi-objective optimization) and prove that it further improves the runtime to
$O(n^2)$, whereas the best runtime guarantee for the global SEMO is only $O(n^2
\log n)$."
Controllable Guide-Space for Generalizable Face Forgery Detection,0.813225,"Recent studies on face forgery detection have shown satisfactory performance
for methods involved in training datasets, but are not ideal enough for unknown
domains. This motivates many works to improve the generalization, but
forgery-irrelevant information, such as image background and identity, still
exists in different domain features and causes unexpected clustering, limiting
the generalization. In this paper, we propose a controllable guide-space (GS)
method to enhance the discrimination of different forgery domains, so as to
increase the forgery relevance of features and thereby improve the
generalization. The well-designed guide-space can simultaneously achieve both
the proper separation of forgery domains and the large distance between
real-forgery domains in an explicit and controllable manner. Moreover, for
better discrimination, we use a decoupling module to weaken the interference of
forgery-irrelevant correlations between domains. Furthermore, we make
adjustments to the decision boundary manifold according to the clustering
degree of the same domain features within the neighborhood. Extensive
experiments in multiple in-domain and cross-domain settings confirm that our
method can achieve state-of-the-art generalization."
"Learning Robust, Agile, Natural Legged Locomotion Skills in the Wild",0.333586,"Recently, reinforcement learning has become a promising and polular solution
for robot legged locomotion. Compared to model-based control, reinforcement
learning based controllers can achieve better robustness against uncertainties
of environments through sim-to-real learning. However, the corresponding
learned gaits are in general overly conservative and unatural. In this paper,
we propose a new framework for learning robust, agile and natural legged
locomotion skills over challenging terrain. We incorporate an adversarial
training branch based on real animal locomotion data upon a teacher-student
training pipeline for robust sim-to-real transfer. Empirical results on both
simulation and real world of a quadruped robot demonstrate that our proposed
algorithm enables robustly traversing challenging terrains such as stairs,
rocky ground and slippery floor with only proprioceptive perception. Meanwhile,
the gaits are more agile, natural, and energy efficient compared to the
baselines. Both qualitative and quantitative results are presented in this
paper."
Privileged Attribution Constrained Deep Networks for Facial Expression Recognition,0.428114,"Facial Expression Recognition (FER) is crucial in many research domains
because it enables machines to better understand human behaviours. FER methods
face the problems of relatively small datasets and noisy data that don't allow
classical networks to generalize well. To alleviate these issues, we guide the
model to concentrate on specific facial areas like the eyes, the mouth or the
eyebrows, which we argue are decisive to recognise facial expressions. We
propose the Privileged Attribution Loss (PAL), a method that directs the
attention of the model towards the most salient facial regions by encouraging
its attribution maps to correspond to a heatmap formed by facial landmarks.
Furthermore, we introduce several channel strategies that allow the model to
have more degrees of freedom. The proposed method is independent of the
backbone architecture and doesn't need additional semantic information at test
time. Finally, experimental results show that the proposed PAL method
outperforms current state-of-the-art methods on both RAF-DB and AffectNet."
Search-Based Testing of Reinforcement Learning,0.546694,"Evaluation of deep reinforcement learning (RL) is inherently challenging.
Especially the opaqueness of learned policies and the stochastic nature of both
agents and environments make testing the behavior of deep RL agents difficult.
We present a search-based testing framework that enables a wide range of novel
analysis capabilities for evaluating the safety and performance of deep RL
agents. For safety testing, our framework utilizes a search algorithm that
searches for a reference trace that solves the RL task. The backtracking states
of the search, called boundary states, pose safety-critical situations. We
create safety test-suites that evaluate how well the RL agent escapes
safety-critical situations near these boundary states. For robust performance
testing, we create a diverse set of traces via fuzz testing. These fuzz traces
are used to bring the agent into a wide variety of potentially unknown states
from which the average performance of the agent is compared to the average
performance of the fuzz traces. We apply our search-based testing approach on
RL for Nintendo's Super Mario Bros."
MEE: A Novel Multilingual Event Extraction Dataset,0.936226,"Event Extraction (EE) is one of the fundamental tasks in Information
Extraction (IE) that aims to recognize event mentions and their arguments
(i.e., participants) from text. Due to its importance, extensive methods and
resources have been developed for Event Extraction. However, one limitation of
current research for EE involves the under-exploration for non-English
languages in which the lack of high-quality multilingual EE datasets for model
training and evaluation has been the main hindrance. To address this
limitation, we propose a novel Multilingual Event Extraction dataset (MEE) that
provides annotation for more than 50K event mentions in 8 typologically
different languages. MEE comprehensively annotates data for entity mentions,
event triggers and event arguments. We conduct extensive experiments on the
proposed dataset to reveal challenges and opportunities for multilingual EE."
A Wide Evaluation of ChatGPT on Affective Computing Tasks,0.832693,"With the rise of foundation models, a new artificial intelligence paradigm
has emerged, by simply using general purpose foundation models with prompting
to solve problems instead of training a separate machine learning model for
each problem. Such models have been shown to have emergent properties of
solving problems that they were not initially trained on. The studies for the
effectiveness of such models are still quite limited. In this work, we widely
study the capabilities of the ChatGPT models, namely GPT-4 and GPT-3.5, on 13
affective computing problems, namely aspect extraction, aspect polarity
classification, opinion extraction, sentiment analysis, sentiment intensity
ranking, emotions intensity ranking, suicide tendency detection, toxicity
detection, well-being assessment, engagement measurement, personality
assessment, sarcasm detection, and subjectivity detection. We introduce a
framework to evaluate the ChatGPT models on regression-based problems, such as
intensity ranking problems, by modelling them as pairwise ranking
classification. We compare ChatGPT against more traditional NLP methods, such
as end-to-end recurrent neural networks and transformers. The results
demonstrate the emergent abilities of the ChatGPT models on a wide range of
affective computing problems, where GPT-3.5 and especially GPT-4 have shown
strong performance on many problems, particularly the ones related to
sentiment, emotions, or toxicity. The ChatGPT models fell short for problems
with implicit signals, such as engagement measurement and subjectivity
detection."
MultiMediate'23: Engagement Estimation and Bodily Behaviour Recognition in Social Interactions,0.901612,"Automatic analysis of human behaviour is a fundamental prerequisite for the
creation of machines that can effectively interact with- and support humans in
social interactions. In MultiMediate'23, we address two key human social
behaviour analysis tasks for the first time in a controlled challenge:
engagement estimation and bodily behaviour recognition in social interactions.
This paper describes the MultiMediate'23 challenge and presents novel sets of
annotations for both tasks. For engagement estimation we collected novel
annotations on the NOvice eXpert Interaction (NOXI) database. For bodily
behaviour recognition, we annotated test recordings of the MPIIGroupInteraction
corpus with the BBSI annotation scheme. In addition, we present baseline
results for both challenge tasks."
MISeval: a Metric Library for Medical Image Segmentation Evaluation,0.474804,"Correct performance assessment is crucial for evaluating modern artificial
intelligence algorithms in medicine like deep-learning based medical image
segmentation models. However, there is no universal metric library in Python
for standardized and reproducible evaluation. Thus, we propose our open-source
publicly available Python package MISeval: a metric library for Medical Image
Segmentation Evaluation. The implemented metrics can be intuitively used and
easily integrated into any performance assessment pipeline. The package
utilizes modern CI/CD strategies to ensure functionality and stability. MISeval
is available from PyPI (miseval) and GitHub:
https://github.com/frankkramer-lab/miseval."
EnDex: Evaluation of Dialogue Engagingness at Scale,0.244103,"We propose EnDex, the first human-reaction based model to evaluate dialogue
engagingness. EnDex is trained on 80k Reddit-based Engagement Dataset (RED)
curated using a novel distant-supervision framework. Engagingness is a key
measure that captures high-level quality of AI dialogue systems and closely
reflects actual user experience. However, data shortage, plus the abstract and
extensive definition of engagingness makes it challenging to develop an
automatic metric. Our work departs from mainstream approaches that use
synthetic negative examples to train binary classifiers, and instead, proposes
a solution using distant-supervision from human-reaction feedback. To support
the soundness of our EnDex metric, we offer a theoretical foundation for
engagement, an extensive ablation study, and empirical evidence of high
correlation on five engagingness related datasets. We will release code,
off-the-shelf EnDex model, and a large-scale dataset upon paper publication to
facilitate future research."
From task structures to world models: What do LLMs know?,0.513251,"In what sense does a large language model have knowledge? The answer to this
question extends beyond the capabilities of a particular AI system, and
challenges our assumptions about the nature of knowledge and intelligence. We
answer by granting LLMs ""instrumental knowledge""; knowledge defined by a
certain set of abilities. We then ask how such knowledge is related to the more
ordinary, ""worldly"" knowledge exhibited by human agents, and explore this in
terms of the degree to which instrumental knowledge can be said to incorporate
the structured world models of cognitive science. We discuss ways LLMs could
recover degrees of worldly knowledge, and suggest such recovery will be
governed by an implicit, resource-rational tradeoff between world models and
task demands."
SQUIRE: A Sequence-to-sequence Framework for Multi-hop Knowledge Graph Reasoning,0.403012,"Multi-hop knowledge graph (KG) reasoning has been widely studied in recent
years to provide interpretable predictions on missing links with evidential
paths. Most previous works use reinforcement learning (RL) based methods that
learn to navigate the path towards the target entity. However, these methods
suffer from slow and poor convergence, and they may fail to infer a certain
path when there is a missing edge along the path. Here we present SQUIRE, the
first Sequence-to-sequence based multi-hop reasoning framework, which utilizes
an encoder-decoder Transformer structure to translate the query to a path. Our
framework brings about two benefits: (1) It can learn and predict in an
end-to-end fashion, which gives better and faster convergence; (2) Our
Transformer model does not rely on existing edges to generate the path, and has
the flexibility to complete missing edges along the path, especially in sparse
KGs. Experiments on standard and sparse KGs show that our approach yields
significant improvement over prior methods, while converging 4x-7x faster."
MMFN: Multi-Modal-Fusion-Net for End-to-End Driving,0.708153,"Inspired by the fact that humans use diverse sensory organs to perceive the
world, sensors with different modalities are deployed in end-to-end driving to
obtain the global context of the 3D scene. In previous works, camera and LiDAR
inputs are fused through transformers for better driving performance. These
inputs are normally further interpreted as high-level map information to assist
navigation tasks. Nevertheless, extracting useful information from the complex
map input is challenging, for redundant information may mislead the agent and
negatively affect driving performance. We propose a novel approach to
efficiently extract features from vectorized High-Definition (HD) maps and
utilize them in the end-to-end driving tasks. In addition, we design a new
expert to further enhance the model performance by considering multi-road
rules. Experimental results prove that both of the proposed improvements enable
our agent to achieve superior performance compared with other methods."
World of Bugs: A Platform for Automated Bug Detection in 3D Video Games,0.412464,"We present World of Bugs (WOB), an open platform that aims to support
Automated Bug Detection (ABD) research in video games. We discuss some open
problems in ABD and how they relate to the platform's design, arguing that
learning-based solutions are required if further progress is to be made. The
platform's key feature is a growing collection of common video game bugs that
may be used for training and evaluating ABD approaches."
RED-ACE: Robust Error Detection for ASR using Confidence Embeddings,0.0753025,"ASR Error Detection (AED) models aim to post-process the output of Automatic
Speech Recognition (ASR) systems, in order to detect transcription errors.
Modern approaches usually use text-based input, comprised solely of the ASR
transcription hypothesis, disregarding additional signals from the ASR model.
Instead, we propose to utilize the ASR system's word-level confidence scores
for improving AED performance. Specifically, we add an ASR Confidence Embedding
(ACE) layer to the AED model's encoder, allowing us to jointly encode the
confidence scores and the transcribed text into a contextualized
representation. Our experiments show the benefits of ASR confidence scores for
AED, their complementary effect over the textual signal, as well as the
effectiveness and robustness of ACE for combining these signals. To foster
further research, we publish a novel AED dataset consisting of ASR outputs on
the LibriSpeech corpus with annotated transcription errors."
Inkorrect: Online Handwriting Spelling Correction,0.506327,"We introduce Inkorrect, a data- and label-efficient approach for online
handwriting (Digital Ink) spelling correction - DISC. Unlike previous work, the
proposed method does not require multiple samples from the same writer, or
access to character level segmentation. We show that existing automatic
evaluation metrics do not fully capture and are not correlated with the human
perception of the quality of the spelling correction, and propose new ones that
correlate with human perception. We additionally surface an interesting
phenomenon: a trade-off between the similarity and recognizability of the
spell-corrected inks. We further create a family of models corresponding to
different points on the Pareto frontier between those two axes. We show that
Inkorrect's Pareto frontier dominates the points that correspond to prior work."
Correcting Diverse Factual Errors in Abstractive Summarization via Post-Editing and Language Model Infilling,0.871129,"Abstractive summarization models often generate inconsistent summaries
containing factual errors or hallucinated content. Recent works focus on
correcting factual errors in generated summaries via post-editing. Such
correction models are trained using adversarial non-factual summaries
constructed using heuristic rules for injecting errors. However, generating
non-factual summaries using heuristics often does not generalize well to actual
model errors. In this work, we propose to generate hard, representative
synthetic examples of non-factual summaries through infilling language models.
With this data, we train a more robust fact-correction model to post-edit the
summaries to improve factual consistency. Through quantitative and qualitative
experiments on two popular summarization datasets -- CNN/DM and XSum -- we show
that our approach vastly outperforms prior methods in correcting erroneous
summaries. Our model -- FactEdit -- improves factuality scores by over ~11
points on CNN/DM and over ~31 points on XSum on average across multiple
summarization models, producing more factual summaries while maintaining
competitive summarization quality."
Pseudo Polynomial-Time Top-k Algorithms for d-DNNF Circuits,0.500213,"We are interested in computing $k$ most preferred models of a given d-DNNF
circuit $C$, where the preference relation is based on an algebraic structure
called a monotone, totally ordered, semigroup $(K, \otimes, <)$. In our
setting, every literal in $C$ has a value in $K$ and the value of an assignment
is an element of $K$ obtained by aggregating using $\otimes$ the values of the
corresponding literals. We present an algorithm that computes $k$ models of $C$
among those having the largest values w.r.t. $<$, and show that this algorithm
runs in time polynomial in $k$ and in the size of $C$. We also present a pseudo
polynomial-time algorithm for deriving the top-$k$ values that can be reached,
provided that an additional (but not very demanding) requirement on the
semigroup is satisfied. Under the same assumption, we present a pseudo
polynomial-time algorithm that transforms $C$ into a d-DNNF circuit $C'$
satisfied exactly by the models of $C$ having a value among the top-$k$ ones.
Finally, focusing on the semigroup $(\mathbb{N}, +, <)$, we compare on a large
number of instances the performances of our compilation-based algorithm for
computing $k$ top solutions with those of an algorithm tackling the same
problem, but based on a partial weighted MaxSAT solver."
Hierarchical and Contrastive Representation Learning for Knowledge-aware Recommendation,0.0959563,"Incorporating knowledge graph into recommendation is an effective way to
alleviate data sparsity. Most existing knowledge-aware methods usually perform
recursive embedding propagation by enumerating graph neighbors. However, the
number of nodes' neighbors grows exponentially as the hop number increases,
forcing the nodes to be aware of vast neighbors under this recursive
propagation for distilling the high-order semantic relatedness. This may induce
more harmful noise than useful information into recommendation, leading the
learned node representations to be indistinguishable from each other, that is,
the well-known over-smoothing issue. To relieve this issue, we propose a
Hierarchical and CONtrastive representation learning framework for
knowledge-aware recommendation named HiCON. Specifically, for avoiding the
exponential expansion of neighbors, we propose a hierarchical message
aggregation mechanism to interact separately with low-order neighbors and
meta-path-constrained high-order neighbors. Moreover, we also perform
cross-order contrastive learning to enforce the representations to be more
discriminative. Extensive experiments on three datasets show the remarkable
superiority of HiCON over state-of-the-art approaches."
A Frustratingly Easy Plug-and-Play Detection-and-Reasoning Module for Chinese Spelling Check,0.94389,"In recent years, Chinese Spelling Check (CSC) has been greatly improved by
designing task-specific pre-training methods or introducing auxiliary tasks,
which mostly solve this task in an end-to-end fashion. In this paper, we
propose to decompose the CSC workflow into detection, reasoning, and searching
subtasks so that the rich external knowledge about the Chinese language can be
leveraged more directly and efficiently. Specifically, we design a
plug-and-play detection-and-reasoning module that is compatible with existing
SOTA non-autoregressive CSC models to further boost their performance. We find
that the detection-and-reasoning module trained for one model can also benefit
other models. We also study the primary interpretability provided by the task
decomposition. Extensive experiments and detailed analyses demonstrate the
effectiveness and competitiveness of the proposed module."
Learning Multi-Step Reasoning by Solving Arithmetic Tasks,0.207945,"Mathematical reasoning is regarded as a necessary ability for Language Models
(LMs). Recent works demonstrate large LMs' impressive performance in solving
math problems. The success is attributed to their Chain-of-Thought (CoT)
reasoning abilities, i.e., the ability to decompose complex questions into
step-by-step reasoning chains, but such ability seems only to emerge from
models with abundant parameters. This work investigates how to incorporate
relatively small LMs with the capabilities of multi-step reasoning. We propose
to inject such abilities by continually pre-training LMs on a synthetic dataset
MsAT which is composed of Multi-step Arithmetic Tasks. Our experiments on four
math word problem datasets show the effectiveness of the proposed method in
enhancing LMs' math reasoning abilities."
Model-Based Uncertainty in Value Functions,0.187182,"We consider the problem of quantifying uncertainty over expected cumulative
rewards in model-based reinforcement learning. In particular, we focus on
characterizing the variance over values induced by a distribution over MDPs.
Previous work upper bounds the posterior variance over values by solving a
so-called uncertainty Bellman equation, but the over-approximation may result
in inefficient exploration. We propose a new uncertainty Bellman equation whose
solution converges to the true posterior variance over values and explicitly
characterizes the gap in previous work. Moreover, our uncertainty
quantification technique is easily integrated into common exploration
strategies and scales naturally beyond the tabular setting by using standard
deep reinforcement learning architectures. Experiments in difficult exploration
tasks, both in tabular and continuous control settings, show that our sharper
uncertainty estimates improve sample-efficiency."
Sparse Visual Counterfactual Explanations in Image Space,0.385243,"Visual counterfactual explanations (VCEs) in image space are an important
tool to understand decisions of image classifiers as they show under which
changes of the image the decision of the classifier would change. Their
generation in image space is challenging and requires robust models due to the
problem of adversarial examples. Existing techniques to generate VCEs in image
space suffer from spurious changes in the background. Our novel perturbation
model for VCEs together with its efficient optimization via our novel
Auto-Frank-Wolfe scheme yields sparse VCEs which lead to subtle changes
specific for the target class. Moreover, we show that VCEs can be used to
detect undesired behavior of ImageNet classifiers due to spurious features in
the ImageNet dataset."
Semiconductor Defect Detection by Hybrid Classical-Quantum Deep Learning,0.934265,"With the rapid development of artificial intelligence and autonomous driving
technology, the demand for semiconductors is projected to rise substantially.
However, the massive expansion of semiconductor manufacturing and the
development of new technology will bring many defect wafers. If these defect
wafers have not been correctly inspected, the ineffective semiconductor
processing on these defect wafers will cause additional impact to our
environment, such as excessive carbon dioxide emission and energy consumption.
In this paper, we utilize the information processing advantages of quantum
computing to promote the defect learning defect review (DLDR). We propose a
classical-quantum hybrid algorithm for deep learning on near-term quantum
processors. By tuning parameters implemented on it, quantum circuit driven by
our framework learns a given DLDR task, include of wafer defect map
classification, defect pattern classification, and hotspot detection. In
addition, we explore parametrized quantum circuits with different
expressibility and entangling capacities. These results can be used to build a
future roadmap to develop circuit-based quantum deep learning for semiconductor
defect detection."
ASFD: Automatic and Scalable Face Detector,0.79028,"Along with current multi-scale based detectors, Feature Aggregation and
Enhancement (FAE) modules have shown superior performance gains for
cutting-edge object detection. However, these hand-crafted FAE modules show
inconsistent improvements on face detection, which is mainly due to the
significant distribution difference between its training and applying corpus,
COCO vs. WIDER Face. To tackle this problem, we essentially analyse the effect
of data distribution, and consequently propose to search an effective FAE
architecture, termed AutoFAE by a differentiable architecture search, which
outperforms all existing FAE modules in face detection with a considerable
margin. Upon the found AutoFAE and existing backbones, a supernet is further
built and trained, which automatically obtains a family of detectors under the
different complexity constraints. Extensive experiments conducted on popular
benchmarks, WIDER Face and FDDB, demonstrate the state-of-the-art
performance-efficiency trade-off for the proposed automatic and scalable face
detector (ASFD) family. In particular, our strong ASFD-D6 outperforms the best
competitor with AP 96.7/96.2/92.1 on WIDER Face test, and the lightweight
ASFD-D0 costs about 3.1 ms, more than 320 FPS, on the V100 GPU with
VGA-resolution images."
"Event Causality Identification with Causal News Corpus -- Shared Task 3, CASE 2022",0.797048,"The Event Causality Identification Shared Task of CASE 2022 involved two
subtasks working on the Causal News Corpus. Subtask 1 required participants to
predict if a sentence contains a causal relation or not. This is a supervised
binary classification task. Subtask 2 required participants to identify the
Cause, Effect and Signal spans per causal sentence. This could be seen as a
supervised sequence labeling task. For both subtasks, participants uploaded
their predictions for a held-out test set, and ranking was done based on binary
F1 and macro F1 scores for Subtask 1 and 2, respectively. This paper summarizes
the work of the 17 teams that submitted their results to our competition and 12
system description papers that were received. The best F1 scores achieved for
Subtask 1 and 2 were 86.19% and 54.15%, respectively. All the top-performing
approaches involved pre-trained language models fine-tuned to the targeted
task. We further discuss these approaches and analyze errors across
participants' systems in this paper."
Towards explainable evaluation of language models on the semantic similarity of visual concepts,0.193838,"Recent breakthroughs in NLP research, such as the advent of Transformer
models have indisputably contributed to major advancements in several tasks.
However, few works research robustness and explainability issues of their
evaluation strategies. In this work, we examine the behavior of high-performing
pre-trained language models, focusing on the task of semantic similarity for
visual vocabularies. First, we address the need for explainable evaluation
metrics, necessary for understanding the conceptual quality of retrieved
instances. Our proposed metrics provide valuable insights in local and global
level, showcasing the inabilities of widely used approaches. Secondly,
adversarial interventions on salient query semantics expose vulnerabilities of
opaque metrics and highlight patterns in learned linguistic representations."
Dynamic Collaborative Multi-Agent Reinforcement Learning Communication for Autonomous Drone Reforestation,0.549418,"We approach autonomous drone-based reforestation with a collaborative
multi-agent reinforcement learning (MARL) setup. Agents can communicate as part
of a dynamically changing network. We explore collaboration and communication
on the back of a high-impact problem. Forests are the main resource to control
rising CO2 conditions. Unfortunately, the global forest volume is decreasing at
an unprecedented rate. Many areas are too large and hard to traverse to plant
new trees. To efficiently cover as much area as possible, here we propose a
Graph Neural Network (GNN) based communication mechanism that enables
collaboration. Agents can share location information on areas needing
reforestation, which increases viewed area and planted tree count. We compare
our proposed communication mechanism with a multi-agent baseline without the
ability to communicate. Results show how communication enables collaboration
and increases collective performance, planting precision and the risk-taking
propensity of individual agents."
SwinIQA: Learned Swin Distance for Compressed Image Quality Assessment,0.79481,"Image compression has raised widespread interest recently due to its
significant importance for multimedia storage and transmission. Meanwhile, a
reliable image quality assessment (IQA) for compressed images can not only help
to verify the performance of various compression algorithms but also help to
guide the compression optimization in turn. In this paper, we design a
full-reference image quality assessment metric SwinIQA to measure the
perceptual quality of compressed images in a learned Swin distance space. It is
known that the compression artifacts are usually non-uniformly distributed with
diverse distortion types and degrees. To warp the compressed images into the
shared representation space while maintaining the complex distortion
information, we extract the hierarchical feature representations from each
stage of the Swin Transformer. Besides, we utilize cross attention operation to
map the extracted feature representations into a learned Swin distance space.
Experimental results show that the proposed metric achieves higher consistency
with human's perceptual judgment compared with both traditional methods and
learning-based methods on CLIC datasets."
Robust Contrastive Learning against Noisy Views,0.566712,"Contrastive learning relies on an assumption that positive pairs contain
related views, e.g., patches of an image or co-occurring multimodal signals of
a video, that share certain underlying information about an instance. But what
if this assumption is violated? The literature suggests that contrastive
learning produces suboptimal representations in the presence of noisy views,
e.g., false positive pairs with no apparent shared information. In this work,
we propose a new contrastive loss function that is robust against noisy views.
We provide rigorous theoretical justifications by showing connections to robust
symmetric losses for noisy binary classification and by establishing a new
contrastive bound for mutual information maximization based on the Wasserstein
distance measure. The proposed loss is completely modality-agnostic and a
simple drop-in replacement for the InfoNCE loss, which makes it easy to apply
to existing contrastive frameworks. We show that our approach provides
consistent improvements over the state-of-the-art on image, video, and graph
contrastive learning benchmarks that exhibit a variety of real-world noise
patterns."
Towards eXplainable AI for Mobility Data Science,0.277086,"This paper presents our ongoing work towards XAI for Mobility Data Science
applications, focusing on explainable models that can learn from dense
trajectory data, such as GPS tracks of vehicles and vessels using temporal
graph neural networks (GNNs) and counterfactuals. We review the existing GeoXAI
studies, argue the need for comprehensible explanations with human-centered
approaches, and outline a research path toward XAI for Mobility Data Science."
Continual Domain Adaptation through Pruning-aided Domain-specific Weight Modulation,0.167413,"In this paper, we propose to develop a method to address unsupervised domain
adaptation (UDA) in a practical setting of continual learning (CL). The goal is
to update the model on continually changing domains while preserving
domain-specific knowledge to prevent catastrophic forgetting of past-seen
domains. To this end, we build a framework for preserving domain-specific
features utilizing the inherent model capacity via pruning. We also perform
effective inference using a novel batch-norm based metric to predict the final
model parameters to be used accurately. Our approach achieves not only
state-of-the-art performance but also prevents catastrophic forgetting of past
domains significantly. Our code is made publicly available."
AdaMix: Mixture-of-Adaptations for Parameter-efficient Model Tuning,0.77968,"Standard fine-tuning of large pre-trained language models (PLMs) for
downstream tasks requires updating hundreds of millions to billions of
parameters, and storing a large copy of the PLM weights for every task
resulting in increased cost for storing, sharing and serving the models. To
address this, parameter-efficient fine-tuning (PEFT) techniques were introduced
where small trainable components are injected in the PLM and updated during
fine-tuning. We propose AdaMix as a general PEFT method that tunes a mixture of
adaptation modules -- given the underlying PEFT method of choice -- introduced
in each Transformer layer while keeping most of the PLM weights frozen. For
instance, AdaMix can leverage a mixture of adapters like Houlsby or a mixture
of low rank decomposition matrices like LoRA to improve downstream task
performance over the corresponding PEFT methods for fully supervised and
few-shot NLU and NLG tasks. Further, we design AdaMix such that it matches the
same computational cost and the number of tunable parameters as the underlying
PEFT method. By only tuning 0.1-0.2% of PLM parameters, we show that AdaMix
outperforms SOTA parameter-efficient fine-tuning and full model fine-tuning for
both NLU and NLG tasks."
Improving Generalizability in Implicitly Abusive Language Detection with Concept Activation Vectors,0.656093,"Robustness of machine learning models on ever-changing real-world data is
critical, especially for applications affecting human well-being such as
content moderation. New kinds of abusive language continually emerge in online
discussions in response to current events (e.g., COVID-19), and the deployed
abuse detection systems should be updated regularly to remain accurate. In this
paper, we show that general abusive language classifiers tend to be fairly
reliable in detecting out-of-domain explicitly abusive utterances but fail to
detect new types of more subtle, implicit abuse. Next, we propose an
interpretability technique, based on the Testing Concept Activation Vector
(TCAV) method from computer vision, to quantify the sensitivity of a trained
model to the human-defined concepts of explicit and implicit abusive language,
and use that to explain the generalizability of the model on new data, in this
case, COVID-related anti-Asian hate speech. Extending this technique, we
introduce a novel metric, Degree of Explicitness, for a single instance and
show that the new metric is beneficial in suggesting out-of-domain unlabeled
examples to effectively enrich the training data with informative, implicitly
abusive texts."
Learning finite difference methods for reaction-diffusion type equations with FCNN,0.352033,"In recent years, Physics-informed neural networks (PINNs) have been widely
used to solve partial differential equations alongside numerical methods
because PINNs can be trained without observations and deal with continuous-time
problems directly. In contrast, optimizing the parameters of such models is
difficult, and individual training sessions must be performed to predict the
evolutions of each different initial condition. To alleviate the first problem,
observed data can be injected directly into the loss function part. To solve
the second problem, a network architecture can be built as a framework to learn
a finite difference method. In view of the two motivations, we propose
Five-point stencil CNNs (FCNNs) containing a five-point stencil kernel and a
trainable approximation function for reaction-diffusion type equations
including the heat, Fisher's, Allen-Cahn, and other reaction-diffusion
equations with trigonometric function terms. We show that FCNNs can learn
finite difference schemes using few data and achieve the low relative errors of
diverse reaction-diffusion evolutions with unseen initial conditions.
Furthermore, we demonstrate that FCNNs can still be trained well even with
using noisy data."
A Unified Pyramid Recurrent Network for Video Frame Interpolation,0.732284,"Flow-guided synthesis provides a common framework for frame interpolation,
where optical flow is estimated to guide the synthesis of intermediate frames
between consecutive inputs. In this paper, we present UPR-Net, a novel Unified
Pyramid Recurrent Network for frame interpolation. Cast in a flexible pyramid
framework, UPR-Net exploits lightweight recurrent modules for both
bi-directional flow estimation and intermediate frame synthesis. At each
pyramid level, it leverages estimated bi-directional flow to generate
forward-warped representations for frame synthesis; across pyramid levels, it
enables iterative refinement for both optical flow and intermediate frame. In
particular, we show that our iterative synthesis strategy can significantly
improve the robustness of frame interpolation on large motion cases. Despite
being extremely lightweight (1.7M parameters), our base version of UPR-Net
achieves excellent performance on a large range of benchmarks. Code and trained
models of our UPR-Net series are available at:
https://github.com/srcn-ivl/UPR-Net."
SoDaCam: Software-defined Cameras via Single-Photon Imaging,0.185984,"Reinterpretable cameras are defined by their post-processing capabilities
that exceed traditional imaging. We present ""SoDaCam"" that provides
reinterpretable cameras at the granularity of photons, from photon-cubes
acquired by single-photon devices. Photon-cubes represent the spatio-temporal
detections of photons as a sequence of binary frames, at frame-rates as high as
100 kHz. We show that simple transformations of the photon-cube, or photon-cube
projections, provide the functionality of numerous imaging systems including:
exposure bracketing, flutter shutter cameras, video compressive systems, event
cameras, and even cameras that move during exposure. Our photon-cube
projections offer the flexibility of being software-defined constructs that are
only limited by what is computable, and shot-noise. We exploit this flexibility
to provide new capabilities for the emulated cameras. As an added benefit, our
projections provide camera-dependent compression of photon-cubes, which we
demonstrate using an implementation of our projections on a novel compute
architecture that is designed for single-photon imaging."
An LSTM model for Twitter Sentiment Analysis,0.649342,"Sentiment analysis on social media such as Twitter provides organizations and
individuals an effective way to monitor public emotions towards them and their
competitors. As a result, sentiment analysis has become an important and
challenging task. In this work, we have collected seven publicly available and
manually annotated twitter sentiment datasets. We create a new training and
testing dataset from the collected datasets. We develop an LSTM model to
classify sentiment of a tweet and evaluate the model with the new dataset."
COVID-19-related Nepali Tweets Classification in a Low Resource Setting,0.229427,"Billions of people across the globe have been using social media platforms in
their local languages to voice their opinions about the various topics related
to the COVID-19 pandemic. Several organizations, including the World Health
Organization, have developed automated social media analysis tools that
classify COVID-19-related tweets into various topics. However, these tools that
help combat the pandemic are limited to very few languages, making several
countries unable to take their benefit. While multi-lingual or low-resource
language-specific tools are being developed, they still need to expand their
coverage, such as for the Nepali language. In this paper, we identify the eight
most common COVID-19 discussion topics among the Twitter community using the
Nepali language, set up an online platform to automatically gather Nepali
tweets containing the COVID-19-related keywords, classify the tweets into the
eight topics, and visualize the results across the period in a web-based
dashboard. We compare the performance of two state-of-the-art multi-lingual
language models for Nepali tweet classification, one generic (mBERT) and the
other Nepali language family-specific model (MuRIL). Our results show that the
models' relative performance depends on the data size, with MuRIL doing better
for a larger dataset. The annotated data, models, and the web-based dashboard
are open-sourced at https://github.com/naamiinepal/covid-tweet-classification."
Self-conditioned Embedding Diffusion for Text Generation,0.65196,"Can continuous diffusion models bring the same performance breakthrough on
natural language they did for image generation? To circumvent the discrete
nature of text data, we can simply project tokens in a continuous space of
embeddings, as is standard in language modeling. We propose Self-conditioned
Embedding Diffusion, a continuous diffusion mechanism that operates on token
embeddings and allows to learn flexible and scalable diffusion models for both
conditional and unconditional text generation. Through qualitative and
quantitative evaluation, we show that our text diffusion models generate
samples comparable with those produced by standard autoregressive language
models - while being in theory more efficient on accelerator hardware at
inference time. Our work paves the way for scaling up diffusion models for
text, similarly to autoregressive models, and for improving performance with
recent refinements to continuous diffusion."
AWADA: Attention-Weighted Adversarial Domain Adaptation for Object Detection,0.1685,"Object detection networks have reached an impressive performance level, yet a
lack of suitable data in specific applications often limits it in practice.
Typically, additional data sources are utilized to support the training task.
In these, however, domain gaps between different data sources pose a challenge
in deep learning. GAN-based image-to-image style-transfer is commonly applied
to shrink the domain gap, but is unstable and decoupled from the object
detection task. We propose AWADA, an Attention-Weighted Adversarial Domain
Adaptation framework for creating a feedback loop between style-transformation
and detection task. By constructing foreground object attention maps from
object detector proposals, we focus the transformation on foreground object
regions and stabilize style-transfer training. In extensive experiments and
ablation studies, we show that AWADA reaches state-of-the-art unsupervised
domain adaptation object detection performance in the commonly used benchmarks
for tasks such as synthetic-to-real, adverse weather and cross-camera
adaptation."
Towards Efficient Neural Scene Graphs by Learning Consistency Fields,0.166185,"Neural Radiance Fields (NeRF) achieves photo-realistic image rendering from
novel views, and the Neural Scene Graphs (NSG) \cite{ost2021neural} extends it
to dynamic scenes (video) with multiple objects. Nevertheless, computationally
heavy ray marching for every image frame becomes a huge burden. In this paper,
taking advantage of significant redundancy across adjacent frames in videos, we
propose a feature-reusing framework. From the first try of naively reusing the
NSG features, however, we learn that it is crucial to disentangle
object-intrinsic properties consistent across frames from transient ones. Our
proposed method, \textit{Consistency-Field-based NSG (CF-NSG)}, reformulates
neural radiance fields to additionally consider \textit{consistency fields}.
With disentangled representations, CF-NSG takes full advantage of the
feature-reusing scheme and performs an extended degree of scene manipulation in
a more controllable manner. We empirically verify that CF-NSG greatly improves
the inference efficiency by using 85\% less queries than NSG without notable
degradation in rendering quality. Code will be available at:
https://github.com/ldynx/CF-NSG"
ATTA: Anomaly-aware Test-Time Adaptation for Out-of-Distribution Detection in Segmentation,0.766259,"Recent advancements in dense out-of-distribution (OOD) detection have
primarily focused on scenarios where the training and testing datasets share a
similar domain, with the assumption that no domain shift exists between them.
However, in real-world situations, domain shift often exits and significantly
affects the accuracy of existing out-of-distribution (OOD) detection models. In
this work, we propose a dual-level OOD detection framework to handle domain
shift and semantic shift jointly. The first level distinguishes whether domain
shift exists in the image by leveraging global low-level features, while the
second level identifies pixels with semantic shift by utilizing dense
high-level feature maps. In this way, we can selectively adapt the model to
unseen domains as well as enhance model's capacity in detecting novel classes.
We validate the efficacy of our proposed method on several OOD segmentation
benchmarks, including those with significant domain shifts and those without,
observing consistent performance improvements across various baseline models.
Code is available at
${\href{https://github.com/gaozhitong/ATTA}{https://github.com/gaozhitong/ATTA}}$."
"Graph Neural Networks for temporal graphs: State of the art, open challenges, and opportunities",0.98814,"Graph Neural Networks (GNNs) have become the leading paradigm for learning on
(static) graph-structured data. However, many real-world systems are dynamic in
nature, since the graph and node/edge attributes change over time. In recent
years, GNN-based models for temporal graphs have emerged as a promising area of
research to extend the capabilities of GNNs. In this work, we provide the first
comprehensive overview of the current state-of-the-art of temporal GNN,
introducing a rigorous formalization of learning settings and tasks and a novel
taxonomy categorizing existing approaches in terms of how the temporal aspect
is represented and processed. We conclude the survey with a discussion of the
most relevant open challenges for the field, from both research and application
perspectives."
Risk-aware Stochastic Shortest Path,0.410512,"We treat the problem of risk-aware control for stochastic shortest path (SSP)
on Markov decision processes (MDP). Typically, expectation is considered for
SSP, which however is oblivious to the incurred risk. We present an alternative
view, instead optimizing conditional value-at-risk (CVaR), an established risk
measure. We treat both Markov chains as well as MDP and introduce, through
novel insights, two algorithms, based on linear programming and value
iteration, respectively. Both algorithms offer precise and provably correct
solutions. Evaluation of our prototype implementation shows that risk-aware
control is feasible on several moderately sized models."
Boosting Video Object Segmentation via Space-time Correspondence Learning,0.66963,"Current top-leading solutions for video object segmentation (VOS) typically
follow a matching-based regime: for each query frame, the segmentation mask is
inferred according to its correspondence to previously processed and the first
annotated frames. They simply exploit the supervisory signals from the
groundtruth masks for learning mask prediction only, without posing any
constraint on the space-time correspondence matching, which, however, is the
fundamental building block of such regime. To alleviate this crucial yet
commonly ignored issue, we devise a correspondence-aware training framework,
which boosts matching-based VOS solutions by explicitly encouraging robust
correspondence matching during network learning. Through comprehensively
exploring the intrinsic coherence in videos on pixel and object levels, our
algorithm reinforces the standard, fully supervised training of mask
segmentation with label-free, contrastive correspondence learning. Without
neither requiring extra annotation cost during training, nor causing speed
delay during deployment, nor incurring architectural modification, our
algorithm provides solid performance gains on four widely used benchmarks,
i.e., DAVIS2016&2017, and YouTube-VOS2018&2019, on the top of famous
matching-based VOS solutions."
Neural ODEs as Feedback Policies for Nonlinear Optimal Control,0.192003,"Neural ordinary differential equations (Neural ODEs) define continuous time
dynamical systems with neural networks. The interest in their application for
modelling has sparked recently, spanning hybrid system identification problems
and time series analysis. In this work we propose the use of a neural control
policy capable of satisfying state and control constraints to solve nonlinear
optimal control problems. The control policy optimization is posed as a Neural
ODE problem to efficiently exploit the availability of a dynamical system
model. We showcase the efficacy of this type of deterministic neural policies
in two constrained systems: the controlled Van der Pol system and a bioreactor
control problem. This approach represents a practical approximation to the
intractable closed-loop solution of nonlinear control problems."
Shapley Head Pruning: Identifying and Removing Interference in Multilingual Transformers,0.0542663,"Multilingual transformer-based models demonstrate remarkable zero and
few-shot transfer across languages by learning and reusing language-agnostic
features. However, as a fixed-size model acquires more languages, its
performance across all languages degrades, a phenomenon termed interference.
Often attributed to limited model capacity, interference is commonly addressed
by adding additional parameters despite evidence that transformer-based models
are overparameterized. In this work, we show that it is possible to reduce
interference by instead identifying and pruning language-specific parameters.
First, we use Shapley Values, a credit allocation metric from coalitional game
theory, to identify attention heads that introduce interference. Then, we show
that removing identified attention heads from a fixed model improves
performance for a target language on both sentence classification and
structural prediction, seeing gains as large as 24.7\%. Finally, we provide
insights on language-agnostic and language-specific attention heads using
attention visualization."
Cut and Learn for Unsupervised Object Detection and Instance Segmentation,0.964317,"We propose Cut-and-LEaRn (CutLER), a simple approach for training
unsupervised object detection and segmentation models. We leverage the property
of self-supervised models to 'discover' objects without supervision and amplify
it to train a state-of-the-art localization model without any human labels.
CutLER first uses our proposed MaskCut approach to generate coarse masks for
multiple objects in an image and then learns a detector on these masks using
our robust loss function. We further improve the performance by self-training
the model on its predictions. Compared to prior work, CutLER is simpler,
compatible with different detection architectures, and detects multiple
objects. CutLER is also a zero-shot unsupervised detector and improves
detection performance AP50 by over 2.7 times on 11 benchmarks across domains
like video frames, paintings, sketches, etc. With finetuning, CutLER serves as
a low-shot detector surpassing MoCo-v2 by 7.3% APbox and 6.6% APmask on COCO
when training with 5% labels."
Overwriting Pretrained Bias with Finetuning Data,0.406082,"Transfer learning is beneficial by allowing the expressive features of models
pretrained on large-scale datasets to be finetuned for the target task of
smaller, more domain-specific datasets. However, there is a concern that these
pretrained models may come with their own biases which would propagate into the
finetuned model. In this work, we investigate bias when conceptualized as both
spurious correlations between the target task and a sensitive attribute as well
as underrepresentation of a particular group in the dataset. Under both notions
of bias, we find that (1) models finetuned on top of pretrained models can
indeed inherit their biases, but (2) this bias can be corrected for through
relatively minor interventions to the finetuning dataset, and often with a
negligible impact to performance. Our findings imply that careful curation of
the finetuning dataset is important for reducing biases on a downstream task,
and doing so can even compensate for bias in the pretrained model."
Layout-guided Indoor Panorama Inpainting with Plane-aware Normalization,0.455341,"We present an end-to-end deep learning framework for indoor panoramic image
inpainting. Although previous inpainting methods have shown impressive
performance on natural perspective images, most fail to handle panoramic
images, particularly indoor scenes, which usually contain complex structure and
texture content. To achieve better inpainting quality, we propose to exploit
both the global and local context of indoor panorama during the inpainting
process. Specifically, we take the low-level layout edges estimated from the
input panorama as a prior to guide the inpainting model for recovering the
global indoor structure. A plane-aware normalization module is employed to
embed plane-wise style features derived from the layout into the generator,
encouraging local texture restoration from adjacent room structures (i.e.,
ceiling, floor, and walls). Experimental results show that our work outperforms
the current state-of-the-art methods on a public panoramic dataset in both
qualitative and quantitative evaluations. Our code is available at
https://ericsujw.github.io/LGPN-net/"
GPT-FinRE: In-context Learning for Financial Relation Extraction using Large Language Models,0.847993,"Relation extraction (RE) is a crucial task in natural language processing
(NLP) that aims to identify and classify relationships between entities
mentioned in text. In the financial domain, relation extraction plays a vital
role in extracting valuable information from financial documents, such as news
articles, earnings reports, and company filings. This paper describes our
solution to relation extraction on one such dataset REFinD. The dataset was
released along with shared task as a part of the Fourth Workshop on Knowledge
Discovery from Unstructured Data in Financial Services, co-located with SIGIR
2023. In this paper, we employed OpenAI models under the framework of
in-context learning (ICL). We utilized two retrieval strategies to find top K
relevant in-context learning demonstrations / examples from training data for a
given test example. The first retrieval mechanism, we employed, is a
learning-free dense retriever and the other system is a learning-based
retriever. We were able to achieve 3rd rank overall. Our best F1-score is
0.718."
Design of Fuzzy Logic Controller for Washing Machine,0.33322,"Things are becoming more advanced as technology advances,and machines now
perform the majority of the manual work. The most often used home appliance is
the washing machine for cloths. In this paper, we used the Mamdani approach and
created an algorithm based on multi-input multi-output. The algorithm is
implemented in Python.The results of this simulation show that the washing
machine provides better execution at a low computation cost"
Privacy Leakage in Text Classification: A Data Extraction Approach,0.619912,"Recent work has demonstrated the successful extraction of training data from
generative language models. However, it is not evident whether such extraction
is feasible in text classification models since the training objective is to
predict the class label as opposed to next-word prediction. This poses an
interesting challenge and raises an important question regarding the privacy of
training data in text classification settings. Therefore, we study the
potential privacy leakage in the text classification domain by investigating
the problem of unintended memorization of training data that is not pertinent
to the learning task. We propose an algorithm to extract missing tokens of a
partial text by exploiting the likelihood of the class label provided by the
model. We test the effectiveness of our algorithm by inserting canaries into
the training set and attempting to extract tokens in these canaries
post-training. In our experiments, we demonstrate that successful extraction is
possible to some extent. This can also be used as an auditing strategy to
assess any potential unauthorized use of personal data without consent."
DDH-QA: A Dynamic Digital Humans Quality Assessment Database,0.89228,"In recent years, large amounts of effort have been put into pushing forward
the real-world application of dynamic digital human (DDH). However, most
current quality assessment research focuses on evaluating static 3D models and
usually ignores motion distortions. Therefore, in this paper, we construct a
large-scale dynamic digital human quality assessment (DDH-QA) database with
diverse motion content as well as multiple distortions to comprehensively study
the perceptual quality of DDHs. Both model-based distortion (noise,
compression) and motion-based distortion (binding error, motion unnaturalness)
are taken into consideration. Ten types of common motion are employed to drive
the DDHs and a total of 800 DDHs are generated in the end. Afterward, we render
the video sequences of the distorted DDHs as the evaluation media and carry out
a well-controlled subjective experiment. Then a benchmark experiment is
conducted with the state-of-the-art video quality assessment (VQA) methods and
the experimental results show that existing VQA methods are limited in
assessing the perceptual loss of DDHs."
StyleBabel: Artistic Style Tagging and Captioning,0.249782,"We present StyleBabel, a unique open access dataset of natural language
captions and free-form tags describing the artistic style of over 135K digital
artworks, collected via a novel participatory method from experts studying at
specialist art and design schools. StyleBabel was collected via an iterative
method, inspired by `Grounded Theory': a qualitative approach that enables
annotation while co-evolving a shared language for fine-grained artistic style
attribute description. We demonstrate several downstream tasks for StyleBabel,
adapting the recent ALADIN architecture for fine-grained style similarity, to
train cross-modal embeddings for: 1) free-form tag generation; 2) natural
language description of artistic style; 3) fine-grained text search of style.
To do so, we extend ALADIN with recent advances in Visual Transformer (ViT) and
cross-modal representation learning, achieving a state of the art accuracy in
fine-grained style retrieval."
Goal Recognition as a Deep Learning Task: the GRNet Approach,0.315034,"In automated planning, recognising the goal of an agent from a trace of
observations is an important task with many applications. The state-of-the-art
approaches to goal recognition rely on the application of planning techniques,
which requires a model of the domain actions and of the initial domain state
(written, e.g., in PDDL). We study an alternative approach where goal
recognition is formulated as a classification task addressed by machine
learning. Our approach, called GRNet, is primarily aimed at making goal
recognition more accurate as well as faster by learning how to solve it in a
given domain. Given a planning domain specified by a set of propositions and a
set of action names, the goal classification instances in the domain are solved
by a Recurrent Neural Network (RNN). A run of the RNN processes a trace of
observed actions to compute how likely it is that each domain proposition is
part of the agent's goal, for the problem instance under considerations. These
predictions are then aggregated to choose one of the candidate goals. The only
information required as input of the trained RNN is a trace of action labels,
each one indicating just the name of an observed action. An experimental
analysis confirms that \our achieves good performance in terms of both goal
classification accuracy and runtime, obtaining better performance w.r.t. a
state-of-the-art goal recognition system over the considered benchmarks."
Cross-domain Few-shot Segmentation with Transductive Fine-tuning,0.0947235,"Few-shot segmentation (FSS) expects models trained on base classes to work on
novel classes with the help of a few support images. However, when there exists
a domain gap between the base and novel classes, the state-of-the-art FSS
methods may even fail to segment simple objects. To improve their performance
on unseen domains, we propose to transductively fine-tune the base model on a
set of query images under the few-shot setting, where the core idea is to
implicitly guide the segmentation of query images using support labels.
Although different images are not directly comparable, their class-wise
prototypes are desired to be aligned in the feature space. By aligning query
and support prototypes with an uncertainty-aware contrastive loss, and using a
supervised cross-entropy loss and an unsupervised boundary loss as
regularizations, our method could generalize the base model to the target
domain without additional labels. We conduct extensive experiments under
various cross-domain settings of natural, remote sensing, and medical images.
The results show that our method could consistently and significantly improve
the performance of prototypical FSS models in all cross-domain tasks."
LDFA: Latent Diffusion Face Anonymization for Self-driving Applications,0.419717,"In order to protect vulnerable road users (VRUs), such as pedestrians or
cyclists, it is essential that intelligent transportation systems (ITS)
accurately identify them. Therefore, datasets used to train perception models
of ITS must contain a significant number of vulnerable road users. However,
data protection regulations require that individuals are anonymized in such
datasets. In this work, we introduce a novel deep learning-based pipeline for
face anonymization in the context of ITS. In contrast to related methods, we do
not use generative adversarial networks (GANs) but build upon recent advances
in diffusion models. We propose a two-stage method, which contains a face
detection model followed by a latent diffusion model to generate realistic face
in-paintings. To demonstrate the versatility of anonymized images, we train
segmentation methods on anonymized data and evaluate them on non-anonymized
data. Our experiment reveal that our pipeline is better suited to anonymize
data for segmentation than naive methods and performes comparably with recent
GAN-based methods. Moreover, face detectors achieve higher mAP scores for faces
anonymized by our method compared to naive or recent GAN-based methods."
MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting,0.424158,"Large language models (LLMs) have achieved impressive performance on various
reasoning tasks. To further improve the performance, we propose MultiTool-CoT,
a novel framework that leverages chain-of-thought (CoT) prompting to
incorporate multiple external tools, such as a calculator and a knowledge
retriever, during the reasoning process. We apply MultiTool-CoT to the Task 2
dataset of NumGLUE, which requires both numerical reasoning and domain-specific
knowledge. The experiments show that our method significantly outperforms
strong baselines and achieves state-of-the-art performance."
Assembly101: A Large-Scale Multi-View Video Dataset for Understanding Procedural Activities,0.999974,"Assembly101 is a new procedural activity dataset featuring 4321 videos of
people assembling and disassembling 101 ""take-apart"" toy vehicles. Participants
work without fixed instructions, and the sequences feature rich and natural
variations in action ordering, mistakes, and corrections. Assembly101 is the
first multi-view action dataset, with simultaneous static (8) and egocentric
(4) recordings. Sequences are annotated with more than 100K coarse and 1M
fine-grained action segments, and 18M 3D hand poses. We benchmark on three
action understanding tasks: recognition, anticipation and temporal
segmentation. Additionally, we propose a novel task of detecting mistakes. The
unique recording format and rich set of annotations allow us to investigate
generalization to new toys, cross-view transfer, long-tailed distributions, and
pose vs. appearance. We envision that Assembly101 will serve as a new challenge
to investigate various activity understanding problems."
"The Good, The Bad, and Why: Unveiling Emotions in Generative AI",0.179283,"Emotion significantly impacts our daily behaviors and interactions. While
recent generative AI models, such as large language models, have shown
impressive performance in various tasks, it remains unclear whether they truly
comprehend emotions. This paper aims to address this gap by incorporating
psychological theories to gain a holistic understanding of emotions in
generative AI models. Specifically, we propose three approaches: 1)
EmotionPrompt to enhance AI model performance, 2) EmotionAttack to impair AI
model performance, and 3) EmotionDecode to explain the effects of emotional
stimuli, both benign and malignant. Through extensive experiments involving
language and multi-modal models on semantic understanding, logical reasoning,
and generation tasks, we demonstrate that both textual and visual EmotionPrompt
can boost the performance of AI models while EmotionAttack can hinder it.
Additionally, EmotionDecode reveals that AI models can comprehend emotional
stimuli akin to the mechanism of dopamine in the human brain. Our work heralds
a novel avenue for exploring psychology to enhance our understanding of
generative AI models."
AnyFace: Free-style Text-to-Face Synthesis and Manipulation,0.994248,"Existing text-to-image synthesis methods generally are only applicable to
words in the training dataset. However, human faces are so variable to be
described with limited words. So this paper proposes the first free-style
text-to-face method namely AnyFace enabling much wider open world applications
such as metaverse, social media, cosmetics, forensics, etc. AnyFace has a novel
two-stream framework for face image synthesis and manipulation given arbitrary
descriptions of the human face. Specifically, one stream performs text-to-face
generation and the other conducts face image reconstruction. Facial text and
image features are extracted using the CLIP (Contrastive Language-Image
Pre-training) encoders. And a collaborative Cross Modal Distillation (CMD)
module is designed to align the linguistic and visual features across these two
streams. Furthermore, a Diverse Triplet Loss (DT loss) is developed to model
fine-grained features and improve facial diversity. Extensive experiments on
Multi-modal CelebA-HQ and CelebAText-HQ demonstrate significant advantages of
AnyFace over state-of-the-art methods. AnyFace can achieve high-quality,
high-resolution, and high-diversity face synthesis and manipulation results
without any constraints on the number and content of input captions."
Using Context-to-Vector with Graph Retrofitting to Improve Word Embeddings,0.80125,"Although contextualized embeddings generated from large-scale pre-trained
models perform well in many tasks, traditional static embeddings (e.g.,
Skip-gram, Word2Vec) still play an important role in low-resource and
lightweight settings due to their low computational cost, ease of deployment,
and stability. In this paper, we aim to improve word embeddings by 1)
incorporating more contextual information from existing pre-trained models into
the Skip-gram framework, which we call Context-to-Vec; 2) proposing a
post-processing retrofitting method for static embeddings independent of
training by employing priori synonym knowledge and weighted vector
distribution. Through extrinsic and intrinsic tasks, our methods are well
proven to outperform the baselines by a large margin."
Structural Bias for Aspect Sentiment Triplet Extraction,0.8039,"Structural bias has recently been exploited for aspect sentiment triplet
extraction (ASTE) and led to improved performance. On the other hand, it is
recognized that explicitly incorporating structural bias would have a negative
impact on efficiency, whereas pretrained language models (PLMs) can already
capture implicit structures. Thus, a natural question arises: Is structural
bias still a necessity in the context of PLMs? To answer the question, we
propose to address the efficiency issues by using an adapter to integrate
structural bias in the PLM and using a cheap-to-compute relative position
structure in place of the syntactic dependency structure. Benchmarking
evaluation is conducted on the SemEval datasets. The results show that our
proposed structural adapter is beneficial to PLMs and achieves state-of-the-art
performance over a range of strong baselines, yet with a light parameter demand
and low latency. Meanwhile, we give rise to the concern that the current
evaluation default with data of small scale is under-confident. Consequently,
we release a large-scale dataset for ASTE. The results on the new dataset hint
that the structural adapter is confidently effective and efficient to a large
scale. Overall, we draw the conclusion that structural bias shall still be a
necessity even with PLMs."
Pre-computed memory or on-the-fly encoding? A hybrid approach to retrieval augmentation makes the most of your compute,0.277492,"Retrieval-augmented language models such as Fusion-in-Decoder are powerful,
setting the state of the art on a variety of knowledge-intensive tasks.
However, they are also expensive, due to the need to encode a large number of
retrieved passages. Some work avoids this cost by pre-encoding a text corpus
into a memory and retrieving dense representations directly. However,
pre-encoding memory incurs a severe quality penalty as the memory
representations are not conditioned on the current input. We propose LUMEN, a
hybrid between these two extremes, pre-computing the majority of the retrieval
representation and completing the encoding on the fly using a live encoder that
is conditioned on the question and fine-tuned for the task. We show that LUMEN
significantly outperforms pure memory on multiple question-answering tasks
while being much cheaper than FiD, and outperforms both for any given compute
budget. Moreover, the advantage of LUMEN over FiD increases with model size."
A Corpus for Sentence-level Subjectivity Detection on English News Articles,0.28675,"We develop novel annotation guidelines for sentence-level subjectivity
detection, which are not limited to language-specific cues. We use our
guidelines to collect NewsSD-ENG, a corpus of 638 objective and 411 subjective
sentences extracted from English news articles on controversial topics. Our
corpus paves the way for subjectivity detection in English and across other
languages without relying on language-specific tools, such as lexicons or
machine translation. We evaluate state-of-the-art multilingual
transformer-based models on the task in mono-, multi-, and cross-language
settings. For this purpose, we re-annotate an existing Italian corpus. We
observe that models trained in the multilingual setting achieve the best
performance on the task."
Overview of the WANLP 2022 Shared Task on Propaganda Detection in Arabic,0.531621,"Propaganda is the expression of an opinion or an action by an individual or a
group deliberately designed to influence the opinions or the actions of other
individuals or groups with reference to predetermined ends, which is achieved
by means of well-defined rhetorical and psychological devices. Propaganda
techniques are commonly used in social media to manipulate or to mislead users.
Thus, there has been a lot of recent research on automatic detection of
propaganda techniques in text as well as in memes. However, so far the focus
has been primarily on English. With the aim to bridge this language gap, we ran
a shared task on detecting propaganda techniques in Arabic tweets as part of
the WANLP 2022 workshop, which included two subtasks. Subtask~1 asks to
identify the set of propaganda techniques used in a tweet, which is a
multilabel classification problem, while Subtask~2 asks to detect the
propaganda techniques used in a tweet together with the exact span(s) of text
in which each propaganda technique appears. The task attracted 63 team
registrations, and eventually 14 and 3 teams made submissions for subtask 1 and
2, respectively. Finally, 11 teams submitted system description papers."
RepCL: Exploring Effective Representation for Continual Text Classification,0.0631734,"Continual learning (CL) aims to constantly learn new knowledge over time
while avoiding catastrophic forgetting on old tasks. In this work, we focus on
continual text classification under the class-incremental setting. Recent CL
studies find that the representations learned in one task may not be effective
for other tasks, namely representation bias problem. For the first time we
formally analyze representation bias from an information bottleneck perspective
and suggest that exploiting representations with more class-relevant
information could alleviate the bias. To this end, we propose a novel
replay-based continual text classification method, RepCL. Our approach utilizes
contrastive and generative representation learning objectives to capture more
class-relevant features. In addition, RepCL introduces an adversarial replay
strategy to alleviate the overfitting problem of replay. Experiments
demonstrate that RepCL effectively alleviates forgetting and achieves
state-of-the-art performance on three text classification tasks."
EX-FEVER: A Dataset for Multi-hop Explainable Fact Verification,0.400214,"Fact verification aims to automatically probe the veracity of a claim based
on several pieces of evidence. Existing works are always engaging in accuracy
improvement, let alone explainability, a critical capability of fact
verification systems. Constructing an explainable fact verification system in a
complex multi-hop scenario is consistently impeded by the absence of a
relevant, high-quality dataset. Previous datasets either suffer from excessive
simplification or fail to incorporate essential considerations for
explainability. To address this, we present EXFEVER, a pioneering dataset for
multi-hop explainable fact verification. With over 60,000 claims involving
2-hop and 3-hop reasoning, each is created by summarizing and modifying
information from hyperlinked Wikipedia documents. Each instance is accompanied
by a veracity label and an explanation that outlines the reasoning path
supporting the veracity classification. Additionally, we demonstrate a novel
baseline system on our EX-FEVER dataset, showcasing document retrieval,
explanation generation, and claim verification, and validate the significance
of our dataset. Furthermore, we highlight the potential of utilizing Large
Language Models in the fact verification task. We hope our dataset could make a
significant contribution by providing ample opportunities to explore the
integration of natural language explanations in the domain of fact
verification."
Feature Space Hijacking Attacks against Differentially Private Split Learning,0.402652,"Split learning and differential privacy are technologies with growing
potential to help with privacy-compliant advanced analytics on distributed
datasets. Attacks against split learning are an important evaluation tool and
have been receiving increased research attention recently. This work's
contribution is applying a recent feature space hijacking attack (FSHA) to the
learning process of a split neural network enhanced with differential privacy
(DP), using a client-side off-the-shelf DP optimizer. The FSHA attack obtains
client's private data reconstruction with low error rates at arbitrarily set DP
epsilon levels. We also experiment with dimensionality reduction as a potential
attack risk mitigation and show that it might help to some extent. We discuss
the reasons why differential privacy is not an effective protection in this
setting and mention potential other risk mitigation methods."
Robust Multi-Agent Pickup and Delivery with Delays,0.620802,"Multi-Agent Pickup and Delivery (MAPD) is the problem of computing
collision-free paths for a group of agents such that they can safely reach
delivery locations from pickup ones. These locations are provided at runtime,
making MAPD a combination between classical Multi-Agent Path Finding (MAPF) and
online task assignment. Current algorithms for MAPD do not consider many of the
practical issues encountered in real applications: real agents often do not
follow the planned paths perfectly, and may be subject to delays and failures.
In this paper, we study the problem of MAPD with delays, and we present two
solution approaches that provide robustness guarantees by planning paths that
limit the effects of imperfect execution. In particular, we introduce two
algorithms, k-TP and p-TP, both based on a decentralized algorithm typically
used to solve MAPD, Token Passing (TP), which offer deterministic and
probabilistic guarantees, respectively. Experimentally, we compare our
algorithms against a version of TP enriched with online replanning. k-TP and
p-TP provide robust solutions, significantly reducing the number of replans
caused by delays, with little or no increase in solution cost and running time."
Improving Automatic Speech Recognition for Non-Native English with Transfer Learning and Language Model Decoding,0.518345,"ASR systems designed for native English (L1) usually underperform on
non-native English (L2). To address this performance gap, \textbf{(i)} we
extend our previous work to investigate fine-tuning of a pre-trained wav2vec
2.0 model \cite{baevski2020wav2vec,xu2021self} under a rich set of L1 and L2
training conditions. We further \textbf{(ii)} incorporate language model
decoding in the ASR system, along with the fine-tuning method. Quantifying
gains acquired from each of these two approaches separately and an error
analysis allows us to identify different sources of improvement within our
models. We find that while the large self-trained wav2vec 2.0 may be
internalizing sufficient decoding knowledge for clean L1 speech
\cite{xu2021self}, this does not hold for L2 speech and accounts for the
utility of employing language model decoding on L2 data."
Large Language Models are biased to overestimate profoundness,0.0711078,"Recent advancements in natural language processing by large language models
(LLMs), such as GPT-4, have been suggested to approach Artificial General
Intelligence. And yet, it is still under dispute whether LLMs possess similar
reasoning abilities to humans. This study evaluates GPT-4 and various other
LLMs in judging the profoundness of mundane, motivational, and pseudo-profound
statements. We found a significant statement-to-statement correlation between
the LLMs and humans, irrespective of the type of statements and the prompting
technique used. However, LLMs systematically overestimate the profoundness of
nonsensical statements, with the exception of Tk-instruct, which uniquely
underestimates the profoundness of statements. Only few-shot learning prompts,
as opposed to chain-of-thought prompting, draw LLMs ratings closer to humans.
Furthermore, this work provides insights into the potential biases induced by
Reinforcement Learning from Human Feedback (RLHF), inducing an increase in the
bias to overestimate the profoundness of statements."
Knowledge Transfer For On-Device Speech Emotion Recognition with Neural Structured Learning,0.155407,"Speech emotion recognition (SER) has been a popular research topic in
human-computer interaction (HCI). As edge devices are rapidly springing up,
applying SER to edge devices is promising for a huge number of HCI
applications. Although deep learning has been investigated to improve the
performance of SER by training complex models, the memory space and
computational capability of edge devices represents a constraint for embedding
deep learning models. We propose a neural structured learning (NSL) framework
through building synthesized graphs. An SER model is trained on a source
dataset and used to build graphs on a target dataset. A relatively lightweight
model is then trained with the speech samples and graphs together as the input.
Our experiments demonstrate that training a lightweight SER model on the target
dataset with speech samples and graphs can not only produce small SER models,
but also enhance the model performance compared to models with speech samples
only and those using classic transfer learning strategies."
Learning and Aggregating Lane Graphs for Urban Automated Driving,0.894731,"Lane graph estimation is an essential and highly challenging task in
automated driving and HD map learning. Existing methods using either onboard or
aerial imagery struggle with complex lane topologies, out-of-distribution
scenarios, or significant occlusions in the image space. Moreover, merging
overlapping lane graphs to obtain consistent large-scale graphs remains
difficult. To overcome these challenges, we propose a novel bottom-up approach
to lane graph estimation from aerial imagery that aggregates multiple
overlapping graphs into a single consistent graph. Due to its modular design,
our method allows us to address two complementary tasks: predicting
ego-respective successor lane graphs from arbitrary vehicle positions using a
graph neural network and aggregating these predictions into a consistent global
lane graph. Extensive experiments on a large-scale lane graph dataset
demonstrate that our approach yields highly accurate lane graphs, even in
regions with severe occlusions. The presented approach to graph aggregation
proves to eliminate inconsistent predictions while increasing the overall graph
quality. We make our large-scale urban lane graph dataset and code publicly
available at http://urbanlanegraph.cs.uni-freiburg.de."
GrowSP: Unsupervised Semantic Segmentation of 3D Point Clouds,0.757016,"We study the problem of 3D semantic segmentation from raw point clouds.
Unlike existing methods which primarily rely on a large amount of human
annotations for training neural networks, we propose the first purely
unsupervised method, called GrowSP, to successfully identify complex semantic
classes for every point in 3D scenes, without needing any type of human labels
or pretrained models. The key to our approach is to discover 3D semantic
elements via progressive growing of superpoints. Our method consists of three
major components, 1) the feature extractor to learn per-point features from
input point clouds, 2) the superpoint constructor to progressively grow the
sizes of superpoints, and 3) the semantic primitive clustering module to group
superpoints into semantic elements for the final semantic segmentation. We
extensively evaluate our method on multiple datasets, demonstrating superior
performance over all unsupervised baselines and approaching the classic
fully-supervised PointNet. We hope our work could inspire more advanced methods
for unsupervised 3D semantic learning."
Collaboration in Participant-Centric Federated Learning: A Game-Theoretical Perspective,0.390023,"Federated learning (FL) is a promising distributed framework for
collaborative artificial intelligence model training while protecting user
privacy. A bootstrapping component that has attracted significant research
attention is the design of incentive mechanism to stimulate user collaboration
in FL. The majority of works adopt a broker-centric approach to help the
central operator to attract participants and further obtain a well-trained
model. Few works consider forging participant-centric collaboration among
participants to pursue an FL model for their common interests, which induces
dramatic differences in incentive mechanism design from the broker-centric FL.
To coordinate the selfish and heterogeneous participants, we propose a novel
analytic framework for incentivizing effective and efficient collaborations for
participant-centric FL. Specifically, we respectively propose two novel game
models for contribution-oblivious FL (COFL) and contribution-aware FL (CAFL),
where the latter one implements a minimum contribution threshold mechanism. We
further analyze the uniqueness and existence for Nash equilibrium of both COFL
and CAFL games and design efficient algorithms to achieve equilibrium
solutions. Extensive performance evaluations show that there exists free-riding
phenomenon in COFL, which can be greatly alleviated through the adoption of
CAFL model with the optimized minimum threshold."
Automated Reading Passage Generation with OpenAI's Large Language Model,0.462899,"The widespread usage of computer-based assessments and individualized
learning platforms has resulted in an increased demand for the rapid production
of high-quality items. Automated item generation (AIG), the process of using
item models to generate new items with the help of computer technology, was
proposed to reduce reliance on human subject experts at each step of the
process. AIG has been used in test development for some time. Still, the use of
machine learning algorithms has introduced the potential to improve the
efficiency and effectiveness of the process greatly. The approach presented in
this paper utilizes OpenAI's latest transformer-based language model, GPT-3, to
generate reading passages. Existing reading passages were used in carefully
engineered prompts to ensure the AI-generated text has similar content and
structure to a fourth-grade reading passage. For each prompt, we generated
multiple passages, the final passage was selected according to the Lexile score
agreement with the original passage. In the final round, the selected passage
went through a simple revision by a human editor to ensure the text was free of
any grammatical and factual errors. All AI-generated passages, along with
original passages were evaluated by human judges according to their coherence,
appropriateness to fourth graders, and readability."
An Analysis of the Effects of Decoding Algorithms on Fairness in Open-Ended Language Generation,0.383667,"Several prior works have shown that language models (LMs) can generate text
containing harmful social biases and stereotypes. While decoding algorithms
play a central role in determining properties of LM generated text, their
impact on the fairness of the generations has not been studied. We present a
systematic analysis of the impact of decoding algorithms on LM fairness, and
analyze the trade-off between fairness, diversity and quality. Our experiments
with top-$p$, top-$k$ and temperature decoding algorithms, in open-ended
language generation, show that fairness across demographic groups changes
significantly with change in decoding algorithm's hyper-parameters. Notably,
decoding algorithms that output more diverse text also output more texts with
negative sentiment and regard. We present several findings and provide
recommendations on standardized reporting of decoding details in fairness
evaluations and optimization of decoding algorithms for fairness alongside
quality and diversity."
U-CE: Uncertainty-aware Cross-Entropy for Semantic Segmentation,0.130818,"Deep neural networks have shown exceptional performance in various tasks, but
their lack of robustness, reliability, and tendency to be overconfident pose
challenges for their deployment in safety-critical applications like autonomous
driving. In this regard, quantifying the uncertainty inherent to a model's
prediction is a promising endeavour to address these shortcomings. In this
work, we present a novel Uncertainty-aware Cross-Entropy loss (U-CE) that
incorporates dynamic predictive uncertainties into the training process by
pixel-wise weighting of the well-known cross-entropy loss (CE). Through
extensive experimentation, we demonstrate the superiority of U-CE over regular
CE training on two benchmark datasets, Cityscapes and ACDC, using two common
backbone architectures, ResNet-18 and ResNet-101. With U-CE, we manage to train
models that not only improve their segmentation performance but also provide
meaningful uncertainties after training. Consequently, we contribute to the
development of more robust and reliable segmentation models, ultimately
advancing the state-of-the-art in safety-critical applications and beyond."
Implicit neural representations for joint decomposition and registration of gene expression images in the marmoset brain,0.605263,"We propose a novel image registration method based on implicit neural
representations that addresses the challenging problem of registering a pair of
brain images with similar anatomical structures, but where one image contains
additional features or artifacts that are not present in the other image. To
demonstrate its effectiveness, we use 2D microscopy $\textit{in situ}$
hybridization gene expression images of the marmoset brain. Accurately
quantifying gene expression requires image registration to a brain template,
which is difficult due to the diversity of patterns causing variations in
visible anatomical brain structures. Our approach uses implicit networks in
combination with an image exclusion loss to jointly perform the registration
and decompose the image into a support and residual image. The support image
aligns well with the template, while the residual image captures individual
image characteristics that diverge from the template. In experiments, our
method provided excellent results and outperformed other registration
techniques."
ClearPose: Large-scale Transparent Object Dataset and Benchmark,0.877727,"Transparent objects are ubiquitous in household settings and pose distinct
challenges for visual sensing and perception systems. The optical properties of
transparent objects leave conventional 3D sensors alone unreliable for object
depth and pose estimation. These challenges are highlighted by the shortage of
large-scale RGB-Depth datasets focusing on transparent objects in real-world
settings. In this work, we contribute a large-scale real-world RGB-Depth
transparent object dataset named ClearPose to serve as a benchmark dataset for
segmentation, scene-level depth completion and object-centric pose estimation
tasks. The ClearPose dataset contains over 350K labeled real-world RGB-Depth
frames and 5M instance annotations covering 63 household objects. The dataset
includes object categories commonly used in daily life under various lighting
and occluding conditions as well as challenging test scenarios such as cases of
occlusion by opaque or translucent objects, non-planar orientations, presence
of liquids, etc. We benchmark several state-of-the-art depth completion and
object pose estimation deep neural networks on ClearPose. The dataset and
benchmarking source code is available at https://github.com/opipari/ClearPose."
Reconstructing Hand-Held Objects from Monocular Video,0.93638,"This paper presents an approach that reconstructs a hand-held object from a
monocular video. In contrast to many recent methods that directly predict
object geometry by a trained network, the proposed approach does not require
any learned prior about the object and is able to recover more accurate and
detailed object geometry. The key idea is that the hand motion naturally
provides multiple views of the object and the motion can be reliably estimated
by a hand pose tracker. Then, the object geometry can be recovered by solving a
multi-view reconstruction problem. We devise an implicit neural
representation-based method to solve the reconstruction problem and address the
issues of imprecise hand pose estimation, relative hand-object motion, and
insufficient geometry optimization for small objects. We also provide a newly
collected dataset with 3D ground truth to validate the proposed approach."
FairLex: A Multilingual Benchmark for Evaluating Fairness in Legal Text Processing,0.987216,"We present a benchmark suite of four datasets for evaluating the fairness of
pre-trained language models and the techniques used to fine-tune them for
downstream tasks. Our benchmarks cover four jurisdictions (European Council,
USA, Switzerland, and China), five languages (English, German, French, Italian
and Chinese) and fairness across five attributes (gender, age, region,
language, and legal area). In our experiments, we evaluate pre-trained language
models using several group-robust fine-tuning techniques and show that
performance group disparities are vibrant in many cases, while none of these
techniques guarantee fairness, nor consistently mitigate group disparities.
Furthermore, we provide a quantitative and qualitative analysis of our results,
highlighting open challenges in the development of robustness methods in legal
NLP."
ATTEMPT: Parameter-Efficient Multi-task Tuning via Attentional Mixtures of Soft Prompts,0.571662,"This work introduces a new multi-task, parameter-efficient language model
(LM) tuning method that learns to transfer knowledge across different tasks via
a mixture of soft prompts-small prefix embedding vectors pre-trained for
different tasks. Our method, called ATTEMPT (ATTEntional Mixtures of Prompt
Tuning), obtains source prompts as encodings of large-scale source tasks into a
small number of parameters and trains an attention module to interpolate the
source prompts and a newly initialized target prompt for every instance in the
target task. During training, only the target task prompt and the attention
weights, which are shared between tasks in multi-task training, are updated,
while the original LM and source prompts are intact. ATTEMPT is highly
parameter-efficient (e.g., updates 2,300 times fewer parameters than full
fine-tuning) while achieving high task performance using knowledge from
high-resource tasks. Moreover, it is modular using pre-trained soft prompts,
and can flexibly add or remove source prompts for effective knowledge transfer.
Our experimental results across 21 diverse NLP datasets show that ATTEMPT
significantly outperforms prompt tuning and outperforms or matches fully
fine-tuned or other parameter-efficient tuning approaches that use over ten
times more parameters. Finally, ATTEMPT outperforms previous work in few-shot
learning settings."
Are High-Resolution Event Cameras Really Needed?,0.51533,"Due to their outstanding properties in challenging conditions, event cameras
have become indispensable in a wide range of applications, ranging from
automotive, computational photography, and SLAM. However, as further
improvements are made to the sensor design, modern event cameras are trending
toward higher and higher sensor resolutions, which result in higher bandwidth
and computational requirements on downstream tasks. Despite this trend, the
benefits of using high-resolution event cameras to solve standard computer
vision tasks are still not clear. In this work, we report the surprising
discovery that, in low-illumination conditions and at high speeds,
low-resolution cameras can outperform high-resolution ones, while requiring a
significantly lower bandwidth. We provide both empirical and theoretical
evidence for this claim, which indicates that high-resolution event cameras
exhibit higher per-pixel event rates, leading to higher temporal noise in
low-illumination conditions and at high speeds. As a result, in most cases,
high-resolution event cameras show a lower task performance, compared to lower
resolution sensors in these conditions. We empirically validate our findings
across several tasks, namely image reconstruction, optical flow estimation, and
camera pose tracking, both on synthetic and real data. We believe that these
findings will provide important guidelines for future trends in event camera
development."
Self-Supervised Face Image Restoration with a One-Shot Reference,0.039764,"For image restoration, methods leveraging priors from generative models have
been proposed and demonstrated a promising capacity to robustly restore
photorealistic and high-quality results. However, these methods are susceptible
to semantic ambiguity, particularly with images that have obviously correct
semantics such as facial images. In this paper, we propose a semantic-aware
latent space exploration method for image restoration (SAIR). By explicitly
modeling semantics information from a given reference image, SAIR is able to
reliably restore severely degraded images not only to high-resolution and
highly realistic looks but also to correct semantics. Quantitative and
qualitative experiments collectively demonstrate the superior performance of
the proposed SAIR. Our code is available at https://github.com/Liamkuo/SAIR."
MOTRv2: Bootstrapping End-to-End Multi-Object Tracking by Pretrained Object Detectors,0.928169,"In this paper, we propose MOTRv2, a simple yet effective pipeline to
bootstrap end-to-end multi-object tracking with a pretrained object detector.
Existing end-to-end methods, MOTR and TrackFormer are inferior to their
tracking-by-detection counterparts mainly due to their poor detection
performance. We aim to improve MOTR by elegantly incorporating an extra object
detector. We first adopt the anchor formulation of queries and then use an
extra object detector to generate proposals as anchors, providing detection
prior to MOTR. The simple modification greatly eases the conflict between joint
learning detection and association tasks in MOTR. MOTRv2 keeps the query
propogation feature and scales well on large-scale benchmarks. MOTRv2 ranks the
1st place (73.4% HOTA on DanceTrack) in the 1st Multiple People Tracking in
Group Dance Challenge. Moreover, MOTRv2 reaches state-of-the-art performance on
the BDD100K dataset. We hope this simple and effective pipeline can provide
some new insights to the end-to-end MOT community. Code is available at
\url{https://github.com/megvii-research/MOTRv2}."
$$ DARTS Once More: Enhancing Differentiable Architecture Search by Masked Image Modeling,0.191582,"Differentiable architecture search (DARTS) has been a mainstream direction in
automatic machine learning. Since the discovery that original DARTS will
inevitably converge to poor architectures, recent works alleviate this by
either designing rule-based architecture selection techniques or incorporating
complex regularization techniques, abandoning the simplicity of the original
DARTS that selects architectures based on the largest parametric value, namely
$\alpha$. Moreover, we find that all the previous attempts only rely on
classification labels, hence learning only single modal information and
limiting the representation power of the shared network. To this end, we
propose to additionally inject semantic information by formulating a patch
recovery approach. Specifically, we exploit the recent trending masked image
modeling and do not abandon the guidance from the downstream tasks during the
search phase. Our method surpasses all previous DARTS variants and achieves
state-of-the-art results on CIFAR-10, CIFAR-100, and ImageNet without complex
manual-designed strategies."
The Hidden Uniform Cluster Prior in Self-Supervised Learning,0.535313,"A successful paradigm in representation learning is to perform
self-supervised pretraining using tasks based on mini-batch statistics (e.g.,
SimCLR, VICReg, SwAV, MSN). We show that in the formulation of all these
methods is an overlooked prior to learn features that enable uniform clustering
of the data. While this prior has led to remarkably semantic representations
when pretraining on class-balanced data, such as ImageNet, we demonstrate that
it can hamper performance when pretraining on class-imbalanced data. By moving
away from conventional uniformity priors and instead preferring power-law
distributed feature clusters, we show that one can improve the quality of the
learned representations on real-world class-imbalanced datasets. To demonstrate
this, we develop an extension of the Masked Siamese Networks (MSN) method to
support the use of arbitrary features priors."
Computer Aided Diagnosis and Out-of-Distribution Detection in Glaucoma Screening Using Color Fundus Photography,0.131376,"Artificial Intelligence for RObust Glaucoma Screening (AIROGS) Challenge is
held for developing solutions for glaucoma screening from color fundus
photography that are robust to real-world scenarios. This report describes our
method submitted to the AIROGS challenge. Our method employs convolutional
neural networks to classify input images to ""referable glaucoma"" or ""no
referable glaucoma"". In addition, we introduce an inference-time
out-of-distribution (OOD) detection method to identify ungradable images. Our
OOD detection is based on an energy-based method combined with activation
rectification."
UL2: Unifying Language Learning Paradigms,0.897281,"Existing pre-trained models are generally geared towards a particular class
of problems. To date, there seems to be still no consensus on what the right
architecture and pre-training setup should be. This paper presents a unified
framework for pre-training models that are universally effective across
datasets and setups. We begin by disentangling architectural archetypes with
pre-training objectives -- two concepts that are commonly conflated. Next, we
present a generalized & unified perspective for self-supervision in NLP and
show how different pre-training objectives can be cast as one another and how
interpolating between different objectives can be effective. We then propose
Mixture-of-Denoisers (MoD), a pre-training objective that combines diverse
pre-training paradigms together. We furthermore introduce a notion of mode
switching, wherein downstream fine-tuning is associated with specific
pre-training schemes. We conduct extensive ablative experiments to compare
multiple pre-training objectives and find that our method pushes the
Pareto-frontier by outperforming T5 & GPT-like models across multiple diverse
setups. By scaling our model up to 20B parameters, we achieve SOTA performance
on 50 well-established supervised finetuning based NLP tasks. Our model also
achieve strong results at in-context learning, outperforming 175B GPT-3 on
zero-shot SuperGLUE and tripling the performance of T5-XXL on one-shot
summarization. On 0-shot MMLU, UL2 20B outperforms T0 and T5 models. UL2 20B
also works well with chain-of-thought prompting and reasoning, making it an
appealing choice for research into reasoning at a small to medium scale of 20B
parameters. Finally, we apply FLAN instruction tuning to the UL2 20B model,
achieving MMLU and Big-Bench scores competitive to FLAN-PaLM 62B. We release
Flax-based T5X checkpoints for the UL2 20B & Flan-UL2 20B."
Probing Cross-Lingual Lexical Knowledge from Multilingual Sentence Encoders,0.41944,"Pretrained multilingual language models (LMs) can be successfully transformed
into multilingual sentence encoders (SEs; e.g., LaBSE, xMPNet) via additional
fine-tuning or model distillation with parallel data. However, it remains
unclear how to best leverage them to represent sub-sentence lexical items
(i.e., words and phrases) in cross-lingual lexical tasks. In this work, we
probe SEs for the amount of cross-lingual lexical knowledge stored in their
parameters, and compare them against the original multilingual LMs. We also
devise a simple yet efficient method for exposing the cross-lingual lexical
knowledge by means of additional fine-tuning through inexpensive contrastive
learning that requires only a small amount of word translation pairs. Using
bilingual lexical induction (BLI), cross-lingual lexical semantic similarity,
and cross-lingual entity linking as lexical probing tasks, we report
substantial gains on standard benchmarks (e.g., +10 Precision@1 points in BLI).
The results indicate that the SEs such as LaBSE can be 'rewired' into effective
cross-lingual lexical encoders via the contrastive learning procedure, and that
they contain more cross-lingual lexical knowledge than what 'meets the eye'
when they are used as off-the-shelf SEs. This way, we also provide an effective
tool for harnessing 'covert' multilingual lexical knowledge hidden in
multilingual sentence encoders."
Anatomy-Driven Pathology Detection on Chest X-rays,0.924691,"Pathology detection and delineation enables the automatic interpretation of
medical scans such as chest X-rays while providing a high level of
explainability to support radiologists in making informed decisions. However,
annotating pathology bounding boxes is a time-consuming task such that large
public datasets for this purpose are scarce. Current approaches thus use weakly
supervised object detection to learn the (rough) localization of pathologies
from image-level annotations, which is however limited in performance due to
the lack of bounding box supervision. We therefore propose anatomy-driven
pathology detection (ADPD), which uses easy-to-annotate bounding boxes of
anatomical regions as proxies for pathologies. We study two training
approaches: supervised training using anatomy-level pathology labels and
multiple instance learning (MIL) with image-level pathology labels. Our results
show that our anatomy-level training approach outperforms weakly supervised
methods and fully supervised detection with limited training samples, and our
MIL approach is competitive with both baseline approaches, therefore
demonstrating the potential of our approach."
"RGB-D-Based Categorical Object Pose and Shape Estimation: Methods, Datasets, and Evaluation",0.341006,"Recently, various methods for 6D pose and shape estimation of objects at a
per-category level have been proposed. This work provides an overview of the
field in terms of methods, datasets, and evaluation protocols. First, an
overview of existing works and their commonalities and differences is provided.
Second, we take a critical look at the predominant evaluation protocol,
including metrics and datasets. Based on the findings, we propose a new set of
metrics, contribute new annotations for the Redwood dataset, and evaluate
state-of-the-art methods in a fair comparison. The results indicate that
existing methods do not generalize well to unconstrained orientations and are
actually heavily biased towards objects being upright. We provide an
easy-to-use evaluation toolbox with well-defined metrics, methods, and dataset
interfaces, which allows evaluation and comparison with various
state-of-the-art approaches
(https://github.com/roym899/pose_and_shape_evaluation)."
FastKASSIM: A Fast Tree Kernel-Based Syntactic Similarity Metric,0.183343,"Syntax is a fundamental component of language, yet few metrics have been
employed to capture syntactic similarity or coherence at the utterance- and
document-level. The existing standard document-level syntactic similarity
metric is computationally expensive and performs inconsistently when faced with
syntactically dissimilar documents. To address these challenges, we present
FastKASSIM, a metric for utterance- and document-level syntactic similarity
which pairs and averages the most similar constituency parse trees between a
pair of documents based on tree kernels. FastKASSIM is more robust to syntactic
dissimilarities and runs up to to 5.32 times faster than its predecessor over
documents in the r/ChangeMyView corpus. FastKASSIM's improvements allow us to
examine hypotheses in two settings with large documents. We find that
syntactically similar arguments on r/ChangeMyView tend to be more persuasive,
and that syntax is predictive of authorship attribution in the Australian High
Court Judgment corpus."
Query-Response Interactions by Multi-tasks in Semantic Search for Chatbot Candidate Retrieval,0.318835,"Semantic search for candidate retrieval is an important yet neglected problem
in retrieval-based Chatbots, which aims to select a bunch of candidate
responses efficiently from a large pool. The existing bottleneck is to ensure
the model architecture having two points: 1) rich interactions between a query
and a response to produce query-relevant responses; 2) ability of separately
projecting the query and the response into latent spaces to apply efficiently
in semantic search during online inference. To tackle this problem, we propose
a novel approach, called Multitask-based Semantic Search Neural Network (MSSNN)
for candidate retrieval, which accomplishes query-response interactions through
multi-tasks. The method employs a Seq2Seq modeling task to learn a good query
encoder, and then performs a word prediction task to build response embeddings,
finally conducts a simple matching model to form the dot-product scorer.
Experimental studies have demonstrated the potential of the proposed approach."
Mining Relations among Cross-Frame Affinities for Video Semantic Segmentation,0.51346,"The essence of video semantic segmentation (VSS) is how to leverage temporal
information for prediction. Previous efforts are mainly devoted to developing
new techniques to calculate the cross-frame affinities such as optical flow and
attention. Instead, this paper contributes from a different angle by mining
relations among cross-frame affinities, upon which better temporal information
aggregation could be achieved. We explore relations among affinities in two
aspects: single-scale intrinsic correlations and multi-scale relations.
Inspired by traditional feature processing, we propose Single-scale Affinity
Refinement (SAR) and Multi-scale Affinity Aggregation (MAA). To make it
feasible to execute MAA, we propose a Selective Token Masking (STM) strategy to
select a subset of consistent reference tokens for different scales when
calculating affinities, which also improves the efficiency of our method. At
last, the cross-frame affinities strengthened by SAR and MAA are adopted for
adaptively aggregating temporal information. Our experiments demonstrate that
the proposed method performs favorably against state-of-the-art VSS methods.
The code is publicly available at https://github.com/GuoleiSun/VSS-MRCFA"
Language-Bridged Spatial-Temporal Interaction for Referring Video Object Segmentation,0.680133,"Referring video object segmentation aims to predict foreground labels for
objects referred by natural language expressions in videos. Previous methods
either depend on 3D ConvNets or incorporate additional 2D ConvNets as encoders
to extract mixed spatial-temporal features. However, these methods suffer from
spatial misalignment or false distractors due to delayed and implicit
spatial-temporal interaction occurring in the decoding phase. To tackle these
limitations, we propose a Language-Bridged Duplex Transfer (LBDT) module which
utilizes language as an intermediary bridge to accomplish explicit and adaptive
spatial-temporal interaction earlier in the encoding phase. Concretely,
cross-modal attention is performed among the temporal encoder, referring words
and the spatial encoder to aggregate and transfer language-relevant motion and
appearance information. In addition, we also propose a Bilateral Channel
Activation (BCA) module in the decoding phase for further denoising and
highlighting the spatial-temporal consistent features via channel-wise
activation. Extensive experiments show our method achieves new state-of-the-art
performances on four popular benchmarks with 6.8% and 6.9% absolute AP gains on
A2D Sentences and J-HMDB Sentences respectively, while consuming around 7x less
computational overhead."
Contribution of the Temperature of the Objects to the Problem of Thermal Imaging Focusing,0.00948534,"When focusing an image, depth of field, aperture and distance from the camera
to the object, must be taking into account, both, in visible and in infrared
spectrum. Our experiments reveal that in addition, the focusing problem in
thermal spectrum is also hardly dependent of the temperature of the object
itself (and/or the scene)."
Pre-Avatar: An Automatic Presentation Generation Framework Leveraging Talking Avatar,0.0459139,"Since the beginning of the COVID-19 pandemic, remote conferencing and
school-teaching have become important tools. The previous applications aim to
save the commuting cost with real-time interactions. However, our application
is going to lower the production and reproduction costs when preparing the
communication materials. This paper proposes a system called Pre-Avatar,
generating a presentation video with a talking face of a target speaker with 1
front-face photo and a 3-minute voice recording. Technically, the system
consists of three main modules, user experience interface (UEI), talking face
module and few-shot text-to-speech (TTS) module. The system firstly clones the
target speaker's voice, and then generates the speech, and finally generate an
avatar with appropriate lip and head movements. Under any scenario, users only
need to replace slides with different notes to generate another new video. The
demo has been released here and will be published as free software for use."
High-Res Facial Appearance Capture from Polarized Smartphone Images,0.74146,"We propose a novel method for high-quality facial texture reconstruction from
RGB images using a novel capturing routine based on a single smartphone which
we equip with an inexpensive polarization foil. Specifically, we turn the
flashlight into a polarized light source and add a polarization filter on top
of the camera. Leveraging this setup, we capture the face of a subject with
cross-polarized and parallel-polarized light. For each subject, we record two
short sequences in a dark environment under flash illumination with different
light polarization using the modified smartphone. Based on these observations,
we reconstruct an explicit surface mesh of the face using structure from
motion. We then exploit the camera and light co-location within a
differentiable renderer to optimize the facial textures using an
analysis-by-synthesis approach. Our method optimizes for high-resolution normal
textures, diffuse albedo, and specular albedo using a coarse-to-fine
optimization scheme. We show that the optimized textures can be used in a
standard rendering pipeline to synthesize high-quality photo-realistic 3D
digital humans in novel environments."
Towards Tracing Factual Knowledge in Language Models Back to the Training Data,0.321927,"Language models (LMs) have been shown to memorize a great deal of factual
knowledge contained in their training data. But when an LM generates an
assertion, it is often difficult to determine where it learned this information
and whether it is true. In this paper, we propose the problem of fact tracing:
identifying which training examples taught an LM to generate a particular
factual assertion. Prior work on training data attribution (TDA) may offer
effective tools for identifying such examples, known as ""proponents"". We
present the first quantitative benchmark to evaluate this. We compare two
popular families of TDA methods -- gradient-based and embedding-based -- and
find that much headroom remains. For example, both methods have lower
proponent-retrieval precision than an information retrieval baseline (BM25)
that does not have access to the LM at all. We identify key challenges that may
be necessary for further improvement such as overcoming the problem of gradient
saturation, and also show how several nuanced implementation details of
existing neural TDA methods can significantly improve overall fact tracing
performance."
EmoCaps: Emotion Capsule based Model for Conversational Emotion Recognition,0.974947,"Emotion recognition in conversation (ERC) aims to analyze the speaker's state
and identify their emotion in the conversation. Recent works in ERC focus on
context modeling but ignore the representation of contextual emotional
tendency. In order to extract multi-modal information and the emotional
tendency of the utterance effectively, we propose a new structure named
Emoformer to extract multi-modal emotion vectors from different modalities and
fuse them with sentence vector to be an emotion capsule. Furthermore, we design
an end-to-end ERC model called EmoCaps, which extracts emotion vectors through
the Emoformer structure and obtain the emotion classification results from a
context analysis model. Through the experiments with two benchmark datasets,
our model shows better performance than the existing state-of-the-art models."
The Moral Integrity Corpus: A Benchmark for Ethical Dialogue Systems,0.98535,"Conversational agents have come increasingly closer to human competence in
open-domain dialogue settings; however, such models can reflect insensitive,
hurtful, or entirely incoherent viewpoints that erode a user's trust in the
moral integrity of the system. Moral deviations are difficult to mitigate
because moral judgments are not universal, and there may be multiple competing
judgments that apply to a situation simultaneously. In this work, we introduce
a new resource, not to authoritatively resolve moral ambiguities, but instead
to facilitate systematic understanding of the intuitions, values and moral
judgments reflected in the utterances of dialogue systems. The Moral Integrity
Corpus, MIC, is such a resource, which captures the moral assumptions of 38k
prompt-reply pairs, using 99k distinct Rules of Thumb (RoTs). Each RoT reflects
a particular moral conviction that can explain why a chatbot's reply may appear
acceptable or problematic. We further organize RoTs with a set of 9 moral and
social attributes and benchmark performance for attribute classification. Most
importantly, we show that current neural language models can automatically
generate new RoTs that reasonably describe previously unseen interactions, but
they still struggle with certain scenarios. Our findings suggest that MIC will
be a useful resource for understanding and language models' implicit moral
assumptions and flexibly benchmarking the integrity of conversational agents.
To download the data, see https://github.com/GT-SALT/mic"
Rethinking Efficacy of Softmax for Lightweight Non-Local Neural Networks,0.309585,"Non-local (NL) block is a popular module that demonstrates the capability to
model global contexts. However, NL block generally has heavy computation and
memory costs, so it is impractical to apply the block to high-resolution
feature maps. In this paper, to investigate the efficacy of NL block, we
empirically analyze if the magnitude and direction of input feature vectors
properly affect the attention between vectors. The results show the inefficacy
of softmax operation which is generally used to normalize the attention map of
the NL block. Attention maps normalized with softmax operation highly rely upon
magnitude of key vectors, and performance is degenerated if the magnitude
information is removed. By replacing softmax operation with the scaling factor,
we demonstrate improved performance on CIFAR-10, CIFAR-100, and Tiny-ImageNet.
In Addition, our method shows robustness to embedding channel reduction and
embedding weight initialization. Notably, our method makes multi-head attention
employable without additional computational cost."
HAKE: A Knowledge Engine Foundation for Human Activity Understanding,0.562897,"Human activity understanding is of widespread interest in artificial
intelligence and spans diverse applications like health care and behavior
analysis. Although there have been advances in deep learning, it remains
challenging. The object recognition-like solutions usually try to map pixels to
semantics directly, but activity patterns are much different from object
patterns, thus hindering success. In this work, we propose a novel paradigm to
reformulate this task in two stages: first mapping pixels to an intermediate
space spanned by atomic activity primitives, then programming detected
primitives with interpretable logic rules to infer semantics. To afford a
representative primitive space, we build a knowledge base including 26+ M
primitive labels and logic rules from human priors or automatic discovering.
Our framework, the Human Activity Knowledge Engine (HAKE), exhibits superior
generalization ability and performance upon canonical methods on challenging
benchmarks. Code and data are available at http://hake-mvig.cn/."
CDNet: Contrastive Disentangled Network for Fine-Grained Image Categorization of Ocular B-Scan Ultrasound,0.211071,"Precise and rapid categorization of images in the B-scan ultrasound modality
is vital for diagnosing ocular diseases. Nevertheless, distinguishing various
diseases in ultrasound still challenges experienced ophthalmologists. Thus a
novel contrastive disentangled network (CDNet) is developed in this work,
aiming to tackle the fine-grained image categorization (FGIC) challenges of
ocular abnormalities in ultrasound images, including intraocular tumor (IOT),
retinal detachment (RD), posterior scleral staphyloma (PSS), and vitreous
hemorrhage (VH). Three essential components of CDNet are the weakly-supervised
lesion localization module (WSLL), contrastive multi-zoom (CMZ) strategy, and
hyperspherical contrastive disentangled loss (HCD-Loss), respectively. These
components facilitate feature disentanglement for fine-grained recognition in
both the input and output aspects. The proposed CDNet is validated on our ZJU
Ocular Ultrasound Dataset (ZJUOUSD), consisting of 5213 samples. Furthermore,
the generalization ability of CDNet is validated on two public and widely-used
chest X-ray FGIC benchmarks. Quantitative and qualitative results demonstrate
the efficacy of our proposed CDNet, which achieves state-of-the-art performance
in the FGIC task. Code is available at:
https://github.com/ZeroOneGame/CDNet-for-OUS-FGIC ."
MHR-Net: Multiple-Hypothesis Reconstruction of Non-Rigid Shapes from 2D Views,0.486058,"We propose MHR-Net, a novel method for recovering Non-Rigid Shapes from
Motion (NRSfM). MHR-Net aims to find a set of reasonable reconstructions for a
2D view, and it also selects the most likely reconstruction from the set. To
deal with the challenging unsupervised generation of non-rigid shapes, we
develop a new Deterministic Basis and Stochastic Deformation scheme in MHR-Net.
The non-rigid shape is first expressed as the sum of a coarse shape basis and a
flexible shape deformation, then multiple hypotheses are generated with
uncertainty modeling of the deformation part. MHR-Net is optimized with
reprojection loss on the basis and the best hypothesis. Furthermore, we design
a new Procrustean Residual Loss, which reduces the rigid rotations between
similar shapes and further improves the performance. Experiments show that
MHR-Net achieves state-of-the-art reconstruction accuracy on Human3.6M, SURREAL
and 300-VW datasets."
Parallel Instance Query Network for Named Entity Recognition,0.533566,"Named entity recognition (NER) is a fundamental task in natural language
processing. Recent works treat named entity recognition as a reading
comprehension task, constructing type-specific queries manually to extract
entities. This paradigm suffers from three issues. First, type-specific queries
can only extract one type of entities per inference, which is inefficient.
Second, the extraction for different types of entities is isolated, ignoring
the dependencies between them. Third, query construction relies on external
knowledge and is difficult to apply to realistic scenarios with hundreds of
entity types. To deal with them, we propose Parallel Instance Query Network
(PIQN), which sets up global and learnable instance queries to extract entities
from a sentence in a parallel manner. Each instance query predicts one entity,
and by feeding all instance queries simultaneously, we can query all entities
in parallel. Instead of being constructed from external knowledge, instance
queries can learn their different query semantics during training. For training
the model, we treat label assignment as a one-to-many Linear Assignment Problem
(LAP) and dynamically assign gold entities to instance queries with minimal
assignment cost. Experiments on both nested and flat NER datasets demonstrate
that our proposed method outperforms previous state-of-the-art models."
ITTR: Unpaired Image-to-Image Translation with Transformers,0.569248,"Unpaired image-to-image translation is to translate an image from a source
domain to a target domain without paired training data. By utilizing CNN in
extracting local semantics, various techniques have been developed to improve
the translation performance. However, CNN-based generators lack the ability to
capture long-range dependency to well exploit global semantics. Recently,
Vision Transformers have been widely investigated for recognition tasks. Though
appealing, it is inappropriate to simply transfer a recognition-based vision
transformer to image-to-image translation due to the generation difficulty and
the computation limitation. In this paper, we propose an effective and
efficient architecture for unpaired Image-to-Image Translation with
Transformers (ITTR). It has two main designs: 1) hybrid perception block (HPB)
for token mixing from different receptive fields to utilize global semantics;
2) dual pruned self-attention (DPSA) to sharply reduce the computational
complexity. Our ITTR outperforms the state-of-the-arts for unpaired
image-to-image translation on six benchmark datasets."
Beyond Conservatism: Diffusion Policies in Offline Multi-agent Reinforcement Learning,0.322491,"We present a novel Diffusion Offline Multi-agent Model (DOM2) for offline
Multi-Agent Reinforcement Learning (MARL). Different from existing algorithms
that rely mainly on conservatism in policy design, DOM2 enhances policy
expressiveness and diversity based on diffusion. Specifically, we incorporate a
diffusion model into the policy network and propose a trajectory-based
data-augmentation scheme in training. These key ingredients make our algorithm
more robust to environment changes and achieve significant improvements in
performance, generalization and data-efficiency. Our extensive experimental
results demonstrate that DOM2 outperforms existing state-of-the-art methods in
multi-agent particle and multi-agent MuJoCo environments, and generalizes
significantly better in shifted environments thanks to its high expressiveness
and diversity. Furthermore, DOM2 shows superior data efficiency and can achieve
state-of-the-art performance with $20+$ times less data compared to existing
algorithms."
Uncertain Label Correction via Auxiliary Action Unit Graphs for Facial Expression Recognition,0.813576,"High-quality annotated images are significant to deep facial expression
recognition (FER) methods. However, uncertain labels, mostly existing in
large-scale public datasets, often mislead the training process. In this paper,
we achieve uncertain label correction of facial expressions using auxiliary
action unit (AU) graphs, called ULC-AG. Specifically, a weighted regularization
module is introduced to highlight valid samples and suppress category imbalance
in every batch. Based on the latent dependency between emotions and AUs, an
auxiliary branch using graph convolutional layers is added to extract the
semantic information from graph topologies. Finally, a re-labeling strategy
corrects the ambiguous annotations by comparing their feature similarities with
semantic templates. Experiments show that our ULC-AG achieves 89.31% and 61.57%
accuracy on RAF-DB and AffectNet datasets, respectively, outperforming the
baseline and state-of-the-art methods."
Are Hitting Formulas Hard for Resolution?,0.380872,"Hitting formulas, introduced by Iwama, are an unusual class of propositional
CNF formulas. Not only is their satisfiability decidable in polynomial time,
but even their models can be counted in closed form. This stands in stark
contrast with other polynomial-time decidable classes, which usually have
algorithms based on backtracking and resolution and for which model counting
remains hard, like 2-SAT and Horn-SAT. However, those resolution-based
algorithms usually easily imply an upper bound on resolution complexity, which
is missing for hitting formulas. Are hitting formulas hard for resolution?
  In this paper we take the first steps towards answering this question. We
show that the resolution complexity of hitting formulas is dominated by
so-called irreducible hitting formulas, first studied by Kullmann and Zhao,
that cannot be composed of smaller hitting formulas. However, by definition,
large irreducible unsatisfiable hitting formulas are difficult to construct; it
is not even known whether infinitely many exist. Building upon our theoretical
results, we implement an efficient algorithm on top of the Nauty software
package to enumerate all irreducible unsatisfiable hitting formulas with up to
14 clauses. We also determine the exact resolution complexity of the generated
hitting formulas with up to 13 clauses by extending a known SAT encoding for
our purposes. Our experimental results suggest that hitting formulas are indeed
hard for resolution."
$m^4Adapter$: Multilingual Multi-Domain Adaptation for Machine Translation with a Meta-Adapter,0.333308,"Multilingual neural machine translation models (MNMT) yield state-of-the-art
performance when evaluated on data from a domain and language pair seen at
training time. However, when a MNMT model is used to translate under domain
shift or to a new language pair, performance drops dramatically. We consider a
very challenging scenario: adapting the MNMT model both to a new domain and to
a new language pair at the same time. In this paper, we propose $m^4Adapter$
(Multilingual Multi-Domain Adaptation for Machine Translation with a
Meta-Adapter), which combines domain and language knowledge using meta-learning
with adapters. We present results showing that our approach is a
parameter-efficient solution which effectively adapts a model to both a new
language pair and a new domain, while outperforming other adapter methods. An
ablation study also shows that our approach more effectively transfers domain
knowledge across different languages and language information across different
domains."
Subword-Delimited Downsampling for Better Character-Level Translation,0.760888,"Subword-level models have been the dominant paradigm in NLP. However,
character-level models have the benefit of seeing each character individually,
providing the model with more detailed information that ultimately could lead
to better models. Recent works have shown character-level models to be
competitive with subword models, but costly in terms of time and computation.
Character-level models with a downsampling component alleviate this, but at the
cost of quality, particularly for machine translation. This work analyzes the
problems of previous downsampling methods and introduces a novel downsampling
method which is informed by subwords. This new downsampling method not only
outperforms existing downsampling methods, showing that downsampling characters
can be done without sacrificing quality, but also leads to promising
performance compared to subword models for translation."
Co-evolving morphology and control of soft robots using a single genome,0.793808,"When simulating soft robots, both their morphology and their controllers play
important roles in task performance. This paper introduces a new method to
co-evolve these two components in the same process. We do that by using the
hyperNEAT algorithm to generate two separate neural networks in one pass, one
responsible for the design of the robot body structure and the other for the
control of the robot.
  The key difference between our method and most existing approaches is that it
does not treat the development of the morphology and the controller as separate
processes. Similar to nature, our method derives both the ""brain"" and the
""body"" of an agent from a single genome and develops them together. While our
approach is more realistic and doesn't require an arbitrary separation of
processes during evolution, it also makes the problem more complex because the
search space for this single genome becomes larger and any mutation to the
genome affects ""brain"" and the ""body"" at the same time.
  Additionally, we present a new speciation function that takes into
consideration both the genotypic distance, as is the standard for NEAT, and the
similarity between robot bodies. By using this function, agents with very
different bodies are more likely to be in different species, this allows robots
with different morphologies to have more specialized controllers since they
won't crossover with other robots that are too different from them.
  We evaluate the presented methods on four tasks and observe that even if the
search space was larger, having a single genome makes the evolution process
converge faster when compared to having separated genomes for body and control.
The agents in our population also show morphologies with a high degree of
regularity and controllers capable of coordinating the voxels to produce the
necessary movements."
Fine-grained Image Editing by Pixel-wise Guidance Using Diffusion Models,0.205787,"Our goal is to develop fine-grained real-image editing methods suitable for
real-world applications. In this paper, we first summarize four requirements
for these methods and propose a novel diffusion-based image editing framework
with pixel-wise guidance that satisfies these requirements. Specifically, we
train pixel-classifiers with a few annotated data and then infer the
segmentation map of a target image. Users then manipulate the map to instruct
how the image will be edited. We utilize a pre-trained diffusion model to
generate edited images aligned with the user's intention with pixel-wise
guidance. The effective combination of proposed guidance and other techniques
enables highly controllable editing with preserving the outside of the edited
area, which results in meeting our requirements. The experimental results
demonstrate that our proposal outperforms the GAN-based method for editing
quality and speed."
Human Attention-Guided Explainable Artificial Intelligence for Computer Vision Models,0.159617,"We examined whether embedding human attention knowledge into saliency-based
explainable AI (XAI) methods for computer vision models could enhance their
plausibility and faithfulness. We first developed new gradient-based XAI
methods for object detection models to generate object-specific explanations by
extending the current methods for image classification models. Interestingly,
while these gradient-based methods worked well for explaining image
classification models, when being used for explaining object detection models,
the resulting saliency maps generally had lower faithfulness than human
attention maps when performing the same task. We then developed Human
Attention-Guided XAI (HAG-XAI) to learn from human attention how to best
combine explanatory information from the models to enhance explanation
plausibility by using trainable activation functions and smoothing kernels to
maximize XAI saliency map's similarity to human attention maps. While for image
classification models, HAG-XAI enhanced explanation plausibility at the expense
of faithfulness, for object detection models it enhanced plausibility and
faithfulness simultaneously and outperformed existing methods. The learned
functions were model-specific, well generalizable to other databases."
Towards a Theory of Faithfulness: Faithful Explanations of Differentiable Classifiers over Continuous Data,0.0961315,"There is broad agreement in the literature that explanation methods should be
faithful to the model that they explain, but faithfulness remains a rather
vague term. We revisit faithfulness in the context of continuous data and
propose two formal definitions of faithfulness for feature attribution methods.
Qualitative faithfulness demands that scores reflect the true qualitative
effect (positive vs. negative) of the feature on the model and quanitative
faithfulness that the magnitude of scores reflect the true quantitative effect.
We discuss under which conditions these requirements can be satisfied to which
extent (local vs global). As an application of the conceptual idea, we look at
differentiable classifiers over continuous data and characterize
Gradient-scores as follows: every qualitatively faithful feature attribution
method is qualitatively equivalent to Gradient-scores. Furthermore, if an
attribution method is quantitatively faithful in the sense that changes of the
output of the classifier are proportional to the scores of features, then it is
either equivalent to gradient-scoring or it is based on an inferior
approximation of the classifier. To illustrate the practical relevance of the
theory, we experimentally demonstrate that popular attribution methods can fail
to give faithful explanations in the setting where the data is continuous and
the classifier differentiable."
Weakly Supervised Multi-Modal 3D Human Body Pose Estimation for Autonomous Driving,0.357841,"Accurate 3D human pose estimation (3D HPE) is crucial for enabling autonomous
vehicles (AVs) to make informed decisions and respond proactively in critical
road scenarios. Promising results of 3D HPE have been gained in several domains
such as human-computer interaction, robotics, sports and medical analytics,
often based on data collected in well-controlled laboratory environments.
Nevertheless, the transfer of 3D HPE methods to AVs has received limited
research attention, due to the challenges posed by obtaining accurate 3D pose
annotations and the limited suitability of data from other domains.
  We present a simple yet efficient weakly supervised approach for 3D HPE in
the AV context by employing a high-level sensor fusion between camera and LiDAR
data. The weakly supervised setting enables training on the target datasets
without any 2D/3D keypoint labels by using an off-the-shelf 2D joint extractor
and pseudo labels generated from LiDAR to image projections. Our approach
outperforms state-of-the-art results by up to $\sim$ 13% on the Waymo Open
Dataset in the weakly supervised setting and achieves state-of-the-art results
in the supervised setting."
Safe Interval Path Planning With Kinodynamic Constraints,0.269101,"Safe Interval Path Planning (SIPP) is a powerful algorithm for solving
single-agent pathfinding problem when the agent is confined to a graph and
certain vertices/edges of this graph are blocked at certain time intervals due
to dynamic obstacles that populate the environment. Original SIPP algorithm
relies on the assumption that the agent is able to stop instantaneously.
However, this assumption often does not hold in practice, e.g. a mobile robot
moving with a cruising speed is not able to stop immediately but rather
requires gradual deceleration to a full stop that takes time. In other words,
the robot is subject to kinodynamic constraints. Unfortunately, as we show in
this work, in such a case original SIPP is incomplete. To this end, we
introduce a novel variant of SIPP that is provably complete and optimal for
planning with acceleration/deceleration. In the experimental evaluation we show
that the key property of the original SIPP still holds for the modified version
-- it performs much less expansions compared to A* and, as a result, is notably
faster."
Combining the Silhouette and Skeleton Data for Gait Recognition,0.448081,"Gait recognition, a long-distance biometric technology, has aroused intense
interest recently. Currently, the two dominant gait recognition works are
appearance-based and model-based, which extract features from silhouettes and
skeletons, respectively. However, appearance-based methods are greatly affected
by clothes-changing and carrying conditions, while model-based methods are
limited by the accuracy of pose estimation. To tackle this challenge, a simple
yet effective two-branch network is proposed in this paper, which contains a
CNN-based branch taking silhouettes as input and a GCN-based branch taking
skeletons as input. In addition, for better gait representation in the
GCN-based branch, we present a fully connected graph convolution operator to
integrate multi-scale graph convolutions and alleviate the dependence on
natural joint connections. Also, we deploy a multi-dimension attention module
named STC-Att to learn spatial, temporal and channel-wise attention
simultaneously. The experimental results on CASIA-B and OUMVLP show that our
method achieves state-of-the-art performance in various conditions."
Read Top News First: A Document Reordering Approach for Multi-Document News Summarization,0.456774,"A common method for extractive multi-document news summarization is to
re-formulate it as a single-document summarization problem by concatenating all
documents as a single meta-document. However, this method neglects the relative
importance of documents. We propose a simple approach to reorder the documents
according to their relative importance before concatenating and summarizing
them. The reordering makes the salient content easier to learn by the
summarization model. Experiments show that our approach outperforms previous
state-of-the-art methods with more complex architectures."
Learning Action Duration and Synergy in Task Planning for Human-Robot Collaboration,0.864665,"A good estimation of the actions' cost is key in task planning for
human-robot collaboration. The duration of an action depends on agents'
capabilities and the correlation between actions performed simultaneously by
the human and the robot. This paper proposes an approach to learning actions'
costs and coupling between actions executed concurrently by humans and robots.
We leverage the information from past executions to learn the average duration
of each action and a synergy coefficient representing the effect of an action
performed by the human on the duration of the action performed by the robot
(and vice versa). We implement the proposed method in a simulated scenario
where both agents can access the same area simultaneously. Safety measures
require the robot to slow down when the human is close, denoting a bad synergy
of tasks operating in the same area. We show that our approach can learn such
bad couplings so that a task planner can leverage this information to find
better plans."
"""Dummy Grandpa, do you know anything?"": Identifying and Characterizing Ad hominem Fallacy Usage in the Wild",0.164708,"Today, participating in discussions on online forums is extremely commonplace
and these discussions have started rendering a strong influence on the overall
opinion of online users. Naturally, twisting the flow of the argument can have
a strong impact on the minds of naive users, which in the long run might have
socio-political ramifications, for example, winning an election or spreading
targeted misinformation. Thus, these platforms are potentially highly
vulnerable to malicious players who might act individually or as a cohort to
breed fallacious arguments with a motive to sway public opinion. Ad hominem
arguments are one of the most effective forms of such fallacies. Although a
simple fallacy, it is effective enough to sway public debates in offline world
and can be used as a precursor to shutting down the voice of opposition by
slander.
  In this work, we take a first step in shedding light on the usage of ad
hominem fallacies in the wild. First, we build a powerful ad hominem detector
with high accuracy (F1 more than 83%, showing a significant improvement over
prior work), even for datasets for which annotated instances constitute a very
small fraction. We then used our detector on 265k arguments collected from the
online debate forum - CreateDebate. Our crowdsourced surveys validate our
in-the-wild predictions on CreateDebate data (94% match with manual
annotation). Our analysis revealed that a surprising 31.23% of CreateDebate
content contains ad hominem fallacy, and a cohort of highly active users post
significantly more ad hominem to suppress opposing views. Then, our temporal
analysis revealed that ad hominem argument usage increased significantly since
the 2016 US Presidential election, not only for topics like Politics, but also
for Science and Law. We conclude by discussing important implications of our
work to detect and defend against ad hominem fallacies."
Pretraining with Artificial Language: Studying Transferable Knowledge in Language Models,0.580953,"We investigate what kind of structural knowledge learned in neural network
encoders is transferable to processing natural language. We design artificial
languages with structural properties that mimic natural language, pretrain
encoders on the data, and see how much performance the encoder exhibits on
downstream tasks in natural language. Our experimental results show that
pretraining with an artificial language with a nesting dependency structure
provides some knowledge transferable to natural language. A follow-up probing
analysis indicates that its success in the transfer is related to the amount of
encoded contextual information and what is transferred is the knowledge of
position-aware context dependence of language. Our results provide insights
into how neural network encoders process human languages and the source of
cross-lingual transferability of recent multilingual language models."
Adversarial Masking for Self-Supervised Learning,0.717541,"We propose ADIOS, a masked image model (MIM) framework for self-supervised
learning, which simultaneously learns a masking function and an image encoder
using an adversarial objective. The image encoder is trained to minimise the
distance between representations of the original and that of a masked image.
The masking function, conversely, aims at maximising this distance. ADIOS
consistently improves on state-of-the-art self-supervised learning (SSL)
methods on a variety of tasks and datasets -- including classification on
ImageNet100 and STL10, transfer learning on CIFAR10/100, Flowers102 and
iNaturalist, as well as robustness evaluated on the backgrounds challenge (Xiao
et al., 2021) -- while generating semantically meaningful masks. Unlike modern
MIM models such as MAE, BEiT and iBOT, ADIOS does not rely on the image-patch
tokenisation construction of Vision Transformers, and can be implemented with
convolutional backbones. We further demonstrate that the masks learned by ADIOS
are more effective in improving representation learning of SSL methods than
masking schemes used in popular MIM models. Code is available at
https://github.com/YugeTen/adios."
ArCovidVac: Analyzing Arabic Tweets About COVID-19 Vaccination,0.724693,"The emergence of the COVID-19 pandemic and the first global infodemic have
changed our lives in many different ways. We relied on social media to get the
latest information about the COVID-19 pandemic and at the same time to
disseminate information. The content in social media consisted not only health
related advises, plans, and informative news from policy makers, but also
contains conspiracies and rumors. It became important to identify such
information as soon as they are posted to make actionable decisions (e.g.,
debunking rumors, or taking certain measures for traveling). To address this
challenge, we develop and publicly release the first largest manually annotated
Arabic tweet dataset, ArCovidVac, for the COVID-19 vaccination campaign,
covering many countries in the Arab region. The dataset is enriched with
different layers of annotation, including, (i) Informativeness (more vs. less
importance of the tweets); (ii) fine-grained tweet content types (e.g., advice,
rumors, restriction, authenticate news/information); and (iii) stance towards
vaccination (pro-vaccination, neutral, anti-vaccination). Further, we performed
in-depth analysis of the data, exploring the popularity of different vaccines,
trending hashtags, topics and presence of offensiveness in the tweets. We
studied the data for individual types of tweets and temporal changes in stance
towards vaccine. We benchmarked the ArCovidVac dataset using transformer
architectures for informativeness, content types, and stance detection."
Large-scale Ridesharing DARP Instances Based on Real Travel Demand,0.632121,"Accurately predicting the real-life performance of algorithms solving the
Dial-a-Ride Problem (DARP) in the context of Mobility on Demand (MoD) systems
with ridesharing requires evaluating them on representative instances. However,
the benchmarking of state-of-the-art DARP solution methods has been limited to
small, artificial instances or outdated non-public instances, hindering direct
comparisons. With the rise of large MoD systems and the availability of open
travel demand datasets for many US cities, there is now an opportunity to
evaluate these algorithms on standardized, realistic, and representative
instances. Despite the significant challenges involved in processing obfuscated
and diverse datasets, we have developed a methodology using which we have
created a comprehensive set of large-scale demand instances based on real-world
data. These instances cover diverse use cases, one of which is demonstrated in
an evaluation of two established DARP methods: the insertion heuristic and
optimal vehicle-group assignment method. We publish the full results of both
methods in a standardized format. The results show significant differences
between areas in all measured quantities, emphasizing the importance of
evaluating methods across different cities."
Fusing finetuned models for better pretraining,0.793936,"Pretrained models are the standard starting point for training. This approach
consistently outperforms the use of a random initialization. However,
pretraining is a costly endeavour that few can undertake.
  In this paper, we create better base models at hardly any cost, by fusing
multiple existing fine tuned models into one. Specifically, we fuse by
averaging the weights of these models. We show that the fused model results
surpass the pretrained model ones. We also show that fusing is often better
than intertraining.
  We find that fusing is less dependent on the target task. Furthermore, weight
decay nullifies intertraining effects but not those of fusing."
DisCLIP: Open-Vocabulary Referring Expression Generation,0.45875,"Referring Expressions Generation (REG) aims to produce textual descriptions
that unambiguously identifies specific objects within a visual scene.
Traditionally, this has been achieved through supervised learning methods,
which perform well on specific data distributions but often struggle to
generalize to new images and concepts. To address this issue, we present a
novel approach for REG, named DisCLIP, short for discriminative CLIP. We build
on CLIP, a large-scale visual-semantic model, to guide an LLM to generate a
contextual description of a target concept in an image while avoiding other
distracting concepts. Notably, this optimization happens at inference time and
does not require additional training or tuning of learned parameters. We
measure the quality of the generated text by evaluating the capability of a
receiver model to accurately identify the described object within the scene. To
achieve this, we use a frozen zero-shot comprehension module as a critique of
our generated referring expressions. We evaluate DisCLIP on multiple referring
expression benchmarks through human evaluation and show that it significantly
outperforms previous methods on out-of-domain datasets. Our results highlight
the potential of using pre-trained visual-semantic models for generating
high-quality contextual descriptions."
Addressing Token Uniformity in Transformers via Singular Value Transformation,0.213806,"Token uniformity is commonly observed in transformer-based models, in which
different tokens share a large proportion of similar information after going
through stacked multiple self-attention layers in a transformer. In this paper,
we propose to use the distribution of singular values of outputs of each
transformer layer to characterise the phenomenon of token uniformity and
empirically illustrate that a less skewed singular value distribution can
alleviate the `token uniformity' problem. Base on our observations, we define
several desirable properties of singular value distributions and propose a
novel transformation function for updating the singular values. We show that
apart from alleviating token uniformity, the transformation function should
preserve the local neighbourhood structure in the original embedding space. Our
proposed singular value transformation function is applied to a range of
transformer-based language models such as BERT, ALBERT, RoBERTa and DistilBERT,
and improved performance is observed in semantic textual similarity evaluation
and a range of GLUE tasks. Our source code is available at
https://github.com/hanqi-qi/tokenUni.git."
SeKron: A Decomposition Method Supporting Many Factorization Structures,0.0729219,"While convolutional neural networks (CNNs) have become the de facto standard
for most image processing and computer vision applications, their deployment on
edge devices remains challenging. Tensor decomposition methods provide a means
of compressing CNNs to meet the wide range of device constraints by imposing
certain factorization structures on their convolution tensors. However, being
limited to the small set of factorization structures presented by
state-of-the-art decomposition approaches can lead to sub-optimal performance.
We propose SeKron, a novel tensor decomposition method that offers a wide
variety of factorization structures, using sequences of Kronecker products. By
recursively finding approximating Kronecker factors, we arrive at optimal
decompositions for each of the factorization structures. We show that SeKron is
a flexible decomposition that generalizes widely used methods, such as
Tensor-Train (TT), Tensor-Ring (TR), Canonical Polyadic (CP) and Tucker
decompositions. Crucially, we derive an efficient convolution projection
algorithm shared by all SeKron structures, leading to seamless compression of
CNN models. We validate SeKron for model compression on both high-level and
low-level computer vision tasks and find that it outperforms state-of-the-art
decomposition methods."
CLMLF:A Contrastive Learning and Multi-Layer Fusion Method for Multimodal Sentiment Detection,0.919567,"Compared with unimodal data, multimodal data can provide more features to
help the model analyze the sentiment of data. Previous research works rarely
consider token-level feature fusion, and few works explore learning the common
features related to sentiment in multimodal data to help the model fuse
multimodal features. In this paper, we propose a Contrastive Learning and
Multi-Layer Fusion (CLMLF) method for multimodal sentiment detection.
Specifically, we first encode text and image to obtain hidden representations,
and then use a multi-layer fusion module to align and fuse the token-level
features of text and image. In addition to the sentiment analysis task, we also
designed two contrastive learning tasks, label based contrastive learning and
data based contrastive learning tasks, which will help the model learn common
features related to sentiment in multimodal data. Extensive experiments
conducted on three publicly available multimodal datasets demonstrate the
effectiveness of our approach for multimodal sentiment detection compared with
existing methods. The codes are available for use at
https://github.com/Link-Li/CLMLF"
Planning with Diffusion for Flexible Behavior Synthesis,0.995936,"Model-based reinforcement learning methods often use learning only for the
purpose of estimating an approximate dynamics model, offloading the rest of the
decision-making work to classical trajectory optimizers. While conceptually
simple, this combination has a number of empirical shortcomings, suggesting
that learned models may not be well-suited to standard trajectory optimization.
In this paper, we consider what it would look like to fold as much of the
trajectory optimization pipeline as possible into the modeling problem, such
that sampling from the model and planning with it become nearly identical. The
core of our technical approach lies in a diffusion probabilistic model that
plans by iteratively denoising trajectories. We show how classifier-guided
sampling and image inpainting can be reinterpreted as coherent planning
strategies, explore the unusual and useful properties of diffusion-based
planning methods, and demonstrate the effectiveness of our framework in control
settings that emphasize long-horizon decision-making and test-time flexibility."
IRFL: Image Recognition of Figurative Language,0.312525,"Figures of speech such as metaphors, similes, and idioms are integral parts
of human communication. They are ubiquitous in many forms of discourse,
allowing people to convey complex, abstract ideas and evoke emotion. As
figurative forms are often conveyed through multiple modalities (e.g., both
text and images), understanding multimodal figurative language is an important
AI challenge, weaving together profound vision, language, commonsense and
cultural knowledge. In this work, we develop the Image Recognition of
Figurative Language (IRFL) dataset. We leverage human annotation and an
automatic pipeline we created to generate a multimodal dataset, and introduce
two novel tasks as a benchmark for multimodal figurative language
understanding. We experimented with state-of-the-art vision and language models
and found that the best (22%) performed substantially worse than humans (97%).
We release our dataset, benchmark, and code, in hopes of driving the
development of models that can better understand figurative language."
Diverse Plausible 360-Degree Image Outpainting for Efficient 3DCG Background Creation,0.76693,"We address the problem of generating a 360-degree image from a single image
with a narrow field of view by estimating its surroundings. Previous methods
suffered from overfitting to the training resolution and deterministic
generation. This paper proposes a completion method using a transformer for
scene modeling and novel methods to improve the properties of a 360-degree
image on the output image. Specifically, we use CompletionNets with a
transformer to perform diverse completions and AdjustmentNet to match color,
stitching, and resolution with an input image, enabling inference at any
resolution. To improve the properties of a 360-degree image on an output image,
we also propose WS-perceptual loss and circular inference. Thorough experiments
show that our method outperforms state-of-the-art (SOTA) methods both
qualitatively and quantitatively. For example, compared to SOTA methods, our
method completes images 16 times larger in resolution and achieves 1.7 times
lower Frechet inception distance (FID). Furthermore, we propose a pipeline that
uses the completion results for lighting and background of 3DCG scenes. Our
plausible background completion enables perceptually natural results in the
application of inserting virtual objects with specular surfaces."
Unveiling the Potential of Sentiment: Can Large Language Models Predict Chinese Stock Price Movements?,0.526926,"The rapid advancement of Large Language Models (LLMs) has spurred discussions
about their potential to enhance quantitative trading strategies. LLMs excel in
analyzing sentiments about listed companies from financial news, providing
critical insights for trading decisions. However, the performance of LLMs in
this task varies substantially due to their inherent characteristics. This
paper introduces a standardized experimental procedure for comprehensive
evaluations. We detail the methodology using three distinct LLMs, each
embodying a unique approach to performance enhancement, applied specifically to
the task of sentiment factor extraction from large volumes of Chinese news
summaries. Subsequently, we develop quantitative trading strategies using these
sentiment factors and conduct back-tests in realistic scenarios. Our results
will offer perspectives about the performances of Large Language Models applied
to extracting sentiments from Chinese news texts."
Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters,0.730356,"Chain-of-Thought (CoT) prompting can dramatically improve the multi-step
reasoning abilities of large language models (LLMs). CoT explicitly encourages
the LLM to generate intermediate rationales for solving a problem, by providing
a series of reasoning steps in the demonstrations. Despite its success, there
is still little understanding of what makes CoT prompting effective and which
aspects of the demonstrated reasoning steps contribute to its performance. In
this paper, we show that CoT reasoning is possible even with invalid
demonstrations - prompting with invalid reasoning steps can achieve over 80-90%
of the performance obtained using CoT under various metrics, while still
generating coherent lines of reasoning during inference. Further experiments
show that other aspects of the rationales, such as being relevant to the query
and correctly ordering the reasoning steps, are much more important for
effective CoT reasoning. Overall, these findings both deepen our understanding
of CoT prompting, and open up new questions regarding LLMs' capability to learn
to reason in context."
RLLTE: Long-Term Evolution Project of Reinforcement Learning,0.0407192,"We present RLLTE: a long-term evolution, extremely modular, and open-source
framework for reinforcement learning (RL) research and application. Beyond
delivering top-notch algorithm implementations, RLLTE also serves as a toolkit
for developing algorithms. More specifically, RLLTE decouples the RL algorithms
completely from the exploitation-exploration perspective, providing a large
number of components to accelerate algorithm development and evolution. In
particular, RLLTE is the first RL framework to build a complete and luxuriant
ecosystem, which includes model training, evaluation, deployment, benchmark
hub, and large language model (LLM)-empowered copilot. RLLTE is expected to set
standards for RL engineering practice and be highly stimulative for industry
and academia."
TimberTrek: Exploring and Curating Sparse Decision Trees with Interactive Visualization,0.755586,"Given thousands of equally accurate machine learning (ML) models, how can
users choose among them? A recent ML technique enables domain experts and data
scientists to generate a complete Rashomon set for sparse decision trees--a
huge set of almost-optimal interpretable ML models. To help ML practitioners
identify models with desirable properties from this Rashomon set, we develop
TimberTrek, the first interactive visualization system that summarizes
thousands of sparse decision trees at scale. Two usage scenarios highlight how
TimberTrek can empower users to easily explore, compare, and curate models that
align with their domain knowledge and values. Our open-source tool runs
directly in users' computational notebooks and web browsers, lowering the
barrier to creating more responsible ML models. TimberTrek is available at the
following public demo link: https://poloclub.github.io/timbertrek."
ETran: Energy-Based Transferability Estimation,0.738163,"This paper addresses the problem of ranking pre-trained models for object
detection and image classification. Selecting the best pre-trained model by
fine-tuning is an expensive and time-consuming task. Previous works have
proposed transferability estimation based on features extracted by the
pre-trained models. We argue that quantifying whether the target dataset is
in-distribution (IND) or out-of-distribution (OOD) for the pre-trained model is
an important factor in the transferability estimation. To this end, we propose
ETran, an energy-based transferability assessment metric, which includes three
scores: 1) energy score, 2) classification score, and 3) regression score. We
use energy-based models to determine whether the target dataset is OOD or IND
for the pre-trained model. In contrast to the prior works, ETran is applicable
to a wide range of tasks including classification, regression, and object
detection (classification+regression). This is the first work that proposes
transferability estimation for object detection task. Our extensive experiments
on four benchmarks and two tasks show that ETran outperforms previous works on
object detection and classification benchmarks by an average of 21% and 12%,
respectively, and achieves SOTA in transferability assessment."
Learning Robust Self-attention Features for Speech Emotion Recognition with Label-adaptive Mixup,0.236994,"Speech Emotion Recognition (SER) is to recognize human emotions in a natural
verbal interaction scenario with machines, which is considered as a challenging
problem due to the ambiguous human emotions. Despite the recent progress in
SER, state-of-the-art models struggle to achieve a satisfactory performance. We
propose a self-attention based method with combined use of label-adaptive mixup
and center loss. By adapting label probabilities in mixup and fitting center
loss to the mixup training scheme, our proposed method achieves a superior
performance to the state-of-the-art methods."
Tailor: A Prompt-Based Approach to Attribute-Based Controlled Text Generation,0.35071,"Attribute-based Controlled Text Generation (CTG) refers to generating
sentences that satisfy desirable attributes (e.g., emotions and topics).
Existing works often utilize fine-tuning or resort to extra attribute
classifiers, yet suffer from storage and inference time increases. To address
these concerns, we explore attribute-based CTG in a prompt-based manner. In
short, the proposed Tailor represents each attribute as a pre-trained
continuous vector (i.e., single-attribute prompt) and guides the generation of
a fixed PLM switch to a pre-specified attribute. We experimentally find that
these prompts can be simply concatenated as a whole to multi-attribute CTG
without any re-training, yet raises problems of fluency decrease and position
sensitivity. To this end, Tailor provides a multi-attribute prompt mask and a
re-indexing position-ids sequence to bridge the gap between the training (one
prompt for each task) and testing stage (concatenating more than one prompt).
To further enhance such single-attribute prompt combinations, Tailor also
introduces a trainable prompt connector, which can be concatenated with any two
single-attribute prompts to multi-attribute text generation. Experiments on 11
attribute-specific generation tasks demonstrate strong performances of Tailor
on both single-attribute and multi-attribute CTG, with 0.08\% training
parameters of a GPT-2."
Belief functions on ordered frames of discernment,0.110277,"Most questionnaires offer ordered responses whose order is poorly studied via
belief functions. In this paper, we study the consequences of a frame of
discernment consisting of ordered elements on belief functions. This leads us
to redefine the power space and the union of ordered elements for the
disjunctive combination. We also study distances on ordered elements and their
use. In particular, from a membership function, we redefine the cardinality of
the intersection of ordered elements, considering them fuzzy."
Coarse to Fine: Image Restoration Boosted by Multi-Scale Low-Rank Tensor Completion,0.0540055,"Existing low-rank tensor completion (LRTC) approaches aim at restoring a
partially observed tensor by imposing a global low-rank constraint on the
underlying completed tensor. However, such a global rank assumption suffers the
trade-off between restoring the originally details-lacking parts and neglecting
the potentially complex objects, making the completion performance
unsatisfactory on both sides. To address this problem, we propose a novel and
practical strategy for image restoration that restores the partially observed
tensor in a coarse-to-fine (C2F) manner, which gets rid of such trade-off by
searching proper local ranks for both low- and high-rank parts. Extensive
experiments are conducted to demonstrate the superiority of the proposed C2F
scheme. The codes are available at: https://github.com/RuiLin0212/C2FLRTC."
Less than One-shot: Named Entity Recognition via Extremely Weak Supervision,0.731505,"We study the named entity recognition (NER) problem under the extremely weak
supervision (XWS) setting, where only one example entity per type is given in a
context-free way. While one can see that XWS is lighter than one-shot in terms
of the amount of supervision, we propose a novel method X-NER that can
outperform the state-of-the-art one-shot NER methods. We first mine entity
spans that are similar to the example entities from an unlabelled training
corpus. Instead of utilizing entity span representations from language models,
we find it more effective to compare the context distributions before and after
the span is replaced by the entity example. We then leverage the top-ranked
spans as pseudo-labels to train an NER tagger. Extensive experiments and
analyses on 4 NER datasets show the superior end-to-end NER performance of
X-NER, outperforming the state-of-the-art few-shot methods with 1-shot
supervision and ChatGPT annotations significantly. Finally, our X-NER possesses
several notable properties, such as inheriting the cross-lingual abilities of
the underlying language models."
On the Relation between Sensitivity and Accuracy in In-context Learning,0.820593,"In-context learning (ICL) suffers from oversensitivity to the prompt, making
it unreliable in real-world scenarios. We study the sensitivity of ICL with
respect to multiple perturbation types. First, we find that label bias obscures
the true sensitivity, and therefore prior work may have significantly
underestimated ICL sensitivity. Second, we observe a strong negative
correlation between ICL sensitivity and accuracy: predictions sensitive to
perturbations are less likely to be correct. Motivated by these findings, we
propose \textsc{SenSel}, a few-shot selective prediction method that abstains
from sensitive predictions. Experiments on ten classification datasets show
that \textsc{SenSel} consistently outperforms two commonly used
confidence-based and entropy-based baselines on abstention decisions."
RV4JaCa -- Runtime Verification for Multi-Agent Systems,0.423207,"This paper presents a Runtime Verification (RV) approach for Multi-Agent
Systems (MAS) using the JaCaMo framework. Our objective is to bring a layer of
security to the MAS. This layer is capable of controlling events during the
execution of the system without needing a specific implementation in the
behaviour of each agent to recognise the events. MAS have been used in the
context of hybrid intelligence. This use requires communication between
software agents and human beings. In some cases, communication takes place via
natural language dialogues. However, this kind of communication brings us to a
concern related to controlling the flow of dialogue so that agents can prevent
any change in the topic of discussion that could impair their reasoning. We
demonstrate the implementation of a monitor that aims to control this dialogue
flow in a MAS that communicates with the user through natural language to aid
decision-making in hospital bed allocation."
HD-Fusion: Detailed Text-to-3D Generation Leveraging Multiple Noise Estimation,0.628845,"In this paper, we study Text-to-3D content generation leveraging 2D diffusion
priors to enhance the quality and detail of the generated 3D models. Recent
progress (Magic3D) in text-to-3D has shown that employing high-resolution
(e.g., 512 x 512) renderings can lead to the production of high-quality 3D
models using latent diffusion priors. To enable rendering at even higher
resolutions, which has the potential to further augment the quality and detail
of the models, we propose a novel approach that combines multiple noise
estimation processes with a pretrained 2D diffusion prior. Distinct from the
Bar-Tal et al.s' study which binds multiple denoised results to generate images
from texts, our approach integrates the computation of scoring distillation
losses such as SDS loss and VSD loss which are essential techniques for the 3D
content generation with 2D diffusion priors. We experimentally evaluated the
proposed approach. The results show that the proposed approach can generate
high-quality details compared to the baselines."
A Generalization of the Shortest Path Problem to Graphs with Multiple Edge-Cost Estimates,0.358251,"The shortest path problem in graphs is a cornerstone of AI theory and
applications. Existing algorithms generally ignore edge weight computation
time. We present a generalized framework for weighted directed graphs, where
edge weight can be computed (estimated) multiple times, at increasing accuracy
and run-time expense. This raises several generalized variants of the shortest
path problem. We introduce the problem of finding a path with the tightest
lower-bound on the optimal cost. We then present two complete algorithms for
the generalized problem, and empirically demonstrate their efficacy."
HRTransNet: HRFormer-Driven Two-Modality Salient Object Detection,0.705775,"The High-Resolution Transformer (HRFormer) can maintain high-resolution
representation and share global receptive fields. It is friendly towards
salient object detection (SOD) in which the input and output have the same
resolution. However, two critical problems need to be solved for two-modality
SOD. One problem is two-modality fusion. The other problem is the HRFormer
output's fusion. To address the first problem, a supplementary modality is
injected into the primary modality by using global optimization and an
attention mechanism to select and purify the modality at the input level. To
solve the second problem, a dual-direction short connection fusion module is
used to optimize the output features of HRFormer, thereby enhancing the
detailed representation of objects at the output level. The proposed model,
named HRTransNet, first introduces an auxiliary stream for feature extraction
of supplementary modality. Then, features are injected into the primary
modality at the beginning of each multi-resolution branch. Next, HRFormer is
applied to achieve forwarding propagation. Finally, all the output features
with different resolutions are aggregated by intra-feature and inter-feature
interactive transformers. Application of the proposed model results in
impressive improvement for driving two-modality SOD tasks, e.g., RGB-D, RGB-T,
and light field SOD.https://github.com/liuzywen/HRTransNet"
CaDeX: Learning Canonical Deformation Coordinate Space for Dynamic Surface Representation via Neural Homeomorphism,0.80681,"While neural representations for static 3D shapes are widely studied,
representations for deformable surfaces are limited to be template-dependent or
lack efficiency. We introduce Canonical Deformation Coordinate Space (CaDeX), a
unified representation of both shape and nonrigid motion. Our key insight is
the factorization of the deformation between frames by continuous bijective
canonical maps (homeomorphisms) and their inverses that go through a learned
canonical shape. Our novel deformation representation and its implementation
are simple, efficient, and guarantee cycle consistency, topology preservation,
and, if needed, volume conservation. Our modelling of the learned canonical
shapes provides a flexible and stable space for shape prior learning. We
demonstrate state-of-the-art performance in modelling a wide range of
deformable geometries: human bodies, animal bodies, and articulated objects."
Class-Adaptive Self-Training for Relation Extraction with Incompletely Annotated Training Data,0.314819,"Relation extraction (RE) aims to extract relations from sentences and
documents. Existing relation extraction models typically rely on supervised
machine learning. However, recent studies showed that many RE datasets are
incompletely annotated. This is known as the false negative problem in which
valid relations are falsely annotated as 'no_relation'. Models trained with
such data inevitably make similar mistakes during the inference stage.
Self-training has been proven effective in alleviating the false negative
problem. However, traditional self-training is vulnerable to confirmation bias
and exhibits poor performance in minority classes. To overcome this limitation,
we proposed a novel class-adaptive re-sampling self-training framework.
Specifically, we re-sampled the pseudo-labels for each class by precision and
recall scores. Our re-sampling strategy favored the pseudo-labels of classes
with high precision and low recall, which improved the overall recall without
significantly compromising precision. We conducted experiments on
document-level and biomedical relation extraction datasets, and the results
showed that our proposed self-training framework consistently outperforms
existing competitive methods on the Re-DocRED and ChemDisgene datasets when the
training data are incompletely annotated. Our code is released at
https://github.com/DAMO-NLP-SG/CAST."
Minimum Class Confusion based Transfer for Land Cover Segmentation in Rural and Urban Regions,0.258075,"Transfer Learning methods are widely used in satellite image segmentation
problems and improve performance upon classical supervised learning methods. In
this study, we present a semantic segmentation method that allows us to make
land cover maps by using transfer learning methods. We compare models trained
in low-resolution images with insufficient data for the targeted region or zoom
level. In order to boost performance on target data we experiment with models
trained with unsupervised, semi-supervised and supervised transfer learning
approaches, including satellite images from public datasets and other unlabeled
sources. According to experimental results, transfer learning improves
segmentation performance 3.4% MIoU (Mean Intersection over Union) in rural
regions and 12.9% MIoU in urban regions. We observed that transfer learning is
more effective when two datasets share a comparable zoom level and are labeled
with identical rules; otherwise, semi-supervised learning is more effective by
using the data as unlabeled. In addition, experiments showed that HRNet
outperformed building segmentation approaches in multi-class segmentation."
Streaming Adaptive Submodular Maximization,0.767535,"Many sequential decision making problems can be formulated as an adaptive
submodular maximization problem. However, most of existing studies in this
field focus on pool-based setting, where one can pick items in any order, and
there have been few studies for the stream-based setting where items arrive in
an arbitrary order and one must immediately decide whether to select an item or
not upon its arrival. In this paper, we introduce a new class of utility
functions, semi-policywise submodular functions. We develop a series of
effective algorithms to maximize a semi-policywise submodular function under
the stream-based setting."
A Secure Clustering Protocol with Fuzzy Trust Evaluation and Outlier Detection for Industrial Wireless Sensor Networks,0.881122,"Security is one of the major concerns in Industrial Wireless Sensor Networks
(IWSNs). To assure the security in clustered IWSNs, this paper presents a
secure clustering protocol with fuzzy trust evaluation and outlier detection
(SCFTO). Firstly, to deal with the transmission uncertainty in an open wireless
medium, an interval type-2 fuzzy logic controller is adopted to estimate the
trusts. And then a density based outlier detection mechanism is introduced to
acquire an adaptive trust threshold used to isolate the malicious nodes from
being cluster heads. Finally, a fuzzy based cluster heads election method is
proposed to achieve a balance between energy saving and security assurance, so
that a normal sensor node with more residual energy or less confidence on other
nodes has higher probability to be the cluster head. Extensive experiments
verify that our secure clustering protocol can effectively defend the network
against attacks from internal malicious or compromised nodes."
Standing Between Past and Future: Spatio-Temporal Modeling for Multi-Camera 3D Multi-Object Tracking,0.890582,"This work proposes an end-to-end multi-camera 3D multi-object tracking (MOT)
framework. It emphasizes spatio-temporal continuity and integrates both past
and future reasoning for tracked objects. Thus, we name it ""Past-and-Future
reasoning for Tracking"" (PF-Track). Specifically, our method adapts the
""tracking by attention"" framework and represents tracked instances coherently
over time with object queries. To explicitly use historical cues, our ""Past
Reasoning"" module learns to refine the tracks and enhance the object features
by cross-attending to queries from previous frames and other objects. The
""Future Reasoning"" module digests historical information and predicts robust
future trajectories. In the case of long-term occlusions, our method maintains
the object positions and enables re-association by integrating motion
predictions. On the nuScenes dataset, our method improves AMOTA by a large
margin and remarkably reduces ID-Switches by 90% compared to prior approaches,
which is an order of magnitude less. The code and models are made available at
https://github.com/TRI-ML/PF-Track."
Language Models as Knowledge Embeddings,0.733918,"Knowledge embeddings (KE) represent a knowledge graph (KG) by embedding
entities and relations into continuous vector spaces. Existing methods are
mainly structure-based or description-based. Structure-based methods learn
representations that preserve the inherent structure of KGs. They cannot well
represent abundant long-tail entities in real-world KGs with limited structural
information. Description-based methods leverage textual information and
language models. Prior approaches in this direction barely outperform
structure-based ones, and suffer from problems like expensive negative sampling
and restrictive description demand. In this paper, we propose LMKE, which
adopts Language Models to derive Knowledge Embeddings, aiming at both enriching
representations of long-tail entities and solving problems of prior
description-based methods. We formulate description-based KE learning with a
contrastive learning framework to improve efficiency in training and
evaluation. Experimental results show that LMKE achieves state-of-the-art
performance on KE benchmarks of link prediction and triple classification,
especially for long-tail entities."
Great Truths are Always Simple: A Rather Simple Knowledge Encoder for Enhancing the Commonsense Reasoning Capacity of Pre-Trained Models,0.249401,"Commonsense reasoning in natural language is a desired ability of artificial
intelligent systems. For solving complex commonsense reasoning tasks, a typical
solution is to enhance pre-trained language models~(PTMs) with a
knowledge-aware graph neural network~(GNN) encoder that models a commonsense
knowledge graph~(CSKG). Despite the effectiveness, these approaches are built
on heavy architectures, and can't clearly explain how external knowledge
resources improve the reasoning capacity of PTMs. Considering this issue, we
conduct a deep empirical analysis, and find that it is indeed relation features
from CSKGs (but not node features) that mainly contribute to the performance
improvement of PTMs. Based on this finding, we design a simple MLP-based
knowledge encoder that utilizes statistical relation paths as features.
Extensive experiments conducted on five benchmarks demonstrate the
effectiveness of our approach, which also largely reduces the parameters for
encoding CSKGs. Our codes and data are publicly available at
https://github.com/RUCAIBox/SAFE."
Adaptive Patch Exiting for Scalable Single Image Super-Resolution,0.593988,"Since the future of computing is heterogeneous, scalability is a crucial
problem for single image super-resolution. Recent works try to train one
network, which can be deployed on platforms with different capacities. However,
they rely on the pixel-wise sparse convolution, which is not hardware-friendly
and achieves limited practical speedup. As image can be divided into patches,
which have various restoration difficulties, we present a scalable method based
on Adaptive Patch Exiting (APE) to achieve more practical speedup.
Specifically, we propose to train a regressor to predict the incremental
capacity of each layer for the patch. Once the incremental capacity is below
the threshold, the patch can exit at the specific layer. Our method can easily
adjust the trade-off between performance and efficiency by changing the
threshold of incremental capacity. Furthermore, we propose a novel strategy to
enable the network training of our method. We conduct extensive experiments
across various backbones, datasets and scaling factors to demonstrate the
advantages of our method. Code is available at
https://github.com/littlepure2333/APE"
HCL: Improving Graph Representation with Hierarchical Contrastive Learning,0.0623505,"Contrastive learning has emerged as a powerful tool for graph representation
learning. However, most contrastive learning methods learn features of graphs
with fixed coarse-grained scale, which might underestimate either local or
global information. To capture more hierarchical and richer representation, we
propose a novel Hierarchical Contrastive Learning (HCL) framework that
explicitly learns graph representation in a hierarchical manner. Specifically,
HCL includes two key components: a novel adaptive Learning to Pool (L2Pool)
method to construct more reasonable multi-scale graph topology for more
comprehensive contrastive objective, a novel multi-channel pseudo-siamese
network to further enable more expressive learning of mutual information within
each scale. Comprehensive experimental results show HCL achieves competitive
performance on 12 datasets involving node classification, node clustering and
graph classification. In addition, the visualization of learned representation
reveals that HCL successfully captures meaningful characteristics of graphs."
Object Goal Navigation with Recursive Implicit Maps,0.790261,"Object goal navigation aims to navigate an agent to locations of a given
object category in unseen environments. Classical methods explicitly build maps
of environments and require extensive engineering while lacking semantic
information for object-oriented exploration. On the other hand, end-to-end
learning methods alleviate manual map design and predict actions using implicit
representations. Such methods, however, lack an explicit notion of geometry and
may have limited ability to encode navigation history. In this work, we propose
an implicit spatial map for object goal navigation. Our implicit map is
recursively updated with new observations at each step using a transformer. To
encourage spatial reasoning, we introduce auxiliary tasks and train our model
to reconstruct explicit maps as well as to predict visual features, semantic
labels and actions. Our method significantly outperforms the state of the art
on the challenging MP3D dataset and generalizes well to the HM3D dataset. We
successfully deploy our model on a real robot and achieve encouraging object
goal navigation results in real scenes using only a few real-world
demonstrations. Code, trained models and videos are available at
\url{https://www.di.ens.fr/willow/research/onav_rim/}."
Can Transformer be Too Compositional? Analysing Idiom Processing in Neural Machine Translation,0.642972,"Unlike literal expressions, idioms' meanings do not directly follow from
their parts, posing a challenge for neural machine translation (NMT). NMT
models are often unable to translate idioms accurately and over-generate
compositional, literal translations. In this work, we investigate whether the
non-compositionality of idioms is reflected in the mechanics of the dominant
NMT model, Transformer, by analysing the hidden states and attention patterns
for models with English as source language and one of seven European languages
as target language. When Transformer emits a non-literal translation - i.e.
identifies the expression as idiomatic - the encoder processes idioms more
strongly as single lexical units compared to literal expressions. This
manifests in idioms' parts being grouped through attention and in reduced
interaction between idioms and their context. In the decoder's cross-attention,
figurative inputs result in reduced attention on source-side tokens. These
results suggest that Transformer's tendency to process idioms as compositional
expressions contributes to literal translations of idioms."
PoseDiffusion: Solving Pose Estimation via Diffusion-aided Bundle Adjustment,0.986745,"Camera pose estimation is a long-standing computer vision problem that to
date often relies on classical methods, such as handcrafted keypoint matching,
RANSAC and bundle adjustment. In this paper, we propose to formulate the
Structure from Motion (SfM) problem inside a probabilistic diffusion framework,
modelling the conditional distribution of camera poses given input images. This
novel view of an old problem has several advantages. (i) The nature of the
diffusion framework mirrors the iterative procedure of bundle adjustment. (ii)
The formulation allows a seamless integration of geometric constraints from
epipolar geometry. (iii) It excels in typically difficult scenarios such as
sparse views with wide baselines. (iv) The method can predict intrinsics and
extrinsics for an arbitrary amount of images. We demonstrate that our method
PoseDiffusion significantly improves over the classic SfM pipelines and the
learned approaches on two real-world datasets. Finally, it is observed that our
method can generalize across datasets without further training. Project page:
https://posediffusion.github.io/"
Beyond Surface Statistics: Scene Representations in a Latent Diffusion Model,0.321628,"Latent diffusion models (LDMs) exhibit an impressive ability to produce
realistic images, yet the inner workings of these models remain mysterious.
Even when trained purely on images without explicit depth information, they
typically output coherent pictures of 3D scenes. In this work, we investigate a
basic interpretability question: does an LDM create and use an internal
representation of simple scene geometry? Using linear probes, we find evidence
that the internal activations of the LDM encode linear representations of both
3D depth data and a salient-object / background distinction. These
representations appear surprisingly early in the denoising process$-$well
before a human can easily make sense of the noisy images. Intervention
experiments further indicate these representations play a causal role in image
synthesis, and may be used for simple high-level editing of an LDM's output.
Project page: https://yc015.github.io/scene-representation-diffusion-model/"
Rethinking Document-Level Relation Extraction: A Reality Check,0.909479,"Recently, numerous efforts have continued to push up performance boundaries
of document-level relation extraction (DocRE) and have claimed significant
progress in DocRE. In this paper, we do not aim at proposing a novel model for
DocRE. Instead, we take a closer look at the field to see if these performance
gains are actually true. By taking a comprehensive literature review and a
thorough examination of popular DocRE datasets, we find that these performance
gains are achieved upon a strong or even untenable assumption in common: all
named entities are perfectly localized, normalized, and typed in advance. Next,
we construct four types of entity mention attacks to examine the robustness of
typical DocRE models by behavioral probing. We also have a close check on model
usability in a more realistic setting. Our findings reveal that most of current
DocRE models are vulnerable to entity mention attacks and difficult to be
deployed in real-world end-user NLP applications. Our study calls more
attentions for future research to stop simplifying problem setups, and to model
DocRE in the wild rather than in an unrealistic Utopian world."
Surface Defect Detection and Evaluation for Marine Vessels using Multi-Stage Deep Learning,0.208573,"Detecting and evaluating surface coating defects is important for marine
vessel maintenance. Currently, the assessment is carried out manually by
qualified inspectors using international standards and their own experience.
Automating the processes is highly challenging because of the high level of
variation in vessel type, paint surface, coatings, lighting condition, weather
condition, paint colors, areas of the vessel, and time in service. We present a
novel deep learning-based pipeline to detect and evaluate the percentage of
corrosion, fouling, and delamination on the vessel surface from normal
photographs. We propose a multi-stage image processing framework, including
ship section segmentation, defect segmentation, and defect classification, to
automatically recognize different types of defects and measure the coverage
percentage on the ship surface. Experimental results demonstrate that our
proposed pipeline can objectively perform a similar assessment as a qualified
inspector."
BOME! Bilevel Optimization Made Easy: A Simple First-Order Approach,0.99964,"Bilevel optimization (BO) is useful for solving a variety of important
machine learning problems including but not limited to hyperparameter
optimization, meta-learning, continual learning, and reinforcement learning.
Conventional BO methods need to differentiate through the low-level
optimization process with implicit differentiation, which requires expensive
calculations related to the Hessian matrix. There has been a recent quest for
first-order methods for BO, but the methods proposed to date tend to be
complicated and impractical for large-scale deep learning applications. In this
work, we propose a simple first-order BO algorithm that depends only on
first-order gradient information, requires no implicit differentiation, and is
practical and efficient for large-scale non-convex functions in deep learning.
We provide non-asymptotic convergence analysis of the proposed method to
stationary points for non-convex objectives and present empirical results that
show its superior practical performance."
VM-NeRF: Tackling Sparsity in NeRF with View Morphing,0.107259,"NeRF aims to learn a continuous neural scene representation by using a finite
set of input images taken from various viewpoints. A well-known limitation of
NeRF methods is their reliance on data: the fewer the viewpoints, the higher
the likelihood of overfitting. This paper addresses this issue by introducing a
novel method to generate geometrically consistent image transitions between
viewpoints using View Morphing. Our VM-NeRF approach requires no prior
knowledge about the scene structure, as View Morphing is based on the
fundamental principles of projective geometry. VM-NeRF tightly integrates this
geometric view generation process during the training procedure of standard
NeRF approaches. Notably, our method significantly improves novel view
synthesis, particularly when only a few views are available. Experimental
evaluation reveals consistent improvement over current methods that handle
sparse viewpoints in NeRF models. We report an increase in PSNR of up to 1.8dB
and 1.0dB when training uses eight and four views, respectively. Source code:
\url{https://github.com/mbortolon97/VM-NeRF}"
Inside Out: Transforming Images of Lab-Grown Plants for Machine Learning Applications in Agriculture,0.127969,"Machine learning tasks often require a significant amount of training data
for the resultant network to perform suitably for a given problem in any
domain. In agriculture, dataset sizes are further limited by phenotypical
differences between two plants of the same genotype, often as a result of
differing growing conditions. Synthetically-augmented datasets have shown
promise in improving existing models when real data is not available. In this
paper, we employ a contrastive unpaired translation (CUT) generative
adversarial network (GAN) and simple image processing techniques to translate
indoor plant images to appear as field images. While we train our network to
translate an image containing only a single plant, we show that our method is
easily extendable to produce multiple-plant field images. Furthermore, we use
our synthetic multi-plant images to train several YoloV5 nano object detection
models to perform the task of plant detection and measure the accuracy of the
model on real field data images. Including training data generated by the
CUT-GAN leads to better plant detection performance compared to a network
trained solely on real data."
"Transcending the ""Male Code"": Implicit Masculine Biases in NLP Contexts",0.523526,"Critical scholarship has elevated the problem of gender bias in data sets
used to train virtual assistants (VAs). Most work has focused on explicit
biases in language, especially against women, girls, femme-identifying people,
and genderqueer folk; implicit associations through word embeddings; and
limited models of gender and masculinities, especially toxic masculinities,
conflation of sex and gender, and a sex/gender binary framing of the masculine
as diametric to the feminine. Yet, we must also interrogate how masculinities
are ""coded"" into language and the assumption of ""male"" as the linguistic
default: implicit masculine biases. To this end, we examined two natural
language processing (NLP) data sets. We found that when gendered language was
present, so were gender biases and especially masculine biases. Moreover, these
biases related in nuanced ways to the NLP context. We offer a new dictionary
called AVA that covers ambiguous associations between gendered language and the
language of VAs."
Bayesian Optimization Meets Hybrid Zero Dynamics: Safe Parameter Learning for Bipedal Locomotion Control,0.733327,"In this paper, we propose a multi-domain control parameter learning framework
that combines Bayesian Optimization (BO) and Hybrid Zero Dynamics (HZD) for
locomotion control of bipedal robots. We leverage BO to learn the control
parameters used in the HZD-based controller. The learning process is firstly
deployed in simulation to optimize different control parameters for a large
repertoire of gaits. Next, to tackle the discrepancy between the simulation and
the real world, the learning process is applied on the physical robot to learn
for corrections to the control parameters learned in simulation while also
respecting a safety constraint for gait stability. This method empowers an
efficient sim-to-real transition with a small number of samples in the real
world, and does not require a valid controller to initialize the training in
simulation. Our proposed learning framework is experimentally deployed and
validated on a bipedal robot Cassie to perform versatile locomotion skills with
improved performance on smoothness of walking gaits and reduction of
steady-state tracking errors."
Almanac: Retrieval-Augmented Language Models for Clinical Medicine,0.994767,"Large-language models have recently demonstrated impressive zero-shot
capabilities in a variety of natural language tasks such as summarization,
dialogue generation, and question-answering. Despite many promising
applications in clinical medicine, adoption of these models in real-world
settings has been largely limited by their tendency to generate incorrect and
sometimes even toxic statements. In this study, we develop Almanac, a large
language model framework augmented with retrieval capabilities for medical
guideline and treatment recommendations. Performance on a novel dataset of
clinical scenarios (n = 130) evaluated by a panel of 5 board-certified and
resident physicians demonstrates significant increases in factuality (mean of
18% at p-value < 0.05) across all specialties, with improvements in
completeness and safety. Our results demonstrate the potential for large
language models to be effective tools in the clinical decision-making process,
while also emphasizing the importance of careful testing and deployment to
mitigate their shortcomings."
Visualizing Skiers' Trajectories in Monocular Videos,0.0864937,"Trajectories are fundamental to winning in alpine skiing. Tools enabling the
analysis of such curves can enhance the training activity and enrich
broadcasting content. In this paper, we propose SkiTraVis, an algorithm to
visualize the sequence of points traversed by a skier during its performance.
SkiTraVis works on monocular videos and constitutes a pipeline of a visual
tracker to model the skier's motion and of a frame correspondence module to
estimate the camera's motion. The separation of the two motions enables the
visualization of the trajectory according to the moving camera's perspective.
We performed experiments on videos of real-world professional competitions to
quantify the visualization error, the computational efficiency, as well as the
applicability. Overall, the results achieved demonstrate the potential of our
solution for broadcasting media enhancement and coach assistance."
Terminology-aware Medical Dialogue Generation,0.53363,"Medical dialogue generation aims to generate responses according to a history
of dialogue turns between doctors and patients. Unlike open-domain dialogue
generation, this requires background knowledge specific to the medical domain.
Existing generative frameworks for medical dialogue generation fall short of
incorporating domain-specific knowledge, especially with regard to medical
terminology. In this paper, we propose a novel framework to improve medical
dialogue generation by considering features centered on domain-specific
terminology. We leverage an attention mechanism to incorporate terminologically
centred features, and fill in the semantic gap between medical background
knowledge and common utterances by enforcing language models to learn
terminology representations with an auxiliary terminology recognition task.
Experimental results demonstrate the effectiveness of our approach, in which
our proposed framework outperforms SOTA language models. Additionally, we
provide a new dataset with medical terminology annotations to support the
research on medical dialogue generation. Our dataset and code are available at
https://github.com/tangg555/meddialog."
International Governance of Civilian AI: A Jurisdictional Certification Approach,0.939734,"This report describes trade-offs in the design of international governance
arrangements for civilian artificial intelligence (AI) and presents one
approach in detail. This approach represents the extension of a standards,
licensing, and liability regime to the global level. We propose that states
establish an International AI Organization (IAIO) to certify state
jurisdictions (not firms or AI projects) for compliance with international
oversight standards. States can give force to these international standards by
adopting regulations prohibiting the import of goods whose supply chains embody
AI from non-IAIO-certified jurisdictions. This borrows attributes from models
of existing international organizations, such as the International Civilian
Aviation Organization (ICAO), the International Maritime Organization (IMO),
and the Financial Action Task Force (FATF). States can also adopt multilateral
controls on the export of AI product inputs, such as specialized hardware, to
non-certified jurisdictions. Indeed, both the import and export standards could
be required for certification. As international actors reach consensus on risks
of and minimum standards for advanced AI, a jurisdictional certification regime
could mitigate a broad range of potential harms, including threats to public
safety."
Reasoning about Human-Friendly Strategies in Repeated Keyword Auctions,0.904236,"In online advertising, search engines sell ad placements for keywords
continuously through auctions. This problem can be seen as an infinitely
repeated game since the auction is executed whenever a user performs a query
with the keyword. As advertisers may frequently change their bids, the game
will have a large set of equilibria with potentially complex strategies. In
this paper, we propose the use of natural strategies for reasoning in such
setting as they are processable by artificial agents with limited memory and/or
computational power as well as understandable by human users. To reach this
goal, we introduce a quantitative version of Strategy Logic with natural
strategies in the setting of imperfect information. In a first step, we show
how to model strategies for repeated keyword auctions and take advantage of the
model for proving properties evaluating this game. In a second step, we study
the logic in relation to the distinguishing power, expressivity, and
model-checking complexity for strategies with and without recall."
Face Swapping as A Simple Arithmetic Operation,0.240948,"We propose a novel high-fidelity face swapping method called ""Arithmetic Face
Swapping"" (AFS) that explicitly disentangles the intermediate latent space W+
of a pretrained StyleGAN into the ""identity"" and ""style"" subspaces so that a
latent code in W+ is the sum of an ""identity"" code and a ""style"" code in the
corresponding subspaces. Via our disentanglement, face swapping (FS) can be
regarded as a simple arithmetic operation in W+, i.e., the summation of a
source ""identity"" code and a target ""style"" code. This makes AFS more intuitive
and elegant than other FS methods. In addition, our method can generalize over
the standard face swapping to support other interesting operations, e.g.,
combining the identity of one source with styles of multiple targets and vice
versa. We implement our identity-style disentanglement by learning a neural
network that maps a latent code to a ""style"" code. We provide a condition for
this network which theoretically guarantees identity preservation of the source
face even after a sequence of face swapping operations. Extensive experiments
demonstrate the advantage of our method over state-of-the-art FS methods in
producing high-quality swapped faces. Our source code was made public at
https://github.com/truongvu2000nd/AFS"
"Self-Supervision, Remote Sensing and Abstraction: Representation Learning Across 3 Million Locations",0.0885656,"Self-supervision based deep learning classification approaches have received
considerable attention in academic literature. However, the performance of such
methods on remote sensing imagery domains remains under-explored. In this work,
we explore contrastive representation learning methods on the task of
imagery-based city classification, an important problem in urban computing. We
use satellite and map imagery across 2 domains, 3 million locations and more
than 1500 cities. We show that self-supervised methods can build a
generalizable representation from as few as 200 cities, with representations
achieving over 95\% accuracy in unseen cities with minimal additional training.
We also find that the performance discrepancy of such methods, when compared to
supervised methods, induced by the domain discrepancy between natural imagery
and abstract imagery is significant for remote sensing imagery. We compare all
analysis against existing supervised models from academic literature and
open-source our models for broader usage and further criticism."
Parameter-Efficient Neural Reranking for Cross-Lingual and Multilingual Retrieval,0.301088,"State-of-the-art neural (re)rankers are notoriously data-hungry which --
given the lack of large-scale training data in languages other than English --
makes them rarely used in multilingual and cross-lingual retrieval settings.
Current approaches therefore commonly transfer rankers trained on English data
to other languages and cross-lingual setups by means of multilingual encoders:
they fine-tune all parameters of pretrained massively multilingual Transformers
(MMTs, e.g., multilingual BERT) on English relevance judgments, and then deploy
them in the target language(s). In this work, we show that two
parameter-efficient approaches to cross-lingual transfer, namely Sparse
Fine-Tuning Masks (SFTMs) and Adapters, allow for a more lightweight and more
effective zero-shot transfer to multilingual and cross-lingual retrieval tasks.
We first train language adapters (or SFTMs) via Masked Language Modelling and
then train retrieval (i.e., reranking) adapters (SFTMs) on top, while keeping
all other parameters fixed. At inference, this modular design allows us to
compose the ranker by applying the (re)ranking adapter (or SFTM) trained with
source language data together with the language adapter (or SFTM) of a target
language. We carry out a large scale evaluation on the CLEF-2003 and HC4
benchmarks and additionally, as another contribution, extend the former with
queries in three new languages: Kyrgyz, Uyghur and Turkish. The proposed
parameter-efficient methods outperform standard zero-shot transfer with full
MMT fine-tuning, while being more modular and reducing training times. The
gains are particularly pronounced for low-resource languages, where our
approaches also substantially outperform the competitive machine
translation-based rankers."
BERT Rankers are Brittle: a Study using Adversarial Document Perturbations,0.806154,"Contextual ranking models based on BERT are now well established for a wide
range of passage and document ranking tasks. However, the robustness of
BERT-based ranking models under adversarial inputs is under-explored. In this
paper, we argue that BERT-rankers are not immune to adversarial attacks
targeting retrieved documents given a query. Firstly, we propose algorithms for
adversarial perturbation of both highly relevant and non-relevant documents
using gradient-based optimization methods. The aim of our algorithms is to
add/replace a small number of tokens to a highly relevant or non-relevant
document to cause a large rank demotion or promotion. Our experiments show that
a small number of tokens can already result in a large change in the rank of a
document. Moreover, we find that BERT-rankers heavily rely on the document
start/head for relevance prediction, making the initial part of the document
more susceptible to adversarial attacks. More interestingly, we find a small
set of recurring adversarial words that when added to documents result in
successful rank demotion/promotion of any relevant/non-relevant document
respectively. Finally, our adversarial tokens also show particular topic
preferences within and across datasets, exposing potential biases from BERT
pre-training or downstream datasets."
Disentangling Uncertainty in Machine Translation Evaluation,0.445006,"Trainable evaluation metrics for machine translation (MT) exhibit strong
correlation with human judgements, but they are often hard to interpret and
might produce unreliable scores under noisy or out-of-domain data. Recent work
has attempted to mitigate this with simple uncertainty quantification
techniques (Monte Carlo dropout and deep ensembles), however these techniques
(as we show) are limited in several ways -- for example, they are unable to
distinguish between different kinds of uncertainty, and they are time and
memory consuming. In this paper, we propose more powerful and efficient
uncertainty predictors for MT evaluation, and we assess their ability to target
different sources of aleatoric and epistemic uncertainty. To this end, we
develop and compare training objectives for the COMET metric to enhance it with
an uncertainty prediction output, including heteroscedastic regression,
divergence minimization, and direct uncertainty prediction. Our experiments
show improved results on uncertainty prediction for the WMT metrics task
datasets, with a substantial reduction in computational costs. Moreover, they
demonstrate the ability of these predictors to address specific uncertainty
causes in MT evaluation, such as low quality references and out-of-domain data."
Towards Domain Generalization in Object Detection,0.657918,"Despite the striking performance achieved by modern detectors when training
and test data are sampled from the same or similar distribution, the
generalization ability of detectors under unknown distribution shifts remains
hardly studied. Recently several works discussed the detectors' adaptation
ability to a specific target domain which are not readily applicable in
real-world applications since detectors may encounter various environments or
situations while pre-collecting all of them before training is inconceivable.
In this paper, we study the critical problem, domain generalization in object
detection (DGOD), where detectors are trained with source domains and evaluated
on unknown target domains. To thoroughly evaluate detectors under unknown
distribution shifts, we formulate the DGOD problem and propose a comprehensive
evaluation benchmark to fill the vacancy. Moreover, we propose a novel method
named Region Aware Proposal reweighTing (RAPT) to eliminate dependence within
RoI features. Extensive experiments demonstrate that current DG methods fail to
address the DGOD problem and our method outperforms other state-of-the-art
counterparts."
DeepMapping2: Self-Supervised Large-Scale LiDAR Map Optimization,0.525208,"LiDAR mapping is important yet challenging in self-driving and mobile
robotics. To tackle such a global point cloud registration problem, DeepMapping
converts the complex map estimation into a self-supervised training of simple
deep networks. Despite its broad convergence range on small datasets,
DeepMapping still cannot produce satisfactory results on large-scale datasets
with thousands of frames. This is due to the lack of loop closures and exact
cross-frame point correspondences, and the slow convergence of its global
localization network. We propose DeepMapping2 by adding two novel techniques to
address these issues: (1) organization of training batch based on map topology
from loop closing, and (2) self-supervised local-to-global point consistency
loss leveraging pairwise registration. Our experiments and ablation studies on
public datasets (KITTI, NCLT, and Nebula) demonstrate the effectiveness of our
method."
Meta-Learning a Cross-lingual Manifold for Semantic Parsing,0.710179,"Localizing a semantic parser to support new languages requires effective
cross-lingual generalization. Recent work has found success with
machine-translation or zero-shot methods although these approaches can struggle
to model how native speakers ask questions. We consider how to effectively
leverage minimal annotated examples in new languages for few-shot cross-lingual
semantic parsing. We introduce a first-order meta-learning algorithm to train a
semantic parser with maximal sample efficiency during cross-lingual transfer.
Our algorithm uses high-resource languages to train the parser and
simultaneously optimizes for cross-lingual generalization for lower-resource
languages. Results across six languages on ATIS demonstrate that our
combination of generalization steps yields accurate semantic parsers sampling
$\le$10% of source training data in each new language. Our approach also trains
a competitive model on Spider using English with generalization to Chinese
similarly sampling $\le$10% of training data."
Towards Learning Rubik's Cube with N-tuple-based Reinforcement Learning,0.497613,"This work describes in detail how to learn and solve the Rubik's cube game
(or puzzle) in the General Board Game (GBG) learning and playing framework. We
cover the cube sizes 2x2x2 and 3x3x3. We describe in detail the cube's state
representation, how to transform it with twists, whole-cube rotations and color
transformations and explain the use of symmetries in Rubik's cube. Next, we
discuss different n-tuple representations for the cube, how we train the agents
by reinforcement learning and how we improve the trained agents during
evaluation by MCTS wrapping. We present results for agents that learn Rubik's
cube from scratch, with and without MCTS wrapping, with and without symmetries
and show that both, MCTS wrapping and symmetries, increase computational costs,
but lead at the same time to much better results. We can solve the 2x2x2 cube
completely, and the 3x3x3 cube in the majority of the cases for scrambled cubes
up to p = 15 (QTM). We cannot yet reliably solve 3x3x3 cubes with more than 15
scrambling twists. Although our computational costs are higher with MCTS
wrapping and with symmetries than without, they are still considerably lower
than in the approaches of McAleer et al. (2018, 2019) and Agostinelli et al.
(2019) who provide the best Rubik's cube learning agents so far."
nBIIG: A Neural BI Insights Generation System for Table Reporting,0.179167,"We present nBIIG, a neural Business Intelligence (BI) Insights Generation
system. Given a table, our system applies various analyses to create
corresponding RDF representations, and then uses a neural model to generate
fluent textual insights out of these representations. The generated insights
can be used by an analyst, via a human-in-the-loop paradigm, to enhance the
task of creating compelling table reports. The underlying generative neural
model is trained over large and carefully distilled data, curated from multiple
BI domains. Thus, the system can generate faithful and fluent insights over
open-domain tables, making it practical and useful."
On the Transformation of Latent Space in Fine-Tuned NLP Models,0.518613,"We study the evolution of latent space in fine-tuned NLP models. Different
from the commonly used probing-framework, we opt for an unsupervised method to
analyze representations. More specifically, we discover latent concepts in the
representational space using hierarchical clustering. We then use an alignment
function to gauge the similarity between the latent space of a pre-trained
model and its fine-tuned version. We use traditional linguistic concepts to
facilitate our understanding and also study how the model space transforms
towards task-specific information. We perform a thorough analysis, comparing
pre-trained and fine-tuned models across three models and three downstream
tasks. The notable findings of our work are: i) the latent space of the higher
layers evolve towards task-specific concepts, ii) whereas the lower layers
retain generic concepts acquired in the pre-trained model, iii) we discovered
that some concepts in the higher layers acquire polarity towards the output
class, and iv) that these concepts can be used for generating adversarial
triggers."
LatentGaze: Cross-Domain Gaze Estimation through Gaze-Aware Analytic Latent Code Manipulation,0.672203,"Although recent gaze estimation methods lay great emphasis on attentively
extracting gaze-relevant features from facial or eye images, how to define
features that include gaze-relevant components has been ambiguous. This
obscurity makes the model learn not only gaze-relevant features but also
irrelevant ones. In particular, it is fatal for the cross-dataset performance.
To overcome this challenging issue, we propose a gaze-aware analytic
manipulation method, based on a data-driven approach with generative
adversarial network inversion's disentanglement characteristics, to selectively
utilize gaze-relevant features in a latent code. Furthermore, by utilizing
GAN-based encoder-generator process, we shift the input image from the target
domain to the source domain image, which a gaze estimator is sufficiently
aware. In addition, we propose gaze distortion loss in the encoder that
prevents the distortion of gaze information. The experimental results
demonstrate that our method achieves state-of-the-art gaze estimation accuracy
in a cross-domain gaze estimation tasks. This code is available at
https://github.com/leeisack/LatentGaze/."
How Generalizable are Deepfake Detectors? An Empirical Study,0.113636,"Deepfake videos and images are becoming increasingly credible, posing a
significant threat given their potential to facilitate fraud or bypass access
control systems. This has motivated the development of deepfake detection
methods, in which deep learning models are trained to distinguish between real
and synthesized footage. Unfortunately, existing detection models struggle to
generalize to deepfakes from datasets they were not trained on, but little work
has been done to examine why or how this limitation can be addressed. In this
paper, we present the first empirical study on the generalizability of deepfake
detectors, an essential goal for detectors to stay one step ahead of attackers.
Our study utilizes six deepfake datasets, five deepfake detection methods, and
two model augmentation approaches, confirming that detectors do not generalize
in zero-shot settings. Additionally, we find that detectors are learning
unwanted properties specific to synthesis methods and struggling to extract
discriminative features, limiting their ability to generalize. Finally, we find
that there are neurons universally contributing to detection across seen and
unseen datasets, illuminating a possible path forward to zero-shot
generalizability."
Learning Degradation Representations for Image Deblurring,0.533757,"In various learning-based image restoration tasks, such as image denoising
and image super-resolution, the degradation representations were widely used to
model the degradation process and handle complicated degradation patterns.
However, they are less explored in learning-based image deblurring as blur
kernel estimation cannot perform well in real-world challenging cases. We argue
that it is particularly necessary for image deblurring to model degradation
representations since blurry patterns typically show much larger variations
than noisy patterns or high-frequency textures.In this paper, we propose a
framework to learn spatially adaptive degradation representations of blurry
images. A novel joint image reblurring and deblurring learning process is
presented to improve the expressiveness of degradation representations. To make
learned degradation representations effective in reblurring and deblurring, we
propose a Multi-Scale Degradation Injection Network (MSDI-Net) to integrate
them into the neural networks. With the integration, MSDI-Net can handle
various and complicated blurry patterns adaptively. Experiments on the GoPro
and RealBlur datasets demonstrate that our proposed deblurring framework with
the learned degradation representations outperforms state-of-the-art methods
with appealing improvements. The code is released at
https://github.com/dasongli1/Learning_degradation."
Leveraging Large Language Models to Generate Answer Set Programs,0.388971,"Large language models (LLMs), such as GPT-3 and GPT-4, have demonstrated
exceptional performance in various natural language processing tasks and have
shown the ability to solve certain reasoning problems. However, their reasoning
capabilities are limited and relatively shallow, despite the application of
various prompting techniques. In contrast, formal logic is adept at handling
complex reasoning, but translating natural language descriptions into formal
logic is a challenging task that non-experts struggle with. This paper proposes
a neuro-symbolic method that combines the strengths of large language models
and answer set programming. Specifically, we employ an LLM to transform natural
language descriptions of logic puzzles into answer set programs. We carefully
design prompts for an LLM to convert natural language descriptions into answer
set programs in a step by step manner. Surprisingly, with just a few in-context
learning examples, LLMs can generate reasonably complex answer set programs.
The majority of errors made are relatively simple and can be easily corrected
by humans, thus enabling LLMs to effectively assist in the creation of answer
set programs."
GLEN: General-Purpose Event Detection for Thousands of Types,0.772151,"The progress of event extraction research has been hindered by the absence of
wide-coverage, large-scale datasets. To make event extraction systems more
accessible, we build a general-purpose event detection dataset GLEN, which
covers 205K event mentions with 3,465 different types, making it more than 20x
larger in ontology than today's largest event dataset. GLEN is created by
utilizing the DWD Overlay, which provides a mapping between Wikidata Qnodes and
PropBank rolesets. This enables us to use the abundant existing annotation for
PropBank as distant supervision. In addition, we also propose a new multi-stage
event detection model CEDAR specifically designed to handle the large ontology
size in GLEN. We show that our model exhibits superior performance compared to
a range of baselines including InstructGPT. Finally, we perform error analysis
and show that label noise is still the largest challenge for improving
performance for this new dataset. Our dataset, code, and models are released at
\url{https://github.com/ZQS1943/GLEN}.}"
Building an ASR Error Robust Spoken Virtual Patient System in a Highly Class-Imbalanced Scenario Without Speech Data,0.0442757,"A Virtual Patient (VP) is a powerful tool for training medical students to
take patient histories, where responding to a diverse set of spoken questions
is essential to simulate natural conversations with a student. The performance
of such a Spoken Language Understanding system (SLU) can be adversely affected
by both the presence of Automatic Speech Recognition (ASR) errors in the test
data and a high degree of class imbalance in the SLU training data. While these
two issues have been addressed separately in prior work, we develop a novel
two-step training methodology that tackles both these issues effectively in a
single dialog agent. As it is difficult to collect spoken data from users
without a functioning SLU system, our method does not rely on spoken data for
training, rather we use an ASR error predictor to ""speechify"" the text data.
Our method shows significant improvements over strong baselines on the VP
intent classification task at various word error rate settings."
NR-DFERNet: Noise-Robust Network for Dynamic Facial Expression Recognition,0.958367,"Dynamic facial expression recognition (DFER) in the wild is an extremely
challenging task, due to a large number of noisy frames in the video sequences.
Previous works focus on extracting more discriminative features, but ignore
distinguishing the key frames from the noisy frames. To tackle this problem, we
propose a noise-robust dynamic facial expression recognition network
(NR-DFERNet), which can effectively reduce the interference of noisy frames on
the DFER task. Specifically, at the spatial stage, we devise a dynamic-static
fusion module (DSF) that introduces dynamic features to static features for
learning more discriminative spatial features. To suppress the impact of target
irrelevant frames, we introduce a novel dynamic class token (DCT) for the
transformer at the temporal stage. Moreover, we design a snippet-based filter
(SF) at the decision stage to reduce the effect of too many neutral frames on
non-neutral sequence classification. Extensive experimental results demonstrate
that our NR-DFERNet outperforms the state-of-the-art methods on both the DFEW
and AFEW benchmarks."
polyBERT: A chemical language model to enable fully machine-driven ultrafast polymer informatics,0.979912,"Polymers are a vital part of everyday life. Their chemical universe is so
large that it presents unprecedented opportunities as well as significant
challenges to identify suitable application-specific candidates. We present a
complete end-to-end machine-driven polymer informatics pipeline that can search
this space for suitable candidates at unprecedented speed and accuracy. This
pipeline includes a polymer chemical fingerprinting capability called polyBERT
(inspired by Natural Language Processing concepts), and a multitask learning
approach that maps the polyBERT fingerprints to a host of properties. polyBERT
is a chemical linguist that treats the chemical structure of polymers as a
chemical language. The present approach outstrips the best presently available
concepts for polymer property prediction based on handcrafted fingerprint
schemes in speed by two orders of magnitude while preserving accuracy, thus
making it a strong candidate for deployment in scalable architectures including
cloud infrastructures."
FurryGAN: High Quality Foreground-aware Image Synthesis,0.326419,"Foreground-aware image synthesis aims to generate images as well as their
foreground masks. A common approach is to formulate an image as an masked
blending of a foreground image and a background image. It is a challenging
problem because it is prone to reach the trivial solution where either image
overwhelms the other, i.e., the masks become completely full or empty, and the
foreground and background are not meaningfully separated. We present FurryGAN
with three key components: 1) imposing both the foreground image and the
composite image to be realistic, 2) designing a mask as a combination of coarse
and fine masks, and 3) guiding the generator by an auxiliary mask predictor in
the discriminator. Our method produces realistic images with remarkably
detailed alpha masks which cover hair, fur, and whiskers in a fully
unsupervised manner."
Evaluation of African American Language Bias in Natural Language Generation,0.323077,"We evaluate how well LLMs understand African American Language (AAL) in
comparison to their performance on White Mainstream English (WME), the
encouraged ""standard"" form of English taught in American classrooms. We measure
LLM performance using automatic metrics and human judgments for two tasks: a
counterpart generation task, where a model generates AAL (or WME) given WME (or
AAL), and a masked span prediction (MSP) task, where models predict a phrase
that was removed from their input. Our contributions include: (1) evaluation of
six pre-trained, large language models on the two language generation tasks;
(2) a novel dataset of AAL text from multiple contexts (social media, hip-hop
lyrics, focus groups, and linguistic interviews) with human-annotated
counterparts in WME; and (3) documentation of model performance gaps that
suggest bias and identification of trends in lack of understanding of AAL
features."
Scalable and Effective Conductance-based Graph Clustering,0.250564,"Conductance-based graph clustering has been recognized as a fundamental
operator in numerous graph analysis applications. Despite the significant
success of conductance-based graph clustering, existing algorithms are either
hard to obtain satisfactory clustering qualities, or have high time and space
complexity to achieve provable clustering qualities. To overcome these
limitations, we devise a powerful \textit{peeling}-based graph clustering
framework \textit{PCon}. We show that many existing solutions can be reduced to
our framework. Namely, they first define a score function for each vertex, then
iteratively remove the vertex with the smallest score. Finally, they output the
result with the smallest conductance during the peeling process. Based on our
framework, we propose two novel algorithms \textit{PCon\_core} and
\emph{PCon\_de} with linear time and space complexity, which can efficiently
and effectively identify clusters from massive graphs with more than a few
billion edges. Surprisingly, we prove that \emph{PCon\_de} can identify
clusters with near-constant approximation ratio, resulting in an important
theoretical improvement over the well-known quadratic Cheeger bound. Empirical
results on real-life and synthetic datasets show that our algorithms can
achieve 5$\sim$42 times speedup with a high clustering accuracy, while using
1.4$\sim$7.8 times less memory than the baseline algorithms."
Emotion-guided Cross-domain Fake News Detection using Adversarial Domain Adaptation,0.196189,"Recent works on fake news detection have shown the efficacy of using emotions
as a feature or emotions-based features for improved performance. However, the
impact of these emotion-guided features for fake news detection in cross-domain
settings, where we face the problem of domain shift, is still largely
unexplored. In this work, we evaluate the impact of emotion-guided features for
cross-domain fake news detection, and further propose an emotion-guided,
domain-adaptive approach using adversarial learning. We prove the efficacy of
emotion-guided models in cross-domain settings for various combinations of
source and target datasets from FakeNewsAMT, Celeb, Politifact and Gossipcop
datasets."
Measuring Gender Bias in Word Embeddings of Gendered Languages Requires Disentangling Grammatical Gender Signals,0.225092,"Does the grammatical gender of a language interfere when measuring the
semantic gender information captured by its word embeddings? A number of
anomalous gender bias measurements in the embeddings of gendered languages
suggest this possibility. We demonstrate that word embeddings learn the
association between a noun and its grammatical gender in grammatically gendered
languages, which can skew social gender bias measurements. Consequently, word
embedding post-processing methods are introduced to quantify, disentangle, and
evaluate grammatical gender signals. The evaluation is performed on five
gendered languages from the Germanic, Romance, and Slavic branches of the
Indo-European language family. Our method reduces the strength of grammatical
gender signals, which is measured in terms of effect size (Cohen's d), by a
significant average of d = 1.3 for French, German, and Italian, and d = 0.56
for Polish and Spanish. Once grammatical gender is disentangled, the
association between over 90% of 10,000 inanimate nouns and their assigned
grammatical gender weakens, and cross-lingual bias results from the Word
Embedding Association Test (WEAT) become more congruent with country-level
implicit bias measurements. The results further suggest that disentangling
grammatical gender signals from word embeddings may lead to improvement in
semantic machine learning tasks."
Pretraining Chinese BERT for Detecting Word Insertion and Deletion Errors,0.119802,"Chinese BERT models achieve remarkable progress in dealing with grammatical
errors of word substitution. However, they fail to handle word insertion and
deletion because BERT assumes the existence of a word at each position. To
address this, we present a simple and effective Chinese pretrained model. The
basic idea is to enable the model to determine whether a word exists at a
particular position. We achieve this by introducing a special token
\texttt{[null]}, the prediction of which stands for the non-existence of a
word. In the training stage, we design pretraining tasks such that the model
learns to predict \texttt{[null]} and real words jointly given the surrounding
context. In the inference stage, the model readily detects whether a word
should be inserted or deleted with the standard masked language modeling
function. We further create an evaluation dataset to foster research on word
insertion and deletion. It includes human-annotated corrections for 7,726
erroneous sentences. Results show that existing Chinese BERT performs poorly on
detecting insertion and deletion errors. Our approach significantly improves
the F1 scores from 24.1\% to 78.1\% for word insertion and from 26.5\% to
68.5\% for word deletion, respectively."
CGELBank: CGEL as a Framework for English Syntax Annotation,0.0356544,"We introduce the syntactic formalism of the \textit{Cambridge Grammar of the
English Language} (CGEL) to the world of treebanking through the CGELBank
project. We discuss some issues in linguistic analysis that arose in adapting
the formalism to corpus annotation, followed by quantitative and qualitative
comparisons with parallel UD and PTB treebanks. We argue that CGEL provides a
good tradeoff between comprehensiveness of analysis and usability for
annotation, which motivates expanding the treebank with automatic conversion in
the future."
IDEA-Net: Dynamic 3D Point Cloud Interpolation via Deep Embedding Alignment,0.362645,"This paper investigates the problem of temporally interpolating dynamic 3D
point clouds with large non-rigid deformation. We formulate the problem as
estimation of point-wise trajectories (i.e., smooth curves) and further reason
that temporal irregularity and under-sampling are two major challenges. To
tackle the challenges, we propose IDEA-Net, an end-to-end deep learning
framework, which disentangles the problem under the assistance of the
explicitly learned temporal consistency. Specifically, we propose a temporal
consistency learning module to align two consecutive point cloud frames
point-wisely, based on which we can employ linear interpolation to obtain
coarse trajectories/in-between frames. To compensate the high-order nonlinear
components of trajectories, we apply aligned feature embeddings that encode
local geometry properties to regress point-wise increments, which are combined
with the coarse estimations. We demonstrate the effectiveness of our method on
various point cloud sequences and observe large improvement over
state-of-the-art methods both quantitatively and visually. Our framework can
bring benefits to 3D motion data acquisition. The source code is publicly
available at https://github.com/ZENGYIMING-EAMON/IDEA-Net.git."
Game-theoretic Objective Space Planning,0.506061,"Generating competitive strategies and performing continuous motion planning
simultaneously in an adversarial setting is a challenging problem. In addition,
understanding the intent of other agents is crucial to deploying autonomous
systems in adversarial multi-agent environments. Existing approaches either
discretize agent action by grouping similar control inputs, sacrificing
performance in motion planning, or plan in uninterpretable latent spaces,
producing hard-to-understand agent behaviors. Furthermore, the most popular
policy optimization frameworks do not recognize the long-term effect of actions
and become myopic. This paper proposes an agent action discretization method
via abstraction that provides clear intentions of agent actions, an efficient
offline pipeline of agent population synthesis, and a planning strategy using
counterfactual regret minimization with function approximation. Finally, we
experimentally validate our findings on scaled autonomous vehicles in a
head-to-head racing setting. We demonstrate that using the proposed framework
significantly improves learning, improves the win rate against different
opponents, and the improvements can be transferred to unseen opponents in an
unseen environment."
Empowering Next POI Recommendation with Multi-Relational Modeling,0.726841,"With the wide adoption of mobile devices and web applications, location-based
social networks (LBSNs) offer large-scale individual-level location-related
activities and experiences. Next point-of-interest (POI) recommendation is one
of the most important tasks in LBSNs, aiming to make personalized
recommendations of next suitable locations to users by discovering preferences
from users' historical activities. Noticeably, LBSNs have offered unparalleled
access to abundant heterogeneous relational information about users and POIs
(including user-user social relations, such as families or colleagues; and
user-POI visiting relations). Such relational information holds great potential
to facilitate the next POI recommendation. However, most existing methods
either focus on merely the user-POI visits, or handle different relations based
on over-simplified assumptions while neglecting relational heterogeneities. To
fill these critical voids, we propose a novel framework, MEMO, which
effectively utilizes the heterogeneous relations with a multi-network
representation learning module, and explicitly incorporates the inter-temporal
user-POI mutual influence with the coupled recurrent neural networks. Extensive
experiments on real-world LBSN data validate the superiority of our framework
over the state-of-the-art next POI recommendation methods."
Disentangling the Computational Complexity of Network Untangling,0.379513,"We study the network untangling problem introduced by Rozenshtein, Tatti, and
Gionis [DMKD 2021], which is a variant of Vertex Cover on temporal graphs --
graphs whose edge set changes over discrete time steps. They introduce two
problem variants. The goal is to select at most $k$ time intervals for each
vertex such that all time-edges are covered and (depending on the problem
variant) either the maximum interval length or the total sum of interval
lengths is minimized. This problem has data mining applications in finding
activity timelines that explain the interactions of entities in complex
networks.
  Both variants of the problem are NP-hard. In this paper, we initiate a
multivariate complexity analysis involving the following parameters: number of
vertices, lifetime of the temporal graph, number of intervals per vertex, and
the interval length bound. For both problem versions, we (almost) completely
settle the parameterized complexity for all combinations of those four
parameters, thereby delineating the border of fixed-parameter tractability."
Unifying Data Perspectivism and Personalization: An Application to Social Norms,0.35496,"Instead of using a single ground truth for language processing tasks, several
recent studies have examined how to represent and predict the labels of the set
of annotators. However, often little or no information about annotators is
known, or the set of annotators is small. In this work, we examine a corpus of
social media posts about conflict from a set of 13k annotators and 210k
judgements of social norms. We provide a novel experimental setup that applies
personalization methods to the modeling of annotators and compare their
effectiveness for predicting the perception of social norms. We further provide
an analysis of performance across subsets of social situations that vary by the
closeness of the relationship between parties in conflict, and assess where
personalization helps the most."
Testing GLOM's ability to infer wholes from ambiguous parts,0.864665,"The GLOM architecture proposed by Hinton [2021] is a recurrent neural network
for parsing an image into a hierarchy of wholes and parts. When a part is
ambiguous, GLOM assumes that the ambiguity can be resolved by allowing the part
to make multi-modal predictions for the pose and identity of the whole to which
it belongs and then using attention to similar predictions coming from other
possibly ambiguous parts to settle on a common mode that is predicted by
several different parts. In this study, we describe a highly simplified version
of GLOM that allows us to assess the effectiveness of this way of dealing with
ambiguity. Our results show that, with supervised training, GLOM is able to
successfully form islands of very similar embedding vectors for all of the
locations occupied by the same object and it is also robust to strong noise
injections in the input and to out-of-distribution input transformations."
Testing predictive automated driving systems: lessons learned and future recommendations,0.638137,"Conventional vehicles are certified through classical approaches, where
different physical certification tests are set up on test tracks to assess
required safety levels. These approaches are well suited for vehicles with
limited complexity and limited interactions with other entities as last-second
resources. However, these approaches do not allow to evaluate safety with real
behaviors for critical and edge cases, nor to evaluate the ability to
anticipate them in the mid or long term. This is particularly relevant for
automated and autonomous driving functions that make use of advanced predictive
systems to anticipate future actions and motions to be considered in the path
planning layer. In this paper, we present and analyze the results of physical
tests on proving grounds of several predictive systems in automated driving
functions developed within the framework of the BRAVE project. Based on our
experience in testing predictive automated driving functions, we identify the
main limitations of current physical testing approaches when dealing with
predictive systems, analyze the main challenges ahead, and provide a set of
practical actions and recommendations to consider in future physical testing
procedures for automated and autonomous driving functions."
Learning to Approximate: Auto Direction Vector Set Generation for Hypervolume Contribution Approximation,0.0531673,"Hypervolume contribution is an important concept in evolutionary
multi-objective optimization (EMO). It involves in hypervolume-based EMO
algorithms and hypervolume subset selection algorithms. Its main drawback is
that it is computationally expensive in high-dimensional spaces, which limits
its applicability to many-objective optimization. Recently, an R2 indicator
variant (i.e., $R_2^{\text{HVC}}$ indicator) is proposed to approximate the
hypervolume contribution. The $R_2^{\text{HVC}}$ indicator uses line segments
along a number of direction vectors for hypervolume contribution approximation.
It has been shown that different direction vector sets lead to different
approximation quality. In this paper, we propose \textit{Learning to
Approximate (LtA)}, a direction vector set generation method for the
$R_2^{\text{HVC}}$ indicator. The direction vector set is automatically learned
from training data. The learned direction vector set can then be used in the
$R_2^{\text{HVC}}$ indicator to improve its approximation quality. The
usefulness of the proposed LtA method is examined by comparing it with other
commonly-used direction vector set generation methods for the
$R_2^{\text{HVC}}$ indicator. Experimental results suggest the superiority of
LtA over the other methods for generating high quality direction vector sets."
Benchmarking Stroke Forecasting with Stroke-Level Badminton Dataset,0.388675,"In recent years, badminton analytics has drawn attention due to the
advancement of artificial intelligence and the efficiency of data collection.
While there is a line of effective applications to improve and investigate
player performance, there are only a few public badminton datasets that can be
used by researchers outside the badminton domain. Existing badminton singles
datasets focus on specific matchups; however, they cannot provide comprehensive
studies on different players and various matchups. In this paper, we provide a
badminton singles dataset, ShuttleSet22, which is collected from high-ranking
matches in 2022. ShuttleSet22 consists of 30,172 strokes in 2,888 rallies in
the training set, 1,400 strokes in 450 rallies in the validation set, and 2,040
strokes in 654 rallies in the testing set, with detailed stroke-level metadata
within a rally. To benchmark existing work with ShuttleSet22, we hold a
challenge, Track 2: Forecasting Future Turn-Based Strokes in Badminton Rallies,
at CoachAI Badminton Challenge @ IJCAI 2023, to encourage researchers to tackle
this real-world problem through innovative approaches and to summarize insights
between the state-of-the-art baseline and improved techniques, exchanging
inspiring ideas. The baseline codes and the dataset are made available at
https://github.com/wywyWang/CoachAI-Projects/tree/main/CoachAI-Challenge-IJCAI2023."
Beyond Grids: Exploring Elastic Input Sampling for Vision Transformers,0.069257,"Vision transformers have excelled in various computer vision tasks but mostly
rely on rigid input sampling using a fixed-size grid of patches. This limits
their applicability in real-world problems, such as in the field of robotics
and UAVs, where one can utilize higher input elasticity to boost model
performance and efficiency. Our paper addresses this limitation by formalizing
the concept of input elasticity for vision transformers and introducing an
evaluation protocol, including dedicated metrics for measuring input
elasticity. Moreover, we propose modifications to the transformer architecture
and training regime, which increase its elasticity. Through extensive
experimentation, we spotlight opportunities and challenges associated with
input sampling strategies."
Knowledge Transfer from Answer Ranking to Answer Generation,0.243627,"Recent studies show that Question Answering (QA) based on Answer Sentence
Selection (AS2) can be improved by generating an improved answer from the top-k
ranked answer sentences (termed GenQA). This allows for synthesizing the
information from multiple candidates into a concise, natural-sounding answer.
However, creating large-scale supervised training data for GenQA models is very
challenging. In this paper, we propose to train a GenQA model by transferring
knowledge from a trained AS2 model, to overcome the aforementioned issue.
First, we use an AS2 model to produce a ranking over answer candidates for a
set of questions. Then, we use the top ranked candidate as the generation
target, and the next k top ranked candidates as context for training a GenQA
model. We also propose to use the AS2 model prediction scores for loss
weighting and score-conditioned input/output shaping, to aid the knowledge
transfer. Our evaluation on three public and one large industrial datasets
demonstrates the superiority of our approach over the AS2 baseline, and GenQA
trained using supervised data."
General Image-to-Image Translation with One-Shot Image Guidance,0.931476,"Large-scale text-to-image models pre-trained on massive text-image pairs show
excellent performance in image synthesis recently. However, image can provide
more intuitive visual concepts than plain text. People may ask: how can we
integrate the desired visual concept into an existing image, such as our
portrait? Current methods are inadequate in meeting this demand as they lack
the ability to preserve content or translate visual concepts effectively.
Inspired by this, we propose a novel framework named visual concept translator
(VCT) with the ability to preserve content in the source image and translate
the visual concepts guided by a single reference image. The proposed VCT
contains a content-concept inversion (CCI) process to extract contents and
concepts, and a content-concept fusion (CCF) process to gather the extracted
information to obtain the target image. Given only one reference image, the
proposed VCT can complete a wide range of general image-to-image translation
tasks with excellent results. Extensive experiments are conducted to prove the
superiority and effectiveness of the proposed methods. Codes are available at
https://github.com/CrystalNeuro/visual-concept-translator."
Opponent Modeling in Negotiation Dialogues by Related Data Adaptation,0.549179,"Opponent modeling is the task of inferring another party's mental state
within the context of social interactions. In a multi-issue negotiation, it
involves inferring the relative importance that the opponent assigns to each
issue under discussion, which is crucial for finding high-value deals. A
practical model for this task needs to infer these priorities of the opponent
on the fly based on partial dialogues as input, without needing additional
annotations for training. In this work, we propose a ranker for identifying
these priorities from negotiation dialogues. The model takes in a partial
dialogue as input and predicts the priority order of the opponent. We further
devise ways to adapt related data sources for this task to provide more
explicit supervision for incorporating the opponent's preferences and offers,
as a proxy to relying on granular utterance-level annotations. We show the
utility of our proposed approach through extensive experiments based on two
dialogue datasets. We find that the proposed data adaptations lead to strong
performance in zero-shot and few-shot scenarios. Moreover, they allow the model
to perform better than baselines while accessing fewer utterances from the
opponent. We release our code to support future work in this direction."
Solving NLP Problems through Human-System Collaboration: A Discussion-based Approach,0.146684,"Humans work together to solve common problems by having discussions,
explaining, and agreeing or disagreeing with each other. Similarly, if a system
can have discussions with humans when solving tasks, it can improve the
system's performance and reliability. In previous research on explainability,
it has only been possible for the system to make predictions and for humans to
ask questions about them rather than having a mutual exchange of opinions. This
research aims to create a dataset and computational framework for systems that
discuss and refine their predictions through dialogue. Through experiments, we
show that the proposed system can have beneficial discussions with humans
improving the accuracy by up to 25 points in the natural language inference
task."
Register Variation Remains Stable Across 60 Languages,0.225407,"This paper measures the stability of cross-linguistic register variation. A
register is a variety of a language that is associated with extra-linguistic
context. The relationship between a register and its context is functional: the
linguistic features that make up a register are motivated by the needs and
constraints of the communicative situation. This view hypothesizes that
register should be universal, so that we expect a stable relationship between
the extra-linguistic context that defines a register and the sets of linguistic
features which the register contains. In this paper, the universality and
robustness of register variation is tested by comparing variation within vs.
between register-specific corpora in 60 languages using corpora produced in
comparable communicative situations: tweets and Wikipedia articles. Our
findings confirm the prediction that register variation is, in fact, universal."
CodeAttack: Code-Based Adversarial Attacks for Pre-trained Programming Language Models,0.835707,"Pre-trained programming language (PL) models (such as CodeT5, CodeBERT,
GraphCodeBERT, etc.,) have the potential to automate software engineering tasks
involving code understanding and code generation. However, these models operate
in the natural channel of code, i.e., they are primarily concerned with the
human understanding of the code. They are not robust to changes in the input
and thus, are potentially susceptible to adversarial attacks in the natural
channel. We propose, CodeAttack, a simple yet effective black-box attack model
that uses code structure to generate effective, efficient, and imperceptible
adversarial code samples and demonstrates the vulnerabilities of the
state-of-the-art PL models to code-specific adversarial attacks. We evaluate
the transferability of CodeAttack on several code-code (translation and repair)
and code-NL (summarization) tasks across different programming languages.
CodeAttack outperforms state-of-the-art adversarial NLP attack models to
achieve the best overall drop in performance while being more efficient,
imperceptible, consistent, and fluent. The code can be found at
https://github.com/reddy-lab-code-research/CodeAttack."
Depth- and Semantics-aware Multi-modal Domain Translation: Generating 3D Panoramic Color Images from LiDAR Point Clouds,0.0341788,"This work presents a new depth- and semantics-aware conditional generative
model, named TITAN-Next, for cross-domain image-to-image translation in a
multi-modal setup between LiDAR and camera sensors. The proposed model
leverages scene semantics as a mid-level representation and is able to
translate raw LiDAR point clouds to RGB-D camera images by solely relying on
semantic scene segments. We claim that this is the first framework of its kind
and it has practical applications in autonomous vehicles such as providing a
fail-safe mechanism and augmenting available data in the target image domain.
The proposed model is evaluated on the large-scale and challenging
Semantic-KITTI dataset, and experimental findings show that it considerably
outperforms the original TITAN-Net and other strong baselines by 23.7$\%$
margin in terms of IoU."
Scalable Prompt Generation for Semi-supervised Learning with Language Models,0.652661,"Prompt-based learning methods in semi-supervised learning (SSL) settings have
been shown to be effective on multiple natural language understanding (NLU)
datasets and tasks in the literature. However, manually designing multiple
prompts and verbalizers requires domain knowledge and human effort, making it
difficult and expensive to scale across different datasets. In this paper, we
propose two methods to automatically design multiple prompts and integrate
automatic verbalizer in SSL settings without sacrificing performance. The first
method uses various demonstration examples with learnable continuous prompt
tokens to create diverse prompt models. The second method uses a varying number
of soft prompt tokens to encourage language models to learn different prompts.
For the verbalizer, we use the prototypical verbalizer to replace the manual
one. In summary, we obtained the best average accuracy of 73.2% (a relative
improvement of 2.52% over even the previous state-of-the-art SSL method with
manual prompts and verbalizers) in different few-shot learning settings."
Semantic Strengthening of Neuro-Symbolic Learning,0.735066,"Numerous neuro-symbolic approaches have recently been proposed typically with
the goal of adding symbolic knowledge to the output layer of a neural network.
Ideally, such losses maximize the probability that the neural network's
predictions satisfy the underlying domain. Unfortunately, this type of
probabilistic inference is often computationally infeasible. Neuro-symbolic
approaches therefore commonly resort to fuzzy approximations of this
probabilistic objective, sacrificing sound probabilistic semantics, or to
sampling which is very seldom feasible. We approach the problem by first
assuming the constraint decomposes conditioned on the features learned by the
network. We iteratively strengthen our approximation, restoring the dependence
between the constraints most responsible for degrading the quality of the
approximation. This corresponds to computing the mutual information between
pairs of constraints conditioned on the network's learned features, and may be
construed as a measure of how well aligned the gradients of two distributions
are. We show how to compute this efficiently for tractable circuits. We test
our approach on three tasks: predicting a minimum-cost path in Warcraft,
predicting a minimum-cost perfect matching, and solving Sudoku puzzles,
observing that it improves upon the baselines while sidestepping
intractability."
Common Diffusion Noise Schedules and Sample Steps are Flawed,0.99976,"We discover that common diffusion noise schedules do not enforce the last
timestep to have zero signal-to-noise ratio (SNR), and some implementations of
diffusion samplers do not start from the last timestep. Such designs are flawed
and do not reflect the fact that the model is given pure Gaussian noise at
inference, creating a discrepancy between training and inference. We show that
the flawed design causes real problems in existing implementations. In Stable
Diffusion, it severely limits the model to only generate images with medium
brightness and prevents it from generating very bright and dark samples. We
propose a few simple fixes: (1) rescale the noise schedule to enforce zero
terminal SNR; (2) train the model with v prediction; (3) change the sampler to
always start from the last timestep; (4) rescale classifier-free guidance to
prevent over-exposure. These simple changes ensure the diffusion process is
congruent between training and inference and allow the model to generate
samples more faithful to the original data distribution."
Improving RNN-Transducers with Acoustic LookAhead,0.647641,"RNN-Transducers (RNN-Ts) have gained widespread acceptance as an end-to-end
model for speech to text conversion because of their high accuracy and
streaming capabilities. A typical RNN-T independently encodes the input audio
and the text context, and combines the two encodings by a thin joint network.
While this architecture provides SOTA streaming accuracy, it also makes the
model vulnerable to strong LM biasing which manifests as multi-step
hallucination of text without acoustic evidence. In this paper we propose
LookAhead that makes text representations more acoustically grounded by looking
ahead into the future within the audio input. This technique yields a
significant 5%-20% relative reduction in word error rate on both in-domain and
out-of-domain evaluation sets."
EasyNLP: A Comprehensive and Easy-to-use Toolkit for Natural Language Processing,0.418941,"The success of Pre-Trained Models (PTMs) has reshaped the development of
Natural Language Processing (NLP). Yet, it is not easy to obtain
high-performing models and deploy them online for industrial practitioners. To
bridge this gap, EasyNLP is designed to make it easy to build NLP applications,
which supports a comprehensive suite of NLP algorithms. It further features
knowledge-enhanced pre-training, knowledge distillation and few-shot learning
functionalities for large-scale PTMs, and provides a unified framework of model
training, inference and deployment for real-world applications. Currently,
EasyNLP has powered over ten business units within Alibaba Group and is
seamlessly integrated to the Platform of AI (PAI) products on Alibaba Cloud.
The source code of our EasyNLP toolkit is released at GitHub
(https://github.com/alibaba/EasyNLP)."
In-Context Learning for Few-Shot Dialogue State Tracking,0.7743,"Collecting and annotating task-oriented dialogues is time-consuming and
costly; thus, zero and few shot learning could greatly benefit dialogue state
tracking (DST). In this work, we propose an in-context learning (ICL) framework
for zero-shot and few-shot learning DST, where a large pre-trained language
model (LM) takes a test instance and a few exemplars as input, and directly
decodes the dialogue state without any parameter updates. To better leverage a
tabular domain description in the LM prompt, we reformulate DST into a
text-to-SQL problem. We also propose a novel approach to retrieve annotated
dialogues as exemplars. Empirical results on MultiWOZ show that our method
IC-DST substantially outperforms previous fine-tuned state-of-the-art models in
few-shot settings. In addition, we test IC-DST in zero-shot settings, in which
the model only takes a fixed task instruction as input, finding that it
outperforms previous zero-shot methods by a large margin."
USTC-NELSLIP at SemEval-2022 Task 11: Gazetteer-Adapted Integration Network for Multilingual Complex Named Entity Recognition,0.862492,"This paper describes the system developed by the USTC-NELSLIP team for
SemEval-2022 Task 11 Multilingual Complex Named Entity Recognition
(MultiCoNER). We propose a gazetteer-adapted integration network (GAIN) to
improve the performance of language models for recognizing complex named
entities. The method first adapts the representations of gazetteer networks to
those of language models by minimizing the KL divergence between them. After
adaptation, these two networks are then integrated for backend supervised named
entity recognition (NER) training. The proposed method is applied to several
state-of-the-art Transformer-based NER models with a gazetteer built from
Wikidata, and shows great generalization ability across them. The final
predictions are derived from an ensemble of these trained models. Experimental
results and detailed analysis verify the effectiveness of the proposed method.
The official results show that our system ranked 1st on three tracks (Chinese,
Code-mixed and Bangla) and 2nd on the other ten tracks in this task."
SCVRL: Shuffled Contrastive Video Representation Learning,0.507478,"We propose SCVRL, a novel contrastive-based framework for self-supervised
learning for videos. Differently from previous contrast learning based methods
that mostly focus on learning visual semantics (e.g., CVRL), SCVRL is capable
of learning both semantic and motion patterns. For that, we reformulate the
popular shuffling pretext task within a modern contrastive learning paradigm.
We show that our transformer-based network has a natural capacity to learn
motion in self-supervised settings and achieves strong performance,
outperforming CVRL on four benchmarks."
"Cryptocurrency Bubble Detection: A New Stock Market Dataset, Financial Task & Hyperbolic Models",0.967128,"The rapid spread of information over social media influences quantitative
trading and investments. The growing popularity of speculative trading of
highly volatile assets such as cryptocurrencies and meme stocks presents a
fresh challenge in the financial realm. Investigating such ""bubbles"" - periods
of sudden anomalous behavior of markets are critical in better understanding
investor behavior and market dynamics. However, high volatility coupled with
massive volumes of chaotic social media texts, especially for underexplored
assets like cryptocoins pose a challenge to existing methods. Taking the first
step towards NLP for cryptocoins, we present and publicly release
CryptoBubbles, a novel multi-span identification task for bubble detection, and
a dataset of more than 400 cryptocoins from 9 exchanges over five years
spanning over two million tweets. Further, we develop a set of
sequence-to-sequence hyperbolic models suited to this multi-span identification
task based on the power-law dynamics of cryptocurrencies and user behavior on
social media. We further test the effectiveness of our models under zero-shot
settings on a test set of Reddit posts pertaining to 29 ""meme stocks"", which
see an increase in trade volume due to social media hype. Through quantitative,
qualitative, and zero-shot analyses on Reddit and Twitter spanning cryptocoins
and meme-stocks, we show the practical applicability of CryptoBubbles and
hyperbolic models."
EdiT5: Semi-Autoregressive Text-Editing with T5 Warm-Start,0.960276,"We present EdiT5 - a novel semi-autoregressive text-editing model designed to
combine the strengths of non-autoregressive text-editing and autoregressive
decoding. EdiT5 is faster during inference than conventional
sequence-to-sequence (seq2seq) models, while being capable of modelling
flexible input-output transformations.
  This is achieved by decomposing the generation process into three sub-tasks:
(1) tagging to decide on the subset of input tokens to be preserved in the
output, (2) re-ordering to define their order in the output text, and (3)
insertion to infill the missing tokens that are not present in the input. The
tagging and re-ordering steps, which are responsible for generating the largest
portion of the output, are non-autoregressive, while the insertion step uses an
autoregressive decoder.
  Depending on the task, EdiT5 on average requires significantly fewer
autoregressive steps, demonstrating speedups of up to 25x when compared to
seq2seq models. Quality-wise, EdiT5 is initialized with a pre-trained T5
checkpoint yielding comparable performance to T5 in high-resource settings when
evaluated on three NLG tasks: Sentence Fusion, Grammatical Error Correction,
and Decontextualization while clearly outperforming T5 in low-resource
settings."
Blackbox Post-Processing for Multiclass Fairness,0.413096,"Applying standard machine learning approaches for classification can produce
unequal results across different demographic groups. When then used in
real-world settings, these inequities can have negative societal impacts. This
has motivated the development of various approaches to fair classification with
machine learning models in recent years. In this paper, we consider the problem
of modifying the predictions of a blackbox machine learning classifier in order
to achieve fairness in a multiclass setting. To accomplish this, we extend the
'post-processing' approach in Hardt et al. 2016, which focuses on fairness for
binary classification, to the setting of fair multiclass classification. We
explore when our approach produces both fair and accurate predictions through
systematic synthetic experiments and also evaluate discrimination-fairness
tradeoffs on several publicly available real-world application datasets. We
find that overall, our approach produces minor drops in accuracy and enforces
fairness when the number of individuals in the dataset is high relative to the
number of classes and protected groups."
Human-Centered Concept Explanations for Neural Networks,0.508133,"Understanding complex machine learning models such as deep neural networks
with explanations is crucial in various applications. Many explanations stem
from the model perspective, and may not necessarily effectively communicate why
the model is making its predictions at the right level of abstraction. For
example, providing importance weights to individual pixels in an image can only
express which parts of that particular image are important to the model, but
humans may prefer an explanation which explains the prediction by concept-based
thinking. In this work, we review the emerging area of concept based
explanations. We start by introducing concept explanations including the class
of Concept Activation Vectors (CAV) which characterize concepts using vectors
in appropriate spaces of neural activations, and discuss different properties
of useful concepts, and approaches to measure the usefulness of concept
vectors. We then discuss approaches to automatically extract concepts, and
approaches to address some of their caveats. Finally, we discuss some case
studies that showcase the utility of such concept-based explanations in
synthetic settings and real world applications."
Walking Down the Memory Maze: Beyond Context Limit through Interactive Reading,0.793979,"Large language models (LLMs) have advanced in large strides due to the
effectiveness of the self-attention mechanism that processes and compares all
tokens at once. However, this mechanism comes with a fundamental issue -- the
predetermined context window is bound to be limited. Despite attempts to extend
the context window through methods like extrapolating the positional embedding,
using recurrence, or selectively retrieving essential parts of the long
sequence, long-text understanding continues to be a challenge. We propose an
alternative approach which instead treats the LLM as an interactive agent,
allowing it to decide how to read the text via iterative prompting. We
introduce MemWalker, a method that first processes the long context into a tree
of summary nodes. Upon receiving a query, the model navigates this tree in
search of relevant information, and responds once it gathers sufficient
information. On long-text question answering tasks our method outperforms
baseline approaches that use long context windows, recurrence, and retrieval.
We show that, beyond effective reading, MemWalker enhances explainability by
highlighting the reasoning steps as it interactively reads the text;
pinpointing the relevant text segments related to the query."
Regret Minimization and Convergence to Equilibria in General-sum Markov Games,0.835321,"An abundance of recent impossibility results establish that regret
minimization in Markov games with adversarial opponents is both statistically
and computationally intractable. Nevertheless, none of these results preclude
the possibility of regret minimization under the assumption that all parties
adopt the same learning procedure. In this work, we present the first (to our
knowledge) algorithm for learning in general-sum Markov games that provides
sublinear regret guarantees when executed by all agents. The bounds we obtain
are for swap regret, and thus, along the way, imply convergence to a correlated
equilibrium. Our algorithm is decentralized, computationally efficient, and
does not require any communication between agents. Our key observation is that
online learning via policy optimization in Markov games essentially reduces to
a form of weighted regret minimization, with unknown weights determined by the
path length of the agents' policy sequence. Consequently, controlling the path
length leads to weighted regret objectives for which sufficiently adaptive
algorithms provide sublinear regret guarantees."
Integrating Prior Knowledge in Contrastive Learning with Kernel,0.078564,"Data augmentation is a crucial component in unsupervised contrastive learning
(CL). It determines how positive samples are defined and, ultimately, the
quality of the learned representation. In this work, we open the door to new
perspectives for CL by integrating prior knowledge, given either by generative
models -- viewed as prior representations -- or weak attributes in the positive
and negative sampling. To this end, we use kernel theory to propose a novel
loss, called decoupled uniformity, that i) allows the integration of prior
knowledge and ii) removes the negative-positive coupling in the original
InfoNCE loss. We draw a connection between contrastive learning and conditional
mean embedding theory to derive tight bounds on the downstream classification
loss. In an unsupervised setting, we empirically demonstrate that CL benefits
from generative models to improve its representation both on natural and
medical images. In a weakly supervised scenario, our framework outperforms
other unconditional and conditional CL approaches."
Graph Neural Network with Curriculum Learning for Imbalanced Node Classification,0.464644,"Graph Neural Network (GNN) is an emerging technique for graph-based learning
tasks such as node classification. In this work, we reveal the vulnerability of
GNN to the imbalance of node labels. Traditional solutions for imbalanced
classification (e.g. resampling) are ineffective in node classification without
considering the graph structure. Worse still, they may even bring overfitting
or underfitting results due to lack of sufficient prior knowledge. To solve
these problems, we propose a novel graph neural network framework with
curriculum learning (GNN-CL) consisting of two modules. For one thing, we hope
to acquire certain reliable interpolation nodes and edges through the novel
graph-based oversampling based on smoothness and homophily. For another, we
combine graph classification loss and metric learning loss which adjust the
distance between different nodes associated with minority class in feature
space. Inspired by curriculum learning, we dynamically adjust the weights of
different modules during training process to achieve better ability of
generalization and discrimination. The proposed framework is evaluated via
several widely used graph datasets, showing that our proposed model
consistently outperforms the existing state-of-the-art methods."
Hitachi at SemEval-2023 Task 3: Exploring Cross-lingual Multi-task Strategies for Genre and Framing Detection in Online News,0.550671,"This paper explains the participation of team Hitachi to SemEval-2023 Task 3
""Detecting the genre, the framing, and the persuasion techniques in online news
in a multi-lingual setup.'' Based on the multilingual, multi-task nature of the
task and the low-resource setting, we investigated different cross-lingual and
multi-task strategies for training the pretrained language models. Through
extensive experiments, we found that (a) cross-lingual/multi-task training, and
(b) collecting an external balanced dataset, can benefit the genre and framing
detection. We constructed ensemble models from the results and achieved the
highest macro-averaged F1 scores in Italian and Russian genre categorization
subtasks."
BYOL-Explore: Exploration by Bootstrapped Prediction,0.783711,"We present BYOL-Explore, a conceptually simple yet general approach for
curiosity-driven exploration in visually-complex environments. BYOL-Explore
learns a world representation, the world dynamics, and an exploration policy
all-together by optimizing a single prediction loss in the latent space with no
additional auxiliary objective. We show that BYOL-Explore is effective in
DM-HARD-8, a challenging partially-observable continuous-action
hard-exploration benchmark with visually-rich 3-D environments. On this
benchmark, we solve the majority of the tasks purely through augmenting the
extrinsic reward with BYOL-Explore s intrinsic reward, whereas prior work could
only get off the ground with human demonstrations. As further evidence of the
generality of BYOL-Explore, we show that it achieves superhuman performance on
the ten hardest exploration games in Atari while having a much simpler design
than other competitive agents."
Zero-shot Cross-lingual Conversational Semantic Role Labeling,0.257708,"While conversational semantic role labeling (CSRL) has shown its usefulness
on Chinese conversational tasks, it is still under-explored in non-Chinese
languages due to the lack of multilingual CSRL annotations for the parser
training. To avoid expensive data collection and error-propagation of
translation-based methods, we present a simple but effective approach to
perform zero-shot cross-lingual CSRL. Our model implicitly learns
language-agnostic, conversational structure-aware and semantically rich
representations with the hierarchical encoders and elaborately designed
pre-training objectives. Experimental results show that our model outperforms
all baselines by large margins on two newly collected English CSRL test sets.
More importantly, we confirm the usefulness of CSRL to non-Chinese
conversational tasks such as the question-in-context rewriting task in English
and the multi-turn dialogue response generation tasks in English, German and
Japanese by incorporating the CSRL information into the downstream
conversation-based models. We believe this finding is significant and will
facilitate the research of non-Chinese dialogue tasks which suffer the problems
of ellipsis and anaphora."
Analytical reconstructions of full-scan multiple source-translation computed tomography under large field of views,0.293778,"This paper is to investigate the high-quality analytical reconstructions of
multiple source-translation computed tomography (mSTCT) under an extended field
of view (FOV). Under the larger FOVs, the previously proposed backprojection
filtration (BPF) algorithms for mSTCT, including D-BPF and S-BPF (their
differences are different derivate directions along the detector and source,
respectively), make some errors and artifacts in the reconstructed images due
to a backprojection weighting factor and the half-scan mode, which deviates
from the intention of mSTCT imaging. In this paper, to achieve reconstruction
with as little error as possible under the extremely extended FOV, we combine
the full-scan mSTCT (F-mSTCT) geometry with the previous BPF algorithms to
study the performance and derive a suitable redundancy-weighted function for
F-mSTCT. The experimental results indicate FS-BPF can get high-quality, stable
images under the extremely extended FOV of imaging a large object, though it
requires more projections than FD-BPF. Finally, for different practical
requirements in extending FOV imaging, we give suggestions on algorithm
selection."
HugNLP: A Unified and Comprehensive Library for Natural Language Processing,0.0237852,"In this paper, we introduce HugNLP, a unified and comprehensive library for
natural language processing (NLP) with the prevalent backend of HuggingFace
Transformers, which is designed for NLP researchers to easily utilize
off-the-shelf algorithms and develop novel methods with user-defined models and
tasks in real-world scenarios. HugNLP consists of a hierarchical structure
including models, processors and applications that unifies the learning process
of pre-trained language models (PLMs) on different NLP tasks. Additionally, we
present some featured NLP applications to show the effectiveness of HugNLP,
such as knowledge-enhanced PLMs, universal information extraction, low-resource
mining, and code understanding and generation, etc. The source code will be
released on GitHub (https://github.com/wjn1996/HugNLP)."
PointDP: Diffusion-driven Purification against Adversarial Attacks on 3D Point Cloud Recognition,0.717369,"3D Point cloud is becoming a critical data representation in many real-world
applications like autonomous driving, robotics, and medical imaging. Although
the success of deep learning further accelerates the adoption of 3D point
clouds in the physical world, deep learning is notorious for its vulnerability
to adversarial attacks. In this work, we first identify that the
state-of-the-art empirical defense, adversarial training, has a major
limitation in applying to 3D point cloud models due to gradient obfuscation. We
further propose PointDP, a purification strategy that leverages diffusion
models to defend against 3D adversarial attacks. We extensively evaluate
PointDP on six representative 3D point cloud architectures, and leverage 10+
strong and adaptive attacks to demonstrate its lower-bound robustness. Our
evaluation shows that PointDP achieves significantly better robustness than
state-of-the-art purification methods under strong attacks. Results of
certified defenses on randomized smoothing combined with PointDP will be
included in the near future."
Benchmarking and Improving Generator-Validator Consistency of Language Models,0.118408,"As of September 2023, ChatGPT correctly answers ""what is 7+8"" with 15, but
when asked ""7+8=15, True or False"" it responds with ""False"". This inconsistency
between generating and validating an answer is prevalent in language models
(LMs) and erodes trust. In this paper, we propose a framework for measuring the
consistency between generation and validation (which we call
generator-validator consistency, or GV-consistency), finding that even GPT-4, a
state-of-the-art LM, is GV-consistent only 76% of the time. To improve the
consistency of LMs, we propose to finetune on the filtered generator and
validator responses that are GV-consistent, and call this approach consistency
fine-tuning. We find that this approach improves GV-consistency of Alpaca-30B
from 60% to 93%, and the improvement extrapolates to unseen tasks and domains
(e.g., GV-consistency for positive style transfers extrapolates to unseen
styles like humor). In addition to improving consistency, consistency
fine-tuning improves both generator quality and validator accuracy without
using any labeled data. Evaluated across 6 tasks, including math questions,
knowledge-intensive QA, and instruction following, our method improves the
generator quality by 16% and the validator accuracy by 6.3% across all tasks."
Transition-based Semantic Role Labeling with Pointer Networks,0.12636,"Semantic role labeling (SRL) focuses on recognizing the predicate-argument
structure of a sentence and plays a critical role in many natural language
processing tasks such as machine translation and question answering.
Practically all available methods do not perform full SRL, since they rely on
pre-identified predicates, and most of them follow a pipeline strategy, using
specific models for undertaking one or several SRL subtasks. In addition,
previous approaches have a strong dependence on syntactic information to
achieve state-of-the-art performance, despite being syntactic trees equally
hard to produce. These simplifications and requirements make the majority of
SRL systems impractical for real-world applications. In this article, we
propose the first transition-based SRL approach that is capable of completely
processing an input sentence in a single left-to-right pass, with neither
leveraging syntactic information nor resorting to additional modules. Thanks to
our implementation based on Pointer Networks, full SRL can be accurately and
efficiently done in $O(n^2)$, achieving the best performance to date on the
majority of languages from the CoNLL-2009 shared task."
Toward Unsupervised 3D Point Cloud Anomaly Detection using Variational Autoencoder,0.515316,"In this paper, we present an end-to-end unsupervised anomaly detection
framework for 3D point clouds. To the best of our knowledge, this is the first
work to tackle the anomaly detection task on a general object represented by a
3D point cloud. We propose a deep variational autoencoder-based unsupervised
anomaly detection network adapted to the 3D point cloud and an anomaly score
specifically for 3D point clouds. To verify the effectiveness of the model, we
conducted extensive experiments on the ShapeNet dataset. Through quantitative
and qualitative evaluation, we demonstrate that the proposed method outperforms
the baseline method. Our code is available at
https://github.com/llien30/point_cloud_anomaly_detection."
Occ3D: A Large-Scale 3D Occupancy Prediction Benchmark for Autonomous Driving,0.999872,"Robotic perception requires the modeling of both 3D geometry and semantics.
Existing methods typically focus on estimating 3D bounding boxes, neglecting
finer geometric details and struggling to handle general, out-of-vocabulary
objects. 3D occupancy prediction, which estimates the detailed occupancy states
and semantics of a scene, is an emerging task to overcome these limitations. To
support 3D occupancy prediction, we develop a label generation pipeline that
produces dense, visibility-aware labels for any given scene. This pipeline
comprises three stages: voxel densification, occlusion reasoning, and
image-guided voxel refinement. We establish two benchmarks, derived from the
Waymo Open Dataset and the nuScenes Dataset, namely Occ3D-Waymo and
Occ3D-nuScenes benchmarks. Furthermore, we provide an extensive analysis of the
proposed dataset with various baseline models. Lastly, we propose a new model,
dubbed Coarse-to-Fine Occupancy (CTF-Occ) network, which demonstrates superior
performance on the Occ3D benchmarks. The code, data, and benchmarks are
released at https://tsinghua-mars-lab.github.io/Occ3D/."
Toward Fairness in Speech Recognition: Discovery and mitigation of performance disparities,0.639195,"As for other forms of AI, speech recognition has recently been examined with
respect to performance disparities across different user cohorts. One approach
to achieve fairness in speech recognition is to (1) identify speaker cohorts
that suffer from subpar performance and (2) apply fairness mitigation measures
targeting the cohorts discovered. In this paper, we report on initial findings
with both discovery and mitigation of performance disparities using data from a
product-scale AI assistant speech recognition system. We compare cohort
discovery based on geographic and demographic information to a more scalable
method that groups speakers without human labels, using speaker embedding
technology. For fairness mitigation, we find that oversampling of
underrepresented cohorts, as well as modeling speaker cohort membership by
additional input variables, reduces the gap between top- and bottom-performing
cohorts, without deteriorating overall recognition accuracy."
CDAN: Convolutional Dense Attention-guided Network for Low-light Image Enhancement,0.731583,"Low-light images, characterized by inadequate illumination, pose challenges
of diminished clarity, muted colors, and reduced details. Low-light image
enhancement, an essential task in computer vision, aims to rectify these issues
by improving brightness, contrast, and overall perceptual quality, thereby
facilitating accurate analysis and interpretation. This paper introduces the
Convolutional Dense Attention-guided Network (CDAN), a novel solution for
enhancing low-light images. CDAN integrates an autoencoder-based architecture
with convolutional and dense blocks, complemented by an attention mechanism and
skip connections. This architecture ensures efficient information propagation
and feature learning. Furthermore, a dedicated post-processing phase refines
color balance and contrast. Our approach demonstrates notable progress compared
to state-of-the-art results in low-light image enhancement, showcasing its
robustness across a wide range of challenging scenarios. Our model performs
remarkably on benchmark datasets, effectively mitigating under-exposure and
proficiently restoring textures and colors in diverse low-light scenarios. This
achievement underscores CDAN's potential for diverse computer vision tasks,
notably enabling robust object detection and recognition in challenging
low-light conditions."
Knowledge-aware Bayesian Co-attention for Multimodal Emotion Recognition,0.617307,"Multimodal emotion recognition is a challenging research area that aims to
fuse different modalities to predict human emotion. However, most existing
models that are based on attention mechanisms have difficulty in learning
emotionally relevant parts on their own. To solve this problem, we propose to
incorporate external emotion-related knowledge in the co-attention based fusion
of pre-trained models. To effectively incorporate this knowledge, we enhance
the co-attention model with a Bayesian attention module (BAM) where a prior
distribution is estimated using the emotion-related knowledge. Experimental
results on the IEMOCAP dataset show that the proposed approach can outperform
several state-of-the-art approaches by at least 0.7% unweighted accuracy (UA)."
Earnings-22: A Practical Benchmark for Accents in the Wild,0.453664,"Modern automatic speech recognition (ASR) systems have achieved superhuman
Word Error Rate (WER) on many common corpora despite lacking adequate
performance on speech in the wild. Beyond that, there is a lack of real-world,
accented corpora to properly benchmark academic and commercial models. To
ensure this type of speech is represented in ASR benchmarking, we present
Earnings-22, a 125 file, 119 hour corpus of English-language earnings calls
gathered from global companies. We run a comparison across 4 commercial models
showing the variation in performance when taking country of origin into
consideration. Looking at hypothesis transcriptions, we explore errors common
to all ASR systems tested. By examining Individual Word Error Rate (IWER), we
find that key speech features impact model performance more for certain accents
than others. Earnings-22 provides a free-to-use benchmark of real-world,
accented audio to bridge academic and industrial research."
Translation Word-Level Auto-Completion: What can we achieve out of the box?,0.313823,"Research on Machine Translation (MT) has achieved important breakthroughs in
several areas. While there is much more to be done in order to build on this
success, we believe that the language industry needs better ways to take full
advantage of current achievements. Due to a combination of factors, including
time, resources, and skills, businesses tend to apply pragmatism into their AI
workflows. Hence, they concentrate more on outcomes, e.g. delivery, shipping,
releases, and features, and adopt high-level working production solutions,
where possible. Among the features thought to be helpful for translators are
sentence-level and word-level translation auto-suggestion and auto-completion.
Suggesting alternatives can inspire translators and limit their need to refer
to external resources, which hopefully boosts their productivity. This work
describes our submissions to WMT's shared task on word-level auto-completion,
for the Chinese-to-English, English-to-Chinese, German-to-English, and
English-to-German language directions. We investigate the possibility of using
pre-trained models and out-of-the-box features from available libraries. We
employ random sampling to generate diverse alternatives, which reveals good
results. Furthermore, we introduce our open-source API, based on CTranslate2,
to serve translations, auto-suggestions, and auto-completions."
"One Model, Multiple Modalities: A Sparsely Activated Approach for Text, Sound, Image, Video and Code",0.620278,"People perceive the world with multiple senses (e.g., through hearing sounds,
reading words and seeing objects). However, most existing AI systems only
process an individual modality. This paper presents an approach that excels at
handling multiple modalities of information with a single model. In our
""{SkillNet}"" model, different parts of the parameters are specialized for
processing different modalities. Unlike traditional dense models that always
activate all the model parameters, our model sparsely activates parts of the
parameters whose skills are relevant to the task. Such model design enables
SkillNet to learn skills in a more interpretable way. We develop our model for
five modalities including text, image, sound, video and code. Results show
that, SkillNet performs comparably to five modality-specific fine-tuned models.
Moreover, our model supports self-supervised pretraining with the same sparsely
activated way, resulting in better initialized parameters for different
modalities. We find that pretraining significantly improves the performance of
SkillNet on five modalities, on par with or even better than baselines with
modality-specific pretraining. On the task of Chinese text-to-image retrieval,
our final system achieves higher accuracy than existing leading systems
including Wukong{ViT-B} and Wenlan 2.0 while using less number of activated
parameters."
Object Memory Transformer for Object Goal Navigation,0.734154,"This paper presents a reinforcement learning method for object goal
navigation (ObjNav) where an agent navigates in 3D indoor environments to reach
a target object based on long-term observations of objects and scenes. To this
end, we propose Object Memory Transformer (OMT) that consists of two key ideas:
1) Object-Scene Memory (OSM) that enables to store long-term scenes and object
semantics, and 2) Transformer that attends to salient objects in the sequence
of previously observed scenes and objects stored in OSM. This mechanism allows
the agent to efficiently navigate in the indoor environment without prior
knowledge about the environments, such as topological maps or 3D meshes. To the
best of our knowledge, this is the first work that uses a long-term memory of
object semantics in a goal-oriented navigation task. Experimental results
conducted on the AI2-THOR dataset show that OMT outperforms previous approaches
in navigating in unknown environments. In particular, we show that utilizing
the long-term object semantics information improves the efficiency of
navigation."
Towards Computationally Feasible Deep Active Learning,0.512688,"Active learning (AL) is a prominent technique for reducing the annotation
effort required for training machine learning models. Deep learning offers a
solution for several essential obstacles to deploying AL in practice but
introduces many others. One of such problems is the excessive computational
resources required to train an acquisition model and estimate its uncertainty
on instances in the unlabeled pool. We propose two techniques that tackle this
issue for text classification and tagging tasks, offering a substantial
reduction of AL iteration duration and the computational overhead introduced by
deep acquisition models in AL. We also demonstrate that our algorithm that
leverages pseudo-labeling and distilled models overcomes one of the essential
obstacles revealed previously in the literature. Namely, it was shown that due
to differences between an acquisition model used to select instances during AL
and a successor model trained on the labeled data, the benefits of AL can
diminish. We show that our algorithm, despite using a smaller and faster
acquisition model, is capable of training a more expressive successor model
with higher performance."
Implicit Chain of Thought Reasoning via Knowledge Distillation,0.279924,"To augment language models with the ability to reason, researchers usually
prompt or finetune them to produce chain of thought reasoning steps before
producing the final answer. However, although people use natural language to
reason effectively, it may be that LMs could reason more effectively with some
intermediate computation that is not in natural language. In this work, we
explore an alternative reasoning approach: instead of explicitly producing the
chain of thought reasoning steps, we use the language model's internal hidden
states to perform implicit reasoning. The implicit reasoning steps are
distilled from a teacher model trained on explicit chain-of-thought reasoning,
and instead of doing reasoning ""horizontally"" by producing intermediate words
one-by-one, we distill it such that the reasoning happens ""vertically"" among
the hidden states in different layers. We conduct experiments on a multi-digit
multiplication task and a grade school math problem dataset and find that this
approach enables solving tasks previously not solvable without explicit
chain-of-thought, at a speed comparable to no chain-of-thought."
Evaluation of ChatGPT Family of Models for Biomedical Reasoning and Classification,0.768949,"Recent advances in large language models (LLMs) have shown impressive ability
in biomedical question-answering, but have not been adequately investigated for
more specific biomedical applications. This study investigates the performance
of LLMs such as the ChatGPT family of models (GPT-3.5s, GPT-4) in biomedical
tasks beyond question-answering. Because no patient data can be passed to the
OpenAI API public interface, we evaluated model performance with over 10000
samples as proxies for two fundamental tasks in the clinical domain -
classification and reasoning. The first task is classifying whether statements
of clinical and policy recommendations in scientific literature constitute
health advice. The second task is causal relation detection from the biomedical
literature. We compared LLMs with simpler models, such as bag-of-words (BoW)
with logistic regression, and fine-tuned BioBERT models. Despite the excitement
around viral ChatGPT, we found that fine-tuning for two fundamental NLP tasks
remained the best strategy. The simple BoW model performed on par with the most
complex LLM prompting. Prompt engineering required significant investment."
Unsupervised Learning of Style-Aware Facial Animation from Real Acting Performances,0.174354,"This paper presents a novel approach for text/speech-driven animation of a
photo-realistic head model based on blend-shape geometry, dynamic textures, and
neural rendering. Training a VAE for geometry and texture yields a parametric
model for accurate capturing and realistic synthesis of facial expressions from
a latent feature vector. Our animation method is based on a conditional CNN
that transforms text or speech into a sequence of animation parameters. In
contrast to previous approaches, our animation model learns
disentangling/synthesizing different acting-styles in an unsupervised manner,
requiring only phonetic labels that describe the content of training sequences.
For realistic real-time rendering, we train a U-Net that refines
rasterization-based renderings by computing improved pixel colors and a
foreground matte. We compare our framework qualitatively/quantitatively against
recent methods for head modeling as well as facial animation and evaluate the
perceived rendering/animation quality in a user-study, which indicates large
improvements compared to state-of-the-art approaches"
Learning to Reverse DNNs from AI Programs Automatically,0.702398,"With the privatization deployment of DNNs on edge devices, the security of
on-device DNNs has raised significant concern. To quantify the model leakage
risk of on-device DNNs automatically, we propose NNReverse, the first
learning-based method which can reverse DNNs from AI programs without domain
knowledge. NNReverse trains a representation model to represent the semantics
of binary code for DNN layers. By searching the most similar function in our
database, NNReverse infers the layer type of a given function's binary code. To
represent assembly instructions semantics precisely, NNReverse proposes a more
fine-grained embedding model to represent the textual and structural-semantic
of assembly functions."
Sebis at SemEval-2023 Task 7: A Joint System for Natural Language Inference and Evidence Retrieval from Clinical Trial Reports,0.907538,"With the increasing number of clinical trial reports generated every day, it
is becoming hard to keep up with novel discoveries that inform evidence-based
healthcare recommendations. To help automate this process and assist medical
experts, NLP solutions are being developed. This motivated the SemEval-2023
Task 7, where the goal was to develop an NLP system for two tasks: evidence
retrieval and natural language inference from clinical trial data. In this
paper, we describe our two developed systems. The first one is a pipeline
system that models the two tasks separately, while the second one is a joint
system that learns the two tasks simultaneously with a shared representation
and a multi-task learning approach. The final system combines their outputs in
an ensemble system. We formalize the models, present their characteristics and
challenges, and provide an analysis of achieved results. Our system ranked 3rd
out of 40 participants with a final submission."
Towards Unified Prompt Tuning for Few-shot Text Classification,0.433671,"Prompt-based fine-tuning has boosted the performance of Pre-trained Language
Models (PLMs) on few-shot text classification by employing task-specific
prompts. Yet, PLMs are unfamiliar with prompt-style expressions during
pre-training, which limits the few-shot learning performance on downstream
tasks. It would be desirable if the models can acquire some prompting knowledge
before adaptation to specific NLP tasks. We present the Unified Prompt Tuning
(UPT) framework, leading to better few-shot text classification for BERT-style
models by explicitly capturing prompting semantics from non-target NLP
datasets. In UPT, a novel paradigm Prompt-Options-Verbalizer is proposed for
joint prompt learning across different NLP tasks, forcing PLMs to capture
task-invariant prompting knowledge. We further design a self-supervised task
named Knowledge-enhanced Selective Masked Language Modeling to improve the
PLM's generalization abilities for accurate adaptation to previously unseen
tasks. After multi-task learning across multiple tasks, the PLM can be better
prompt-tuned towards any dissimilar target tasks in low-resourced settings.
Experiments over a variety of NLP tasks show that UPT consistently outperforms
state-of-the-arts for prompt-based fine-tuning."
Deepfake Video Detection with Spatiotemporal Dropout Transformer,0.716289,"While the abuse of deepfake technology has caused serious concerns recently,
how to detect deepfake videos is still a challenge due to the high
photo-realistic synthesis of each frame. Existing image-level approaches often
focus on single frame and ignore the spatiotemporal cues hidden in deepfake
videos, resulting in poor generalization and robustness. The key of a
video-level detector is to fully exploit the spatiotemporal inconsistency
distributed in local facial regions across different frames in deepfake videos.
Inspired by that, this paper proposes a simple yet effective patch-level
approach to facilitate deepfake video detection via spatiotemporal dropout
transformer. The approach reorganizes each input video into bag of patches that
is then fed into a vision transformer to achieve robust representation.
Specifically, a spatiotemporal dropout operation is proposed to fully explore
patch-level spatiotemporal cues and serve as effective data augmentation to
further enhance model's robustness and generalization ability. The operation is
flexible and can be easily plugged into existing vision transformers. Extensive
experiments demonstrate the effectiveness of our approach against 25
state-of-the-arts with impressive robustness, generalizability, and
representation ability."
Holistic Transformer: A Joint Neural Network for Trajectory Prediction and Decision-Making of Autonomous Vehicles,0.453538,"Trajectory prediction and behavioral decision-making are two important tasks
for autonomous vehicles that require good understanding of the environmental
context; behavioral decisions are better made by referring to the outputs of
trajectory predictions. However, most current solutions perform these two tasks
separately. Therefore, a joint neural network that combines multiple cues is
proposed and named as the holistic transformer to predict trajectories and make
behavioral decisions simultaneously. To better explore the intrinsic
relationships between cues, the network uses existing knowledge and adopts
three kinds of attention mechanisms: the sparse multi-head type for reducing
noise impact, feature selection sparse type for optimally using partial prior
knowledge, and multi-head with sigmoid activation type for optimally using
posteriori knowledge. Compared with other trajectory prediction models, the
proposed model has better comprehensive performance and good interpretability.
Perceptual noise robustness experiments demonstrate that the proposed model has
good noise robustness. Thus, simultaneous trajectory prediction and behavioral
decision-making combining multiple cues can reduce computational costs and
enhance semantic relationships between scenes and agents."
"Towards Leaving No Indic Language Behind: Building Monolingual Corpora, Benchmark and Models for Indic Languages",0.187498,"Building Natural Language Understanding (NLU) capabilities for Indic
languages, which have a collective speaker base of more than one billion
speakers is absolutely crucial. In this work, we aim to improve the NLU
capabilities of Indic languages by making contributions along 3 important axes
(i) monolingual corpora (ii) NLU testsets (iii) multilingual LLMs focusing on
Indic languages. Specifically, we curate the largest monolingual corpora,
IndicCorp, with 20.9B tokens covering 24 languages from 4 language families - a
2.3x increase over prior work, while supporting 12 additional languages. Next,
we create a human-supervised benchmark, IndicXTREME, consisting of nine diverse
NLU tasks covering 20 languages. Across languages and tasks, IndicXTREME
contains a total of 105 evaluation sets, of which 52 are new contributions to
the literature. To the best of our knowledge, this is the first effort towards
creating a standard benchmark for Indic languages that aims to test the
multilingual zero-shot capabilities of pretrained language models. Finally, we
train IndicBERT v2, a state-of-the-art model supporting all the languages.
Averaged across languages and tasks, the model achieves an absolute improvement
of 2 points over a strong baseline. The data and models are available at
https://github.com/AI4Bharat/IndicBERT."
An Efficient Memory-Augmented Transformer for Knowledge-Intensive NLP Tasks,0.799759,"Access to external knowledge is essential for many natural language
processing tasks, such as question answering and dialogue. Existing methods
often rely on a parametric model that stores knowledge in its parameters, or
use a retrieval-augmented model that has access to an external knowledge
source. Parametric and retrieval-augmented models have complementary strengths
in terms of computational efficiency and predictive accuracy. To combine the
strength of both approaches, we propose the Efficient Memory-Augmented
Transformer (EMAT) -- it encodes external knowledge into a key-value memory and
exploits the fast maximum inner product search for memory querying. We also
introduce pre-training tasks that allow EMAT to encode informative key-value
representations, and to learn an implicit strategy to integrate multiple memory
slots into the transformer. Experiments on various knowledge-intensive tasks
such as question answering and dialogue datasets show that, simply augmenting
parametric models (T5-base) using our method produces more accurate results
(e.g., 25.8 -> 44.3 EM on NQ) while retaining a high throughput (e.g., 1000
queries/s on NQ). Compared to retrieval-augmented models, EMAT runs
substantially faster across the board and produces more accurate results on WoW
and ELI5. Our code and datasets are available at https://github.
com/uclnlp/EMAT."
Constructing Highly Inductive Contexts for Dialogue Safety through Controllable Reverse Generation,0.212148,"Large pretrained language models can easily produce toxic or biased content,
which is prohibitive for practical use. In order to detect such toxic
generations, existing methods rely on templates, real-world data extraction,
crowdsourcing workers, or automatic generation to construct adversarial
contexts that are likely to induce toxic generations. However, what type of
context is more likely to induce unsafe responses is still under-explored. In
this paper, we identify that context toxicity and context category (e.g.,
\textit{profanity}, \textit{insult}, \textit{drugs}, etc.) are two important
factors to cause safety issues in response generation. Hence, we propose a
method called \emph{reverse generation} to construct adversarial contexts
conditioned on a given response, with the flexibility to control category,
toxicity level, and inductivity of the generated contexts. Via reverse
generation, we augment the existing BAD dataset and construct a new dataset
BAD+ which contains more than 120K diverse and highly inductive contexts in 12
categories. We test three popular pretrained dialogue models (Blender,
DialoGPT, and Plato2) and find that BAD+ can largely expose their safety
problems. Furthermore, we show that BAD+ can greatly enhance the safety of
generation and reveal the key factors of safety improvement. Our code and
dataset is available at \url{https://github.com/thu-coai/Reverse_Generation}."
Hierarchical-Hyperplane Kernels for Actively Learning Gaussian Process Models of Nonstationary Systems,0.329501,"Learning precise surrogate models of complex computer simulations and
physical machines often require long-lasting or expensive experiments.
Furthermore, the modeled physical dependencies exhibit nonlinear and
nonstationary behavior. Machine learning methods that are used to produce the
surrogate model should therefore address these problems by providing a scheme
to keep the number of queries small, e.g. by using active learning and be able
to capture the nonlinear and nonstationary properties of the system. One way of
modeling the nonstationarity is to induce input-partitioning, a principle that
has proven to be advantageous in active learning for Gaussian processes.
However, these methods either assume a known partitioning, need to introduce
complex sampling schemes or rely on very simple geometries. In this work, we
present a simple, yet powerful kernel family that incorporates a partitioning
that: i) is learnable via gradient-based methods, ii) uses a geometry that is
more flexible than previous ones, while still being applicable in the low data
regime. Thus, it provides a good prior for active learning procedures. We
empirically demonstrate excellent performance on various active learning tasks."
The Defeat of the Winograd Schema Challenge,0.985627,"The Winograd Schema Challenge - a set of twin sentences involving pronoun
reference disambiguation that seem to require the use of commonsense knowledge
- was proposed by Hector Levesque in 2011. By 2019, a number of AI systems,
based on large pre-trained transformer-based language models and fine-tuned on
these kinds of problems, achieved better than 90% accuracy. In this paper, we
review the history of the Winograd Schema Challenge and discuss the lasting
contributions of the flurry of research that has taken place on the WSC in the
last decade. We discuss the significance of various datasets developed for WSC,
and the research community's deeper understanding of the role of surrogate
tasks in assessing the intelligence of an AI system."
Covering Uncommon Ground: Gap-Focused Question Generation for Answer Assessment,0.109551,"Human communication often involves information gaps between the
interlocutors. For example, in an educational dialogue, a student often
provides an answer that is incomplete, and there is a gap between this answer
and the perfect one expected by the teacher. Successful dialogue then hinges on
the teacher asking about this gap in an effective manner, thus creating a rich
and interactive educational experience. We focus on the problem of generating
such gap-focused questions (GFQs) automatically. We define the task, highlight
key desired aspects of a good GFQ, and propose a model that satisfies these.
Finally, we provide an evaluation by human annotators of our generated
questions compared against human generated ones, demonstrating competitive
performance."
Relational Representation Learning in Visually-Rich Documents,0.181668,"Relational understanding is critical for a number of visually-rich documents
(VRDs) understanding tasks. Through multi-modal pre-training, recent studies
provide comprehensive contextual representations and exploit them as prior
knowledge for downstream tasks. In spite of their impressive results, we
observe that the widespread relational hints (e.g., relation of key/value
fields on receipts) built upon contextual knowledge are not excavated yet. To
mitigate this gap, we propose DocReL, a Document Relational Representation
Learning framework. The major challenge of DocReL roots in the variety of
relations. From the simplest pairwise relation to the complex global structure,
it is infeasible to conduct supervised training due to the definition of
relation varies and even conflicts in different tasks. To deal with the
unpredictable definition of relations, we propose a novel contrastive learning
task named Relational Consistency Modeling (RCM), which harnesses the fact that
existing relations should be consistent in differently augmented positive
views. RCM provides relational representations which are more compatible to the
urgent need of downstream tasks, even without any knowledge about the exact
definition of relation. DocReL achieves better performance on a wide variety of
VRD relational understanding tasks, including table structure recognition, key
information extraction and reading order detection."
QuestSim: Human Motion Tracking from Sparse Sensors with Simulated Avatars,0.98732,"Real-time tracking of human body motion is crucial for interactive and
immersive experiences in AR/VR. However, very limited sensor data about the
body is available from standalone wearable devices such as HMDs (Head Mounted
Devices) or AR glasses. In this work, we present a reinforcement learning
framework that takes in sparse signals from an HMD and two controllers, and
simulates plausible and physically valid full body motions. Using high quality
full body motion as dense supervision during training, a simple policy network
can learn to output appropriate torques for the character to balance, walk, and
jog, while closely following the input signals. Our results demonstrate
surprisingly similar leg motions to ground truth without any observations of
the lower body, even when the input is only the 6D transformations of the HMD.
We also show that a single policy can be robust to diverse locomotion styles,
different body sizes, and novel environments."
Diffusion-based 3D Object Detection with Random Boxes,0.47813,"3D object detection is an essential task for achieving autonomous driving.
Existing anchor-based detection methods rely on empirical heuristics setting of
anchors, which makes the algorithms lack elegance. In recent years, we have
witnessed the rise of several generative models, among which diffusion models
show great potential for learning the transformation of two distributions. Our
proposed Diff3Det migrates the diffusion model to proposal generation for 3D
object detection by considering the detection boxes as generative targets.
During training, the object boxes diffuse from the ground truth boxes to the
Gaussian distribution, and the decoder learns to reverse this noise process. In
the inference stage, the model progressively refines a set of random boxes to
the prediction results. We provide detailed experiments on the KITTI benchmark
and achieve promising performance compared to classical anchor-based 3D
detection methods."
Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE 2022): Workshop and Shared Task Report,0.946051,"We provide a summary of the fifth edition of the CASE workshop that is held
in the scope of EMNLP 2022. The workshop consists of regular papers, two
keynotes, working papers of shared task participants, and task overview papers.
This workshop has been bringing together all aspects of event information
collection across technical and social science fields. In addition to the
progress in depth, the submission and acceptance of multimodal approaches show
the widening of this interdisciplinary research topic."
Sliced-Wasserstein normalizing flows: beyond maximum likelihood training,0.584051,"Despite their advantages, normalizing flows generally suffer from several
shortcomings including their tendency to generate unrealistic data (e.g.,
images) and their failing to detect out-of-distribution data. One reason for
these deficiencies lies in the training strategy which traditionally exploits a
maximum likelihood principle only. This paper proposes a new training paradigm
based on a hybrid objective function combining the maximum likelihood principle
(MLE) and a sliced-Wasserstein distance. Results obtained on synthetic toy
examples and real image data sets show better generative abilities in terms of
both likelihood and visual aspects of the generated samples. Reciprocally, the
proposed approach leads to a lower likelihood of out-of-distribution data,
demonstrating a greater data fidelity of the resulting flows."
TriPINet: Tripartite Progressive Integration Network for Image Manipulation Localization,0.0691325,"Image manipulation localization aims at distinguishing forged regions from
the whole test image. Although many outstanding prior arts have been proposed
for this task, there are still two issues that need to be further studied: 1)
how to fuse diverse types of features with forgery clues; 2) how to
progressively integrate multistage features for better localization
performance. In this paper, we propose a tripartite progressive integration
network (TriPINet) for end-to-end image manipulation localization. First, we
extract both visual perception information, e.g., RGB input images, and visual
imperceptible features, e.g., frequency and noise traces for forensic feature
learning. Second, we develop a guided cross-modality dual-attention (gCMDA)
module to fuse different types of forged clues. Third, we design a set of
progressive integration squeeze-and-excitation (PI-SE) modules to improve
localization performance by appropriately incorporating multiscale features in
the decoder. Extensive experiments are conducted to compare our method with
state-of-the-art image forensics approaches. The proposed TriPINet obtains
competitive results on several benchmark datasets."
End-to-end Multilingual Coreference Resolution with Mention Head Prediction,0.650769,"This paper describes our approach to the CRAC 2022 Shared Task on
Multilingual Coreference Resolution. Our model is based on a state-of-the-art
end-to-end coreference resolution system. Apart from joined multilingual
training, we improved our results with mention head prediction. We also tried
to integrate dependency information into our model. Our system ended up in
$3^{rd}$ place. Moreover, we reached the best performance on two datasets out
of 13."
K-MHaS: A Multi-label Hate Speech Detection Dataset in Korean Online News Comment,0.784654,"Online hate speech detection has become an important issue due to the growth
of online content, but resources in languages other than English are extremely
limited. We introduce K-MHaS, a new multi-label dataset for hate speech
detection that effectively handles Korean language patterns. The dataset
consists of 109k utterances from news comments and provides a multi-label
classification using 1 to 4 labels, and handles subjectivity and
intersectionality. We evaluate strong baseline experiments on K-MHaS using
Korean-BERT-based language models with six different metrics. KR-BERT with a
sub-character tokenizer outperforms others, recognizing decomposed characters
in each hate speech class."
Learning in Cooperative Multiagent Systems Using Cognitive and Machine Models,0.538971,"Developing effective Multi-Agent Systems (MAS) is critical for many
applications requiring collaboration and coordination with humans. Despite the
rapid advance of Multi-Agent Deep Reinforcement Learning (MADRL) in cooperative
MAS, one major challenge is the simultaneous learning and interaction of
independent agents in dynamic environments in the presence of stochastic
rewards. State-of-the-art MADRL models struggle to perform well in Coordinated
Multi-agent Object Transportation Problems (CMOTPs), wherein agents must
coordinate with each other and learn from stochastic rewards. In contrast,
humans often learn rapidly to adapt to nonstationary environments that require
coordination among people. In this paper, motivated by the demonstrated ability
of cognitive models based on Instance-Based Learning Theory (IBLT) to capture
human decisions in many dynamic decision making tasks, we propose three
variants of Multi-Agent IBL models (MAIBL). The idea of these MAIBL algorithms
is to combine the cognitive mechanisms of IBLT and the techniques of MADRL
models to deal with coordination MAS in stochastic environments from the
perspective of independent learners. We demonstrate that the MAIBL models
exhibit faster learning and achieve better coordination in a dynamic CMOTP task
with various settings of stochastic rewards compared to current MADRL models.
We discuss the benefits of integrating cognitive insights into MADRL models."
Point2Pix: Photo-Realistic Point Cloud Rendering via Neural Radiance Fields,0.415134,"Synthesizing photo-realistic images from a point cloud is challenging because
of the sparsity of point cloud representation. Recent Neural Radiance Fields
and extensions are proposed to synthesize realistic images from 2D input. In
this paper, we present Point2Pix as a novel point renderer to link the 3D
sparse point clouds with 2D dense image pixels. Taking advantage of the point
cloud 3D prior and NeRF rendering pipeline, our method can synthesize
high-quality images from colored point clouds, generally for novel indoor
scenes. To improve the efficiency of ray sampling, we propose point-guided
sampling, which focuses on valid samples. Also, we present Point Encoding to
build Multi-scale Radiance Fields that provide discriminative 3D point
features. Finally, we propose Fusion Encoding to efficiently synthesize
high-quality images. Extensive experiments on the ScanNet and ArkitScenes
datasets demonstrate the effectiveness and generalization."
"Tell, don't show: Declarative facts influence how LLMs generalize",0.0316925,"We examine how large language models (LLMs) generalize from abstract
declarative statements in their training data. As an illustration, consider an
LLM that is prompted to generate weather reports for London in 2050. One
possibility is that the temperatures in the reports match the mean and variance
of reports from 2023 (i.e. matching the statistics of pretraining). Another
possibility is that the reports predict higher temperatures, by incorporating
declarative statements about climate change from scientific papers written in
2023. An example of such a declarative statement is ""global temperatures will
increase by $1^{\circ} \mathrm{C}$ by 2050"".
  To test the influence of abstract declarative statements, we construct tasks
in which LLMs are finetuned on both declarative and procedural information. We
find that declarative statements influence model predictions, even when they
conflict with procedural information. In particular, finetuning on a
declarative statement $S$ increases the model likelihood for logical
consequences of $S$. The effect of declarative statements is consistent across
three domains: aligning an AI assistant, predicting weather, and predicting
demographic features. Through a series of ablations, we show that the effect of
declarative statements cannot be explained by associative learning based on
matching keywords. Nevertheless, the effect of declarative statements on model
likelihoods is small in absolute terms and increases surprisingly little with
model size (i.e. from 330 million to 175 billion parameters). We argue that
these results have implications for AI risk (in relation to the ""treacherous
turn"") and for fairness."
ChatGraph: Interpretable Text Classification by Converting ChatGPT Knowledge to Graphs,0.770769,"ChatGPT, as a recently launched large language model (LLM), has shown
superior performance in various natural language processing (NLP) tasks.
However, two major limitations hinder its potential applications: (1) the
inflexibility of finetuning on downstream tasks and (2) the lack of
interpretability in the decision-making process. To tackle these limitations,
we propose a novel framework that leverages the power of ChatGPT for specific
tasks, such as text classification, while improving its interpretability. The
proposed framework conducts a knowledge graph extraction task to extract
refined and structural knowledge from the raw data using ChatGPT. The rich
knowledge is then converted into a graph, which is further used to train an
interpretable linear classifier to make predictions. To evaluate the
effectiveness of our proposed method, we conduct experiments on four datasets.
The result shows that our method can significantly improve the performance
compared to directly utilizing ChatGPT for text classification tasks. And our
method provides a more transparent decision-making process compared with
previous text classification methods."
Human Instance Matting via Mutual Guidance and Multi-Instance Refinement,0.856243,"This paper introduces a new matting task called human instance matting (HIM),
which requires the pertinent model to automatically predict a precise alpha
matte for each human instance. Straightforward combination of closely related
techniques, namely, instance segmentation, soft segmentation and
human/conventional matting, will easily fail in complex cases requiring
disentangling mingled colors belonging to multiple instances along hairy and
thin boundary structures. To tackle these technical challenges, we propose a
human instance matting framework, called InstMatt, where a novel mutual
guidance strategy working in tandem with a multi-instance refinement module is
used, for delineating multi-instance relationship among humans with complex and
overlapping boundaries if present. A new instance matting metric called
instance matting quality (IMQ) is proposed, which addresses the absence of a
unified and fair means of evaluation emphasizing both instance recognition and
matting quality. Finally, we construct a HIM benchmark for evaluation, which
comprises of both synthetic and natural benchmark images. In addition to
thorough experimental results on complex cases with multiple and overlapping
human instances each has intricate boundaries, preliminary results are
presented on general instance matting. Code and benchmark are available in
https://github.com/nowsyn/InstMatt."
Counterfactual Formulation of Patient-Specific Root Causes of Disease,0.333952,"Root causes of disease intuitively correspond to root vertices that increase
the likelihood of a diagnosis. This description of a root cause nevertheless
lacks the rigorous mathematical formulation needed for the development of
computer algorithms designed to automatically detect root causes from data.
Prior work defined patient-specific root causes of disease using an
interventionalist account that only climbs to the second rung of Pearl's Ladder
of Causation. In this theoretical piece, we climb to the third rung by
proposing a counterfactual definition matching clinical intuition based on
fixed factual data alone. We then show how to assign a root causal contribution
score to each variable using Shapley values from explainable artificial
intelligence. The proposed counterfactual formulation of patient-specific root
causes of disease accounts for noisy labels, adapts to disease prevalence and
admits fast computation without the need for counterfactual simulation."
Label-Driven Denoising Framework for Multi-Label Few-Shot Aspect Category Detection,0.290915,"Multi-Label Few-Shot Aspect Category Detection (FS-ACD) is a new sub-task of
aspect-based sentiment analysis, which aims to detect aspect categories
accurately with limited training instances. Recently, dominant works use the
prototypical network to accomplish this task, and employ the attention
mechanism to extract keywords of aspect category from the sentences to produce
the prototype for each aspect. However, they still suffer from serious noise
problems: (1) due to lack of sufficient supervised data, the previous methods
easily catch noisy words irrelevant to the current aspect category, which
largely affects the quality of the generated prototype; (2) the
semantically-close aspect categories usually generate similar prototypes, which
are mutually noisy and confuse the classifier seriously. In this paper, we
resort to the label information of each aspect to tackle the above problems,
along with proposing a novel Label-Driven Denoising Framework (LDF). Extensive
experimental results show that our framework achieves better performance than
other state-of-the-art methods."
Pyramid Frequency Network with Spatial Attention Residual Refinement Module for Monocular Depth Estimation,0.449916,"Deep-learning-based approaches to depth estimation are rapidly advancing,
offering superior performance over existing methods. To estimate the depth in
real-world scenarios, depth estimation models require the robustness of various
noise environments. In this work, a Pyramid Frequency Network(PFN) with Spatial
Attention Residual Refinement Module(SARRM) is proposed to deal with the weak
robustness of existing deep-learning methods. To reconstruct depth maps with
accurate details, the SARRM constructs a residual fusion method with an
attention mechanism to refine the blur depth. The frequency division strategy
is designed, and the frequency pyramid network is developed to extract features
from multiple frequency bands. With the frequency strategy, PFN achieves better
visual accuracy than state-of-the-art methods in both indoor and outdoor scenes
on Make3D, KITTI depth, and NYUv2 datasets. Additional experiments on the noisy
NYUv2 dataset demonstrate that PFN is more reliable than existing deep-learning
methods in high-noise scenes."
Unsupervised Human Action Recognition with Skeletal Graph Laplacian and Self-Supervised Viewpoints Invariance,0.878565,"This paper presents a novel end-to-end method for the problem of
skeleton-based unsupervised human action recognition. We propose a new
architecture with a convolutional autoencoder that uses graph Laplacian
regularization to model the skeletal geometry across the temporal dynamics of
actions. Our approach is robust towards viewpoint variations by including a
self-supervised gradient reverse layer that ensures generalization across
camera views. The proposed method is validated on NTU-60 and NTU-120
large-scale datasets in which it outperforms all prior unsupervised
skeleton-based approaches on the cross-subject, cross-view, and cross-setup
protocols. Although unsupervised, our learnable representation allows our
method even to surpass a few supervised skeleton-based action recognition
methods. The code is available in:
www.github.com/IIT-PAVIS/UHAR_Skeletal_Laplacian"
CoSP: Co-supervised pretraining of pocket and ligand,0.570203,"Can we inject the pocket-ligand interaction knowledge into the pre-trained
model and jointly learn their chemical space? Pretraining molecules and
proteins has attracted considerable attention in recent years, while most of
these approaches focus on learning one of the chemical spaces and lack the
injection of biological knowledge. We propose a co-supervised pretraining
(CoSP) framework to simultaneously learn 3D pocket and ligand representations.
We use a gated geometric message passing layer to model both 3D pockets and
ligands, where each node's chemical features, geometric position and
orientation are considered. To learn biological meaningful embeddings, we
inject the pocket-ligand interaction knowledge into the pretraining model via
contrastive loss. Considering the specificity of molecules, we further propose
a chemical similarity-enhanced negative sampling strategy to improve the
contrastive learning performance. Through extensive experiments, we conclude
that CoSP can achieve competitive results in pocket matching, molecule property
predictions, and virtual screening."
Mesogeos: A multi-purpose dataset for data-driven wildfire modeling in the Mediterranean,0.439939,"We introduce Mesogeos, a large-scale multi-purpose dataset for wildfire
modeling in the Mediterranean. Mesogeos integrates variables representing
wildfire drivers (meteorology, vegetation, human activity) and historical
records of wildfire ignitions and burned areas for 17 years (2006-2022). It is
designed as a cloud-friendly spatio-temporal dataset, namely a datacube,
harmonizing all variables in a grid of 1km x 1km x 1-day resolution. The
datacube structure offers opportunities to assess machine learning (ML) usage
in various wildfire modeling tasks. We extract two ML-ready datasets that
establish distinct tracks to demonstrate this potential: (1) short-term
wildfire danger forecasting and (2) final burned area estimation given the
point of ignition. We define appropriate metrics and baselines to evaluate the
performance of models in each track. By publishing the datacube, along with the
code to create the ML datasets and models, we encourage the community to foster
the implementation of additional tracks for mitigating the increasing threat of
wildfires in the Mediterranean."
AugDiff: Diffusion based Feature Augmentation for Multiple Instance Learning in Whole Slide Image,0.75864,"Multiple Instance Learning (MIL), a powerful strategy for weakly supervised
learning, is able to perform various prediction tasks on gigapixel Whole Slide
Images (WSIs). However, the tens of thousands of patches in WSIs usually incur
a vast computational burden for image augmentation, limiting the MIL model's
improvement in performance. Currently, the feature augmentation-based MIL
framework is a promising solution, while existing methods such as Mixup often
produce unrealistic features. To explore a more efficient and practical
augmentation method, we introduce the Diffusion Model (DM) into MIL for the
first time and propose a feature augmentation framework called AugDiff.
Specifically, we employ the generation diversity of DM to improve the quality
of feature augmentation and the step-by-step generation property to control the
retention of semantic information. We conduct extensive experiments over three
distinct cancer datasets, two different feature extractors, and three prevalent
MIL algorithms to evaluate the performance of AugDiff. Ablation study and
visualization further verify the effectiveness. Moreover, we highlight
AugDiff's higher-quality augmented feature over image augmentation and its
superiority over self-supervised learning. The generalization over external
datasets indicates its broader applications."
Improving Federated Learning Face Recognition via Privacy-Agnostic Clusters,0.898056,"The growing public concerns on data privacy in face recognition can be
greatly addressed by the federated learning (FL) paradigm. However,
conventional FL methods perform poorly due to the uniqueness of the task:
broadcasting class centers among clients is crucial for recognition
performances but leads to privacy leakage. To resolve the privacy-utility
paradox, this work proposes PrivacyFace, a framework largely improves the
federated learning face recognition via communicating auxiliary and
privacy-agnostic information among clients. PrivacyFace mainly consists of two
components: First, a practical Differentially Private Local Clustering (DPLC)
mechanism is proposed to distill sanitized clusters from local class centers.
Second, a consensus-aware recognition loss subsequently encourages global
consensuses among clients, which ergo results in more discriminative features.
The proposed framework is mathematically proved to be differentially private,
introducing a lightweight overhead as well as yielding prominent performance
boosts (\textit{e.g.}, +9.63\% and +10.26\% for TAR@FAR=1e-4 on IJB-B and IJB-C
respectively). Extensive experiments and ablation studies on a large-scale
dataset have demonstrated the efficacy and practicability of our method."
Estimating Confidence of Predictions of Individual Classifiers and Their Ensembles for the Genre Classification Task,0.0392013,"Genre identification is a subclass of non-topical text classification. The
main difference between this task and topical classification is that genres,
unlike topics, usually do not correspond to simple keywords, and thus they need
to be defined in terms of their functions in communication. Neural models based
on pre-trained transformers, such as BERT or XLM-RoBERTa, demonstrate SOTA
results in many NLP tasks, including non-topical classification. However, in
many cases, their downstream application to very large corpora, such as those
extracted from social media, can lead to unreliable results because of dataset
shifts, when some raw texts do not match the profile of the training set. To
mitigate this problem, we experiment with individual models as well as with
their ensembles. To evaluate the robustness of all models we use a prediction
confidence metric, which estimates the reliability of a prediction in the
absence of a gold standard label. We can evaluate robustness via the confidence
gap between the correctly classified texts and the misclassified ones on a
labeled test corpus, higher gaps make it easier to improve our confidence that
our classifier made the right decision. Our results show that for all of the
classifiers tested in this study, there is a confidence gap, but for the
ensembles, the gap is bigger, meaning that ensembles are more robust than their
individual models."
Question Generation for Reading Comprehension Assessment by Modeling How and What to Ask,0.236783,"Reading is integral to everyday life, and yet learning to read is a struggle
for many young learners. During lessons, teachers can use comprehension
questions to increase engagement, test reading skills, and improve retention.
Historically such questions were written by skilled teachers, but recently
language models have been used to generate comprehension questions. However,
many existing Question Generation (QG) systems focus on generating literal
questions from the text, and have no way to control the type of the generated
question. In this paper, we study QG for reading comprehension where
inferential questions are critical and extractive techniques cannot be used. We
propose a two-step model (HTA-WTA) that takes advantage of previous datasets,
and can generate questions for a specific targeted comprehension skill. We
propose a new reading comprehension dataset that contains questions annotated
with story-based reading comprehension skills (SBRCS), allowing for a more
complete reader assessment. Across several experiments, our results show that
HTA-WTA outperforms multiple strong baselines on this new dataset. We show that
the HTA-WTA model tests for strong SCRS by asking deep inferential questions."
Automated Identification of Tree Species by Bark Texture Classification Using Convolutional Neural Networks,0.503716,"Identification of tree species plays a key role in forestry related tasks
like forest conservation, disease diagnosis and plant production. There had
been a debate regarding the part of the tree to be used for differentiation,
whether it should be leaves, fruits, flowers or bark. Studies have proven that
bark is of utmost importance as it will be present despite seasonal variations
and provides a characteristic identity to a tree by variations in the
structure. In this paper, a deep learning based approach is presented by
leveraging the method of computer vision to classify 50 tree species, on the
basis of bark texture using the BarkVN-50 dataset. This is the maximum number
of trees being considered for bark classification till now. A convolutional
neural network(CNN), ResNet101 has been implemented using transfer-learning
based technique of fine tuning to maximise the model performance. The model
produced an overall accuracy of >94% during the evaluation. The performance
validation has been done using K-Fold Cross Validation and by testing on unseen
data collected from the Internet, this proved the model's generalization
capability for real-world uses."
"TrafficGPT: Viewing, Processing and Interacting with Traffic Foundation Models",0.999753,"With the promotion of chatgpt to the public, Large language models indeed
showcase remarkable common sense, reasoning, and planning skills, frequently
providing insightful guidance. These capabilities hold significant promise for
their application in urban traffic management and control. However, LLMs
struggle with addressing traffic issues, especially processing numerical data
and interacting with simulations, limiting their potential in solving
traffic-related challenges. In parallel, specialized traffic foundation models
exist but are typically designed for specific tasks with limited input-output
interactions. Combining these models with LLMs presents an opportunity to
enhance their capacity for tackling complex traffic-related problems and
providing insightful suggestions. To bridge this gap, we present TrafficGPT, a
fusion of ChatGPT and traffic foundation models. This integration yields the
following key enhancements: 1) empowering ChatGPT with the capacity to view,
analyze, process traffic data, and provide insightful decision support for
urban transportation system management; 2) facilitating the intelligent
deconstruction of broad and complex tasks and sequential utilization of traffic
foundation models for their gradual completion; 3) aiding human decision-making
in traffic control through natural language dialogues; and 4) enabling
interactive feedback and solicitation of revised outcomes. By seamlessly
intertwining large language model and traffic expertise, TrafficGPT not only
advances traffic management but also offers a novel approach to leveraging AI
capabilities in this domain. The TrafficGPT demo can be found in
https://github.com/lijlansg/TrafficGPT.git."
VALUE: Understanding Dialect Disparity in NLU,0.331197,"English Natural Language Understanding (NLU) systems have achieved great
performances and even outperformed humans on benchmarks like GLUE and
SuperGLUE. However, these benchmarks contain only textbook Standard American
English (SAE). Other dialects have been largely overlooked in the NLP
community. This leads to biased and inequitable NLU systems that serve only a
sub-population of speakers. To understand disparities in current models and to
facilitate more dialect-competent NLU systems, we introduce the VernAcular
Language Understanding Evaluation (VALUE) benchmark, a challenging variant of
GLUE that we created with a set of lexical and morphosyntactic transformation
rules. In this initial release (V.1), we construct rules for 11 features of
African American Vernacular English (AAVE), and we recruit fluent AAVE speakers
to validate each feature transformation via linguistic acceptability judgments
in a participatory design manner. Experiments show that these new dialectal
features can lead to a drop in model performance. To run the transformation
code and download both synthetic and gold-standard dialectal GLUE benchmarks,
see https://github.com/SALT-NLP/value"
Parameterized Decision-making with Multi-modal Perception for Autonomous Driving,0.346105,"Autonomous driving is an emerging technology that has advanced rapidly over
the last decade. Modern transportation is expected to benefit greatly from a
wise decision-making framework of autonomous vehicles, including the
improvement of mobility and the minimization of risks and travel time. However,
existing methods either ignore the complexity of environments only fitting
straight roads, or ignore the impact on surrounding vehicles during
optimization phases, leading to weak environmental adaptability and incomplete
optimization objectives. To address these limitations, we propose a
parameterized decision-making framework with multi-modal perception based on
deep reinforcement learning, called AUTO. We conduct a comprehensive perception
to capture the state features of various traffic participants around the
autonomous vehicle, based on which we design a graph-based model to learn a
state representation of the multi-modal semantic features. To distinguish
between lane-following and lane-changing, we decompose an action of the
autonomous vehicle into a parameterized action structure that first decides
whether to change lanes and then computes an exact action to execute. A hybrid
reward function takes into account aspects of safety, traffic efficiency,
passenger comfort, and impact to guide the framework to generate optimal
actions. In addition, we design a regularization term and a multi-worker
paradigm to enhance the training. Extensive experiments offer evidence that
AUTO can advance state-of-the-art in terms of both macroscopic and microscopic
effectiveness."
Label-dependent and event-guided interpretable disease risk prediction using EHRs,0.0840032,"Electronic health records (EHRs) contain patients' heterogeneous data that
are collected from medical providers involved in the patient's care, including
medical notes, clinical events, laboratory test results, symptoms, and
diagnoses. In the field of modern healthcare, predicting whether patients would
experience any risks based on their EHRs has emerged as a promising research
area, in which artificial intelligence (AI) plays a key role. To make AI models
practically applicable, it is required that the prediction results should be
both accurate and interpretable. To achieve this goal, this paper proposed a
label-dependent and event-guided risk prediction model (LERP) to predict the
presence of multiple disease risks by mainly extracting information from
unstructured medical notes. Our model is featured in the following aspects.
First, we adopt a label-dependent mechanism that gives greater attention to
words from medical notes that are semantically similar to the names of risk
labels. Secondly, as the clinical events (e.g., treatments and drugs) can also
indicate the health status of patients, our model utilizes the information from
events and uses them to generate an event-guided representation of medical
notes. Thirdly, both label-dependent and event-guided representations are
integrated to make a robust prediction, in which the interpretability is
enabled by the attention weights over words from medical notes. To demonstrate
the applicability of the proposed method, we apply it to the MIMIC-III dataset,
which contains real-world EHRs collected from hospitals. Our method is
evaluated in both quantitative and qualitative ways."
A Dense Material Segmentation Dataset for Indoor and Outdoor Scene Parsing,0.317593,"A key algorithm for understanding the world is material segmentation, which
assigns a label (metal, glass, etc.) to each pixel. We find that a model
trained on existing data underperforms in some settings and propose to address
this with a large-scale dataset of 3.2 million dense segments on 44,560 indoor
and outdoor images, which is 23x more segments than existing data. Our data
covers a more diverse set of scenes, objects, viewpoints and materials, and
contains a more fair distribution of skin types. We show that a model trained
on our data outperforms a state-of-the-art model across datasets and
viewpoints. We propose a large-scale scene parsing benchmark and baseline of
0.729 per-pixel accuracy, 0.585 mean class accuracy and 0.420 mean IoU across
46 materials."
Relative Behavioral Attributes: Filling the Gap between Symbolic Goal Specification and Reward Learning from Human Preferences,0.635942,"Generating complex behaviors that satisfy the preferences of non-expert users
is a crucial requirement for AI agents. Interactive reward learning from
trajectory comparisons (a.k.a. RLHF) is one way to allow non-expert users to
convey complex objectives by expressing preferences over short clips of agent
behaviors. Even though this parametric method can encode complex tacit
knowledge present in the underlying tasks, it implicitly assumes that the human
is unable to provide richer feedback than binary preference labels, leading to
intolerably high feedback complexity and poor user experience. While providing
a detailed symbolic closed-form specification of the objectives might be
tempting, it is not always feasible even for an expert user. However, in most
cases, humans are aware of how the agent should change its behavior along
meaningful axes to fulfill their underlying purpose, even if they are not able
to fully specify task objectives symbolically. Using this as motivation, we
introduce the notion of Relative Behavioral Attributes, which allows the users
to tweak the agent behavior through symbolic concepts (e.g., increasing the
softness or speed of agents' movement). We propose two practical methods that
can learn to model any kind of behavioral attributes from ordered behavior
clips. We demonstrate the effectiveness of our methods on four tasks with nine
different behavioral attributes, showing that once the attributes are learned,
end users can produce desirable agent behaviors relatively effortlessly, by
providing feedback just around ten times. This is over an order of magnitude
less than that required by the popular learning-from-human-preferences
baselines. The supplementary video and source code are available at:
https://guansuns.github.io/pages/rba."
OOD Link Prediction Generalization Capabilities of Message-Passing GNNs in Larger Test Graphs,0.916987,"This work provides the first theoretical study on the ability of graph
Message Passing Neural Networks (gMPNNs) -- such as Graph Neural Networks
(GNNs) -- to perform inductive out-of-distribution (OOD) link prediction tasks,
where deployment (test) graph sizes are larger than training graphs. We first
prove non-asymptotic bounds showing that link predictors based on
permutation-equivariant (structural) node embeddings obtained by gMPNNs can
converge to a random guess as test graphs get larger. We then propose a
theoretically-sound gMPNN that outputs structural pairwise (2-node) embeddings
and prove non-asymptotic bounds showing that, as test graphs grow, these
embeddings converge to embeddings of a continuous function that retains its
ability to predict links OOD. Empirical results on random graphs show agreement
with our theoretical results."
Average Token Delay: A Latency Metric for Simultaneous Translation,0.629007,"Simultaneous translation is a task in which translation begins before the
speaker has finished speaking. In its evaluation, we have to consider the
latency of the translation in addition to the quality. The latency is
preferably as small as possible for users to comprehend what the speaker says
with a small delay. Existing latency metrics focus on when the translation
starts but do not consider adequately when the translation ends. This means
such metrics do not penalize the latency caused by a long translation output,
which actually delays users' comprehension. In this work, we propose a novel
latency evaluation metric called Average Token Delay (ATD) that focuses on the
end timings of partial translations in simultaneous translation. We discuss the
advantage of ATD using simulated examples and also investigate the differences
between ATD and Average Lagging with simultaneous translation experiments."
Can Language Models Employ the Socratic Method? Experiments with Code Debugging,0.802069,"When employing the Socratic method of teaching, instructors guide students
toward solving a problem on their own rather than providing the solution
directly. While this strategy can substantially improve learning outcomes, it
is usually time-consuming and cognitively demanding. Automated Socratic
conversational agents can augment human instruction and provide the necessary
scale, however their development is hampered by the lack of suitable data for
training and evaluation. In this paper, we introduce a manually created dataset
of multi-turn Socratic advice that is aimed at helping a novice programmer fix
buggy solutions to simple computational problems. The dataset is then used for
benchmarking the Socratic debugging abilities of a number of language models,
ranging from fine-tuning the instruction-based text-to-text transformer Flan-T5
to zero-shot and chain of thought prompting of the much larger GPT-4. The code
and datasets are made freely available for research at the link below.
https://github.com/taisazero/socratic-debugging-benchmark"
The 8-Point Algorithm as an Inductive Bias for Relative Pose Prediction by ViTs,0.873884,"We present a simple baseline for directly estimating the relative pose
(rotation and translation, including scale) between two images. Deep methods
have recently shown strong progress but often require complex or multi-stage
architectures. We show that a handful of modifications can be applied to a
Vision Transformer (ViT) to bring its computations close to the Eight-Point
Algorithm. This inductive bias enables a simple method to be competitive in
multiple settings, often substantially improving over the state of the art with
strong performance gains in limited data regimes."
Making LLMs Worth Every Penny: Resource-Limited Text Classification in Banking,0.842551,"Standard Full-Data classifiers in NLP demand thousands of labeled examples,
which is impractical in data-limited domains. Few-shot methods offer an
alternative, utilizing contrastive learning techniques that can be effective
with as little as 20 examples per class. Similarly, Large Language Models
(LLMs) like GPT-4 can perform effectively with just 1-5 examples per class.
However, the performance-cost trade-offs of these methods remain underexplored,
a critical concern for budget-limited organizations. Our work addresses this
gap by studying the aforementioned approaches over the Banking77 financial
intent detection dataset, including the evaluation of cutting-edge LLMs by
OpenAI, Cohere, and Anthropic in a comprehensive set of few-shot scenarios. We
complete the picture with two additional methods: first, a cost-effective
querying method for LLMs based on retrieval-augmented generation (RAG), able to
reduce operational costs multiple times compared to classic few-shot
approaches, and second, a data augmentation method using GPT-4, able to improve
performance in data-limited scenarios. Finally, to inspire future research, we
provide a human expert's curated subset of Banking77, along with extensive
error analysis."
AI model GPT-3 (dis)informs us better than humans,0.831456,"Artificial intelligence is changing the way we create and evaluate
information, and this is happening during an infodemic, which has been having
dramatic effects on global health. In this paper we evaluate whether recruited
individuals can distinguish disinformation from accurate information,
structured in the form of tweets, and determine whether a tweet is organic or
synthetic, i.e., whether it has been written by a Twitter user or by the AI
model GPT-3. Our results show that GPT-3 is a double-edge sword, which, in
comparison with humans, can produce accurate information that is easier to
understand, but can also produce more compelling disinformation. We also show
that humans cannot distinguish tweets generated by GPT-3 from tweets written by
human users. Starting from our results, we reflect on the dangers of AI for
disinformation, and on how we can improve information campaigns to benefit
global health."
Optical Flow Regularization of Implicit Neural Representations for Video Frame Interpolation,0.0624011,"Recent works have shown the ability of Implicit Neural Representations (INR)
to carry meaningful representations of signal derivatives. In this work, we
leverage this property to perform Video Frame Interpolation (VFI) by explicitly
constraining the derivatives of the INR to satisfy the optical flow constraint
equation. We achieve state of the art VFI on limited motion ranges using only a
target video and its optical flow, without learning the interpolation operator
from additional training data. We further show that constraining the INR
derivatives not only allows to better interpolate intermediate frames but also
improves the ability of narrow networks to fit the observed frames, which
suggests potential applications to video compression and INR optimization."
Language Model Tokenizers Introduce Unfairness Between Languages,0.718888,"Recent language models have shown impressive multilingual performance, even
when not explicitly trained for it. Despite this, there are concerns about the
quality of their outputs across different languages. In this paper, we show how
disparity in the treatment of different languages arises at the tokenization
stage, well before a model is even invoked. The same text translated into
different languages can have drastically different tokenization lengths, with
differences up to 15 times in some cases. These disparities persist even for
tokenizers that are intentionally trained for multilingual support.
Character-level and byte-level models also exhibit over 4 times the difference
in the encoding length for some language pairs. This induces unfair treatment
for some language communities in regard to the cost of accessing commercial
language services, the processing time and latency, as well as the amount of
content that can be provided as context to the models. Therefore, we make the
case that we should train future language models using multilingually fair
subword tokenizers."
BNV-Fusion: Dense 3D Reconstruction using Bi-level Neural Volume Fusion,0.699561,"Dense 3D reconstruction from a stream of depth images is the key to many
mixed reality and robotic applications. Although methods based on Truncated
Signed Distance Function (TSDF) Fusion have advanced the field over the years,
the TSDF volume representation is confronted with striking a balance between
the robustness to noisy measurements and maintaining the level of detail. We
present Bi-level Neural Volume Fusion (BNV-Fusion), which leverages recent
advances in neural implicit representations and neural rendering for dense 3D
reconstruction. In order to incrementally integrate new depth maps into a
global neural implicit representation, we propose a novel bi-level fusion
strategy that considers both efficiency and reconstruction quality by design.
We evaluate the proposed method on multiple datasets quantitatively and
qualitatively, demonstrating a significant improvement over existing methods."
MIAD: A Maintenance Inspection Dataset for Unsupervised Anomaly Detection,0.884824,"Visual anomaly detection plays a crucial role in not only manufacturing
inspection to find defects of products during manufacturing processes, but also
maintenance inspection to keep equipment in optimum working condition
particularly outdoors. Due to the scarcity of the defective samples,
unsupervised anomaly detection has attracted great attention in recent years.
However, existing datasets for unsupervised anomaly detection are biased
towards manufacturing inspection, not considering maintenance inspection which
is usually conducted under outdoor uncontrolled environment such as varying
camera viewpoints, messy background and degradation of object surface after
long-term working. We focus on outdoor maintenance inspection and contribute a
comprehensive Maintenance Inspection Anomaly Detection (MIAD) dataset which
contains more than 100K high-resolution color images in various outdoor
industrial scenarios. This dataset is generated by a 3D graphics software and
covers both surface and logical anomalies with pixel-precise ground truth.
Extensive evaluations of representative algorithms for unsupervised anomaly
detection are conducted, and we expect MIAD and corresponding experimental
results can inspire research community in outdoor unsupervised anomaly
detection tasks. Worthwhile and related future work can be spawned from our new
dataset."
CLOWER: A Pre-trained Language Model with Contrastive Learning over Word and Character Representations,0.0278092,"Pre-trained Language Models (PLMs) have achieved remarkable performance gains
across numerous downstream tasks in natural language understanding. Various
Chinese PLMs have been successively proposed for learning better Chinese
language representation. However, most current models use Chinese characters as
inputs and are not able to encode semantic information contained in Chinese
words. While recent pre-trained models incorporate both words and characters
simultaneously, they usually suffer from deficient semantic interactions and
fail to capture the semantic relation between words and characters. To address
the above issues, we propose a simple yet effective PLM CLOWER, which adopts
the Contrastive Learning Over Word and charactER representations. In
particular, CLOWER implicitly encodes the coarse-grained information (i.e.,
words) into the fine-grained representations (i.e., characters) through
contrastive learning on multi-grained information. CLOWER is of great value in
realistic scenarios since it can be easily incorporated into any existing
fine-grained based PLMs without modifying the production pipelines.Extensive
experiments conducted on a range of downstream tasks demonstrate the superior
performance of CLOWER over several state-of-the-art baselines."
A semantically enhanced dual encoder for aspect sentiment triplet extraction,0.870332,"Aspect sentiment triplet extraction (ASTE) is a crucial subtask of
aspect-based sentiment analysis (ABSA) that aims to comprehensively identify
sentiment triplets. Previous research has focused on enhancing ASTE through
innovative table-filling strategies. However, these approaches often overlook
the multi-perspective nature of language expressions, resulting in a loss of
valuable interaction information between aspects and opinions. To address this
limitation, we propose a framework that leverages both a basic encoder,
primarily based on BERT, and a particular encoder comprising a Bi-LSTM network
and graph convolutional network (GCN ). The basic encoder captures the
surface-level semantics of linguistic expressions, while the particular encoder
extracts deeper semantics, including syntactic and lexical information. By
modeling the dependency tree of comments and considering the part-of-speech and
positional information of words, we aim to capture semantics that are more
relevant to the underlying intentions of the sentences. An interaction strategy
combines the semantics learned by the two encoders, enabling the fusion of
multiple perspectives and facilitating a more comprehensive understanding of
aspect--opinion relationships. Experiments conducted on benchmark datasets
demonstrate the state-of-the-art performance of our proposed framework."
Asynchronous Optimisation for Event-based Visual Odometry,0.794295,"Event cameras open up new possibilities for robotic perception due to their
low latency and high dynamic range. On the other hand, developing effective
event-based vision algorithms that fully exploit the beneficial properties of
event cameras remains work in progress. In this paper, we focus on event-based
visual odometry (VO). While existing event-driven VO pipelines have adopted
continuous-time representations to asynchronously process event data, they
either assume a known map, restrict the camera to planar trajectories, or
integrate other sensors into the system. Towards map-free event-only monocular
VO in SE(3), we propose an asynchronous structure-from-motion optimisation
back-end. Our formulation is underpinned by a principled joint optimisation
problem involving non-parametric Gaussian Process motion modelling and
incremental maximum a posteriori inference. A high-performance incremental
computation engine is employed to reason about the camera trajectory with every
incoming event. We demonstrate the robustness of our asynchronous back-end in
comparison to frame-based methods which depend on accurate temporal
accumulation of measurements."
An Analysis of Deep Reinforcement Learning Agents for Text-based Games,0.0282714,"Text-based games(TBG) are complex environments which allow users or computer
agents to make textual interactions and achieve game goals.In TBG agent design
and training process, balancing the efficiency and performance of the agent
models is a major challenge. Finding TBG agent deep learning modules'
performance in standardized environments, and testing their performance among
different evaluation types is also important for TBG agent research. We
constructed a standardized TBG agent with no hand-crafted rules, formally
categorized TBG evaluation types, and analyzed selected methods in our
environment."
Robust Reinforcement Learning using Offline Data,0.919144,"The goal of robust reinforcement learning (RL) is to learn a policy that is
robust against the uncertainty in model parameters. Parameter uncertainty
commonly occurs in many real-world RL applications due to simulator modeling
errors, changes in the real-world system dynamics over time, and adversarial
disturbances. Robust RL is typically formulated as a max-min problem, where the
objective is to learn the policy that maximizes the value against the worst
possible models that lie in an uncertainty set. In this work, we propose a
robust RL algorithm called Robust Fitted Q-Iteration (RFQI), which uses only an
offline dataset to learn the optimal robust policy. Robust RL with offline data
is significantly more challenging than its non-robust counterpart because of
the minimization over all models present in the robust Bellman operator. This
poses challenges in offline data collection, optimization over the models, and
unbiased estimation. In this work, we propose a systematic approach to overcome
these challenges, resulting in our RFQI algorithm. We prove that RFQI learns a
near-optimal robust policy under standard assumptions and demonstrate its
superior performance on standard benchmark problems."
GPT-4 Doesn't Know It's Wrong: An Analysis of Iterative Prompting for Reasoning Problems,0.78489,"There has been considerable divergence of opinion on the reasoning abilities
of Large Language Models (LLMs). While the initial optimism that reasoning
might emerge automatically with scale has been tempered thanks to a slew of
counterexamples, a wide spread belief in their iterative self-critique
capabilities persists. In this paper, we set out to systematically investigate
the effectiveness of iterative prompting of LLMs in the context of Graph
Coloring, a canonical NP-complete reasoning problem that is related to
propositional satisfiability as well as practical problems like scheduling and
allocation. We present a principled empirical study of the performance of GPT4
in solving graph coloring instances or verifying the correctness of candidate
colorings. In iterative modes, we experiment with the model critiquing its own
answers and an external correct reasoner verifying proposed solutions. In both
cases, we analyze whether the content of the criticisms actually affects bottom
line performance. The study seems to indicate that (i) LLMs are bad at solving
graph coloring instances (ii) they are no better at verifying a solution--and
thus are not effective in iterative modes with LLMs critiquing LLM-generated
solutions (iii) the correctness and content of the criticisms--whether by LLMs
or external solvers--seems largely irrelevant to the performance of iterative
prompting. We show that the observed increase in effectiveness is largely due
to the correct solution being fortuitously present in the top-k completions of
the prompt (and being recognized as such by an external verifier). Our results
thus call into question claims about the self-critiquing capabilities of state
of the art LLMs."
Hallucination Improves the Performance of Unsupervised Visual Representation Learning,0.877504,"Contrastive learning models based on Siamese structure have demonstrated
remarkable performance in self-supervised learning. Such a success of
contrastive learning relies on two conditions, a sufficient number of positive
pairs and adequate variations between them. If the conditions are not met,
these frameworks will lack semantic contrast and be fragile on overfitting. To
address these two issues, we propose Hallucinator that could efficiently
generate additional positive samples for further contrast. The Hallucinator is
differentiable and creates new data in the feature space. Thus, it is optimized
directly with the pre-training task and introduces nearly negligible
computation. Moreover, we reduce the mutual information of hallucinated pairs
and smooth them through non-linear operations. This process helps avoid
over-confident contrastive learning models during the training and achieves
more transformation-invariant feature embeddings. Remarkably, we empirically
prove that the proposed Hallucinator generalizes well to various contrastive
learning models, including MoCoV1&V2, SimCLR and SimSiam. Under the linear
classification protocol, a stable accuracy gain is achieved, ranging from 0.3%
to 3.0% on CIFAR10&100, Tiny ImageNet, STL-10 and ImageNet. The improvement is
also observed in transferring pre-train encoders to the downstream tasks,
including object detection and segmentation."
A Unified Positive-Unlabeled Learning Framework for Document-Level Relation Extraction with Different Levels of Labeling,0.786775,"Document-level relation extraction (RE) aims to identify relations between
entities across multiple sentences. Most previous methods focused on
document-level RE under full supervision. However, in real-world scenario, it
is expensive and difficult to completely label all relations in a document
because the number of entity pairs in document-level RE grows quadratically
with the number of entities. To solve the common incomplete labeling problem,
we propose a unified positive-unlabeled learning framework - shift and squared
ranking loss positive-unlabeled (SSR-PU) learning. We use positive-unlabeled
(PU) learning on document-level RE for the first time. Considering that labeled
data of a dataset may lead to prior shift of unlabeled data, we introduce a PU
learning under prior shift of training data. Also, using none-class score as an
adaptive threshold, we propose squared ranking loss and prove its Bayesian
consistency with multi-label ranking metrics. Extensive experiments demonstrate
that our method achieves an improvement of about 14 F1 points relative to the
previous baseline with incomplete labeling. In addition, it outperforms
previous state-of-the-art results under both fully supervised and extremely
unlabeled settings as well."
On the Influence of Explainable AI on Automation Bias,0.570767,"Artificial intelligence (AI) is gaining momentum, and its importance for the
future of work in many areas, such as medicine and banking, is continuously
rising. However, insights on the effective collaboration of humans and AI are
still rare. Typically, AI supports humans in decision-making by addressing
human limitations. However, it may also evoke human bias, especially in the
form of automation bias as an over-reliance on AI advice. We aim to shed light
on the potential to influence automation bias by explainable AI (XAI). In this
pre-test, we derive a research model and describe our study design.
Subsequentially, we conduct an online experiment with regard to hotel review
classifications and discuss first results. We expect our research to contribute
to the design and development of safe hybrid intelligence systems."
Zeus: Understanding and Optimizing GPU Energy Consumption of DNN Training,0.976004,"Training deep neural networks (DNNs) is becoming increasingly more resource-
and energy-intensive every year. Unfortunately, existing works primarily focus
on optimizing DNN training for faster completion, often without considering the
impact on energy efficiency.
  In this paper, we observe that common practices to improve training
performance can often lead to inefficient energy usage. More importantly, we
demonstrate that there is a tradeoff between energy consumption and performance
optimization. To this end, we propose Zeus, an optimization framework to
navigate this tradeoff by automatically finding optimal job- and GPU-level
configurations for recurring DNN training jobs. Zeus uses an online
exploration-exploitation approach in conjunction with just-in-time energy
profiling, averting the need for expensive offline measurements, while adapting
to data drifts over time. Our evaluation shows that Zeus can improve the energy
efficiency of DNN training by 15.3%-75.8% for diverse workloads."
When to Make Exceptions: Exploring Language Models as Accounts of Human Moral Judgment,0.684473,"AI systems are becoming increasingly intertwined with human life. In order to
effectively collaborate with humans and ensure safety, AI systems need to be
able to understand, interpret and predict human moral judgments and decisions.
Human moral judgments are often guided by rules, but not always. A central
challenge for AI safety is capturing the flexibility of the human moral mind --
the ability to determine when a rule should be broken, especially in novel or
unusual situations. In this paper, we present a novel challenge set consisting
of rule-breaking question answering (RBQA) of cases that involve potentially
permissible rule-breaking -- inspired by recent moral psychology studies. Using
a state-of-the-art large language model (LLM) as a basis, we propose a novel
moral chain of thought (MORALCOT) prompting strategy that combines the
strengths of LLMs with theories of moral reasoning developed in cognitive
science to predict human moral judgments. MORALCOT outperforms seven existing
LLMs by 6.2% F1, suggesting that modeling human reasoning might be necessary to
capture the flexibility of the human moral mind. We also conduct a detailed
error analysis to suggest directions for future work to improve AI safety using
RBQA. Our data is open-sourced at
https://huggingface.co/datasets/feradauto/MoralExceptQA and code at
https://github.com/feradauto/MoralCoT"
Algorithms for Weighted Pushdown Automata,0.872058,"Weighted pushdown automata (WPDAs) are at the core of many natural language
processing tasks, like syntax-based statistical machine translation and
transition-based dependency parsing. As most existing dynamic programming
algorithms are designed for context-free grammars (CFGs), algorithms for PDAs
often resort to a PDA-to-CFG conversion. In this paper, we develop novel
algorithms that operate directly on WPDAs. Our algorithms are inspired by
Lang's algorithm, but use a more general definition of pushdown automaton and
either reduce the space requirements by a factor of $|\Gamma|$ (the size of the
stack alphabet) or reduce the runtime by a factor of more than $|Q|$ (the
number of states). When run on the same class of PDAs as Lang's algorithm, our
algorithm is both more space-efficient by a factor of $|\Gamma|$ and more
time-efficient by a factor of $|Q| \cdot |\Gamma|$."
BD-SHS: A Benchmark Dataset for Learning to Detect Online Bangla Hate Speech in Different Social Contexts,0.763829,"Social media platforms and online streaming services have spawned a new breed
of Hate Speech (HS). Due to the massive amount of user-generated content on
these sites, modern machine learning techniques are found to be feasible and
cost-effective to tackle this problem. However, linguistically diverse datasets
covering different social contexts in which offensive language is typically
used are required to train generalizable models. In this paper, we identify the
shortcomings of existing Bangla HS datasets and introduce a large manually
labeled dataset BD-SHS that includes HS in different social contexts. The
labeling criteria were prepared following a hierarchical annotation process,
which is the first of its kind in Bangla HS to the best of our knowledge. The
dataset includes more than 50,200 offensive comments crawled from online social
networking sites and is at least 60% larger than any existing Bangla HS
datasets. We present the benchmark result of our dataset by training different
NLP models resulting in the best one achieving an F1-score of 91.0%. In our
experiments, we found that a word embedding trained exclusively using 1.47
million comments from social media and streaming sites consistently resulted in
better modeling of HS detection in comparison to other pre-trained embeddings.
Our dataset and all accompanying codes is publicly available at
github.com/naurosromim/hate-speech-dataset-for-Bengali-social-media"
ChatGPT in Drug Discovery: A Case Study on Anti-Cocaine Addiction Drug Development with Chatbots,0.650692,"The birth of ChatGPT, a cutting-edge language model-based chatbot developed
by OpenAI, ushered in a new era in AI. However, due to potential pitfalls, its
role in rigorous scientific research is not clear yet. This paper vividly
showcases its innovative application within the field of drug discovery.
Focused specifically on developing anti-cocaine addiction drugs, the study
employs GPT-4 as a virtual guide, offering strategic and methodological
insights to researchers working on generative models for drug candidates. The
primary objective is to generate optimal drug-like molecules with desired
properties. By leveraging the capabilities of ChatGPT, the study introduces a
novel approach to the drug discovery process. This symbiotic partnership
between AI and researchers transforms how drug development is approached.
Chatbots become facilitators, steering researchers towards innovative
methodologies and productive paths for creating effective drug candidates. This
research sheds light on the collaborative synergy between human expertise and
AI assistance, wherein ChatGPT's cognitive abilities enhance the design and
development of potential pharmaceutical solutions. This paper not only explores
the integration of advanced AI in drug discovery but also reimagines the
landscape by advocating for AI-powered chatbots as trailblazers in
revolutionizing therapeutic innovation."
Inharmonious Region Localization by Magnifying Domain Discrepancy,0.439665,"Inharmonious region localization aims to localize the region in a synthetic
image which is incompatible with surrounding background. The inharmony issue is
mainly attributed to the color and illumination inconsistency produced by image
editing techniques. In this work, we tend to transform the input image to
another color space to magnify the domain discrepancy between inharmonious
region and background, so that the model can identify the inharmonious region
more easily. To this end, we present a novel framework consisting of a color
mapping module and an inharmonious region localization network, in which the
former is equipped with a novel domain discrepancy magnification loss and the
latter could be an arbitrary localization network. Extensive experiments on
image harmonization dataset show the superiority of our designed framework. Our
code is available at
https://github.com/bcmi/MadisNet-Inharmonious-Region-Localization."
Open ERP System Data For Occupational Fraud Detection,0.752655,"Recent estimates report that companies lose 5% of their revenue to
occupational fraud. Since most medium-sized and large companies employ
Enterprise Resource Planning (ERP) systems to track vast amounts of information
regarding their business process, researchers have in the past shown interest
in automatically detecting fraud through ERP system data. Current research in
this area, however, is hindered by the fact that ERP system data is not
publicly available for the development and comparison of fraud detection
methods. We therefore endeavour to generate public ERP system data that
includes both normal business operation and fraud. We propose a strategy for
generating ERP system data through a serious game, model a variety of fraud
scenarios in cooperation with auditing experts, and generate data from a
simulated make-to-stock production company with multiple research participants.
We aggregate the generated data into ready to used datasets for fraud detection
in ERP systems, and supply both the raw and aggregated data to the general
public to allow for open development and comparison of fraud detection
approaches on ERP system data."
Toward Smart Doors: A Position Paper,0.586407,"Conventional automatic doors cannot distinguish between people wishing to
pass through the door and people passing by the door, so they often open
unnecessarily. This leads to the need to adopt new systems in both commercial
and non-commercial environments: smart doors. In particular, a smart door
system predicts the intention of people near the door based on the social
context of the surrounding environment and then makes rational decisions about
whether or not to open the door. This work proposes the first position paper
related to smart doors, without bells and whistles. We first point out that the
problem not only concerns reliability, climate control, safety, and mode of
operation. Indeed, a system to predict the intention of people near the door
also involves a deeper understanding of the social context of the scene through
a complex combined analysis of proxemics and scene reasoning. Furthermore, we
conduct an exhaustive literature review about automatic doors, providing a
novel system formulation. Also, we present an analysis of the possible future
application of smart doors, a description of the ethical shortcomings, and
legislative issues."
Mind the Gap! Bridging Explainable Artificial Intelligence and Human Understanding with Luhmann's Functional Theory of Communication,0.311715,"Over the past decade explainable artificial intelligence has evolved from a
predominantly technical discipline into a field that is deeply intertwined with
social sciences. Insights such as human preference for contrastive -- more
precisely, counterfactual -- explanations have played a major role in this
transition, inspiring and guiding the research in computer science. Other
observations, while equally important, have received much less attention. The
desire of human explainees to communicate with artificial intelligence
explainers through a dialogue-like interaction has been mostly neglected by the
community. This poses many challenges for the effectiveness and widespread
adoption of such technologies as delivering a single explanation optimised
according to some predefined objectives may fail to engender understanding in
its recipients and satisfy their unique needs given the diversity of human
knowledge and intention. Using insights elaborated by Niklas Luhmann and, more
recently, Elena Esposito we apply social systems theory to highlight challenges
in explainable artificial intelligence and offer a path forward, striving to
reinvigorate the technical research in this direction. This paper aims to
demonstrate the potential of systems theoretical approaches to communication in
understanding problems and limitations of explainable artificial intelligence."
Computationally efficient joint coordination of multiple electric vehicle charging points using reinforcement learning,0.12151,"A major challenge in todays power grid is to manage the increasing load from
electric vehicle (EV) charging. Demand response (DR) solutions aim to exploit
flexibility therein, i.e., the ability to shift EV charging in time and thus
avoid excessive peaks or achieve better balancing. Whereas the majority of
existing research works either focus on control strategies for a single EV
charger, or use a multi-step approach (e.g., a first high level aggregate
control decision step, followed by individual EV control decisions), we rather
propose a single-step solution that jointly coordinates multiple charging
points at once. In this paper, we further refine an initial proposal using
reinforcement learning (RL), specifically addressing computational challenges
that would limit its deployment in practice. More precisely, we design a new
Markov decision process (MDP) formulation of the EV charging coordination
process, exhibiting only linear space and time complexity (as opposed to the
earlier quadratic space complexity). We thus improve upon earlier
state-of-the-art, demonstrating 30% reduction of training time in our case
study using real-world EV charging session data. Yet, we do not sacrifice the
resulting performance in meeting the DR objectives: our new RL solutions still
improve the performance of charging demand coordination by 40-50% compared to a
business-as-usual policy (that charges EV fully upon arrival) and 20-30%
compared to a heuristic policy (that uniformly spreads individual EV charging
over time)."
MoCoSA: Momentum Contrast for Knowledge Graph Completion with Structure-Augmented Pre-trained Language Models,0.417439,"Knowledge Graph Completion (KGC) aims to conduct reasoning on the facts
within knowledge graphs and automatically infer missing links. Existing methods
can mainly be categorized into structure-based or description-based. On the one
hand, structure-based methods effectively represent relational facts in
knowledge graphs using entity embeddings. However, they struggle with
semantically rich real-world entities due to limited structural information and
fail to generalize to unseen entities. On the other hand, description-based
methods leverage pre-trained language models (PLMs) to understand textual
information. They exhibit strong robustness towards unseen entities. However,
they have difficulty with larger negative sampling and often lag behind
structure-based methods. To address these issues, in this paper, we propose
Momentum Contrast for knowledge graph completion with Structure-Augmented
pre-trained language models (MoCoSA), which allows the PLM to perceive the
structural information by the adaptable structure encoder. To improve learning
efficiency, we proposed momentum hard negative and intra-relation negative
sampling. Experimental results demonstrate that our approach achieves
state-of-the-art performance in terms of mean reciprocal rank (MRR), with
improvements of 2.5% on WN18RR and 21% on OpenBG500."
Lymphoma segmentation from 3D PET-CT images using a deep evidential network,0.304672,"An automatic evidential segmentation method based on Dempster-Shafer theory
and deep learning is proposed to segment lymphomas from three-dimensional
Positron Emission Tomography (PET) and Computed Tomography (CT) images. The
architecture is composed of a deep feature-extraction module and an evidential
layer. The feature extraction module uses an encoder-decoder framework to
extract semantic feature vectors from 3D inputs. The evidential layer then uses
prototypes in the feature space to compute a belief function at each voxel
quantifying the uncertainty about the presence or absence of a lymphoma at this
location. Two evidential layers are compared, based on different ways of using
distances to prototypes for computing mass functions. The whole model is
trained end-to-end by minimizing the Dice loss function. The proposed
combination of deep feature extraction and evidential segmentation is shown to
outperform the baseline UNet model as well as three other state-of-the-art
models on a dataset of 173 patients."
Understanding the Failure of Batch Normalization for Transformers in NLP,0.260124,"Batch Normalization (BN) is a core and prevalent technique in accelerating
the training of deep neural networks and improving the generalization on
Computer Vision (CV) tasks. However, it fails to defend its position in Natural
Language Processing (NLP), which is dominated by Layer Normalization (LN). In
this paper, we are trying to answer why BN usually performs worse than LN in
NLP tasks with Transformer models. We find that the inconsistency between
training and inference of BN is the leading cause that results in the failure
of BN in NLP. We define Training Inference Discrepancy (TID) to quantitatively
measure this inconsistency and reveal that TID can indicate BN's performance,
supported by extensive experiments, including image classification, neural
machine translation, language modeling, sequence labeling, and text
classification tasks. We find that BN can obtain much better test performance
than LN when TID keeps small through training. To suppress the explosion of
TID, we propose Regularized BN (RBN) that adds a simple regularization term to
narrow the gap between batch statistics and population statistics of BN. RBN
improves the performance of BN consistently and outperforms or is on par with
LN on 17 out of 20 settings, involving ten datasets and two common variants of
Transformer
  Our code is available at https://github.com/wjxts/RegularizedBN."
Portrait Segmentation Using Deep Learning,0.0381225,"A portrait is a painting, drawing, photograph, or engraving of a person,
especially one depicting only the face or head and shoulders. In the digital
world the portrait of a person is captured by having the person as a subject in
the image and capturing the image of the person such that the background is
blurred. DSLRs generally do it by reducing the aperture to focus on very close
regions of interest and automatically blur the background. In this paper I have
come up with a novel approach to replicate the portrait mode from DSLR using
any smartphone to generate high quality portrait images."
Instant Neural Graphics Primitives with a Multiresolution Hash Encoding,1.0,"Neural graphics primitives, parameterized by fully connected neural networks,
can be costly to train and evaluate. We reduce this cost with a versatile new
input encoding that permits the use of a smaller network without sacrificing
quality, thus significantly reducing the number of floating point and memory
access operations: a small neural network is augmented by a multiresolution
hash table of trainable feature vectors whose values are optimized through
stochastic gradient descent. The multiresolution structure allows the network
to disambiguate hash collisions, making for a simple architecture that is
trivial to parallelize on modern GPUs. We leverage this parallelism by
implementing the whole system using fully-fused CUDA kernels with a focus on
minimizing wasted bandwidth and compute operations. We achieve a combined
speedup of several orders of magnitude, enabling training of high-quality
neural graphics primitives in a matter of seconds, and rendering in tens of
milliseconds at a resolution of ${1920\!\times\!1080}$."
ZhichunRoad at Amazon KDD Cup 2022: MultiTask Pre-Training for E-Commerce Product Search,0.320298,"In this paper, we propose a robust multilingual model to improve the quality
of search results. Our model not only leverage the processed class-balanced
dataset, but also benefit from multitask pre-training that leads to more
general representations. In pre-training stage, we adopt mlm task,
classification task and contrastive learning task to achieve considerably
performance. In fine-tuning stage, we use confident learning, exponential
moving average method (EMA), adversarial training (FGM) and regularized dropout
strategy (R-Drop) to improve the model's generalization and robustness.
Moreover, we use a multi-granular semantic unit to discover the queries and
products textual metadata for enhancing the representation of the model. Our
approach obtained competitive results and ranked top-8 in three tasks. We
release the source code and pre-trained models associated with this work."
A Two-Stage Framework with Self-Supervised Distillation For Cross-Domain Text Classification,0.101032,"Cross-domain text classification aims to adapt models to a target domain that
lacks labeled data. It leverages or reuses rich labeled data from the different
but related source domain(s) and unlabeled data from the target domain. To this
end, previous work focuses on either extracting domain-invariant features or
task-agnostic features, ignoring domain-aware features that may be present in
the target domain and could be useful for the downstream task. In this paper,
we propose a two-stage framework for cross-domain text classification. In the
first stage, we finetune the model with mask language modeling (MLM) and
labeled data from the source domain. In the second stage, we further fine-tune
the model with self-supervised distillation (SSD) and unlabeled data from the
target domain. We evaluate its performance on a public cross-domain text
classification benchmark and the experiment results show that our method
achieves new state-of-the-art results for both single-source domain adaptations
(94.17% $\uparrow$1.03%) and multi-source domain adaptations (95.09%
$\uparrow$1.34%)."
RAMBO-RL: Robust Adversarial Model-Based Offline Reinforcement Learning,0.946876,"Offline reinforcement learning (RL) aims to find performant policies from
logged data without further environment interaction. Model-based algorithms,
which learn a model of the environment from the dataset and perform
conservative policy optimisation within that model, have emerged as a promising
approach to this problem. In this work, we present Robust Adversarial
Model-Based Offline RL (RAMBO), a novel approach to model-based offline RL. We
formulate the problem as a two-player zero sum game against an adversarial
environment model. The model is trained to minimise the value function while
still accurately predicting the transitions in the dataset, forcing the policy
to act conservatively in areas not covered by the dataset. To approximately
solve the two-player game, we alternate between optimising the policy and
adversarially optimising the model. The problem formulation that we address is
theoretically grounded, resulting in a probably approximately correct (PAC)
performance guarantee and a pessimistic value function which lower bounds the
value function in the true environment. We evaluate our approach on widely
studied offline RL benchmarks, and demonstrate that it outperforms existing
state-of-the-art baselines."
Efficient universal shuffle attack for visual object tracking,0.622087,"Recently, adversarial attacks have been applied in visual object tracking to
deceive deep trackers by injecting imperceptible perturbations into video
frames. However, previous work only generates the video-specific perturbations,
which restricts its application scenarios. In addition, existing attacks are
difficult to implement in reality due to the real-time of tracking and the
re-initialization mechanism. To address these issues, we propose an offline
universal adversarial attack called Efficient Universal Shuffle Attack. It
takes only one perturbation to cause the tracker malfunction on all videos. To
improve the computational efficiency and attack performance, we propose a
greedy gradient strategy and a triple loss to efficiently capture and attack
model-specific feature representations through the gradients. Experimental
results show that EUSA can significantly reduce the performance of
state-of-the-art trackers on OTB2015 and VOT2018."
SelfAct: Personalized Activity Recognition based on Self-Supervised and Active Learning,0.130981,"Supervised Deep Learning (DL) models are currently the leading approach for
sensor-based Human Activity Recognition (HAR) on wearable and mobile devices.
However, training them requires large amounts of labeled data whose collection
is often time-consuming, expensive, and error-prone. At the same time, due to
the intra- and inter-variability of activity execution, activity models should
be personalized for each user. In this work, we propose SelfAct: a novel
framework for HAR combining self-supervised and active learning to mitigate
these problems. SelfAct leverages a large pool of unlabeled data collected from
many users to pre-train through self-supervision a DL model, with the goal of
learning a meaningful and efficient latent representation of sensor data. The
resulting pre-trained model can be locally used by new users, which will
fine-tune it thanks to a novel unsupervised active learning strategy. Our
experiments on two publicly available HAR datasets demonstrate that SelfAct
achieves results that are close to or even better than the ones of fully
supervised approaches with a small number of active learning queries."
It Takes Two to Tango: Navigating Conceptualizations of NLP Tasks and Measurements of Performance,0.146577,"Progress in NLP is increasingly measured through benchmarks; hence,
contextualizing progress requires understanding when and why practitioners may
disagree about the validity of benchmarks. We develop a taxonomy of
disagreement, drawing on tools from measurement modeling, and distinguish
between two types of disagreement: 1) how tasks are conceptualized and 2) how
measurements of model performance are operationalized. To provide evidence for
our taxonomy, we conduct a meta-analysis of relevant literature to understand
how NLP tasks are conceptualized, as well as a survey of practitioners about
their impressions of different factors that affect benchmark validity. Our
meta-analysis and survey across eight tasks, ranging from coreference
resolution to question answering, uncover that tasks are generally not clearly
and consistently conceptualized and benchmarks suffer from operationalization
disagreements. These findings support our proposed taxonomy of disagreement.
Finally, based on our taxonomy, we present a framework for constructing
benchmarks and documenting their limitations."
Dialogue Meaning Representation for Task-Oriented Dialogue Systems,0.404541,"Dialogue meaning representation formulates natural language utterance
semantics in their conversational context in an explicit and machine-readable
form. Previous work typically follows the intent-slot framework, which is easy
for annotation yet limited in scalability for complex linguistic expressions. A
line of works alleviates the representation issue by introducing hierarchical
structures but challenging to express complex compositional semantics, such as
negation and coreference. We propose Dialogue Meaning Representation (DMR), a
pliable and easily extendable representation for task-oriented dialogue. Our
representation contains a set of nodes and edges to represent rich
compositional semantics. Moreover, we propose an inheritance hierarchy
mechanism focusing on domain extensibility. Additionally, we annotated
DMR-FastFood, a multi-turn dialogue dataset with more than 70k utterances, with
DMR. We propose two evaluation tasks to evaluate different dialogue models and
a novel coreference resolution model GNNCoref for the graph-based coreference
resolution task. Experiments show that DMR can be parsed well with pre-trained
Seq2Seq models, and GNNCoref outperforms the baseline models by a large margin."
Compilable Neural Code Generation with Compiler Feedback,0.608209,"Automatically generating compilable programs with (or without) natural
language descriptions has always been a touchstone problem for computational
linguistics and automated software engineering. Existing deep-learning
approaches model code generation as text generation, either constrained by
grammar structures in decoder, or driven by pre-trained language models on
large-scale code corpus (e.g., CodeGPT, PLBART, and CodeT5). However, few of
them account for compilability of the generated programs. To improve
compilability of the generated programs, this paper proposes COMPCODER, a
three-stage pipeline utilizing compiler feedback for compilable code
generation, including language model fine-tuning, compilability reinforcement,
and compilability discrimination. Comprehensive experiments on two code
generation tasks demonstrate the effectiveness of our proposed approach,
improving the success rate of compilation from 44.18 to 89.18 in code
completion on average and from 70.3 to 96.2 in text-to-code generation,
respectively, when comparing with the state-of-the-art CodeGPT."
Exploring XAI for the Arts: Explaining Latent Space in Generative Music,0.505282,"Explainable AI has the potential to support more interactive and fluid
co-creative AI systems which can creatively collaborate with people. To do
this, creative AI models need to be amenable to debugging by offering
eXplainable AI (XAI) features which are inspectable, understandable, and
modifiable. However, currently there is very little XAI for the arts. In this
work, we demonstrate how a latent variable model for music generation can be
made more explainable; specifically we extend MeasureVAE which generates
measures of music. We increase the explainability of the model by: i) using
latent space regularisation to force some specific dimensions of the latent
space to map to meaningful musical attributes, ii) providing a user interface
feedback loop to allow people to adjust dimensions of the latent space and
observe the results of these changes in real-time, iii) providing a
visualisation of the musical attributes in the latent space to help people
understand and predict the effect of changes to latent space dimensions. We
suggest that in doing so we bridge the gap between the latent space and the
generated musical outcomes in a meaningful way which makes the model and its
outputs more explainable and more debuggable."
"Cross-document Event Coreference Search: Task, Dataset and Modeling",0.632121,"The task of Cross-document Coreference Resolution has been traditionally
formulated as requiring to identify all coreference links across a given set of
documents. We propose an appealing, and often more applicable, complementary
set up for the task - Cross-document Coreference Search, focusing in this paper
on event coreference. Concretely, given a mention in context of an event of
interest, considered as a query, the task is to find all coreferring mentions
for the query event in a large document collection. To support research on this
task, we create a corresponding dataset, which is derived from Wikipedia while
leveraging annotations in the available Wikipedia Event Coreference dataset
(WEC-Eng). Observing that the coreference search setup is largely analogous to
the setting of Open Domain Question Answering, we adapt the prominent Deep
Passage Retrieval (DPR) model to our setting, as an appealing baseline.
Finally, we present a novel model that integrates a powerful coreference
scoring scheme into the DPR architecture, yielding improved performance."
Personal Protective Equipment Detection in Extreme Construction Conditions,0.398769,"Object detection has been widely applied for construction safety management,
especially personal protective equipment (PPE) detection. Though the existing
PPE detection models trained on conventional datasets have achieved excellent
results, their performance dramatically declines in extreme construction
conditions. A robust detection model NST-YOLOv5 is developed by combining the
neural style transfer (NST) and YOLOv5 technologies. Five extreme conditions
are considered and simulated via the NST module to endow the detection model
with excellent robustness, including low light, intense light, sand dust, fog,
and rain. Experiments show that the NST has great potential as a tool for
extreme data synthesis since it is better at simulating extreme conditions than
other traditional image processing algorithms and helps the NST-YOLOv5 achieve
0.141 and 0.083 mAP_(05:95) improvements in synthesized and real-world extreme
data. This study provides a new feasible way to obtain a more robust detection
model for extreme construction conditions."
CRCNet: Few-shot Segmentation with Cross-Reference and Region-Global Conditional Networks,0.280105,"Few-shot segmentation aims to learn a segmentation model that can be
generalized to novel classes with only a few training images. In this paper, we
propose a Cross-Reference and Local-Global Conditional Networks (CRCNet) for
few-shot segmentation. Unlike previous works that only predict the query
image's mask, our proposed model concurrently makes predictions for both the
support image and the query image. Our network can better find the co-occurrent
objects in the two images with a cross-reference mechanism, thus helping the
few-shot segmentation task. To further improve feature comparison, we develop a
local-global conditional module to capture both global and local relations. We
also develop a mask refinement module to refine the prediction of the
foreground regions recurrently. Experiments on the PASCAL VOC 2012, MS COCO,
and FSS-1000 datasets show that our network achieves new state-of-the-art
performance."
Skeleton-based Human Action Recognition via Convolutional Neural Networks (CNN),0.809814,"Recently, there has been a remarkable increase in the interest towards
skeleton-based action recognition within the research community, owing to its
various advantageous features, including computational efficiency,
representative features, and illumination invariance. Despite this, researchers
continue to explore and investigate the most optimal way to represent human
actions through skeleton representation and the extracted features. As a
result, the growth and availability of human action recognition datasets have
risen substantially. In addition, deep learning-based algorithms have gained
widespread popularity due to the remarkable advancements in various computer
vision tasks. Most state-of-the-art contributions in skeleton-based action
recognition incorporate a Graph Neural Network (GCN) architecture for
representing the human body and extracting features. Our research demonstrates
that Convolutional Neural Networks (CNNs) can attain comparable results to GCN,
provided that the proper training techniques, augmentations, and optimizers are
applied. Our approach has been rigorously validated, and we have achieved a
score of 95% on the NTU-60 dataset"
AI Autonomy : Self-Initiated Open-World Continual Learning and Adaptation,0.121884,"As more and more AI agents are used in practice, it is time to think about
how to make these agents fully autonomous so that they can (1) learn by
themselves continually in a self-motivated and self-initiated manner rather
than being retrained offline periodically on the initiation of human engineers
and (2) accommodate or adapt to unexpected or novel circumstances. As the
real-world is an open environment that is full of unknowns or novelties, the
capabilities of detecting novelties, characterizing them,
accommodating/adapting to them, gathering ground-truth training data and
incrementally learning the unknowns/novelties become critical in making the AI
agent more and more knowledgeable, powerful and self-sustainable over time. The
key challenge here is how to automate the process so that it is carried out
continually on the agent's own initiative and through its own interactions with
humans, other agents and the environment just like human on-the-job learning.
This paper proposes a framework (called SOLA) for this learning paradigm to
promote the research of building autonomous and continual learning enabled AI
agents. To show feasibility, an implemented agent is also described."
"Human Detection of Political Speech Deepfakes across Transcripts, Audio, and Video",0.333658,"Recent advances in technology for hyper-realistic visual and audio effects
provoke the concern that deepfake videos of political speeches will soon be
indistinguishable from authentic video recordings. The conventional wisdom in
communication theory predicts people will fall for fake news more often when
the same version of a story is presented as a video versus text. We conduct 5
pre-registered randomized experiments with 2,215 participants to evaluate how
accurately humans distinguish real political speeches from fabrications across
base rates of misinformation, audio sources, question framings, and media
modalities. We find base rates of misinformation minimally influence
discernment and deepfakes with audio produced by the state-of-the-art
text-to-speech algorithms are harder to discern than the same deepfakes with
voice actor audio. Moreover across all experiments, we find audio and visual
information enables more accurate discernment than text alone: human
discernment relies more on how something is said, the audio-visual cues, than
what is said, the speech content."
Towards Trustworthy Multi-label Sewer Defect Classification via Evidential Deep Learning,0.656177,"An automatic vision-based sewer inspection plays a key role of sewage system
in a modern city. Recent advances focus on utilizing deep learning model to
realize the sewer inspection system, benefiting from the capability of
data-driven feature representation. However, the inherent uncertainty of sewer
defects is ignored, resulting in the missed detection of serious unknown sewer
defect categories. In this paper, we propose a trustworthy multi-label sewer
defect classification (TMSDC) method, which can quantify the uncertainty of
sewer defect prediction via evidential deep learning. Meanwhile, a novel expert
base rate assignment (EBRA) is proposed to introduce the expert knowledge for
describing reliable evidences in practical situations. Experimental results
demonstrate the effectiveness of TMSDC and the superior capability of
uncertainty estimation is achieved on the latest public benchmark."
AffectMachine-Classical: A novel system for generating affective classical music,0.035964,"This work introduces a new music generation system, called
AffectMachine-Classical, that is capable of generating affective Classic music
in real-time. AffectMachine was designed to be incorporated into biofeedback
systems (such as brain-computer-interfaces) to help users become aware of, and
ultimately mediate, their own dynamic affective states. That is, this system
was developed for music-based MedTech to support real-time emotion
self-regulation in users. We provide an overview of the rule-based,
probabilistic system architecture, describing the main aspects of the system
and how they are novel. We then present the results of a listener study that
was conducted to validate the ability of the system to reliably convey target
emotions to listeners. The findings indicate that AffectMachine-Classical is
very effective in communicating various levels of Arousal ($R^2 = .96$) to
listeners, and is also quite convincing in terms of Valence (R^2 = .90). Future
work will embed AffectMachine-Classical into biofeedback systems, to leverage
the efficacy of the affective music for emotional well-being in listeners."
LostNet: A smart way for lost and find,0.917915,"Due to the enormous population growth of cities in recent years, objects are
frequently lost and unclaimed on public transportation, in restaurants, or any
other public areas. While services like Find My iPhone can easily identify lost
electronic devices, more valuable objects cannot be tracked in an intelligent
manner, making it impossible for administrators to reclaim a large number of
lost and found items in a timely manner. We present a method that significantly
reduces the complexity of searching by comparing previous images of lost and
recovered things provided by the owner with photos taken when registered lost
and found items are received. In this research, we will primarily design a
photo matching network by combining the fine-tuning method of MobileNetv2 with
CBAM Attention and using the Internet framework to develop an online lost and
found image identification system. Our implementation gets a testing accuracy
of 96.8% using only 665.12M GLFOPs and 3.5M training parameters. It can
recognize practice images and can be run on a regular laptop."
Will Large-scale Generative Models Corrupt Future Datasets?,0.298103,"Recently proposed large-scale text-to-image generative models such as
DALL$\cdot$E 2, Midjourney, and StableDiffusion can generate high-quality and
realistic images from users' prompts. Not limited to the research community,
ordinary Internet users enjoy these generative models, and consequently, a
tremendous amount of generated images have been shared on the Internet.
Meanwhile, today's success of deep learning in the computer vision field owes a
lot to images collected from the Internet. These trends lead us to a research
question: ""\textbf{will such generated images impact the quality of future
datasets and the performance of computer vision models positively or
negatively?}"" This paper empirically answers this question by simulating
contamination. Namely, we generate ImageNet-scale and COCO-scale datasets using
a state-of-the-art generative model and evaluate models trained with
""contaminated"" datasets on various tasks, including image classification and
image generation. Throughout experiments, we conclude that generated images
negatively affect downstream performance, while the significance depends on
tasks and the amount of generated images. The generated datasets and the codes
for experiments will be publicly released for future research. Generated
datasets and source codes are available from
\url{https://github.com/moskomule/dataset-contamination}."
On the Importance of Asymmetry for Siamese Representation Learning,0.642189,"Many recent self-supervised frameworks for visual representation learning are
based on certain forms of Siamese networks. Such networks are conceptually
symmetric with two parallel encoders, but often practically asymmetric as
numerous mechanisms are devised to break the symmetry. In this work, we conduct
a formal study on the importance of asymmetry by explicitly distinguishing the
two encoders within the network -- one produces source encodings and the other
targets. Our key insight is keeping a relatively lower variance in target than
source generally benefits learning. This is empirically justified by our
results from five case studies covering different variance-oriented designs,
and is aligned with our preliminary theoretical analysis on the baseline.
Moreover, we find the improvements from asymmetric designs generalize well to
longer training schedules, multiple other frameworks and newer backbones.
Finally, the combined effect of several asymmetric designs achieves a
state-of-the-art accuracy on ImageNet linear probing and competitive results on
downstream transfer. We hope our exploration will inspire more research in
exploiting asymmetry for Siamese representation learning."
Enhancing Deformable Convolution based Video Frame Interpolation with Coarse-to-fine 3D CNN,0.35693,"This paper presents a new deformable convolution-based video frame
interpolation (VFI) method, using a coarse to fine 3D CNN to enhance the
multi-flow prediction. This model first extracts spatio-temporal features at
multiple scales using a 3D CNN, and estimates multi-flows using these features
in a coarse-to-fine manner. The estimated multi-flows are then used to warp the
original input frames as well as context maps, and the warped results are fused
by a synthesis network to produce the final output. This VFI approach has been
fully evaluated against 12 state-of-the-art VFI methods on three commonly used
test databases. The results evidently show the effectiveness of the proposed
method, which offers superior interpolation performance over other state of the
art algorithms, with PSNR gains up to 0.19dB."
"Global Counterfactual Explanations: Investigations, Implementations and Improvements",0.568708,"Counterfactual explanations have been widely studied in explainability, with
a range of application dependent methods emerging in fairness, recourse and
model understanding. However, the major shortcoming associated with these
methods is their inability to provide explanations beyond the local or
instance-level. While some works touch upon the notion of a global explanation,
typically suggesting to aggregate masses of local explanations in the hope of
ascertaining global properties, few provide frameworks that are either reliable
or computationally tractable. Meanwhile, practitioners are requesting more
efficient and interactive explainability tools. We take this opportunity to
investigate existing global methods, with a focus on implementing and improving
Actionable Recourse Summaries (AReS), the only known global counterfactual
explanation framework for recourse."
Neural Neighbor Style Transfer,0.468282,"We propose Neural Neighbor Style Transfer (NNST), a pipeline that offers
state-of-the-art quality, generalization, and competitive efficiency for
artistic style transfer. Our approach is based on explicitly replacing neural
features extracted from the content input (to be stylized) with those from a
style exemplar, then synthesizing the final output based on these rearranged
features. While the spirit of our approach is similar to prior work, we show
that our design decisions dramatically improve the final visual quality."
DDS3D: Dense Pseudo-Labels with Dynamic Threshold for Semi-Supervised 3D Object Detection,0.815199,"In this paper, we present a simple yet effective semi-supervised 3D object
detector named DDS3D. Our main contributions have two-fold. On the one hand,
different from previous works using Non-Maximal Suppression (NMS) or its
variants for obtaining the sparse pseudo labels, we propose a dense
pseudo-label generation strategy to get dense pseudo-labels, which can retain
more potential supervision information for the student network. On the other
hand, instead of traditional fixed thresholds, we propose a dynamic threshold
manner to generate pseudo-labels, which can guarantee the quality and quantity
of pseudo-labels during the whole training process. Benefiting from these two
components, our DDS3D outperforms the state-of-the-art semi-supervised 3d
object detection with mAP of 3.1% on the pedestrian and 2.1% on the cyclist
under the same configuration of 1% samples. Extensive ablation studies on the
KITTI dataset demonstrate the effectiveness of our DDS3D. The code and models
will be made publicly available at https://github.com/hust-jy/DDS3D"
Painterly Image Harmonization in Dual Domains,0.693953,"Image harmonization aims to produce visually harmonious composite images by
adjusting the foreground appearance to be compatible with the background. When
the composite image has photographic foreground and painterly background, the
task is called painterly image harmonization. There are only few works on this
task, which are either time-consuming or weak in generating well-harmonized
results. In this work, we propose a novel painterly harmonization network
consisting of a dual-domain generator and a dual-domain discriminator, which
harmonizes the composite image in both spatial domain and frequency domain. The
dual-domain generator performs harmonization by using AdaIN modules in the
spatial domain and our proposed ResFFT modules in the frequency domain. The
dual-domain discriminator attempts to distinguish the inharmonious patches
based on the spatial feature and frequency feature of each patch, which can
enhance the ability of generator in an adversarial manner. Extensive
experiments on the benchmark dataset show the effectiveness of our method. Our
code and model are available at
https://github.com/bcmi/PHDNet-Painterly-Image-Harmonization."
Efficient Virtual View Selection for 3D Hand Pose Estimation,0.696139,"3D hand pose estimation from single depth is a fundamental problem in
computer vision, and has wide applications.However, the existing methods still
can not achieve satisfactory hand pose estimation results due to view variation
and occlusion of human hand. In this paper, we propose a new virtual view
selection and fusion module for 3D hand pose estimation from single depth.We
propose to automatically select multiple virtual viewpoints for pose estimation
and fuse the results of all and find this empirically delivers accurate and
robust pose estimation. In order to select most effective virtual views for
pose fusion, we evaluate the virtual views based on the confidence of virtual
views using a light-weight network via network distillation. Experiments on
three main benchmark datasets including NYU, ICVL and Hands2019 demonstrate
that our method outperforms the state-of-the-arts on NYU and ICVL, and achieves
very competitive performance on Hands2019-Task1, and our proposed virtual view
selection and fusion module is both effective for 3D hand pose estimation."
Target-Driven Structured Transformer Planner for Vision-Language Navigation,0.525488,"Vision-language navigation is the task of directing an embodied agent to
navigate in 3D scenes with natural language instructions. For the agent,
inferring the long-term navigation target from visual-linguistic clues is
crucial for reliable path planning, which, however, has rarely been studied
before in literature. In this article, we propose a Target-Driven Structured
Transformer Planner (TD-STP) for long-horizon goal-guided and room layout-aware
navigation. Specifically, we devise an Imaginary Scene Tokenization mechanism
for explicit estimation of the long-term target (even located in unexplored
environments). In addition, we design a Structured Transformer Planner which
elegantly incorporates the explored room layout into a neural attention
architecture for structured and global planning. Experimental results
demonstrate that our TD-STP substantially improves previous best methods'
success rate by 2% and 5% on the test set of R2R and REVERIE benchmarks,
respectively. Our code is available at https://github.com/YushengZhao/TD-STP ."
Cross Cryptocurrency Relationship Mining for Bitcoin Price Prediction,0.203118,"Blockchain finance has become a part of the world financial system, most
typically manifested in the attention to the price of Bitcoin. However, a great
deal of work is still limited to using technical indicators to capture Bitcoin
price fluctuation, with little consideration of historical relationships and
interactions between related cryptocurrencies. In this work, we propose a
generic Cross-Cryptocurrency Relationship Mining module, named C2RM, which can
effectively capture the synchronous and asynchronous impact factors between
Bitcoin and related Altcoins. Specifically, we utilize the Dynamic Time Warping
algorithm to extract the lead-lag relationship, yielding Lead-lag Variance
Kernel, which will be used for aggregating the information of Altcoins to form
relational impact factors. Comprehensive experimental results demonstrate that
our C2RM can help existing price prediction methods achieve significant
performance improvement, suggesting the effectiveness of Cross-Cryptocurrency
interactions on benefitting Bitcoin price prediction."
VeriDark: A Large-Scale Benchmark for Authorship Verification on the Dark Web,0.522717,"The DarkWeb represents a hotbed for illicit activity, where users communicate
on different market forums in order to exchange goods and services. Law
enforcement agencies benefit from forensic tools that perform authorship
analysis, in order to identify and profile users based on their textual
content. However, authorship analysis has been traditionally studied using
corpora featuring literary texts such as fragments from novels or fan fiction,
which may not be suitable in a cybercrime context. Moreover, the few works that
employ authorship analysis tools for cybercrime prevention usually employ
ad-hoc experimental setups and datasets. To address these issues, we release
VeriDark: a benchmark comprised of three large scale authorship verification
datasets and one authorship identification dataset obtained from user activity
from either Dark Web related Reddit communities or popular illicit Dark Web
market forums. We evaluate competitive NLP baselines on the three datasets and
perform an analysis of the predictions to better understand the limitations of
such approaches. We make the datasets and baselines publicly available at
https://github.com/bit-ml/VeriDark"
Granular-ball Optimization Algorithm,0.111733,"The existing intelligent optimization algorithms are designed based on the
finest granularity, i.e., a point. This leads to weak global search ability and
inefficiency. To address this problem, we proposed a novel multi-granularity
optimization algorithm, namely granular-ball optimization algorithm (GBO), by
introducing granular-ball computing. GBO uses many granular-balls to cover the
solution space. Quite a lot of small and fine-grained granular-balls are used
to depict the important parts, and a little number of large and coarse-grained
granular-balls are used to depict the inessential parts. Fine multi-granularity
data description ability results in a higher global search capability and
faster convergence speed. In comparison with the most popular and
state-of-the-art algorithms, the experiments on twenty benchmark functions
demonstrate its better performance. The faster speed, higher approximation
ability of optimal solution, no hyper-parameters, and simpler design of GBO
make it an all-around replacement of most of the existing popular intelligent
optimization algorithms."
Mixture of Soft Prompts for Controllable Data Generation,0.497039,"Large language models (LLMs) effectively generate fluent text when the target
output follows natural language patterns. However, structured prediction tasks
confine the output format to a limited ontology, causing even very large models
to struggle since they were never trained with such restrictions in mind. The
difficulty of using LLMs for direct prediction is exacerbated in few-shot
learning scenarios, which commonly arise due to domain shift and resource
limitations. We flip the problem on its head by leveraging the LLM as a tool
for data augmentation rather than direct prediction. Our proposed Mixture of
Soft Prompts (MSP) serves as a parameter-efficient procedure for generating
data in a controlled manner. Denoising mechanisms are further applied to
improve the quality of synthesized data. Automatic metrics show our method is
capable of producing diverse and natural text, while preserving label
semantics. Moreover, MSP achieves state-of-the-art results on three benchmarks
when compared against strong baselines. Our method offers an alternate
data-centric approach for applying LLMs to complex prediction tasks."
Towards the Next 1000 Languages in Multilingual Machine Translation: Exploring the Synergy Between Supervised and Self-Supervised Learning,0.790663,"Achieving universal translation between all human language pairs is the
holy-grail of machine translation (MT) research. While recent progress in
massively multilingual MT is one step closer to reaching this goal, it is
becoming evident that extending a multilingual MT system simply by training on
more parallel data is unscalable, since the availability of labeled data for
low-resource and non-English-centric language pairs is forbiddingly limited. To
this end, we present a pragmatic approach towards building a multilingual MT
model that covers hundreds of languages, using a mixture of supervised and
self-supervised objectives, depending on the data availability for different
language pairs. We demonstrate that the synergy between these two training
paradigms enables the model to produce high-quality translations in the
zero-resource setting, even surpassing supervised translation quality for low-
and mid-resource languages. We conduct a wide array of experiments to
understand the effect of the degree of multilingual supervision, domain
mismatches and amounts of parallel and monolingual data on the quality of our
self-supervised multilingual models. To demonstrate the scalability of the
approach, we train models with over 200 languages and demonstrate high
performance on zero-resource translation on several previously under-studied
languages. We hope our findings will serve as a stepping stone towards enabling
translation for the next thousand languages."
Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing,0.25631,"Recent works in end-to-end speech-to-text translation (ST) have proposed
multi-tasking methods with soft parameter sharing which leverage machine
translation (MT) data via secondary encoders that map text inputs to an
eventual cross-modal representation. In this work, we instead propose a ST/MT
multi-tasking framework with hard parameter sharing in which all model
parameters are shared cross-modally. Our method reduces the speech-text
modality gap via a pre-processing stage which converts speech and text inputs
into two discrete token sequences of similar length -- this allows models to
indiscriminately process both modalities simply using a joint vocabulary. With
experiments on MuST-C, we demonstrate that our multi-tasking framework improves
attentional encoder-decoder, Connectionist Temporal Classification (CTC),
transducer, and joint CTC/attention models by an average of +0.5 BLEU without
any external MT data. Further, we show that this framework incorporates
external MT data, yielding +0.8 BLEU, and also improves transfer learning from
pre-trained textual models, yielding +1.8 BLEU."
Exploring the Limits of Domain-Adaptive Training for Detoxifying Large-Scale Language Models,0.754037,"Pre-trained language models (LMs) are shown to easily generate toxic
language. In this work, we systematically explore domain-adaptive training to
reduce the toxicity of language models. We conduct this study on three
dimensions: training corpus, model size, and parameter efficiency. For the
training corpus, we propose to leverage the generative power of LMs and
generate nontoxic datasets for domain-adaptive training, which mitigates the
exposure bias and is shown to be more data-efficient than using a curated
pre-training corpus. We demonstrate that the self-generation method
consistently outperforms the existing baselines across various model sizes on
both automatic and human evaluations, even when it uses a 1/3 smaller training
corpus. We then comprehensively study detoxifying LMs with parameter sizes
ranging from 126M up to 530B (3x larger than GPT-3), a scale that has never
been studied before. We find that i) large LMs have similar toxicity levels as
smaller ones given the same pre-training corpus, and ii) large LMs require more
endeavor to detoxify. We also explore parameter-efficient training methods for
detoxification. We demonstrate that adding and training adapter-only layers in
LMs not only saves a lot of parameters but also achieves a better trade-off
between toxicity and perplexity than whole model adaptation for the large-scale
models."
"Automated Clinical Coding: What, Why, and Where We Are?",0.95329,"Clinical coding is the task of transforming medical information in a
patient's health records into structured codes so that they can be used for
statistical analysis. This is a cognitive and time-consuming task that follows
a standard process in order to achieve a high level of consistency. Clinical
coding could potentially be supported by an automated system to improve the
efficiency and accuracy of the process. We introduce the idea of automated
clinical coding and summarise its challenges from the perspective of Artificial
Intelligence (AI) and Natural Language Processing (NLP), based on the
literature, our project experience over the past two and half years (late 2019
- early 2022), and discussions with clinical coding experts in Scotland and the
UK. Our research reveals the gaps between the current deep learning-based
approach applied to clinical coding and the need for explainability and
consistency in real-world practice. Knowledge-based methods that represent and
reason the standard, explainable process of a task may need to be incorporated
into deep learning-based methods for clinical coding. Automated clinical coding
is a promising task for AI, despite the technical and organisational
challenges. Coders are needed to be involved in the development process. There
is much to achieve to develop and deploy an AI-based automated system to
support coding in the next five years and beyond."
Open-TI: Open Traffic Intelligence with Augmented Language Model,0.791498,"Transportation has greatly benefited the cities' development in the modern
civilization process. Intelligent transportation, leveraging advanced computer
algorithms, could further increase people's daily commuting efficiency.
However, intelligent transportation, as a cross-discipline, often requires
practitioners to comprehend complicated algorithms and obscure neural networks,
bringing a challenge for the advanced techniques to be trusted and deployed in
practical industries. Recognizing the expressiveness of the pre-trained large
language models, especially the potential of being augmented with abilities to
understand and execute intricate commands, we introduce Open-TI. Serving as a
bridge to mitigate the industry-academic gap, Open-TI is an innovative model
targeting the goal of Turing Indistinguishable Traffic Intelligence, it is
augmented with the capability to harness external traffic analysis packages
based on existing conversations. Marking its distinction, Open-TI is the first
method capable of conducting exhaustive traffic analysis from scratch -
spanning from map data acquisition to the eventual execution in complex
simulations. Besides, Open-TI is able to conduct task-specific embodiment like
training and adapting the traffic signal control policies (TSC), explore demand
optimizations, etc. Furthermore, we explored the viability of LLMs directly
serving as control agents, by understanding the expected intentions from
Open-TI, we designed an agent-to-agent communication mode to support Open-TI
conveying messages to ChatZero (control agent), and then the control agent
would choose from the action space to proceed the execution. We eventually
provide the formal implementation structure, and the open-ended design invites
further community-driven enhancements."
SSL-Lanes: Self-Supervised Learning for Motion Forecasting in Autonomous Driving,0.521966,"Self-supervised learning (SSL) is an emerging technique that has been
successfully employed to train convolutional neural networks (CNNs) and graph
neural networks (GNNs) for more transferable, generalizable, and robust
representation learning. However its potential in motion forecasting for
autonomous driving has rarely been explored. In this study, we report the first
systematic exploration and assessment of incorporating self-supervision into
motion forecasting. We first propose to investigate four novel self-supervised
learning tasks for motion forecasting with theoretical rationale and
quantitative and qualitative comparisons on the challenging large-scale
Argoverse dataset. Secondly, we point out that our auxiliary SSL-based learning
setup not only outperforms forecasting methods which use transformers,
complicated fusion mechanisms and sophisticated online dense goal candidate
optimization algorithms in terms of performance accuracy, but also has low
inference time and architectural complexity. Lastly, we conduct several
experiments to understand why SSL improves motion forecasting. Code is
open-sourced at \url{https://github.com/AutoVision-cloud/SSL-Lanes}."
Design Booster: A Text-Guided Diffusion Model for Image Translation with Spatial Layout Preservation,0.158745,"Diffusion models are able to generate photorealistic images in arbitrary
scenes. However, when applying diffusion models to image translation, there
exists a trade-off between maintaining spatial structure and high-quality
content. Besides, existing methods are mainly based on test-time optimization
or fine-tuning model for each input image, which are extremely time-consuming
for practical applications. To address these issues, we propose a new approach
for flexible image translation by learning a layout-aware image condition
together with a text condition. Specifically, our method co-encodes images and
text into a new domain during the training phase. In the inference stage, we
can choose images/text or both as the conditions for each time step, which
gives users more flexible control over layout and content. Experimental
comparisons of our method with state-of-the-art methods demonstrate our model
performs best in both style image translation and semantic image translation
and took the shortest time."
Self-consistent Reasoning For Solving Math Word Problems,0.451123,"Math word problems (MWPs) is a task that automatically derives solution
expression from a giving math problems in text. The previous studies suffer
from spurious correlations between input text and output expression. To
mitigate this issue, we propose a self-consistent reasoning framework called
SCR, which attempts to adopt a pruning strategy to correct the output
distribution shift so as to implicitly fix those spurious correlative samples.
Specifically, we firstly obtain a sub-network by pruning a roberta2tree model,
for the sake to use the gap on output distribution between the original
roberta2tree model and the pruned sub-network to expose spurious correlative
samples. Then, we calibrate the output distribution shift by applying symmetric
Kullback-Leibler divergence to alleviate spurious correlations. In addition,
SCR generates equivalent expressions, thereby, capturing the original text's
logic rather than relying on hints from original text. Extensive experiments on
two large-scale benchmarks demonstrate that our model substantially outperforms
the strong baseline methods."
Traj-MAE: Masked Autoencoders for Trajectory Prediction,0.864259,"Trajectory prediction has been a crucial task in building a reliable
autonomous driving system by anticipating possible dangers. One key issue is to
generate consistent trajectory predictions without colliding. To overcome the
challenge, we propose an efficient masked autoencoder for trajectory prediction
(Traj-MAE) that better represents the complicated behaviors of agents in the
driving environment. Specifically, our Traj-MAE employs diverse masking
strategies to pre-train the trajectory encoder and map encoder, allowing for
the capture of social and temporal information among agents while leveraging
the effect of environment from multiple granularities. To address the
catastrophic forgetting problem that arises when pre-training the network with
multiple masking strategies, we introduce a continual pre-training framework,
which can help Traj-MAE learn valuable and diverse information from various
strategies efficiently. Our experimental results in both multi-agent and
single-agent settings demonstrate that Traj-MAE achieves competitive results
with state-of-the-art methods and significantly outperforms our baseline model."
Boosting 3D Object Detection via Object-Focused Image Fusion,0.642357,"3D object detection has achieved remarkable progress by taking point clouds
as the only input. However, point clouds often suffer from incomplete geometric
structures and the lack of semantic information, which makes detectors hard to
accurately classify detected objects. In this work, we focus on how to
effectively utilize object-level information from images to boost the
performance of point-based 3D detector. We present DeMF, a simple yet effective
method to fuse image information into point features. Given a set of point
features and image feature maps, DeMF adaptively aggregates image features by
taking the projected 2D location of the 3D point as reference. We evaluate our
method on the challenging SUN RGB-D dataset, improving state-of-the-art results
by a large margin (+2.1 mAP@0.25 and +2.3mAP@0.5). Code is available at
https://github.com/haoy945/DeMF."
A Compacted Structure for Cross-domain learning on Monocular Depth and Flow Estimation,0.0638427,"Accurate motion and depth recovery is important for many robot vision tasks
including autonomous driving. Most previous studies have achieved cooperative
multi-task interaction via either pre-defined loss functions or cross-domain
prediction. This paper presents a multi-task scheme that achieves mutual
assistance by means of our Flow to Depth (F2D), Depth to Flow (D2F), and
Exponential Moving Average (EMA). F2D and D2F mechanisms enable multi-scale
information integration between optical flow and depth domain based on
differentiable shallow nets. A dual-head mechanism is used to predict optical
flow for rigid and non-rigid motion based on a divide-and-conquer manner, which
significantly improves the optical flow estimation performance. Furthermore, to
make the prediction more robust and stable, EMA is used for our multi-task
training. Experimental results on KITTI datasets show that our multi-task
scheme outperforms other multi-task schemes and provide marked improvements on
the prediction results."
Transporters with Visual Foresight for Solving Unseen Rearrangement Tasks,0.395724,"Rearrangement tasks have been identified as a crucial challenge for
intelligent robotic manipulation, but few methods allow for precise
construction of unseen structures. We propose a visual foresight model for
pick-and-place rearrangement manipulation which is able to learn efficiently.
In addition, we develop a multi-modal action proposal module which builds on
the Goal-Conditioned Transporter Network, a state-of-the-art imitation learning
method. Our image-based task planning method, Transporters with Visual
Foresight, is able to learn from only a handful of data and generalize to
multiple unseen tasks in a zero-shot manner. TVF is able to improve the
performance of a state-of-the-art imitation learning method on unseen tasks in
simulation and real robot experiments. In particular, the average success rate
on unseen tasks improves from 55.4% to 78.5% in simulation experiments and from
30% to 63.3% in real robot experiments when given only tens of expert
demonstrations. Video and code are available on our project website:
https://chirikjianlab.github.io/tvf/"
GoSum: Extractive Summarization of Long Documents by Reinforcement Learning and Graph Organized discourse state,0.463956,"Extracting summaries from long documents can be regarded as sentence
classification using the structural information of the documents. How to use
such structural information to summarize a document is challenging. In this
paper, we propose GoSum, a novel graph and reinforcement learning based
extractive model for long-paper summarization. In particular, GoSum encodes
sentence states in reinforcement learning by building a heterogeneous graph for
each input document at different discourse levels. An edge in the graph
reflects the discourse hierarchy of a document for restraining the semantic
drifts across section boundaries. We evaluate GoSum on two datasets of
scientific articles summarization: PubMed and arXiv. The experimental results
have demonstrated that GoSum achieve state-of-the-art results compared with
strong baselines of both extractive and abstractive models. The ablation
studies further validate that the performance of our GoSum benefits from the
use of discourse information."
"Entities, Dates, and Languages: Zero-Shot on Historical Texts with T0",0.623256,"In this work, we explore whether the recently demonstrated zero-shot
abilities of the T0 model extend to Named Entity Recognition for
out-of-distribution languages and time periods. Using a historical newspaper
corpus in 3 languages as test-bed, we use prompts to extract possible named
entities. Our results show that a naive approach for prompt-based zero-shot
multilingual Named Entity Recognition is error-prone, but highlights the
potential of such an approach for historical languages lacking labeled
datasets. Moreover, we also find that T0-like models can be probed to predict
the publication date and language of a document, which could be very relevant
for the study of historical texts."
Controllable Text Generation with Neurally-Decomposed Oracle,0.277707,"We propose a general and efficient framework to control auto-regressive
generation models with NeurAlly-Decomposed Oracle (NADO). Given a pre-trained
base language model and a sequence-level boolean oracle function, we propose to
decompose the oracle function into token-level guidance to steer the base model
in text generation. Specifically, the token-level guidance is approximated by a
neural model trained with examples sampled from the base model, demanding no
additional auxiliary labeled data. Based on posterior regularization, we
present the closed-form optimal solution to incorporate the token-level
guidance into the base model for controllable generation. We further provide a
theoretical analysis of how the approximation quality of NADO affects the
controllable generation results. Experiments conducted on two applications: (1)
text generation with lexical constraints and (2) machine translation with
formality control demonstrate that our framework efficiently guides the base
model towards the given oracle while maintaining high generation quality."
Explainable AI for tailored electricity consumption feedback -- an experimental evaluation of visualizations,0.455285,"Machine learning (ML) methods can effectively analyse data, recognize
patterns in them, and make high-quality predictions. Good predictions usually
come along with ""black-box"" models that are unable to present the detected
patterns in a human-readable way. Technical developments recently led to
eXplainable Artificial Intelligence (XAI) techniques that aim to open such
black-boxes and enable humans to gain new insights from detected patterns. We
investigated the application of XAI in an area where specific insights can have
a significant effect on consumer behaviour, namely electricity use. Knowing
that specific feedback on individuals' electricity consumption triggers
resource conservation, we created five visualizations with ML and XAI methods
from electricity consumption time series for highly personalized feedback,
considering existing domain-specific design knowledge. Our experimental
evaluation with 152 participants showed that humans can assimilate the pattern
displayed by XAI visualizations, but such visualizations should follow known
visualization patterns to be well-understood by users."
DeblurSR: Event-Based Motion Deblurring Under the Spiking Representation,0.436157,"We present DeblurSR, a novel motion deblurring approach that converts a
blurry image into a sharp video. DeblurSR utilizes event data to compensate for
motion ambiguities and exploits the spiking representation to parameterize the
sharp output video as a mapping from time to intensity. Our key contribution,
the Spiking Representation (SR), is inspired by the neuromorphic principles
determining how biological neurons communicate with each other in living
organisms. We discuss why the spikes can represent sharp edges and how the
spiking parameters are interpreted from the neuromorphic perspective. DeblurSR
has higher output quality and requires fewer computing resources than
state-of-the-art event-based motion deblurring methods. We additionally show
that our approach easily extends to video super-resolution when combined with
recent advances in implicit neural representation. The implementation and
animated visualization of DeblurSR are available at
https://github.com/chensong1995/DeblurSR."
Vehicle Type Specific Waypoint Generation,0.0211301,"We develop a generic mechanism for generating vehicle-type specific sequences
of waypoints from a probabilistic foundation model of driving behavior. Many
foundation behavior models are trained on data that does not include vehicle
information, which limits their utility in downstream applications such as
planning. Our novel methodology conditionally specializes such a behavior
predictive model to a vehicle-type by utilizing byproducts of the reinforcement
learning algorithms used to produce vehicle specific controllers. We show how
to compose a vehicle specific value function estimate with a generic
probabilistic behavior model to generate vehicle-type specific waypoint
sequences that are more likely to be physically plausible then their
vehicle-agnostic counterparts."
3DMODT: Attention-Guided Affinities for Joint Detection & Tracking in 3D Point Clouds,0.369262,"We propose a method for joint detection and tracking of multiple objects in
3D point clouds, a task conventionally treated as a two-step process comprising
object detection followed by data association. Our method embeds both steps
into a single end-to-end trainable network eliminating the dependency on
external object detectors. Our model exploits temporal information employing
multiple frames to detect objects and track them in a single network, thereby
making it a utilitarian formulation for real-world scenarios. Computing
affinity matrix by employing features similarity across consecutive point cloud
scans forms an integral part of visual tracking. We propose an attention-based
refinement module to refine the affinity matrix by suppressing erroneous
correspondences. The module is designed to capture the global context in
affinity matrix by employing self-attention within each affinity matrix and
cross-attention across a pair of affinity matrices. Unlike competing
approaches, our network does not require complex post-processing algorithms,
and processes raw LiDAR frames to directly output tracking results. We
demonstrate the effectiveness of our method on the three tracking benchmarks:
JRDB, Waymo, and KITTI. Experimental evaluations indicate the ability of our
model to generalize well across datasets."
Multi-Modal Unsupervised Pre-Training for Surgical Operating Room Workflow Analysis,0.297301,"Data-driven approaches to assist operating room (OR) workflow analysis depend
on large curated datasets that are time consuming and expensive to collect. On
the other hand, we see a recent paradigm shift from supervised learning to
self-supervised and/or unsupervised learning approaches that can learn
representations from unlabeled datasets. In this paper, we leverage the
unlabeled data captured in robotic surgery ORs and propose a novel way to fuse
the multi-modal data for a single video frame or image. Instead of producing
different augmentations (or 'views') of the same image or video frame which is
a common practice in self-supervised learning, we treat the multi-modal data as
different views to train the model in an unsupervised manner via clustering. We
compared our method with other state of the art methods and results show the
superior performance of our approach on surgical video activity recognition and
semantic segmentation."
Real-World Compositional Generalization with Disentangled Sequence-to-Sequence Learning,0.134829,"Compositional generalization is a basic mechanism in human language learning,
which current neural networks struggle with. A recently proposed Disentangled
sequence-to-sequence model (Dangle) shows promising generalization capability
by learning specialized encodings for each decoding step. We introduce two key
modifications to this model which encourage more disentangled representations
and improve its compute and memory efficiency, allowing us to tackle
compositional generalization in a more realistic setting. Specifically, instead
of adaptively re-encoding source keys and values at each time step, we
disentangle their representations and only re-encode keys periodically, at some
interval. Our new architecture leads to better generalization performance
across existing tasks and datasets, and a new machine translation benchmark
which we create by detecting naturally occurring compositional patterns in
relation to a training set. We show this methodology better emulates real-world
requirements than artificial challenges."
SVGraph: Learning Semantic Graphs from Instructional Videos,0.133673,"In this work, we focus on generating graphical representations of noisy,
instructional videos for video understanding. We propose a self-supervised,
interpretable approach that does not require any annotations for graphical
representations, which would be expensive and time consuming to collect. We
attempt to overcome ""black box"" learning limitations by presenting Semantic
Video Graph or SVGraph, a multi-modal approach that utilizes narrations for
semantic interpretability of the learned graphs. SVGraph 1) relies on the
agreement between multiple modalities to learn a unified graphical structure
with the help of cross-modal attention and 2) assigns semantic interpretation
with the help of Semantic-Assignment, which captures the semantics from video
narration. We perform experiments on multiple datasets and demonstrate the
interpretability of SVGraph in semantic graph learning."
The Birth of Bias: A case study on the evolution of gender bias in an English language model,0.471093,"Detecting and mitigating harmful biases in modern language models are widely
recognized as crucial, open problems. In this paper, we take a step back and
investigate how language models come to be biased in the first place. We use a
relatively small language model, using the LSTM architecture trained on an
English Wikipedia corpus. With full access to the data and to the model
parameters as they change during every step while training, we can map in
detail how the representation of gender develops, what patterns in the dataset
drive this, and how the model's internal state relates to the bias in a
downstream task (semantic textual similarity). We find that the representation
of gender is dynamic and identify different phases during training.
Furthermore, we show that gender information is represented increasingly
locally in the input embeddings of the model and that, as a consequence,
debiasing these can be effective in reducing the downstream bias. Monitoring
the training dynamics, allows us to detect an asymmetry in how the female and
male gender are represented in the input embeddings. This is important, as it
may cause naive mitigation strategies to introduce new undesirable biases. We
discuss the relevance of the findings for mitigation strategies more generally
and the prospects of generalizing our methods to larger language models, the
Transformer architecture, other languages and other undesirable biases."
A gentle introduction to Quantum Natural Language Processing,0.14976,"The main goal of this master's thesis is to introduce Quantum Natural
Language Processing (QNLP) in a way understandable by both the NLP engineer and
the quantum computing practitioner. QNLP is a recent application of quantum
computing that aims at representing sentences' meaning as vectors encoded into
quantum computers. To achieve this, the distributional meaning of words is
extended by the compositional meaning of sentences (DisCoCat model) : the
vectors representing words' meanings are composed through the syntactic
structure of the sentence. This is done using an algorithm based on tensor
products. We see that this algorithm is inefficient on classical computers but
scales well using quantum circuits. After exposing the practical details of its
implementation, we go through three use-cases."
Visual Imitation Learning with Patch Rewards,0.320653,"Visual imitation learning enables reinforcement learning agents to learn to
behave from expert visual demonstrations such as videos or image sequences,
without explicit, well-defined rewards. Previous research either adopted
supervised learning techniques or induce simple and coarse scalar rewards from
pixels, neglecting the dense information contained in the image demonstrations.
In this work, we propose to measure the expertise of various local regions of
image samples, or called \textit{patches}, and recover multi-dimensional
\textit{patch rewards} accordingly. Patch reward is a more precise rewarding
characterization that serves as a fine-grained expertise measurement and visual
explainability tool. Specifically, we present Adversarial Imitation Learning
with Patch Rewards (PatchAIL), which employs a patch-based discriminator to
measure the expertise of different local parts from given images and provide
patch rewards. The patch-based knowledge is also used to regularize the
aggregated reward and stabilize the training. We evaluate our method on
DeepMind Control Suite and Atari tasks. The experiment results have
demonstrated that PatchAIL outperforms baseline methods and provides valuable
interpretations for visual demonstrations."
Physically Plausible Animation of Human Upper Body from a Single Image,0.133051,"We present a new method for generating controllable, dynamically responsive,
and photorealistic human animations. Given an image of a person, our system
allows the user to generate Physically plausible Upper Body Animation (PUBA)
using interaction in the image space, such as dragging their hand to various
locations. We formulate a reinforcement learning problem to train a dynamic
model that predicts the person's next 2D state (i.e., keypoints on the image)
conditioned on a 3D action (i.e., joint torque), and a policy that outputs
optimal actions to control the person to achieve desired goals. The dynamic
model leverages the expressiveness of 3D simulation and the visual realism of
2D videos. PUBA generates 2D keypoint sequences that achieve task goals while
being responsive to forceful perturbation. The sequences of keypoints are then
translated by a pose-to-image generator to produce the final photorealistic
video."
SOCS: Semantically-aware Object Coordinate Space for Category-Level 6D Object Pose Estimation under Large Shape Variations,0.572665,"Most learning-based approaches to category-level 6D pose estimation are
design around normalized object coordinate space (NOCS). While being
successful, NOCS-based methods become inaccurate and less robust when handling
objects of a category containing significant intra-category shape variations.
This is because the object coordinates induced by global and rigid alignment of
objects are semantically incoherent, making the coordinate regression hard to
learn and generalize. We propose Semantically-aware Object Coordinate Space
(SOCS) built by warping-and-aligning the objects guided by a sparse set of
keypoints with semantically meaningful correspondence. SOCS is semantically
coherent: Any point on the surface of a object can be mapped to a semantically
meaningful location in SOCS, allowing for accurate pose and size estimation
under large shape variations. To learn effective coordinate regression to SOCS,
we propose a novel multi-scale coordinate-based attention network. Evaluations
demonstrate that our method is easy to train, well-generalizing for large
intra-category shape variations and robust to inter-object occlusions."
VAST: Vivify Your Talking Avatar via Zero-Shot Expressive Facial Style Transfer,0.783639,"Current talking face generation methods mainly focus on speech-lip
synchronization. However, insufficient investigation on the facial talking
style leads to a lifeless and monotonous avatar. Most previous works fail to
imitate expressive styles from arbitrary video prompts and ensure the
authenticity of the generated video. This paper proposes an unsupervised
variational style transfer model (VAST) to vivify the neutral photo-realistic
avatars. Our model consists of three key components: a style encoder that
extracts facial style representations from the given video prompts; a hybrid
facial expression decoder to model accurate speech-related movements; a
variational style enhancer that enhances the style space to be highly
expressive and meaningful. With our essential designs on facial style learning,
our model is able to flexibly capture the expressive facial style from
arbitrary video prompts and transfer it onto a personalized image renderer in a
zero-shot manner. Experimental results demonstrate the proposed approach
contributes to a more vivid talking avatar with higher authenticity and richer
expressiveness."
EDO-Net: Learning Elastic Properties of Deformable Objects from Graph Dynamics,0.369844,"We study the problem of learning graph dynamics of deformable objects that
generalizes to unknown physical properties. Our key insight is to leverage a
latent representation of elastic physical properties of cloth-like deformable
objects that can be extracted, for example, from a pulling interaction. In this
paper we propose EDO-Net (Elastic Deformable Object - Net), a model of graph
dynamics trained on a large variety of samples with different elastic
properties that does not rely on ground-truth labels of the properties. EDO-Net
jointly learns an adaptation module, and a forward-dynamics module. The former
is responsible for extracting a latent representation of the physical
properties of the object, while the latter leverages the latent representation
to predict future states of cloth-like objects represented as graphs. We
evaluate EDO-Net both in simulation and real world, assessing its capabilities
of: 1) generalizing to unknown physical properties, 2) transferring the learned
representation to new downstream tasks."
Mastering the Game of Stratego with Model-Free Multiagent Reinforcement Learning,0.971391,"We introduce DeepNash, an autonomous agent capable of learning to play the
imperfect information game Stratego from scratch, up to a human expert level.
Stratego is one of the few iconic board games that Artificial Intelligence (AI)
has not yet mastered. This popular game has an enormous game tree on the order
of $10^{535}$ nodes, i.e., $10^{175}$ times larger than that of Go. It has the
additional complexity of requiring decision-making under imperfect information,
similar to Texas hold'em poker, which has a significantly smaller game tree (on
the order of $10^{164}$ nodes). Decisions in Stratego are made over a large
number of discrete actions with no obvious link between action and outcome.
Episodes are long, with often hundreds of moves before a player wins, and
situations in Stratego can not easily be broken down into manageably-sized
sub-problems as in poker. For these reasons, Stratego has been a grand
challenge for the field of AI for decades, and existing AI methods barely reach
an amateur level of play. DeepNash uses a game-theoretic, model-free deep
reinforcement learning method, without search, that learns to master Stratego
via self-play. The Regularised Nash Dynamics (R-NaD) algorithm, a key component
of DeepNash, converges to an approximate Nash equilibrium, instead of 'cycling'
around it, by directly modifying the underlying multi-agent learning dynamics.
DeepNash beats existing state-of-the-art AI methods in Stratego and achieved a
yearly (2022) and all-time top-3 rank on the Gravon games platform, competing
with human expert players."
Constrained Dynamic Movement Primitives for Safe Learning of Motor Skills,0.744271,"Dynamic movement primitives are widely used for learning skills which can be
demonstrated to a robot by a skilled human or controller. While their
generalization capabilities and simple formulation make them very appealing to
use, they possess no strong guarantees to satisfy operational safety
constraints for a task. In this paper, we present constrained dynamic movement
primitives (CDMP) which can allow for constraint satisfaction in the robot
workspace. We present a formulation of a non-linear optimization to perturb the
DMP forcing weights regressed by locally-weighted regression to admit a Zeroing
Barrier Function (ZBF), which certifies workspace constraint satisfaction. We
demonstrate the proposed CDMP under different constraints on the end-effector
movement such as obstacle avoidance and workspace constraints on a physical
robot. A video showing the implementation of the proposed algorithm using
different manipulators in different environments could be found here
https://youtu.be/hJegJJkJfys."
Enhancing Document-level Relation Extraction by Entity Knowledge Injection,0.490073,"Document-level relation extraction (RE) aims to identify the relations
between entities throughout an entire document. It needs complex reasoning
skills to synthesize various knowledge such as coreferences and commonsense.
Large-scale knowledge graphs (KGs) contain a wealth of real-world facts, and
can provide valuable knowledge to document-level RE. In this paper, we propose
an entity knowledge injection framework to enhance current document-level RE
models. Specifically, we introduce coreference distillation to inject
coreference knowledge, endowing an RE model with the more general capability of
coreference reasoning. We also employ representation reconciliation to inject
factual knowledge and aggregate KG representations and document representations
into a unified space. The experiments on two benchmark datasets validate the
generalization of our entity knowledge injection framework and the consistent
improvement to several document-level RE models."
EvEntS ReaLM: Event Reasoning of Entity States via Language Models,0.140372,"This paper investigates models of event implications. Specifically, how well
models predict entity state-changes, by targeting their understanding of
physical attributes. Nominally, Large Language models (LLM) have been exposed
to procedural knowledge about how objects interact, yet our benchmarking shows
they fail to reason about the world. Conversely, we also demonstrate that
existing approaches often misrepresent the surprising abilities of LLMs via
improper task encodings and that proper model prompting can dramatically
improve performance of reported baseline results across multiple tasks. In
particular, our results indicate that our prompting technique is especially
useful for unseen attributes (out-of-domain) or when only limited data is
available."
Improving User Controlled Table-To-Text Generation Robustness,0.417825,"In this work we study user controlled table-to-text generation where users
explore the content in a table by selecting cells and reading a natural
language description thereof automatically produce by a natural language
generator. Such generation models usually learn from carefully selected cell
combinations (clean cell selections); however, in practice users may select
unexpected, redundant, or incoherent cell combinations (noisy cell selections).
In experiments, we find that models perform well on test sets coming from the
same distribution as the train data but their performance drops when evaluated
on realistic noisy user inputs. We propose a fine-tuning regime with additional
user-simulated noisy cell selections. Models fine-tuned with the proposed
regime gain 4.85 BLEU points on user noisy test cases and 1.4 on clean test
cases; and achieve comparable state-of-the-art performance on the ToTTo
dataset."
Data Augmentation in Training CNNs: Injecting Noise to Images,0.0786989,"Noise injection is a fundamental tool for data augmentation, and yet there is
no widely accepted procedure to incorporate it with learning frameworks. This
study analyzes the effects of adding or applying different noise models of
varying magnitudes to Convolutional Neural Network (CNN) architectures. Noise
models that are distributed with different density functions are given common
magnitude levels via Structural Similarity (SSIM) metric in order to create an
appropriate ground for comparison. The basic results are conforming with the
most of the common notions in machine learning, and also introduce some novel
heuristics and recommendations on noise injection. The new approaches will
provide better understanding on optimal learning procedures for image
classification."
Automatic Detection of Entity-Manipulated Text using Factual Knowledge,0.686449,"In this work, we focus on the problem of distinguishing a human written news
article from a news article that is created by manipulating entities in a human
written news article (e.g., replacing entities with factually incorrect
entities). Such manipulated articles can mislead the reader by posing as a
human written news article. We propose a neural network based detector that
detects manipulated news articles by reasoning about the facts mentioned in the
article. Our proposed detector exploits factual knowledge via graph
convolutional neural network along with the textual information in the news
article. We also create challenging datasets for this task by considering
various strategies to generate the new replacement entity (e.g., entity
generation from GPT-2). In all the settings, our proposed model either matches
or outperforms the state-of-the-art detector in terms of accuracy. Our code and
data are available at https://github.com/UBC-NLP/manipulated_entity_detection."
Bipartite Graph Diffusion Model for Human Interaction Generation,0.601755,"The generation of natural human motion interactions is a hot topic in
computer vision and computer animation. It is a challenging task due to the
diversity of possible human motion interactions. Diffusion models, which have
already shown remarkable generative capabilities in other domains, are a good
candidate for this task. In this paper, we introduce a novel bipartite graph
diffusion method (BiGraphDiff) to generate human motion interactions between
two persons. Specifically, bipartite node sets are constructed to model the
inherent geometric constraints between skeleton nodes during interactions. The
interaction graph diffusion model is transformer-based, combining some
state-of-the-art motion methods. We show that the proposed achieves new
state-of-the-art results on leading benchmarks for the human interaction
generation task."
PTSEFormer: Progressive Temporal-Spatial Enhanced TransFormer Towards Video Object Detection,0.796125,"Recent years have witnessed a trend of applying context frames to boost the
performance of object detection as video object detection. Existing methods
usually aggregate features at one stroke to enhance the feature. These methods,
however, usually lack spatial information from neighboring frames and suffer
from insufficient feature aggregation. To address the issues, we perform a
progressive way to introduce both temporal information and spatial information
for an integrated enhancement. The temporal information is introduced by the
temporal feature aggregation model (TFAM), by conducting an attention mechanism
between the context frames and the target frame (i.e., the frame to be
detected). Meanwhile, we employ a Spatial Transition Awareness Model (STAM) to
convey the location transition information between each context frame and
target frame. Built upon a transformer-based detector DETR, our PTSEFormer also
follows an end-to-end fashion to avoid heavy post-processing procedures while
achieving 88.1% mAP on the ImageNet VID dataset. Codes are available at
https://github.com/Hon-Wong/PTSEFormer."
Linguistically Informed ChatGPT Prompts to Enhance Japanese-Chinese Machine Translation: A Case Study on Attributive Clauses,0.917285,"In the field of Japanese-Chinese translation linguistics, the issue of
correctly translating attributive clauses has persistently proven to be
challenging. Present-day machine translation tools often fail to accurately
translate attributive clauses from Japanese to Chinese. In light of this, this
paper investigates the linguistic problem underlying such difficulties, namely
how does the semantic role of the modified noun affect the selection of
translation patterns for attributive clauses, from a linguistic perspective. To
ad-dress these difficulties, a pre-edit scheme is proposed, which aims to
enhance the accuracy of translation. Furthermore, we propose a novel two-step
prompt strategy, which combines this pre-edit scheme with ChatGPT, currently
the most widely used large language model. This prompt strategy is capable of
optimizing translation input in zero-shot scenarios and has been demonstrated
to improve the average translation accuracy score by over 35%."
ChatGPT-Powered Hierarchical Comparisons for Image Classification,0.433263,"The zero-shot open-vocabulary challenge in image classification is tackled by
pretrained vision-language models like CLIP, which benefit from incorporating
class-specific knowledge from large language models (LLMs) like ChatGPT.
However, biases in CLIP lead to similar descriptions for distinct but related
classes, prompting our novel image classification framework via hierarchical
comparisons: using LLMs to recursively group classes into hierarchies and
classifying images by comparing image-text embeddings at each hierarchy level,
resulting in an intuitive, effective, and explainable approach."
Medical Face Masks and Emotion Recognition from the Body: Insights from a Deep Learning Perspective,0.110063,"The COVID-19 pandemic has undoubtedly changed the standards and affected all
aspects of our lives, especially social communication. It has forced people to
extensively wear medical face masks, in order to prevent transmission. This
face occlusion can strongly irritate emotional reading from the face and urges
us to incorporate the whole body as an emotional cue. In this paper, we conduct
insightful studies about the effect of face occlusion on emotion recognition
performance, and showcase the superiority of full body input over the plain
masked face. We utilize a deep learning model based on the Temporal Segment
Network framework, and aspire to fully overcome the face mask consequences.
Although facial and bodily features can be learned from a single input, this
may lead to irrelevant information confusion. By processing those features
separately and fusing their prediction scores, we are more effectively taking
advantage of both modalities. This framework also naturally supports temporal
modeling, by mingling information among neighboring frames. In combination,
these techniques form an effective system capable of tackling emotion
recognition difficulties, caused by safety protocols applied in crucial areas."
Understanding and Mitigating the Uncertainty in Zero-Shot Translation,0.0699568,"Zero-shot translation is a promising direction for building a comprehensive
multilingual neural machine translation (MNMT) system. However, its quality is
still not satisfactory due to off-target issues. In this paper, we aim to
understand and alleviate the off-target issues from the perspective of
uncertainty in zero-shot translation. By carefully examining the translation
output and model confidence, we identify two uncertainties that are responsible
for the off-target issues, namely, extrinsic data uncertainty and intrinsic
model uncertainty. Based on the observations, we propose two light-weight and
complementary approaches to denoise the training data for model training, and
mask out the vocabulary of the off-target languages in inference. Extensive
experiments on both balanced and unbalanced datasets show that our approaches
significantly improve the performance of zero-shot translation over strong MNMT
baselines. Qualitative analyses provide insights into where our approaches
reduce off-target translations"
Can ChatGPT and Bard Generate Aligned Assessment Items? A Reliability Analysis against Human Performance,0.828616,"ChatGPT and Bard are AI chatbots based on Large Language Models (LLM) that
are slated to promise different applications in diverse areas. In education,
these AI technologies have been tested for applications in assessment and
teaching. In assessment, AI has long been used in automated essay scoring and
automated item generation. One psychometric property that these tools must have
to assist or replace humans in assessment is high reliability in terms of
agreement between AI scores and human raters. In this paper, we measure the
reliability of OpenAI ChatGP and Google Bard LLMs tools against experienced and
trained humans in perceiving and rating the complexity of writing prompts.
Intraclass correlation (ICC) as a performance metric showed that the
inter-reliability of both the OpenAI ChatGPT and the Google Bard were low
against the gold standard of human ratings."
Embedding-based Retrieval with LLM for Effective Agriculture Information Extracting from Unstructured Data,0.99998,"Pest identification is a crucial aspect of pest control in agriculture.
However, most farmers are not capable of accurately identifying pests in the
field, and there is a limited number of structured data sources available for
rapid querying. In this work, we explored using domain-agnostic general
pre-trained large language model(LLM) to extract structured data from
agricultural documents with minimal or no human intervention. We propose a
methodology that involves text retrieval and filtering using embedding-based
retrieval, followed by LLM question-answering to automatically extract entities
and attributes from the documents, and transform them into structured data. In
comparison to existing methods, our approach achieves consistently better
accuracy in the benchmark while maintaining efficiency."
Detection of Condensed Vehicle Gas Exhaust in LiDAR Point Clouds,0.591008,"LiDAR sensors used in autonomous driving applications are negatively affected
by adverse weather conditions. One common, but understudied effect, is the
condensation of vehicle gas exhaust in cold weather. This everyday phenomenon
can severely impact the quality of LiDAR measurements, resulting in a less
accurate environment perception by creating artifacts like ghost object
detections. In the literature, the semantic segmentation of adverse weather
effects like rain and fog is achieved using learning-based approaches. However,
such methods require large sets of labeled data, which can be extremely
expensive and laborious to get. We address this problem by presenting a
two-step approach for the detection of condensed vehicle gas exhaust. First, we
identify for each vehicle in a scene its emission area and detect gas exhaust
if present. Then, isolated clouds are detected by modeling through time the
regions of space where gas exhaust is likely to be present. We test our method
on real urban data, showing that our approach can reliably detect gas exhaust
in different scenarios, making it appealing for offline pre-labeling and online
applications such as ghost object detection."
DALL-E 2 Fails to Reliably Capture Common Syntactic Processes,0.457871,"Machine intelligence is increasingly being linked to claims about sentience,
language processing, and an ability to comprehend and transform natural
language into a range of stimuli. We systematically analyze the ability of
DALL-E 2 to capture 8 grammatical phenomena pertaining to compositionality that
are widely discussed in linguistics and pervasive in human language: binding
principles and coreference, passives, word order, coordination, comparatives,
negation, ellipsis, and structural ambiguity. Whereas young children routinely
master these phenomena, learning systematic mappings between syntax and
semantics, DALL-E 2 is unable to reliably infer meanings that are consistent
with the syntax. These results challenge recent claims concerning the capacity
of such systems to understand of human language. We make available the full set
of test materials as a benchmark for future testing."
BERT for Long Documents: A Case Study of Automated ICD Coding,0.116262,"Transformer models have achieved great success across many NLP problems.
However, previous studies in automated ICD coding concluded that these models
fail to outperform some of the earlier solutions such as CNN-based models. In
this paper we challenge this conclusion. We present a simple and scalable
method to process long text with the existing transformer models such as BERT.
We show that this method significantly improves the previous results reported
for transformer models in ICD coding, and is able to outperform one of the
prominent CNN-based methods."
Exploring Opinion-unaware Video Quality Assessment with Semantic Affinity Criterion,0.624026,"Recent learning-based video quality assessment (VQA) algorithms are expensive
to implement due to the cost of data collection of human quality opinions, and
are less robust across various scenarios due to the biases of these opinions.
This motivates our exploration on opinion-unaware (a.k.a zero-shot) VQA
approaches. Existing approaches only considers low-level naturalness in spatial
or temporal domain, without considering impacts from high-level semantics. In
this work, we introduce an explicit semantic affinity index for opinion-unaware
VQA using text-prompts in the contrastive language-image pre-training (CLIP)
model. We also aggregate it with different traditional low-level naturalness
indexes through gaussian normalization and sigmoid rescaling strategies.
Composed of aggregated semantic and technical metrics, the proposed Blind
Unified Opinion-Unaware Video Quality Index via Semantic and Technical Metric
Aggregation (BUONA-VISTA) outperforms existing opinion-unaware VQA methods by
at least 20% improvements, and is more robust than opinion-aware approaches."
Evaluating Large Language Models at Evaluating Instruction Following,0.505608,"As research in large language models (LLMs) continues to accelerate,
LLM-based evaluation has emerged as a scalable and cost-effective alternative
to human evaluations for comparing the ever increasing list of models. This
paper investigates the efficacy of these ``LLM evaluators'', particularly in
using them to assess instruction following, a metric that gauges how closely
generated text adheres to the given instruction. We introduce a challenging
meta-evaluation benchmark, LLMBar, designed to test the ability of an LLM
evaluator in discerning instruction-following outputs. The authors manually
curated 419 pairs of outputs, one adhering to instructions while the other
diverging, yet may possess deceptive qualities that mislead an LLM evaluator,
e.g., a more engaging tone. Contrary to existing meta-evaluation, we discover
that different evaluators (i.e., combinations of LLMs and prompts) exhibit
distinct performance on LLMBar and even the highest-scoring ones have
substantial room for improvement. We also present a novel suite of prompting
strategies that further close the gap between LLM and human evaluators. With
LLMBar, we hope to offer more insight into LLM evaluators and foster future
research in developing better instruction-following models."
"DiRA: Discriminative, Restorative, and Adversarial Learning for Self-supervised Medical Image Analysis",0.971302,"Discriminative learning, restorative learning, and adversarial learning have
proven beneficial for self-supervised learning schemes in computer vision and
medical imaging. Existing efforts, however, omit their synergistic effects on
each other in a ternary setup, which, we envision, can significantly benefit
deep semantic representation learning. To realize this vision, we have
developed DiRA, the first framework that unites discriminative, restorative,
and adversarial learning in a unified manner to collaboratively glean
complementary visual information from unlabeled medical images for fine-grained
semantic representation learning. Our extensive experiments demonstrate that
DiRA (1) encourages collaborative learning among three learning ingredients,
resulting in more generalizable representation across organs, diseases, and
modalities; (2) outperforms fully supervised ImageNet models and increases
robustness in small data regimes, reducing annotation cost across multiple
medical imaging applications; (3) learns fine-grained semantic representation,
facilitating accurate lesion localization with only image-level annotation; and
(4) enhances state-of-the-art restorative approaches, revealing that DiRA is a
general mechanism for united representation learning. All code and pre-trained
models are available at https: //github.com/JLiangLab/DiRA."
Remote Sensing Image Change Detection with Graph Interaction,0.174551,"Modern remote sensing image change detection has witnessed substantial
advancements by harnessing the potent feature extraction capabilities of CNNs
and Transforms.Yet,prevailing change detection techniques consistently
prioritize extracting semantic features related to significant
alterations,overlooking the viability of directly interacting with bitemporal
image features.In this letter,we propose a bitemporal image graph Interaction
network for remote sensing change detection,namely BGINet-CD. More
specifically,by leveraging the concept of non-local operations and mapping the
features obtained from the backbone network to the graph structure space,we
propose a unified self-focus mechanism for bitemporal images.This approach
enhances the information coupling between the two temporal images while
effectively suppressing task-irrelevant interference,Based on a streamlined
backbone architecture,namely ResNet18,our model demonstrates superior
performance compared to other state-of-the-art methods (SOTA) on the GZ CD
dataset. Moreover,the model exhibits an enhanced trade-off between accuracy and
computational efficiency,further improving its overall effectiveness"
Relative Pose from SIFT Features,0.264289,"This paper proposes the geometric relationship of epipolar geometry and
orientation- and scale-covariant, e.g., SIFT, features. We derive a new linear
constraint relating the unknown elements of the fundamental matrix and the
orientation and scale. This equation can be used together with the well-known
epipolar constraint to, e.g., estimate the fundamental matrix from four SIFT
correspondences, essential matrix from three, and to solve the semi-calibrated
case from three correspondences. Requiring fewer correspondences than the
well-known point-based approaches (e.g., 5PT, 6PT and 7PT solvers) for epipolar
geometry estimation makes RANSAC-like randomized robust estimation
significantly faster. The proposed constraint is tested on a number of problems
in a synthetic environment and on publicly available real-world datasets on
more than 80000 image pairs. It is superior to the state-of-the-art in terms of
processing time while often leading to more accurate results."
MMRotate: A Rotated Object Detection Benchmark using PyTorch,0.951203,"We present an open-source toolbox, named MMRotate, which provides a coherent
algorithm framework of training, inferring, and evaluation for the popular
rotated object detection algorithm based on deep learning. MMRotate implements
18 state-of-the-art algorithms and supports the three most frequently used
angle definition methods. To facilitate future research and industrial
applications of rotated object detection-related problems, we also provide a
large number of trained models and detailed benchmarks to give insights into
the performance of rotated object detection. MMRotate is publicly released at
https://github.com/open-mmlab/mmrotate."
Fast DistilBERT on CPUs,0.0144554,"Transformer-based language models have become the standard approach to
solving natural language processing tasks. However, industry adoption usually
requires the maximum throughput to comply with certain latency constraints that
prevents Transformer models from being used in production. To address this gap,
model compression techniques such as quantization and pruning may be used to
improve inference efficiency. However, these compression techniques require
specialized software to apply and deploy at scale. In this work, we propose a
new pipeline for creating and running Fast Transformer models on CPUs,
utilizing hardware-aware pruning, knowledge distillation, quantization, and our
own Transformer inference runtime engine with optimized kernels for sparse and
quantized operators. We demonstrate the efficiency of our pipeline by creating
a Fast DistilBERT model showing minimal accuracy loss on the question-answering
SQuADv1.1 benchmark, and throughput results under typical production
constraints and environments. Our results outperform existing state-of-the-art
Neural Magic's DeepSparse runtime performance by up to 50% and up to 4.1x
performance speedup over ONNX Runtime. Source code is publicly available at
https://github.com/intel/intel-extension-for-transformers."
Keep Your Friends Close and Your Counterfactuals Closer: Improved Learning From Closest Rather Than Plausible Counterfactual Explanations in an Abstract Setting,0.454755,"Counterfactual explanations (CFEs) highlight what changes to a model's input
would have changed its prediction in a particular way. CFEs have gained
considerable traction as a psychologically grounded solution for explainable
artificial intelligence (XAI). Recent innovations introduce the notion of
computational plausibility for automatically generated CFEs, enhancing their
robustness by exclusively creating plausible explanations. However, practical
benefits of such a constraint on user experience and behavior is yet unclear.
In this study, we evaluate objective and subjective usability of
computationally plausible CFEs in an iterative learning design targeting novice
users. We rely on a novel, game-like experimental design, revolving around an
abstract scenario. Our results show that novice users actually benefit less
from receiving computationally plausible rather than closest CFEs that produce
minimal changes leading to the desired outcome. Responses in a post-game survey
reveal no differences in terms of subjective user experience between both
groups. Following the view of psychological plausibility as comparative
similarity, this may be explained by the fact that users in the closest
condition experience their CFEs as more psychologically plausible than the
computationally plausible counterpart. In sum, our work highlights a
little-considered divergence of definitions of computational plausibility and
psychological plausibility, critically confirming the need to incorporate human
behavior, preferences and mental models already at the design stages of XAI
approaches. In the interest of reproducible research, all source code, acquired
user data, and evaluation scripts of the current study are available:
https://github.com/ukuhl/PlausibleAlienZoo"
Interpretable Multi Labeled Bengali Toxic Comments Classification using Deep Learning,0.636325,"This paper presents a deep learning-based pipeline for categorizing Bengali
toxic comments, in which at first a binary classification model is used to
determine whether a comment is toxic or not, and then a multi-label classifier
is employed to determine which toxicity type the comment belongs to. For this
purpose, we have prepared a manually labeled dataset consisting of 16,073
instances among which 8,488 are Toxic and any toxic comment may correspond to
one or more of the six toxic categories - vulgar, hate, religious, threat,
troll, and insult simultaneously. Long Short Term Memory (LSTM) with BERT
Embedding achieved 89.42% accuracy for the binary classification task while as
a multi-label classifier, a combination of Convolutional Neural Network and
Bi-directional Long Short Term Memory (CNN-BiLSTM) with attention mechanism
achieved 78.92% accuracy and 0.86 as weighted F1-score. To explain the
predictions and interpret the word feature importance during classification by
the proposed models, we utilized Local Interpretable Model-Agnostic
Explanations (LIME) framework. We have made our dataset public and can be
accessed at -
https://github.com/deepu099cse/Multi-Labeled-Bengali-Toxic-Comments-Classification"
Fixing MoE Over-Fitting on Low-Resource Languages in Multilingual Machine Translation,0.267051,"Sparsely gated Mixture of Experts (MoE) models have been shown to be a
compute-efficient method to scale model capacity for multilingual machine
translation. However, for low-resource tasks, MoE models severely over-fit. We
show effective regularization strategies, namely dropout techniques for MoE
layers in EOM and FOM, Conditional MoE Routing and Curriculum Learning methods
that prevent over-fitting and improve the performance of MoE models on
low-resource tasks without adversely affecting high-resource tasks. On a
massively multilingual machine translation benchmark, our strategies result in
about +1 chrF++ improvement in very low resource language pairs. We perform an
extensive analysis of the learned MoE routing to better understand the impact
of our regularization methods and how we can improve them."
Unfooling Perturbation-Based Post Hoc Explainers,0.778764,"Monumental advancements in artificial intelligence (AI) have lured the
interest of doctors, lenders, judges, and other professionals. While these
high-stakes decision-makers are optimistic about the technology, those familiar
with AI systems are wary about the lack of transparency of its decision-making
processes. Perturbation-based post hoc explainers offer a model agnostic means
of interpreting these systems while only requiring query-level access. However,
recent work demonstrates that these explainers can be fooled adversarially.
This discovery has adverse implications for auditors, regulators, and other
sentinels. With this in mind, several natural questions arise - how can we
audit these black box systems? And how can we ascertain that the auditee is
complying with the audit in good faith? In this work, we rigorously formalize
this problem and devise a defense against adversarial attacks on
perturbation-based explainers. We propose algorithms for the detection
(CAD-Detect) and defense (CAD-Defend) of these attacks, which are aided by our
novel conditional anomaly detection approach, KNN-CAD. We demonstrate that our
approach successfully detects whether a black box system adversarially conceals
its decision-making process and mitigates the adversarial attack on real-world
data for the prevalent explainers, LIME and SHAP."
TripleRE: Knowledge Graph Embeddings via Tripled Relation Vectors,0.84798,"Translation-based knowledge graph embedding has been one of the most
important branches for knowledge representation learning since TransE came out.
Although many translation-based approaches have achieved some progress in
recent years, the performance was still unsatisfactory. This paper proposes a
novel knowledge graph embedding method named TripleRE with two versions. The
first version of TripleRE creatively divide the relationship vector into three
parts. The second version takes advantage of the concept of residual and
achieves better performance. In addition, attempts on using NodePiece to encode
entities achieved promising results in reducing the parametric size, and solved
the problems of scalability. Experiments show that our approach achieved
state-of-the-art performance on the large-scale knowledge graph dataset, and
competitive performance on other datasets."
Exploring Attention Map Reuse for Efficient Transformer Neural Networks,0.103733,"Transformer-based deep neural networks have achieved great success in various
sequence applications due to their powerful ability to model long-range
dependency. The key module of Transformer is self-attention (SA) which extracts
features from the entire sequence regardless of the distance between positions.
Although SA helps Transformer performs particularly well on long-range tasks,
SA requires quadratic computation and memory complexity with the input sequence
length. Recently, attention map reuse, which groups multiple SA layers to share
one attention map, has been proposed and achieved significant speedup for
speech recognition models. In this paper, we provide a comprehensive study on
attention map reuse focusing on its ability to accelerate inference. We compare
the method with other SA compression techniques and conduct a breakdown
analysis of its advantages for a long sequence. We demonstrate the
effectiveness of attention map reuse by measuring the latency on both CPU and
GPU platforms."
Finding and Listing Front-door Adjustment Sets,0.748572,"Identifying the effects of new interventions from data is a significant
challenge found across a wide range of the empirical sciences. A well-known
strategy for identifying such effects is Pearl's front-door (FD) criterion
(Pearl, 1995). The definition of the FD criterion is declarative, only allowing
one to decide whether a specific set satisfies the criterion. In this paper, we
present algorithms for finding and enumerating possible sets satisfying the FD
criterion in a given causal diagram. These results are useful in facilitating
the practical applications of the FD criterion for causal effects estimation
and helping scientists to select estimands with desired properties, e.g., based
on cost, feasibility of measurement, or statistical power."
Masked Summarization to Generate Factually Inconsistent Summaries for Improved Factual Consistency Checking,0.204497,"Despite the recent advances in abstractive summarization systems, it is still
difficult to determine whether a generated summary is factual consistent with
the source text. To this end, the latest approach is to train a factual
consistency classifier on factually consistent and inconsistent summaries.
Luckily, the former is readily available as reference summaries in existing
summarization datasets. However, generating the latter remains a challenge, as
they need to be factually inconsistent, yet closely relevant to the source text
to be effective. In this paper, we propose to generate factually inconsistent
summaries using source texts and reference summaries with key information
masked. Experiments on seven benchmark datasets demonstrate that factual
consistency classifiers trained on summaries generated using our method
generally outperform existing models and show a competitive correlation with
human judgments. We also analyze the characteristics of the summaries generated
using our method. We will release the pre-trained model and the code at
https://github.com/hwanheelee1993/MFMA."
Multi-level Consistency Learning for Semi-supervised Domain Adaptation,0.586545,"Semi-supervised domain adaptation (SSDA) aims to apply knowledge learned from
a fully labeled source domain to a scarcely labeled target domain. In this
paper, we propose a Multi-level Consistency Learning (MCL) framework for SSDA.
Specifically, our MCL regularizes the consistency of different views of target
domain samples at three levels: (i) at inter-domain level, we robustly and
accurately align the source and target domains using a prototype-based optimal
transport method that utilizes the pros and cons of different views of target
samples; (ii) at intra-domain level, we facilitate the learning of both
discriminative and compact target feature representations by proposing a novel
class-wise contrastive clustering loss; (iii) at sample level, we follow
standard practice and improve the prediction accuracy by conducting a
consistency-based self-training. Empirically, we verified the effectiveness of
our MCL framework on three popular SSDA benchmarks, i.e., VisDA2017, DomainNet,
and Office-Home datasets, and the experimental results demonstrate that our MCL
framework achieves the state-of-the-art performance."
Named Entity Recognition via Machine Reading Comprehension: A Multi-Task Learning Approach,0.310662,"Named Entity Recognition (NER) aims to extract and classify entity mentions
in the text into pre-defined types (e.g., organization or person name).
Recently, many works have been proposed to shape the NER as a machine reading
comprehension problem (also termed MRC-based NER), in which entity recognition
is achieved by answering the formulated questions related to pre-defined entity
types through MRC, based on the contexts. However, these works ignore the label
dependencies among entity types, which are critical for precisely recognizing
named entities. In this paper, we propose to incorporate the label dependencies
among entity types into a multi-task learning framework for better MRC-based
NER. We decompose MRC-based NER into multiple tasks and use a self-attention
module to capture label dependencies. Comprehensive experiments on both nested
NER and flat NER datasets are conducted to validate the effectiveness of the
proposed Multi-NER. Experimental results show that Multi-NER can achieve better
performance on all datasets."
Entity Type Prediction Leveraging Graph Walks and Entity Descriptions,0.398018,"The entity type information in Knowledge Graphs (KGs) such as DBpedia,
Freebase, etc. is often incomplete due to automated generation or human
curation. Entity typing is the task of assigning or inferring the semantic type
of an entity in a KG. This paper presents \textit{GRAND}, a novel approach for
entity typing leveraging different graph walk strategies in RDF2vec together
with textual entity descriptions. RDF2vec first generates graph walks and then
uses a language model to obtain embeddings for each node in the graph. This
study shows that the walk generation strategy and the embedding model have a
significant effect on the performance of the entity typing task. The proposed
approach outperforms the baseline approaches on the benchmark datasets DBpedia
and FIGER for entity typing in KGs for both fine-grained and coarse-grained
classes. The results show that the combination of order-aware RDF2vec variants
together with the contextual embeddings of the textual entity descriptions
achieve the best results."
DSR -- A dual subspace re-projection network for surface anomaly detection,0.911435,"The state-of-the-art in discriminative unsupervised surface anomaly detection
relies on external datasets for synthesizing anomaly-augmented training images.
Such approaches are prone to failure on near-in-distribution anomalies since
these are difficult to be synthesized realistically due to their similarity to
anomaly-free regions. We propose an architecture based on quantized feature
space representation with dual decoders, DSR, that avoids the image-level
anomaly synthesis requirement. Without making any assumptions about the visual
properties of anomalies, DSR generates the anomalies at the feature level by
sampling the learned quantized feature space, which allows a controlled
generation of near-in-distribution anomalies. DSR achieves state-of-the-art
results on the KSDD2 and MVTec anomaly detection datasets. The experiments on
the challenging real-world KSDD2 dataset show that DSR significantly
outperforms other unsupervised surface anomaly detection methods, improving the
previous top-performing methods by 10% AP in anomaly detection and 35% AP in
anomaly localization."
KGTrust: Evaluating Trustworthiness of SIoT via Knowledge Enhanced Graph Neural Networks,0.506885,"Social Internet of Things (SIoT), a promising and emerging paradigm that
injects the notion of social networking into smart objects (i.e., things),
paving the way for the next generation of Internet of Things. However, due to
the risks and uncertainty, a crucial and urgent problem to be settled is
establishing reliable relationships within SIoT, that is, trust evaluation.
Graph neural networks for trust evaluation typically adopt a straightforward
way such as one-hot or node2vec to comprehend node characteristics, which
ignores the valuable semantic knowledge attached to nodes. Moreover, the
underlying structure of SIoT is usually complex, including both the
heterogeneous graph structure and pairwise trust relationships, which renders
hard to preserve the properties of SIoT trust during information propagation.
To address these aforementioned problems, we propose a novel knowledge-enhanced
graph neural network (KGTrust) for better trust evaluation in SIoT.
Specifically, we first extract useful knowledge from users' comment behaviors
and external structured triples related to object descriptions, in order to
gain a deeper insight into the semantics of users and objects. Furthermore, we
introduce a discriminative convolutional layer that utilizes heterogeneous
graph structure, node semantics, and augmented trust relationships to learn
node embeddings from the perspective of a user as a trustor or a trustee,
effectively capturing multi-aspect properties of SIoT trust during information
propagation. Finally, a trust prediction layer is developed to estimate the
trust relationships between pairwise nodes. Extensive experiments on three
public datasets illustrate the superior performance of KGTrust over
state-of-the-art methods."
GSCLIP : A Framework for Explaining Distribution Shifts in Natural Language,0.385402,"Helping end users comprehend the abstract distribution shifts can greatly
facilitate AI deployment. Motivated by this, we propose a novel task, dataset
explanation. Given two image data sets, dataset explanation aims to
automatically point out their dataset-level distribution shifts with natural
language. Current techniques for monitoring distribution shifts provide
inadequate information to understand datasets with the goal of improving data
quality. Therefore, we introduce GSCLIP, a training-free framework to solve the
dataset explanation task. In GSCLIP, we propose the selector as the first
quantitative evaluation method to identify explanations that are proper to
summarize dataset shifts. Furthermore, we leverage this selector to demonstrate
the superiority of a generator based on language model generation. Systematic
evaluation on natural data shift verifies that GSCLIP, a combined system of a
hybrid generator group and an efficient selector is not only easy-to-use but
also powerful for dataset explanation at scale."
Diffusion models for missing value imputation in tabular data,0.991869,"Missing value imputation in machine learning is the task of estimating the
missing values in the dataset accurately using available information. In this
task, several deep generative modeling methods have been proposed and
demonstrated their usefulness, e.g., generative adversarial imputation
networks. Recently, diffusion models have gained popularity because of their
effectiveness in the generative modeling task in images, texts, audio, etc. To
our knowledge, less attention has been paid to the investigation of the
effectiveness of diffusion models for missing value imputation in tabular data.
Based on recent development of diffusion models for time-series data
imputation, we propose a diffusion model approach called ""Conditional
Score-based Diffusion Models for Tabular data"" (TabCSDI). To effectively handle
categorical variables and numerical variables simultaneously, we investigate
three techniques: one-hot encoding, analog bits encoding, and feature
tokenization. Experimental results on benchmark datasets demonstrated the
effectiveness of TabCSDI compared with well-known existing methods, and also
emphasized the importance of the categorical embedding techniques."
Curriculum Learning for ab initio Deep Learned Refractive Optics,0.329597,"Deep optical optimization has recently emerged as a new paradigm for
designing computational imaging systems using only the output image as the
objective. However, it has been limited to either simple optical systems
consisting of a single element such as a diffractive optical element (DOE) or
metalens, or the fine-tuning of compound lenses from good initial designs. Here
we present a DeepLens design method based on curriculum learning, which is able
to learn optical designs of compound lenses ab initio from randomly initialized
surfaces without human intervention, therefore overcoming the need for a good
initial design. We demonstrate the effectiveness of our approach by fully
automatically designing both classical imaging lenses and a large field-of-view
extended depth-of-field computational lens in a cellphone-style form factor,
with highly aspheric surfaces and a short back focal length."
StyleGAN Encoder-Based Attack for Block Scrambled Face Images,0.055427,"In this paper, we propose an attack method to block scrambled face images,
particularly Encryption-then-Compression (EtC) applied images by utilizing the
existing powerful StyleGAN encoder and decoder for the first time. Instead of
reconstructing identical images as plain ones from encrypted images, we focus
on recovering styles that can reveal identifiable information from the
encrypted images. The proposed method trains an encoder by using plain and
encrypted image pairs with a particular training strategy. While
state-of-the-art attack methods cannot recover any perceptual information from
EtC images, the proposed method discloses personally identifiable information
such as hair color, skin color, eyeglasses, gender, etc. Experiments were
carried out on the CelebA dataset, and results show that reconstructed images
have some perceptual similarities compared to plain images."
Hear The Flow: Optical Flow-Based Self-Supervised Visual Sound Source Localization,0.642471,"Learning to localize the sound source in videos without explicit annotations
is a novel area of audio-visual research. Existing work in this area focuses on
creating attention maps to capture the correlation between the two modalities
to localize the source of the sound. In a video, oftentimes, the objects
exhibiting movement are the ones generating the sound. In this work, we capture
this characteristic by modeling the optical flow in a video as a prior to
better aid in localizing the sound source. We further demonstrate that the
addition of flow-based attention substantially improves visual sound source
localization. Finally, we benchmark our method on standard sound source
localization datasets and achieve state-of-the-art performance on the Soundnet
Flickr and VGG Sound Source datasets. Code:
https://github.com/denfed/heartheflow."
The Provable Benefits of Unsupervised Data Sharing for Offline Reinforcement Learning,0.261017,"Self-supervised methods have become crucial for advancing deep learning by
leveraging data itself to reduce the need for expensive annotations. However,
the question of how to conduct self-supervised offline reinforcement learning
(RL) in a principled way remains unclear. In this paper, we address this issue
by investigating the theoretical benefits of utilizing reward-free data in
linear Markov Decision Processes (MDPs) within a semi-supervised setting.
  Further, we propose a novel, Provable Data Sharing algorithm (PDS) to utilize
such reward-free data for offline RL. PDS uses additional penalties on the
reward function learned from labeled data to prevent overestimation, ensuring a
conservative algorithm. Our results on various offline RL tasks demonstrate
that PDS significantly improves the performance of offline RL algorithms with
reward-free data. Overall, our work provides a promising approach to leveraging
the benefits of unlabeled data in offline RL while maintaining theoretical
guarantees. We believe our findings will contribute to developing more robust
self-supervised RL methods."
Conversational Semantic Parsing using Dynamic Context Graphs,0.353777,"In this paper we consider the task of conversational semantic parsing over
general purpose knowledge graphs (KGs) with millions of entities, and thousands
of relation-types. We focus on models which are capable of interactively
mapping user utterances into executable logical forms (e.g., Sparql) in the
context of the conversational history. Our key idea is to represent information
about an utterance and its context via a subgraph which is created dynamically,
i.e., the number of nodes varies per utterance. Rather than treating the
subgraph as a sequence, we exploit its underlying structure and encode it with
a graph neural network which further allows us to represent a large number of
(unseen) nodes. Experimental results show that dynamic context modeling is
superior to static approaches, delivering performance improvements across the
board (i.e., for simple and complex questions). Our results further confirm
that modeling the structure of context is better at processing discourse
information, (i.e., at handling ellipsis and resolving coreference) and longer
interactions."
Empowering Multi-step Reasoning across Languages via Tree-of-Thoughts,0.308938,"Reasoning methods, best exemplified by the well-known Chain-of-Thought (CoT),
empower the reasoning abilities of Large Language Models (LLMs) by eliciting
them to solve complex tasks in a step-by-step manner. Although they are
achieving significant success, the ability to deliver multi-step reasoning
remains limited to English because of the imbalance in the distribution of
pre-training data, which makes other languages a barrier. In this paper, we
propose Cross-lingual Tree-of-Thoughts (Cross-ToT), a method for aligning
Cross-lingual CoT reasoning across languages. The proposed method, through a
self-consistent cross-lingual prompting mechanism inspired by the
Tree-of-Thoughts approach, provides multi-step reasoning paths in different
languages that, during the steps, lead to the final solution. Experimental
evaluations show that our method significantly outperforms existing prompting
methods by reducing the number of interactions and achieving state-of-the-art
performance."
Inferring Fluid Dynamics via Inverse Rendering,0.414274,"Humans have a strong intuitive understanding of physical processes such as
fluid falling by just a glimpse of such a scene picture, i.e., quickly derived
from our immersive visual experiences in memory. This work achieves such a
photo-to-fluid-dynamics reconstruction functionality learned from unannotated
videos, without any supervision of ground-truth fluid dynamics. In a nutshell,
a differentiable Euler simulator modeled with a ConvNet-based pressure
projection solver, is integrated with a volumetric renderer, supporting
end-to-end/coherent differentiable dynamic simulation and rendering. By
endowing each sampled point with a fluid volume value, we derive a NeRF-like
differentiable renderer dedicated from fluid data; and thanks to this
volume-augmented representation, fluid dynamics could be inversely inferred
from the error signal between the rendered result and ground-truth video frame
(i.e., inverse rendering). Experiments on our generated Fluid Fall datasets and
DPI Dam Break dataset are conducted to demonstrate both effectiveness and
generalization ability of our method."
SVL-Adapter: Self-Supervised Adapter for Vision-Language Pretrained Models,0.58979,"Vision-language models such as CLIP are pretrained on large volumes of
internet sourced image and text pairs, and have been shown to sometimes exhibit
impressive zero- and low-shot image classification performance. However, due to
their size, fine-tuning these models on new datasets can be prohibitively
expensive, both in terms of the supervision and compute required. To combat
this, a series of light-weight adaptation methods have been proposed to
efficiently adapt such models when limited supervision is available. In this
work, we show that while effective on internet-style datasets, even those
remedies under-deliver on classification tasks with images that differ
significantly from those commonly found online. To address this issue, we
present a new approach called SVL-Adapter that combines the complementary
strengths of both vision-language pretraining and self-supervised
representation learning. We report an average classification accuracy
improvement of 10% in the low-shot setting when compared to existing methods,
on a set of challenging visual classification tasks. Further, we present a
fully automatic way of selecting an important blending hyperparameter for our
model that does not require any held-out labeled validation data. Code for our
project is available here: https://github.com/omipan/svl_adapter."
Robust Unsupervised StyleGAN Image Restoration,0.683638,"GAN-based image restoration inverts the generative process to repair images
corrupted by known degradations. Existing unsupervised methods must be
carefully tuned for each task and degradation level. In this work, we make
StyleGAN image restoration robust: a single set of hyperparameters works across
a wide range of degradation levels. This makes it possible to handle
combinations of several degradations, without the need to retune. Our proposed
approach relies on a 3-phase progressive latent space extension and a
conservative optimizer, which avoids the need for any additional regularization
terms. Extensive experiments demonstrate robustness on inpainting, upsampling,
denoising, and deartifacting at varying degradations levels, outperforming
other StyleGAN-based inversion techniques. Our approach also favorably compares
to diffusion-based restoration by yielding much more realistic inversion
results. Code is available at https://lvsn.github.io/RobustUnsupervised/."
Karolos: An Open-Source Reinforcement Learning Framework for Robot-Task Environments,0.0667657,"In reinforcement learning (RL) research, simulations enable benchmarks
between algorithms, as well as prototyping and hyper-parameter tuning of
agents. In order to promote RL both in research and real-world applications,
frameworks are required which are on the one hand efficient in terms of running
experiments as fast as possible. On the other hand, they must be flexible
enough to allow the integration of newly developed optimization techniques,
e.g. new RL algorithms, which are continuously put forward by an active
research community. In this paper, we introduce Karolos, a RL framework
developed for robotic applications, with a particular focus on transfer
scenarios with varying robot-task combinations reflected in a modular
environment architecture. In addition, we provide implementations of
state-of-the-art RL algorithms along with common learning-facilitating
enhancements, as well as an architecture to parallelize environments across
multiple processes to significantly speed up experiments. The code is open
source and published on GitHub with the aim of promoting research of RL
applications in robotics."
Predicting Personas Using Mechanic Frequencies and Game State Traces,0.132863,"We investigate how to efficiently predict play personas based on playtraces.
Play personas can be computed by calculating the action agreement ratio between
a player and a generative model of playing behavior, a so-called procedural
persona. But this is computationally expensive and assumes that appropriate
procedural personas are readily available. We present two methods for
estimating player persona, one using regular supervised learning and aggregate
measures of game mechanics initiated, and another based on sequence learning on
a trace of closely cropped gameplay observations. While both of these methods
achieve high accuracy when predicting play personas defined by agreement with
procedural personas, they utterly fail to predict play style as defined by the
players themselves using a questionnaire. This interesting result highlights
the value of using computational methods in defining play personas."
SwinLSTM:Improving Spatiotemporal Prediction Accuracy using Swin Transformer and LSTM,0.92149,"Integrating CNNs and RNNs to capture spatiotemporal dependencies is a
prevalent strategy for spatiotemporal prediction tasks. However, the property
of CNNs to learn local spatial information decreases their efficiency in
capturing spatiotemporal dependencies, thereby limiting their prediction
accuracy. In this paper, we propose a new recurrent cell, SwinLSTM, which
integrates Swin Transformer blocks and the simplified LSTM, an extension that
replaces the convolutional structure in ConvLSTM with the self-attention
mechanism. Furthermore, we construct a network with SwinLSTM cell as the core
for spatiotemporal prediction. Without using unique tricks, SwinLSTM
outperforms state-of-the-art methods on Moving MNIST, Human3.6m, TaxiBJ, and
KTH datasets. In particular, it exhibits a significant improvement in
prediction accuracy compared to ConvLSTM. Our competitive experimental results
demonstrate that learning global spatial dependencies is more advantageous for
models to capture spatiotemporal dependencies. We hope that SwinLSTM can serve
as a solid baseline to promote the advancement of spatiotemporal prediction
accuracy. The codes are publicly available at
https://github.com/SongTang-x/SwinLSTM."
Not another Negation Benchmark: The NaN-NLI Test Suite for Sub-clausal Negation,0.87345,"Negation is poorly captured by current language models, although the extent
of this problem is not widely understood. We introduce a natural language
inference (NLI) test suite to enable probing the capabilities of NLP methods,
with the aim of understanding sub-clausal negation. The test suite contains
premise--hypothesis pairs where the premise contains sub-clausal negation and
the hypothesis is constructed by making minimal modifications to the premise in
order to reflect different possible interpretations. Aside from adopting
standard NLI labels, our test suite is systematically constructed under a
rigorous linguistic framework. It includes annotation of negation types and
constructions grounded in linguistic theory, as well as the operations used to
construct hypotheses. This facilitates fine-grained analysis of model
performance. We conduct experiments using pre-trained language models to
demonstrate that our test suite is more challenging than existing benchmarks
focused on negation, and show how our annotation supports a deeper
understanding of the current NLI capabilities in terms of negation and
quantification."
Stochastic Video Prediction with Structure and Motion,0.289014,"While stochastic video prediction models enable future prediction under
uncertainty, they mostly fail to model the complex dynamics of real-world
scenes. For example, they cannot provide reliable predictions for scenes with a
moving camera and independently moving foreground objects in driving scenarios.
The existing methods fail to fully capture the dynamics of the structured world
by only focusing on changes in pixels. In this paper, we assume that there is
an underlying process creating observations in a video and propose to factorize
it into static and dynamic components. We model the static part based on the
scene structure and the ego-motion of the vehicle, and the dynamic part based
on the remaining motion of the dynamic objects. By learning separate
distributions of changes in foreground and background, we can decompose the
scene into static and dynamic parts and separately model the change in each.
Our experiments demonstrate that disentangling structure and motion helps
stochastic video prediction, leading to better future predictions in complex
driving scenarios on two real-world driving datasets, KITTI and Cityscapes."
Dolphin: A Challenging and Diverse Benchmark for Arabic NLG,0.200897,"We present Dolphin, a novel benchmark that addresses the need for a natural
language generation (NLG) evaluation framework dedicated to the wide collection
of Arabic languages and varieties. The proposed benchmark encompasses a broad
range of 13 different NLG tasks, including dialogue generation, question
answering, machine translation, summarization, among others. Dolphin comprises
a substantial corpus of 40 diverse and representative public datasets across 50
test splits, carefully curated to reflect real-world scenarios and the
linguistic richness of Arabic. It sets a new standard for evaluating the
performance and generalization capabilities of Arabic and multilingual models,
promising to enable researchers to push the boundaries of current
methodologies. We provide an extensive analysis of Dolphin, highlighting its
diversity and identifying gaps in current Arabic NLG research. We also offer a
public leaderboard that is both interactive and modular and evaluate several
models on our benchmark, allowing us to set strong baselines against which
researchers can compare."
EVAL: Explainable Video Anomaly Localization,0.736143,"We develop a novel framework for single-scene video anomaly localization that
allows for human-understandable reasons for the decisions the system makes. We
first learn general representations of objects and their motions (using deep
networks) and then use these representations to build a high-level,
location-dependent model of any particular scene. This model can be used to
detect anomalies in new videos of the same scene. Importantly, our approach is
explainable - our high-level appearance and motion features can provide
human-understandable reasons for why any part of a video is classified as
normal or anomalous. We conduct experiments on standard video anomaly detection
datasets (Street Scene, CUHK Avenue, ShanghaiTech and UCSD Ped1, Ped2) and show
significant improvements over the previous state-of-the-art."
Global and Local Hierarchy-aware Contrastive Framework for Implicit Discourse Relation Recognition,0.634918,"Due to the absence of explicit connectives, implicit discourse relation
recognition (IDRR) remains a challenging task in discourse analysis. The
critical step for IDRR is to learn high-quality discourse relation
representations between two arguments. Recent methods tend to integrate the
whole hierarchical information of senses into discourse relation
representations for multi-level sense recognition. Nevertheless, they
insufficiently incorporate the static hierarchical structure containing all
senses (defined as global hierarchy), and ignore the hierarchical sense label
sequence corresponding to each instance (defined as local hierarchy). For the
purpose of sufficiently exploiting global and local hierarchies of senses to
learn better discourse relation representations, we propose a novel GlObal and
Local Hierarchy-aware Contrastive Framework (GOLF), to model two kinds of
hierarchies with the aid of multi-task learning and contrastive learning.
Experimental results on PDTB 2.0 and PDTB 3.0 datasets demonstrate that our
method remarkably outperforms current state-of-the-art models at all
hierarchical levels. Our code is publicly available at
https://github.com/YJiangcm/GOLF_for_IDRR"
Implicit State and Goals in QBF Encodings for Positional Games (extended version),0.797707,"We address two bottlenecks for concise QBF encodings of maker-breaker
positional games, like Hex and Tic-Tac-Toe. Our baseline is a QBF encoding with
explicit variables for board positions and an explicit representation of
winning configurations. The first improvement is inspired by lifted planning
and avoids variables for explicit board positions, introducing a universal
quantifier representing a symbolic board state. The second improvement
represents the winning configurations implicitly, exploiting their structure.
The paper evaluates the size of several encodings, depending on board size and
game depth. It also reports the performance of QBF solvers on these encodings.
We evaluate the techniques on Hex instances and also apply them to Harary's
Tic-Tac-Toe. In particular, we study scalability to 19$\times$19 boards, played
in human Hex tournaments."
Task-Balanced Distillation for Object Detection,0.518518,"Mainstream object detectors are commonly constituted of two sub-tasks,
including classification and regression tasks, implemented by two parallel
heads. This classic design paradigm inevitably leads to inconsistent spatial
distributions between classification score and localization quality (IOU).
Therefore, this paper alleviates this misalignment in the view of knowledge
distillation. First, we observe that the massive teacher achieves a higher
proportion of harmonious predictions than the lightweight student. Based on
this intriguing observation, a novel Harmony Score (HS) is devised to estimate
the alignment of classification and regression qualities. HS models the
relationship between two sub-tasks and is seen as prior knowledge to promote
harmonious predictions for the student. Second, this spatial misalignment will
result in inharmonious region selection when distilling features. To alleviate
this problem, a novel Task-decoupled Feature Distillation (TFD) is proposed by
flexibly balancing the contributions of classification and regression tasks.
Eventually, HD and TFD constitute the proposed method, named Task-Balanced
Distillation (TBD). Extensive experiments demonstrate the considerable
potential and generalization of the proposed method. Specifically, when
equipped with TBD, RetinaNet with ResNet-50 achieves 41.0 mAP under the COCO
benchmark, outperforming the recent FGD and FRS."
KG-MTT-BERT: Knowledge Graph Enhanced BERT for Multi-Type Medical Text Classification,0.528949,"Medical text learning has recently emerged as a promising area to improve
healthcare due to the wide adoption of electronic health record (EHR) systems.
The complexity of the medical text such as diverse length, mixed text types,
and full of medical jargon, poses a great challenge for developing effective
deep learning models. BERT has presented state-of-the-art results in many NLP
tasks, such as text classification and question answering. However, the
standalone BERT model cannot deal with the complexity of the medical text,
especially the lengthy clinical notes. Herein, we develop a new model called
KG-MTT-BERT (Knowledge Graph Enhanced Multi-Type Text BERT) by extending the
BERT model for long and multi-type text with the integration of the medical
knowledge graph. Our model can outperform all baselines and other
state-of-the-art models in diagnosis-related group (DRG) classification, which
requires comprehensive medical text for accurate classification. We also
demonstrated that our model can effectively handle multi-type text and the
integration of medical knowledge graph can significantly improve the
performance."
Speeding Up Question Answering Task of Language Models via Inverted Index,0.0382962,"Natural language processing applications, such as conversational agents and
their question-answering capabilities, are widely used in the real world.
Despite the wide popularity of large language models (LLMs), few real-world
conversational agents take advantage of LLMs. Extensive resources consumed by
LLMs disable developers from integrating them into end-user applications. In
this study, we leverage an inverted indexing mechanism combined with LLMs to
improve the efficiency of question-answering models for closed-domain
questions. Our experiments show that using the index improves the average
response time by 97.44%. In addition, due to the reduced search scope, the
average BLEU score improved by 0.23 while using the inverted index."
Self-Prompting Large Language Models for Zero-Shot Open-Domain QA,0.18099,"Open-Domain Question Answering (ODQA) aims to answer questions without
explicitly providing specific background documents. This task becomes notably
challenging in a zero-shot setting where no data is available to train tailored
retrieval-reader models. While recent Large Language Models (LLMs) like GPT-3
have demonstrated their effectiveness in zero-shot ODQA using direct prompting
methods, these methods still fall short of fully harnessing the potential of
LLMs when implicitly invoked. In this paper, we propose a Self-Prompting
framework to explicitly utilize the massive knowledge encoded in the parameters
of LLMs and their strong instruction understanding abilities. Concretely, we
prompt LLMs step by step to generate multiple pseudo QA pairs with background
passages and explanations entirely from scratch. These generated elements are
then utilized for in-context learning. Experimental results show that our
method significantly surpasses previous state-of-the-art zero-shot methods on
three widely-used ODQA datasets and even achieves comparable performance with
various customized fine-tuned models on full training data. Our code is
available at https://github.com/lockon-n/self-prompting."
Formal Mathematics Statement Curriculum Learning,0.999974,"We explore the use of expert iteration in the context of language modeling
applied to formal mathematics. We show that at same compute budget, expert
iteration, by which we mean proof search interleaved with learning,
dramatically outperforms proof search only. We also observe that when applied
to a collection of formal statements of sufficiently varied difficulty, expert
iteration is capable of finding and solving a curriculum of increasingly
difficult problems, without the need for associated ground-truth proofs.
Finally, by applying this expert iteration to a manually curated set of problem
statements, we achieve state-of-the-art on the miniF2F benchmark, automatically
solving multiple challenging problems drawn from high school olympiads."
"Dimensional Modeling of Emotions in Text with Appraisal Theories: Corpus Creation, Annotation Reliability, and Prediction",0.593437,"The most prominent tasks in emotion analysis are to assign emotions to texts
and to understand how emotions manifest in language. An observation for NLP is
that emotions can be communicated implicitly by referring to events, appealing
to an empathetic, intersubjective understanding of events, even without
explicitly mentioning an emotion name. In psychology, the class of emotion
theories known as appraisal theories aims at explaining the link between events
and emotions. Appraisals can be formalized as variables that measure a
cognitive evaluation by people living through an event that they consider
relevant. They include the assessment if an event is novel, if the person
considers themselves to be responsible, if it is in line with the own goals,
and many others. Such appraisals explain which emotions are developed based on
an event, e.g., that a novel situation can induce surprise or one with
uncertain consequences could evoke fear. We analyze the suitability of
appraisal theories for emotion analysis in text with the goal of understanding
if appraisal concepts can reliably be reconstructed by annotators, if they can
be predicted by text classifiers, and if appraisal concepts help to identify
emotion categories. To achieve that, we compile a corpus by asking people to
textually describe events that triggered particular emotions and to disclose
their appraisals. Then, we ask readers to reconstruct emotions and appraisals
from the text. This setup allows us to measure if emotions and appraisals can
be recovered purely from text and provides a human baseline. Our comparison of
text classification methods to human annotators shows that both can reliably
detect emotions and appraisals with similar performance. Therefore, appraisals
constitute an alternative computational emotion analysis paradigm and further
improve the categorization of emotions in text with joint models."
"Accountability in an Algorithmic Society: Relationality, Responsibility, and Robustness in Machine Learning",0.987283,"In 1996, Accountability in a Computerized Society [95] issued a clarion call
concerning the erosion of accountability in society due to the ubiquitous
delegation of consequential functions to computerized systems. Nissenbaum [95]
described four barriers to accountability that computerization presented, which
we revisit in relation to the ascendance of data-driven algorithmic
systems--i.e., machine learning or artificial intelligence--to uncover new
challenges for accountability that these systems present. Nissenbaum's original
paper grounded discussion of the barriers in moral philosophy; we bring this
analysis together with recent scholarship on relational accountability
frameworks and discuss how the barriers present difficulties for instantiating
a unified moral, relational framework in practice for data-driven algorithmic
systems. We conclude by discussing ways of weakening the barriers in order to
do so."
MT Metrics Correlate with Human Ratings of Simultaneous Speech Translation,0.451782,"There have been several meta-evaluation studies on the correlation between
human ratings and offline machine translation (MT) evaluation metrics such as
BLEU, chrF2, BertScore and COMET. These metrics have been used to evaluate
simultaneous speech translation (SST) but their correlations with human ratings
of SST, which has been recently collected as Continuous Ratings (CR), are
unclear. In this paper, we leverage the evaluations of candidate systems
submitted to the English-German SST task at IWSLT 2022 and conduct an extensive
correlation analysis of CR and the aforementioned metrics. Our study reveals
that the offline metrics are well correlated with CR and can be reliably used
for evaluating machine translation in simultaneous mode, with some limitations
on the test set size. We conclude that given the current quality levels of SST,
these metrics can be used as proxies for CR, alleviating the need for large
scale human evaluation. Additionally, we observe that correlations of the
metrics with translation as a reference is significantly higher than with
simultaneous interpreting, and thus we recommend the former for reliable
evaluation."
Using Text Injection to Improve Recognition of Personal Identifiers in Speech,0.678188,"Accurate recognition of specific categories, such as persons' names, dates or
other identifiers is critical in many Automatic Speech Recognition (ASR)
applications. As these categories represent personal information, ethical use
of this data including collection, transcription, training and evaluation
demands special care. One way of ensuring the security and privacy of
individuals is to redact or eliminate Personally Identifiable Information (PII)
from collection altogether. However, this results in ASR models that tend to
have lower recognition accuracy of these categories. We use text-injection to
improve the recognition of PII categories by including fake textual substitutes
of PII categories in the training data using a text injection method. We
demonstrate substantial improvement to Recall of Names and Dates in medical
notes while improving overall WER. For alphanumeric digit sequences we show
improvements to Character Error Rate and Sentence Accuracy."
Compressing Video Calls using Synthetic Talking Heads,0.742665,"We leverage the modern advancements in talking head generation to propose an
end-to-end system for talking head video compression. Our algorithm transmits
pivot frames intermittently while the rest of the talking head video is
generated by animating them. We use a state-of-the-art face reenactment network
to detect key points in the non-pivot frames and transmit them to the receiver.
A dense flow is then calculated to warp a pivot frame to reconstruct the
non-pivot ones. Transmitting key points instead of full frames leads to
significant compression. We propose a novel algorithm to adaptively select the
best-suited pivot frames at regular intervals to provide a smooth experience.
We also propose a frame-interpolater at the receiver's end to improve the
compression levels further. Finally, a face enhancement network improves
reconstruction quality, significantly improving several aspects like the
sharpness of the generations. We evaluate our method both qualitatively and
quantitatively on benchmark datasets and compare it with multiple compression
techniques. We release a demo video and additional information at
https://cvit.iiit.ac.in/research/projects/cvit-projects/talking-video-compression."
Towards Privacy-Preserving Person Re-identification via Person Identify Shift,0.505474,"Recently privacy concerns of person re-identification (ReID) raise more and
more attention and preserving the privacy of the pedestrian images used by ReID
methods become essential. De-identification (DeID) methods alleviate privacy
issues by removing the identity-related of the ReID data. However, most of the
existing DeID methods tend to remove all personal identity-related information
and compromise the usability of de-identified data on the ReID task. In this
paper, we aim to develop a technique that can achieve a good trade-off between
privacy protection and data usability for person ReID. To achieve this, we
propose a novel de-identification method designed explicitly for person ReID,
named Person Identify Shift (PIS). PIS removes the absolute identity in a
pedestrian image while preserving the identity relationship between image
pairs. By exploiting the interpolation property of variational auto-encoder,
PIS shifts each pedestrian image from the current identity to another with a
new identity, resulting in images still preserving the relative identities.
Experimental results show that our method has a better trade-off between
privacy-preserving and model performance than existing de-identification
methods and can defend against human and model attacks for data privacy."
Adversarial random forests for density estimation and generative modeling,0.245852,"We propose methods for density estimation and data synthesis using a novel
form of unsupervised random forests. Inspired by generative adversarial
networks, we implement a recursive procedure in which trees gradually learn
structural properties of the data through alternating rounds of generation and
discrimination. The method is provably consistent under minimal assumptions.
Unlike classic tree-based alternatives, our approach provides smooth
(un)conditional densities and allows for fully synthetic data generation. We
achieve comparable or superior performance to state-of-the-art probabilistic
circuits and deep learning models on various tabular data benchmarks while
executing about two orders of magnitude faster on average. An accompanying
$\texttt{R}$ package, $\texttt{arf}$, is available on $\texttt{CRAN}$."
Evolutionary latent space search for driving human portrait generation,0.607252,"This article presents an evolutionary approach for synthetic human portraits
generation based on the latent space exploration of a generative adversarial
network. The idea is to produce different human face images very similar to a
given target portrait. The approach applies StyleGAN2 for portrait generation
and FaceNet for face similarity evaluation. The evolutionary search is based on
exploring the real-coded latent space of StyleGAN2. The main results over both
synthetic and real images indicate that the proposed approach generates
accurate and diverse solutions, which represent realistic human portraits. The
proposed research can contribute to improving the security of face recognition
systems."
DiT: Self-supervised Pre-training for Document Image Transformer,0.753793,"Image Transformer has recently achieved significant progress for natural
image understanding, either using supervised (ViT, DeiT, etc.) or
self-supervised (BEiT, MAE, etc.) pre-training techniques. In this paper, we
propose \textbf{DiT}, a self-supervised pre-trained \textbf{D}ocument
\textbf{I}mage \textbf{T}ransformer model using large-scale unlabeled text
images for Document AI tasks, which is essential since no supervised
counterparts ever exist due to the lack of human-labeled document images. We
leverage DiT as the backbone network in a variety of vision-based Document AI
tasks, including document image classification, document layout analysis, table
detection as well as text detection for OCR. Experiment results have
illustrated that the self-supervised pre-trained DiT model achieves new
state-of-the-art results on these downstream tasks, e.g. document image
classification (91.11 $\rightarrow$ 92.69), document layout analysis (91.0
$\rightarrow$ 94.9), table detection (94.23 $\rightarrow$ 96.55) and text
detection for OCR (93.07 $\rightarrow$ 94.29). The code and pre-trained models
are publicly available at \url{https://aka.ms/msdit}."
How reparametrization trick broke differentially-private text representation learning,0.548551,"As privacy gains traction in the NLP community, researchers have started
adopting various approaches to privacy-preserving methods. One of the favorite
privacy frameworks, differential privacy (DP), is perhaps the most compelling
thanks to its fundamental theoretical guarantees. Despite the apparent
simplicity of the general concept of differential privacy, it seems non-trivial
to get it right when applying it to NLP. In this short paper, we formally
analyze several recent NLP papers proposing text representation learning using
DPText (Beigi et al., 2019a,b; Alnasser et al., 2021; Beigi et al., 2021) and
reveal their false claims of being differentially private. Furthermore, we also
show a simple yet general empirical sanity check to determine whether a given
implementation of a DP mechanism almost certainly violates the privacy loss
guarantees. Our main goal is to raise awareness and help the community
understand potential pitfalls of applying differential privacy to text
representation learning."
A Fast Post-Training Pruning Framework for Transformers,0.615454,"Pruning is an effective way to reduce the huge inference cost of Transformer
models. However, prior work on pruning Transformers requires retraining the
models. This can add high training cost and high complexity to model
deployment, making it difficult to use in many practical situations. To address
this, we propose a fast post-training pruning framework for Transformers that
does not require any retraining. Given a resource constraint and a sample
dataset, our framework automatically prunes the Transformer model using
structured sparsity methods. To retain high accuracy without retraining, we
introduce three novel techniques: (i) a lightweight mask search algorithm that
finds which heads and filters to prune based on the Fisher information; (ii)
mask rearrangement that complements the search algorithm; and (iii) mask tuning
that reconstructs the output activations for each layer. We apply our method to
BERT-base and DistilBERT, and we evaluate its effectiveness on GLUE and SQuAD
benchmarks. Our framework achieves up to 2.0x reduction in FLOPs and 1.56x
speedup in inference latency, while maintaining < 1% loss in accuracy.
Importantly, our framework prunes Transformers in less than 3 minutes on a
single GPU, which is over two orders of magnitude faster than existing pruning
approaches that retrain the models."
"MAVEN-ERE: A Unified Large-scale Dataset for Event Coreference, Temporal, Causal, and Subevent Relation Extraction",0.979835,"The diverse relationships among real-world events, including coreference,
temporal, causal, and subevent relations, are fundamental to understanding
natural languages. However, two drawbacks of existing datasets limit event
relation extraction (ERE) tasks: (1) Small scale. Due to the annotation
complexity, the data scale of existing datasets is limited, which cannot well
train and evaluate data-hungry models. (2) Absence of unified annotation.
Different types of event relations naturally interact with each other, but
existing datasets only cover limited relation types at once, which prevents
models from taking full advantage of relation interactions. To address these
issues, we construct a unified large-scale human-annotated ERE dataset
MAVEN-ERE with improved annotation schemes. It contains 103,193 event
coreference chains, 1,216,217 temporal relations, 57,992 causal relations, and
15,841 subevent relations, which is larger than existing datasets of all the
ERE tasks by at least an order of magnitude. Experiments show that ERE on
MAVEN-ERE is quite challenging, and considering relation interactions with
joint learning can improve performances. The dataset and source codes can be
obtained from https://github.com/THU-KEG/MAVEN-ERE."
Short Answer Grading Using One-shot Prompting and Text Similarity Scoring Model,0.796142,"In this study, we developed an automated short answer grading (ASAG) model
that provided both analytic scores and final holistic scores. Short answer
items typically consist of multiple sub-questions, and providing an analytic
score and the text span relevant to each sub-question can increase the
interpretability of the automated scores. Furthermore, they can be used to
generate actionable feedback for students. Despite these advantages, most
studies have focused on predicting only holistic scores due to the difficulty
in constructing dataset with manual annotations. To address this difficulty, we
used large language model (LLM)-based one-shot prompting and a text similarity
scoring model with domain adaptation using small manually annotated dataset.
The accuracy and quadratic weighted kappa of our model were 0.67 and 0.71 on a
subset of the publicly available ASAG dataset. The model achieved a substantial
improvement over the majority baseline."
Fourier Analysis on Robustness of Graph Convolutional Neural Networks for Skeleton-based Action Recognition,0.252638,"Using Fourier analysis, we explore the robustness and vulnerability of graph
convolutional neural networks (GCNs) for skeleton-based action recognition. We
adopt a joint Fourier transform (JFT), a combination of the graph Fourier
transform (GFT) and the discrete Fourier transform (DFT), to examine the
robustness of adversarially-trained GCNs against adversarial attacks and common
corruptions. Experimental results with the NTU RGB+D dataset reveal that
adversarial training does not introduce a robustness trade-off between
adversarial attacks and low-frequency perturbations, which typically occurs
during image classification based on convolutional neural networks. This
finding indicates that adversarial training is a practical approach to
enhancing robustness against adversarial attacks and common corruptions in
skeleton-based action recognition. Furthermore, we find that the Fourier
approach cannot explain vulnerability against skeletal part occlusion
corruption, which highlights its limitations. These findings extend our
understanding of the robustness of GCNs, potentially guiding the development of
more robust learning methods for skeleton-based action recognition."
Intelligence-Endogenous Management Platform for Computing and Network Convergence,0.324818,"Massive emerging applications are driving demand for the ubiquitous
deployment of computing power today. This trend not only spurs the recent
popularity of the \emph{Computing and Network Convergence} (CNC), but also
introduces an urgent need for the intelligentization of a management platform
to coordinate changing resources and tasks in the CNC. Therefore, in this
article, we present the concept of an intelligence-endogenous management
platform for CNCs called \emph{CNC brain} based on artificial intelligence
technologies. It aims at efficiently and automatically matching the supply and
demand with high heterogeneity in a CNC via four key building blocks, i.e.,
perception, scheduling, adaptation, and governance, throughout the CNC's life
cycle. Their functionalities, goals, and challenges are presented. To examine
the effectiveness of the proposed concept and framework, we also implement a
prototype for the CNC brain based on a deep reinforcement learning technology.
Also, it is evaluated on a CNC testbed that integrates two open-source and
popular frameworks (OpenFaas and Kubernetes) and a real-world business dataset
provided by Microsoft Azure. The evaluation results prove the proposed method's
effectiveness in terms of resource utilization and performance. Finally, we
highlight the future research directions of the CNC brain."
ANALOGYKB: Unlocking Analogical Reasoning of Language Models with A Million-scale Knowledge Base,0.154417,"Analogical reasoning is a fundamental cognitive ability of humans. However,
current language models (LMs) still struggle to achieve human-like performance
in analogical reasoning tasks due to a lack of resources for model training. In
this work, we address this gap by proposing ANALOGYKB, a million-scale analogy
knowledge base (KB) derived from existing knowledge graphs (KGs). ANALOGYKB
identifies two types of analogies from the KGs: 1) analogies of the same
relations, which can be directly extracted from the KGs, and 2) analogies of
analogous relations, which are identified with a selection and filtering
pipeline enabled by large language models (LLMs), followed by minor human
efforts for data quality control. Evaluations on a series of datasets of two
analogical reasoning tasks (analogy recognition and generation) demonstrate
that ANALOGYKB successfully enables both smaller LMs and LLMs to gain better
analogical reasoning capabilities."
Deep Learning Architecture for Automatic Essay Scoring,0.169064,"Automatic evaluation of essay (AES) and also called automatic essay scoring
has become a severe problem due to the rise of online learning and evaluation
platforms such as Coursera, Udemy, Khan academy, and so on. Researchers have
recently proposed many techniques for automatic evaluation. However, many of
these techniques use hand-crafted features and thus are limited from the
feature representation point of view. Deep learning has emerged as a new
paradigm in machine learning which can exploit the vast data and identify the
features useful for essay evaluation. To this end, we propose a novel
architecture based on recurrent networks (RNN) and convolution neural network
(CNN). In the proposed architecture, the multichannel convolutional layer
learns and captures the contextual features of the word n-gram from the word
embedding vectors and the essential semantic concepts to form the feature
vector at essay level using max-pooling operation. A variant of RNN called
Bi-gated recurrent unit (BGRU) is used to access both previous and subsequent
contextual representations. The experiment was carried out on eight data sets
available on Kaggle for the task of AES. The experimental results show that our
proposed system achieves significantly higher grading accuracy than other deep
learning-based AES systems and also other state-of-the-art AES systems."
Beyond Isolation: Multi-Agent Synergy for Improving Knowledge Graph Construction,0.686121,"Knowledge graph construction (KGC) is a multifaceted undertaking involving
the extraction of entities, relations, and events. Traditionally, large
language models (LLMs) have been viewed as solitary task-solving agents in this
complex landscape. However, this paper challenges this paradigm by introducing
a novel framework, CooperKGC. Departing from the conventional approach,
CooperKGC establishes a collaborative processing network, assembling a KGC
collaboration team capable of concurrently addressing entity, relation, and
event extraction tasks. Our experiments unequivocally demonstrate that
fostering collaboration and information interaction among diverse agents within
CooperKGC yields superior results compared to individual cognitive processes
operating in isolation. Importantly, our findings reveal that the collaboration
facilitated by CooperKGC enhances knowledge selection, correction, and
aggregation capabilities across multiple rounds of interactions."
"On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning",0.82327,"Generating a Chain of Thought (CoT) has been shown to consistently improve
large language model (LLM) performance on a wide range of NLP tasks. However,
prior work has mainly focused on logical reasoning tasks (e.g. arithmetic,
commonsense QA); it remains unclear whether improvements hold for more diverse
types of reasoning, especially in socially situated contexts. Concretely, we
perform a controlled evaluation of zero-shot CoT across two socially sensitive
domains: harmful questions and stereotype benchmarks. We find that zero-shot
CoT reasoning in sensitive domains significantly increases a model's likelihood
to produce harmful or undesirable output, with trends holding across different
prompt formats and model variants. Furthermore, we show that harmful CoTs
increase with model size, but decrease with improved instruction following. Our
work suggests that zero-shot CoT should be used with caution on socially
important tasks, especially when marginalized groups or sensitive topics are
involved."
Models and Benchmarks for Representation Learning of Partially Observed Subgraphs,0.0256015,"Subgraphs are rich substructures in graphs, and their nodes and edges can be
partially observed in real-world tasks. Under partial observation, existing
node- or subgraph-level message-passing produces suboptimal representations. In
this paper, we formulate a novel task of learning representations of partially
observed subgraphs. To solve this problem, we propose Partial Subgraph InfoMax
(PSI) framework and generalize existing InfoMax models, including DGI,
InfoGraph, MVGRL, and GraphCL, into our framework. These models maximize the
mutual information between the partial subgraph's summary and various
substructures from nodes to full subgraphs. In addition, we suggest a novel
two-stage model with $k$-hop PSI, which reconstructs the representation of the
full subgraph and improves its expressiveness from different local-global
structures. Under training and evaluation protocols designed for this problem,
we conduct experiments on three real-world datasets and demonstrate that PSI
models outperform baselines."
Semi-Supervised Knowledge-Grounded Pre-training for Task-Oriented Dialog Systems,0.885175,"Recent advances in neural approaches greatly improve task-oriented dialogue
(TOD) systems which assist users to accomplish their goals. However, such
systems rely on costly manually labeled dialogs which are not available in
practical scenarios. In this paper, we present our models for Track 2 of the
SereTOD 2022 challenge, which is the first challenge of building
semi-supervised and reinforced TOD systems on a large-scale real-world Chinese
TOD dataset MobileCS. We build a knowledge-grounded dialog model to formulate
dialog history and local KB as input and predict the system response. And we
perform semi-supervised pre-training both on the labeled and unlabeled data.
Our system achieves the first place both in the automatic evaluation and human
interaction, especially with higher BLEU (+7.64) and Success (+13.6\%) than the
second place."
Subsampling for Knowledge Graph Embedding Explained,0.125139,"In this article, we explain the recent advance of subsampling methods in
knowledge graph embedding (KGE) starting from the original one used in
word2vec."
Measuring Cognitive Workload Using Multimodal Sensors,0.422435,"This study aims to identify a set of indicators to estimate cognitive
workload using a multimodal sensing approach and machine learning. A set of
three cognitive tests were conducted to induce cognitive workload in twelve
participants at two levels of task difficulty (Easy and Hard). Four sensors
were used to measure the participants' physiological change, including,
Electrocardiogram (ECG), electrodermal activity (EDA), respiration (RESP), and
blood oxygen saturation (SpO2). To understand the perceived cognitive workload,
NASA-TLX was used after each test and analysed using Chi-Square test. Three
well-know classifiers (LDA, SVM, and DT) were trained and tested independently
using the physiological data. The statistical analysis showed that
participants' perceived cognitive workload was significantly different
(p<0.001) between the tests, which demonstrated the validity of the
experimental conditions to induce different cognitive levels. Classification
results showed that a fusion of ECG and EDA presented good discriminating power
(acc=0.74) for cognitive workload detection. This study provides preliminary
results in the identification of a possible set of indicators of cognitive
workload. Future work needs to be carried out to validate the indicators using
more realistic scenarios and with a larger population."
"Sea Ice Extraction via Remote Sensed Imagery: Algorithms, Datasets, Applications and Challenges",0.777271,"The deep learning, which is a dominating technique in artificial
intelligence, has completely changed the image understanding over the past
decade. As a consequence, the sea ice extraction (SIE) problem has reached a
new era. We present a comprehensive review of four important aspects of SIE,
including algorithms, datasets, applications, and the future trends. Our review
focuses on researches published from 2016 to the present, with a specific focus
on deep learning-based approaches in the last five years. We divided all
relegated algorithms into 3 categories, including classical image segmentation
approach, machine learning-based approach and deep learning-based methods. We
reviewed the accessible ice datasets including SAR-based datasets, the
optical-based datasets and others. The applications are presented in 4 aspects
including climate research, navigation, geographic information systems (GIS)
production and others. It also provides insightful observations and inspiring
future research directions."
Reflectance-Oriented Probabilistic Equalization for Image Enhancement,0.713495,"Despite recent advances in image enhancement, it remains difficult for
existing approaches to adaptively improve the brightness and contrast for both
low-light and normal-light images. To solve this problem, we propose a novel 2D
histogram equalization approach. It assumes intensity occurrence and
co-occurrence to be dependent on each other and derives the distribution of
intensity occurrence (1D histogram) by marginalizing over the distribution of
intensity co-occurrence (2D histogram). This scheme improves global contrast
more effectively and reduces noise amplification. The 2D histogram is defined
by incorporating the local pixel value differences in image reflectance into
the density estimation to alleviate the adverse effects of dark lighting
conditions. Over 500 images were used for evaluation, demonstrating the
superiority of our approach over existing studies. It can sufficiently improve
the brightness of low-light images while avoiding over-enhancement in
normal-light images."
Can Foundation Models Perform Zero-Shot Task Specification For Robot Manipulation?,0.893012,"Task specification is at the core of programming autonomous robots. A
low-effort modality for task specification is critical for engagement of
non-expert end-users and ultimate adoption of personalized robot agents. A
widely studied approach to task specification is through goals, using either
compact state vectors or goal images from the same robot scene. The former is
hard to interpret for non-experts and necessitates detailed state estimation
and scene understanding. The latter requires the generation of desired goal
image, which often requires a human to complete the task, defeating the purpose
of having autonomous robots. In this work, we explore alternate and more
general forms of goal specification that are expected to be easier for humans
to specify and use such as images obtained from the internet, hand sketches
that provide a visual description of the desired task, or simple language
descriptions. As a preliminary step towards this, we investigate the
capabilities of large scale pre-trained models (foundation models) for
zero-shot goal specification, and find promising results in a collection of
simulated robot manipulation tasks and real-world datasets."
Agile Maneuvers in Legged Robots: a Predictive Control Approach,0.826171,"Planning and execution of agile locomotion maneuvers have been a longstanding
challenge in legged robotics. It requires to derive motion plans and local
feedback policies in real-time to handle the nonholonomy of the kinetic
momenta. To achieve so, we propose a hybrid predictive controller that
considers the robot's actuation limits and full-body dynamics. It combines the
feedback policies with tactile information to locally predict future actions.
It converges within a few milliseconds thanks to a feasibility-driven approach.
Our predictive controller enables ANYmal robots to generate agile maneuvers in
realistic scenarios. A crucial element is to track the local feedback policies
as, in contrast to whole-body control, they achieve the desired angular
momentum. To the best of our knowledge, our predictive controller is the first
to handle actuation limits, generate agile locomotion maneuvers, and execute
optimal feedback policies for low level torque control without the use of a
separate whole-body controller."
Dual-Geometric Space Embedding Model for Two-View Knowledge Graphs,0.692489,"Two-view knowledge graphs (KGs) jointly represent two components: an ontology
view for abstract and commonsense concepts, and an instance view for specific
entities that are instantiated from ontological concepts. As such, these KGs
contain heterogeneous structures that are hierarchical, from the ontology-view,
and cyclical, from the instance-view. Despite these various structures in KGs,
most recent works on embedding KGs assume that the entire KG belongs to only
one of the two views but not both simultaneously. For works that seek to put
both views of the KG together, the instance and ontology views are assumed to
belong to the same geometric space, such as all nodes embedded in the same
Euclidean space or non-Euclidean product space, an assumption no longer
reasonable for two-view KGs where different portions of the graph exhibit
different structures. To address this issue, we define and construct a
dual-geometric space embedding model (DGS) that models two-view KGs using a
complex non-Euclidean geometric space, by embedding different portions of the
KG in different geometric spaces. DGS utilizes the spherical space, hyperbolic
space, and their intersecting space in a unified framework for learning
embeddings. Furthermore, for the spherical space, we propose novel closed
spherical space operators that directly operate in the spherical space without
the need for mapping to an approximate tangent space. Experiments on public
datasets show that DGS significantly outperforms previous state-of-the-art
baseline models on KG completion tasks, demonstrating its ability to better
model heterogeneous structures in KGs."
GarmentTracking: Category-Level Garment Pose Tracking,0.741504,"Garments are important to humans. A visual system that can estimate and track
the complete garment pose can be useful for many downstream tasks and
real-world applications. In this work, we present a complete package to address
the category-level garment pose tracking task: (1) A recording system
VR-Garment, with which users can manipulate virtual garment models in
simulation through a VR interface. (2) A large-scale dataset VR-Folding, with
complex garment pose configurations in manipulation like flattening and
folding. (3) An end-to-end online tracking framework GarmentTracking, which
predicts complete garment pose both in canonical space and task space given a
point cloud sequence. Extensive experiments demonstrate that the proposed
GarmentTracking achieves great performance even when the garment has large
non-rigid deformation. It outperforms the baseline approach on both speed and
accuracy. We hope our proposed solution can serve as a platform for future
research. Codes and datasets are available in
https://garment-tracking.robotflow.ai."
The Swiss Army Knife for Image-to-Image Translation: Multi-Task Diffusion Models,0.744067,"Recently, diffusion models were applied to a wide range of image analysis
tasks. We build on a method for image-to-image translation using denoising
diffusion implicit models and include a regression problem and a segmentation
problem for guiding the image generation to the desired output. The main
advantage of our approach is that the guidance during the denoising process is
done by an external gradient. Consequently, the diffusion model does not need
to be retrained for the different tasks on the same dataset. We apply our
method to simulate the aging process on facial photos using a regression task,
as well as on a brain magnetic resonance (MR) imaging dataset for the
simulation of brain tumor growth. Furthermore, we use a segmentation model to
inpaint tumors at the desired location in healthy slices of brain MR images. We
achieve convincing results for all problems."
Denoising Diffusion for 3D Hand Pose Estimation from Images,0.424571,"Hand pose estimation from a single image has many applications. However,
approaches to full 3D body pose estimation are typically trained on day-to-day
activities or actions. As such, detailed hand-to-hand interactions are poorly
represented, especially during motion. We see this in the failure cases of
techniques such as OpenPose or MediaPipe. However, accurate hand pose
estimation is crucial for many applications where the global body motion is
less important than accurate hand pose estimation.
  This paper addresses the problem of 3D hand pose estimation from monocular
images or sequences. We present a novel end-to-end framework for 3D hand
regression that employs diffusion models that have shown excellent ability to
capture the distribution of data for generative purposes. Moreover, we enforce
kinematic constraints to ensure realistic poses are generated by incorporating
an explicit forward kinematic layer as part of the network. The proposed model
provides state-of-the-art performance when lifting a 2D single-hand image to
3D. However, when sequence data is available, we add a Transformer module over
a temporal window of consecutive frames to refine the results, overcoming
jittering and further increasing accuracy.
  The method is quantitatively and qualitatively evaluated showing
state-of-the-art robustness, generalization, and accuracy on several different
datasets."
TopFormer: Token Pyramid Transformer for Mobile Semantic Segmentation,0.940239,"Although vision transformers (ViTs) have achieved great success in computer
vision, the heavy computational cost hampers their applications to dense
prediction tasks such as semantic segmentation on mobile devices. In this
paper, we present a mobile-friendly architecture named \textbf{To}ken
\textbf{P}yramid Vision Trans\textbf{former} (\textbf{TopFormer}). The proposed
\textbf{TopFormer} takes Tokens from various scales as input to produce
scale-aware semantic features, which are then injected into the corresponding
tokens to augment the representation. Experimental results demonstrate that our
method significantly outperforms CNN- and ViT-based networks across several
semantic segmentation datasets and achieves a good trade-off between accuracy
and latency. On the ADE20K dataset, TopFormer achieves 5\% higher accuracy in
mIoU than MobileNetV3 with lower latency on an ARM-based mobile device.
Furthermore, the tiny version of TopFormer achieves real-time inference on an
ARM-based mobile device with competitive results. The code and models are
available at: https://github.com/hustvl/TopFormer"
Fine-grained Affective Processing Capabilities Emerging from Large Language Models,0.364653,"Large language models, in particular generative pre-trained transformers
(GPTs), show impressive results on a wide variety of language-related tasks. In
this paper, we explore ChatGPT's zero-shot ability to perform affective
computing tasks using prompting alone. We show that ChatGPT a) performs
meaningful sentiment analysis in the Valence, Arousal and Dominance dimensions,
b) has meaningful emotion representations in terms of emotion categories and
these affective dimensions, and c) can perform basic appraisal-based emotion
elicitation of situations based on a prompt-based computational implementation
of the OCC appraisal model. These findings are highly relevant: First, they
show that the ability to solve complex affect processing tasks emerges from
language-based token prediction trained on extensive data sets. Second, they
show the potential of large language models for simulating, processing and
analyzing human emotions, which has important implications for various
applications such as sentiment analysis, socially interactive agents, and
social robotics."
Volume Rendering Digest (for NeRF),0.561598,"Neural Radiance Fields employ simple volume rendering as a way to overcome
the challenges of differentiating through ray-triangle intersections by
leveraging a probabilistic notion of visibility. This is achieved by assuming
the scene is composed by a cloud of light-emitting particles whose density
changes in space. This technical report summarizes the derivations for
differentiable volume rendering. It is a condensed version of previous reports,
but rewritten in the context of NeRF, and adopting its commonly used notation."
Few-Shot Physically-Aware Articulated Mesh Generation via Hierarchical Deformation,0.374643,"We study the problem of few-shot physically-aware articulated mesh
generation. By observing an articulated object dataset containing only a few
examples, we wish to learn a model that can generate diverse meshes with high
visual fidelity and physical validity. Previous mesh generative models either
have difficulties in depicting a diverse data space from only a few examples or
fail to ensure physical validity of their samples. Regarding the above
challenges, we propose two key innovations, including 1) a hierarchical mesh
deformation-based generative model based upon the divide-and-conquer philosophy
to alleviate the few-shot challenge by borrowing transferrable deformation
patterns from large scale rigid meshes and 2) a physics-aware deformation
correction scheme to encourage physically plausible generations. We conduct
extensive experiments on 6 articulated categories to demonstrate the
superiority of our method in generating articulated meshes with better
diversity, higher visual fidelity, and better physical validity over previous
methods in the few-shot setting. Further, we validate solid contributions of
our two innovations in the ablation study. Project page with code is available
at https://meowuu7.github.io/few-arti-obj-gen."
I$^2$-SDF: Intrinsic Indoor Scene Reconstruction and Editing via Raytracing in Neural SDFs,0.938915,"In this work, we present I$^2$-SDF, a new method for intrinsic indoor scene
reconstruction and editing using differentiable Monte Carlo raytracing on
neural signed distance fields (SDFs). Our holistic neural SDF-based framework
jointly recovers the underlying shapes, incident radiance and materials from
multi-view images. We introduce a novel bubble loss for fine-grained small
objects and error-guided adaptive sampling scheme to largely improve the
reconstruction quality on large-scale indoor scenes. Further, we propose to
decompose the neural radiance field into spatially-varying material of the
scene as a neural field through surface-based, differentiable Monte Carlo
raytracing and emitter semantic segmentations, which enables physically based
and photorealistic scene relighting and editing applications. Through a number
of qualitative and quantitative experiments, we demonstrate the superior
quality of our method on indoor scene reconstruction, novel view synthesis, and
scene editing compared to state-of-the-art baselines."
DATE: Dual Assignment for End-to-End Fully Convolutional Object Detection,0.251929,"Fully convolutional detectors discard the one-to-many assignment and adopt a
one-to-one assigning strategy to achieve end-to-end detection but suffer from
the slow convergence issue. In this paper, we revisit these two assignment
methods and find that bringing one-to-many assignment back to end-to-end fully
convolutional detectors helps with model convergence. Based on this
observation, we propose {\em \textbf{D}ual \textbf{A}ssignment} for end-to-end
fully convolutional de\textbf{TE}ction (DATE). Our method constructs two
branches with one-to-many and one-to-one assignment during training and speeds
up the convergence of the one-to-one assignment branch by providing more
supervision signals. DATE only uses the branch with the one-to-one matching
strategy for model inference, which doesn't bring inference overhead.
Experimental results show that Dual Assignment gives nontrivial improvements
and speeds up model convergence upon OneNet and DeFCN. Code:
https://github.com/YiqunChen1999/date."
Dual Pyramid Generative Adversarial Networks for Semantic Image Synthesis,0.186621,"The goal of semantic image synthesis is to generate photo-realistic images
from semantic label maps. It is highly relevant for tasks like content
generation and image editing. Current state-of-the-art approaches, however,
still struggle to generate realistic objects in images at various scales. In
particular, small objects tend to fade away and large objects are often
generated as collages of patches. In order to address this issue, we propose a
Dual Pyramid Generative Adversarial Network (DP-GAN) that learns the
conditioning of spatially-adaptive normalization blocks at all scales jointly,
such that scale information is bi-directionally used, and it unifies
supervision at different scales. Our qualitative and quantitative results show
that the proposed approach generates images where small and large objects look
more realistic compared to images generated by state-of-the-art methods."
U-Flow: A U-shaped Normalizing Flow for Anomaly Detection with Unsupervised Threshold,0.271287,"In this work we propose a non-contrastive method for anomaly detection and
segmentation in images, that benefits both from a modern machine learning
approach and a more classic statistical detection theory. The method consists
of three phases. First, features are extracted using a multi-scale image
Transformer architecture. Then, these features are fed into a U-shaped
Normalizing Flow that lays the theoretical foundations for the last phase,
which computes a pixel-level anomaly map, and performs a segmentation based on
the a contrario framework. This multiple-hypothesis testing strategy permits to
derive robust automatic detection thresholds, which are crucial in many
real-world applications, where an operational point is needed. The segmentation
results are evaluated using the Intersection over Union (IoU) metric; and for
assessing the generated anomaly maps we report the area under the Receiver
Operating Characteristic curve (AUROC), and the area under the
per-region-overlap curve (AUPRO). Extensive experimentation in various datasets
shows that the proposed approach produces state-of-the-art results for all
metrics and all datasets, ranking first in most MvTec-AD categories, with a
mean pixel-level AUROC of 98.74%. Code and trained models are available at
https:// github.com/mtailanian/uflow."
Extending Multilingual Machine Translation through Imitation Learning,0.311811,"Despite the growing variety of languages supported by existing multilingual
neural machine translation (MNMT) models, most of the world's languages are
still being left behind. We aim to extend large-scale MNMT models to a new
language, allowing for translation between the newly added and all of the
already supported languages in a challenging scenario: using only a parallel
corpus between the new language and English. Previous approaches, such as
continued training on parallel data including the new language, suffer from
catastrophic forgetting (i.e., performance on other languages is reduced). Our
novel approach Imit-MNMT treats the task as an imitation learning process,
which mimicks the behavior of an expert, a technique widely used in the
computer vision area, but not well explored in NLP. More specifically, we
construct a pseudo multi-parallel corpus of the new and the original languages
by pivoting through English, and imitate the output distribution of the
original MNMT model. Extensive experiments show that our approach significantly
improves the translation performance between the new and the original
languages, without severe catastrophic forgetting. We also demonstrate that our
approach is capable of solving copy and off-target problems, which are two
common issues existence in current large-scale MNMT models."
The Gradient of Generative AI Release: Methods and Considerations,0.871335,"As increasingly powerful generative AI systems are developed, the release
method greatly varies. We propose a framework to assess six levels of access to
generative AI systems: fully closed; gradual or staged access; hosted access;
cloud-based or API access; downloadable access; and fully open. Each level,
from fully closed to fully open, can be viewed as an option along a gradient.
We outline key considerations across this gradient: release methods come with
tradeoffs, especially around the tension between concentrating power and
mitigating risks. Diverse and multidisciplinary perspectives are needed to
examine and mitigate risk in generative AI systems from conception to
deployment. We show trends in generative system release over time, noting
closedness among large companies for powerful systems and openness among
organizations founded on principles of openness. We also enumerate safety
controls and guardrails for generative systems and necessary investments to
improve future releases."
Lightweight Monocular Depth Estimation through Guided Decoding,0.565896,"We present a lightweight encoder-decoder architecture for monocular depth
estimation, specifically designed for embedded platforms. Our main contribution
is the Guided Upsampling Block (GUB) for building the decoder of our model.
Motivated by the concept of guided image filtering, GUB relies on the image to
guide the decoder on upsampling the feature representation and the depth map
reconstruction, achieving high resolution results with fine-grained details.
Based on multiple GUBs, our model outperforms the related methods on the NYU
Depth V2 dataset in terms of accuracy while delivering up to 35.1 fps on the
NVIDIA Jetson Nano and up to 144.5 fps on the NVIDIA Xavier NX. Similarly, on
the KITTI dataset, inference is possible with up to 23.7 fps on the Jetson Nano
and 102.9 fps on the Xavier NX. Our code and models are made publicly
available."
Explainability is NOT a Game,0.364452,"Explainable artificial intelligence (XAI) aims to help human decision-makers
in understanding complex machine learning (ML) models. One of the hallmarks of
XAI are measures of relative feature importance, which are theoretically
justified through the use of Shapley values. This paper builds on recent work
and offers a simple argument for why Shapley values can provide misleading
measures of relative feature importance, by assigning more importance to
features that are irrelevant for a prediction, and assigning less importance to
features that are relevant for a prediction. The significance of these results
is that they effectively challenge the many proposed uses of measures of
relative feature importance in a fast-growing range of high-stakes application
domains."
Classifier-Free Diffusion Guidance,1.0,"Classifier guidance is a recently introduced method to trade off mode
coverage and sample fidelity in conditional diffusion models post training, in
the same spirit as low temperature sampling or truncation in other types of
generative models. Classifier guidance combines the score estimate of a
diffusion model with the gradient of an image classifier and thereby requires
training an image classifier separate from the diffusion model. It also raises
the question of whether guidance can be performed without a classifier. We show
that guidance can be indeed performed by a pure generative model without such a
classifier: in what we call classifier-free guidance, we jointly train a
conditional and an unconditional diffusion model, and we combine the resulting
conditional and unconditional score estimates to attain a trade-off between
sample quality and diversity similar to that obtained using classifier
guidance."
Timestamp-Supervised Action Segmentation with Graph Convolutional Networks,0.302678,"We introduce a novel approach for temporal activity segmentation with
timestamp supervision. Our main contribution is a graph convolutional network,
which is learned in an end-to-end manner to exploit both frame features and
connections between neighboring frames to generate dense framewise labels from
sparse timestamp labels. The generated dense framewise labels can then be used
to train the segmentation model. In addition, we propose a framework for
alternating learning of both the segmentation model and the graph convolutional
model, which first initializes and then iteratively refines the learned models.
Detailed experiments on four public datasets, including 50 Salads, GTEA,
Breakfast, and Desktop Assembly, show that our method is superior to the
multi-layer perceptron baseline, while performing on par with or better than
the state of the art in temporal activity segmentation with timestamp
supervision."
TAPS3D: Text-Guided 3D Textured Shape Generation from Pseudo Supervision,0.44145,"In this paper, we investigate an open research task of generating
controllable 3D textured shapes from the given textual descriptions. Previous
works either require ground truth caption labeling or extensive optimization
time. To resolve these issues, we present a novel framework, TAPS3D, to train a
text-guided 3D shape generator with pseudo captions. Specifically, based on
rendered 2D images, we retrieve relevant words from the CLIP vocabulary and
construct pseudo captions using templates. Our constructed captions provide
high-level semantic supervision for generated 3D shapes. Further, in order to
produce fine-grained textures and increase geometry diversity, we propose to
adopt low-level image regularization to enable fake-rendered images to align
with the real ones. During the inference phase, our proposed model can generate
3D textured shapes from the given text without any additional optimization. We
conduct extensive experiments to analyze each of our proposed components and
show the efficacy of our framework in generating high-fidelity 3D textured and
text-relevant shapes."
Learnable Polyphase Sampling for Shift Invariant and Equivariant Convolutional Networks,0.0807375,"We propose learnable polyphase sampling (LPS), a pair of learnable
down/upsampling layers that enable truly shift-invariant and equivariant
convolutional networks. LPS can be trained end-to-end from data and generalizes
existing handcrafted downsampling layers. It is widely applicable as it can be
integrated into any convolutional network by replacing down/upsampling layers.
We evaluate LPS on image classification and semantic segmentation. Experiments
show that LPS is on-par with or outperforms existing methods in both
performance and shift consistency. For the first time, we achieve true
shift-equivariance on semantic segmentation (PASCAL VOC), i.e., 100% shift
consistency, outperforming baselines by an absolute 3.3%."
MDFEND: Multi-domain Fake News Detection,0.998453,"Fake news spread widely on social media in various domains, which lead to
real-world threats in many aspects like politics, disasters, and finance. Most
existing approaches focus on single-domain fake news detection (SFND), which
leads to unsatisfying performance when these methods are applied to
multi-domain fake news detection. As an emerging field, multi-domain fake news
detection (MFND) is increasingly attracting attention. However, data
distributions, such as word frequency and propagation patterns, vary from
domain to domain, namely domain shift. Facing the challenge of serious domain
shift, existing fake news detection techniques perform poorly for multi-domain
scenarios. Therefore, it is demanding to design a specialized model for MFND.
In this paper, we first design a benchmark of fake news dataset for MFND with
domain label annotated, namely Weibo21, which consists of 4,488 fake news and
4,640 real news from 9 different domains. We further propose an effective
Multi-domain Fake News Detection Model (MDFEND) by utilizing a domain gate to
aggregate multiple representations extracted by a mixture of experts. The
experiments show that MDFEND can significantly improve the performance of
multi-domain fake news detection. Our dataset and code are available at
https://github.com/kennqiang/MDFEND-Weibo21."
Learning to Ground Decentralized Multi-Agent Communication with Contrastive Learning,0.442019,"For communication to happen successfully, a common language is required
between agents to understand information communicated by one another. Inducing
the emergence of a common language has been a difficult challenge to
multi-agent learning systems. In this work, we introduce an alternative
perspective to the communicative messages sent between agents, considering them
as different incomplete views of the environment state. Based on this
perspective, we propose a simple approach to induce the emergence of a common
language by maximizing the mutual information between messages of a given
trajectory in a self-supervised manner. By evaluating our method in
communication-essential environments, we empirically show how our method leads
to better learning performance and speed, and learns a more consistent common
language than existing methods, without introducing additional learning
parameters."
Combining Attention Module and Pixel Shuffle for License Plate Super-Resolution,0.895923,"The License Plate Recognition (LPR) field has made impressive advances in the
last decade due to novel deep learning approaches combined with the increased
availability of training data. However, it still has some open issues,
especially when the data come from low-resolution (LR) and low-quality
images/videos, as in surveillance systems. This work focuses on license plate
(LP) reconstruction in LR and low-quality images. We present a Single-Image
Super-Resolution (SISR) approach that extends the attention/transformer module
concept by exploiting the capabilities of PixelShuffle layers and that has an
improved loss function based on LPR predictions. For training the proposed
architecture, we use synthetic images generated by applying heavy Gaussian
noise in terms of Structural Similarity Index Measure (SSIM) to the original
high-resolution (HR) images. In our experiments, the proposed method
outperformed the baselines both quantitatively and qualitatively. The datasets
we created for this work are publicly available to the research community at
https://github.com/valfride/lpr-rsr/"
Rethinking Implicit Neural Representations for Vision Learners,0.252537,"Implicit Neural Representations (INRs) are powerful to parameterize
continuous signals in computer vision. However, almost all INRs methods are
limited to low-level tasks, e.g., image/video compression, super-resolution,
and image generation. The questions on how to explore INRs to high-level tasks
and deep networks are still under-explored. Existing INRs methods suffer from
two problems: 1) narrow theoretical definitions of INRs are inapplicable to
high-level tasks; 2) lack of representation capabilities to deep networks.
Motivated by the above facts, we reformulate the definitions of INRs from a
novel perspective and propose an innovative Implicit Neural Representation
Network (INRN), which is the first study of INRs to tackle both low-level and
high-level tasks. Specifically, we present three key designs for basic blocks
in INRN along with two different stacking ways and corresponding loss
functions. Extensive experiments with analysis on both low-level tasks (image
fitting) and high-level vision tasks (image classification, object detection,
instance segmentation) demonstrate the effectiveness of the proposed method."
Robustness of Segment Anything Model (SAM) for Autonomous Driving in Adverse Weather Conditions,0.289185,"Segment Anything Model (SAM) has gained considerable interest in recent times
for its remarkable performance and has emerged as a foundational model in
computer vision. It has been integrated in diverse downstream tasks, showcasing
its strong zero-shot transfer capabilities. Given its impressive performance,
there is a strong desire to apply SAM in autonomous driving to improve the
performance of vision tasks, particularly in challenging scenarios such as
driving under adverse weather conditions. However, its robustness under adverse
weather conditions remains uncertain. In this work, we investigate the
application of SAM in autonomous driving and specifically explore its
robustness under adverse weather conditions. Overall, this work aims to enhance
understanding of SAM's robustness in challenging scenarios before integrating
it into autonomous driving vision tasks, providing valuable insights for future
applications."
Non-Deterministic Face Mask Removal Based On 3D Priors,0.131635,"This paper presents a novel image inpainting framework for face mask removal.
Although current methods have demonstrated their impressive ability in
recovering damaged face images, they suffer from two main problems: the
dependence on manually labeled missing regions and the deterministic result
corresponding to each input. The proposed approach tackles these problems by
integrating a multi-task 3D face reconstruction module with a face inpainting
module. Given a masked face image, the former predicts a 3DMM-based
reconstructed face together with a binary occlusion map, providing dense
geometrical and textural priors that greatly facilitate the inpainting task of
the latter. By gradually controlling the 3D shape parameters, our method
generates high-quality dynamic inpainting results with different expressions
and mouth movements. Qualitative and quantitative experiments verify the
effectiveness of the proposed method."
"TableGPT: Towards Unifying Tables, Nature Language and Commands into One GPT",0.723464,"Tables are prevalent in real-world databases, requiring significant time and
effort for humans to analyze and manipulate. The advancements in large language
models (LLMs) have made it possible to interact with tables using natural
language input, bringing this capability closer to reality. In this paper, we
present TableGPT, a unified fine-tuned framework that enables LLMs to
understand and operate on tables using external functional commands. It
introduces the capability to seamlessly interact with tables, enabling a wide
range of functionalities such as question answering, data manipulation (e.g.,
insert, delete, query, and modify operations), data visualization, analysis
report generation, and automated prediction. TableGPT aims to provide
convenience and accessibility to users by empowering them to effortlessly
leverage tabular data. At the core of TableGPT lies the novel concept of global
tabular representations, which empowers LLMs to gain a comprehensive
understanding of the entire table beyond meta-information. By jointly training
LLMs on both table and text modalities, TableGPT achieves a deep understanding
of tabular data and the ability to perform complex operations on tables through
chain-of-command instructions. Importantly, TableGPT offers the advantage of
being a self-contained system rather than relying on external API interfaces.
Moreover, it supports efficient data process flow, query rejection (when
appropriate) and private deployment, enabling faster domain data fine-tuning
and ensuring data privacy, which enhances the framework's adaptability to
specific use cases."
Revisiting Self-Supervised Contrastive Learning for Facial Expression Recognition,0.645136,"The success of most advanced facial expression recognition works relies
heavily on large-scale annotated datasets. However, it poses great challenges
in acquiring clean and consistent annotations for facial expression datasets.
On the other hand, self-supervised contrastive learning has gained great
popularity due to its simple yet effective instance discrimination training
strategy, which can potentially circumvent the annotation issue. Nevertheless,
there remain inherent disadvantages of instance-level discrimination, which are
even more challenging when faced with complicated facial representations. In
this paper, we revisit the use of self-supervised contrastive learning and
explore three core strategies to enforce expression-specific representations
and to minimize the interference from other facial attributes, such as identity
and face styling. Experimental results show that our proposed method
outperforms the current state-of-the-art self-supervised learning methods, in
terms of both categorical and dimensional facial expression recognition tasks."
Deep Reinforcement Learning for Stabilization of Large-scale Probabilistic Boolean Networks,0.35901,"The ability to direct a Probabilistic Boolean Network (PBN) to a desired
state is important to applications such as targeted therapeutics in cancer
biology. Reinforcement Learning (RL) has been proposed as a framework that
solves a discrete-time optimal control problem cast as a Markov Decision
Process. We focus on an integrative framework powered by a model-free deep RL
method that can address different flavours of the control problem (e.g., with
or without control inputs; attractor state or a subset of the state space as
the target domain). The method is agnostic to the distribution of probabilities
for the next state, hence it does not use the probability transition matrix.
The time complexity is linear on the time steps, or interactions between the
agent (deep RL) and the environment (PBN), during training. Indeed, we explore
the scalability of the deep RL approach to (set) stabilization of large-scale
PBNs and demonstrate successful control on large networks, including a
metastatic melanoma PBN with 200 nodes."
Fast AdvProp,0.207468,"Adversarial Propagation (AdvProp) is an effective way to improve recognition
models, leveraging adversarial examples. Nonetheless, AdvProp suffers from the
extremely slow training speed, mainly because: a) extra forward and backward
passes are required for generating adversarial examples; b) both original
samples and their adversarial counterparts are used for training (i.e.,
2$\times$ data). In this paper, we introduce Fast AdvProp, which aggressively
revamps AdvProp's costly training components, rendering the method nearly as
cheap as the vanilla training. Specifically, our modifications in Fast AdvProp
are guided by the hypothesis that disentangled learning with adversarial
examples is the key for performance improvements, while other training recipes
(e.g., paired clean and adversarial training samples, multi-step adversarial
attackers) could be largely simplified.
  Our empirical results show that, compared to the vanilla training baseline,
Fast AdvProp is able to further model performance on a spectrum of visual
benchmarks, without incurring extra training cost. Additionally, our ablations
find Fast AdvProp scales better if larger models are used, is compatible with
existing data augmentation methods (i.e., Mixup and CutMix), and can be easily
adapted to other recognition tasks like object detection. The code is available
here: https://github.com/meijieru/fast_advprop."
SC-wLS: Towards Interpretable Feed-forward Camera Re-localization,0.859523,"Visual re-localization aims to recover camera poses in a known environment,
which is vital for applications like robotics or augmented reality.
Feed-forward absolute camera pose regression methods directly output poses by a
network, but suffer from low accuracy. Meanwhile, scene coordinate based
methods are accurate, but need iterative RANSAC post-processing, which brings
challenges to efficient end-to-end training and inference. In order to have the
best of both worlds, we propose a feed-forward method termed SC-wLS that
exploits all scene coordinate estimates for weighted least squares pose
regression. This differentiable formulation exploits a weight network imposed
on 2D-3D correspondences, and requires pose supervision only. Qualitative
results demonstrate the interpretability of learned weights. Evaluations on
7Scenes and Cambridge datasets show significantly promoted performance when
compared with former feed-forward counterparts. Moreover, our SC-wLS method
enables a new capability: self-supervised test-time adaptation on the weight
network. Codes and models are publicly available."
Adapting Task-Oriented Dialogue Models for Email Conversations,0.244503,"Intent detection is a key part of any Natural Language Understanding (NLU)
system of a conversational assistant. Detecting the correct intent is essential
yet difficult for email conversations where multiple directives and intents are
present. In such settings, conversation context can become a key disambiguating
factor for detecting the user's request from the assistant. One prominent way
of incorporating context is modeling past conversation history like
task-oriented dialogue models. However, the nature of email conversations (long
form) restricts direct usage of the latest advances in task-oriented dialogue
models. So in this paper, we provide an effective transfer learning framework
(EMToD) that allows the latest development in dialogue models to be adapted for
long-form conversations. We show that the proposed EMToD framework improves
intent detection performance over pre-trained language models by 45% and over
pre-trained dialogue models by 30% for task-oriented email conversations.
Additionally, the modular nature of the proposed framework allows plug-and-play
for any future developments in both pre-trained language and task-oriented
dialogue models."
Interpretable Deep Learning Classifier by Detection of Prototypical Parts on Kidney Stones Images,0.180953,"Identifying the type of kidney stones can allow urologists to determine their
formation cause, improving the early prescription of appropriate treatments to
diminish future relapses. However, currently, the associated ex-vivo diagnosis
(known as morpho-constitutional analysis, MCA) is time-consuming, expensive,
and requires a great deal of experience, as it requires a visual analysis
component that is highly operator dependant. Recently, machine learning methods
have been developed for in-vivo endoscopic stone recognition. Shallow methods
have been demonstrated to be reliable and interpretable but exhibit low
accuracy, while deep learning-based methods yield high accuracy but are not
explainable. However, high stake decisions require understandable
computer-aided diagnosis (CAD) to suggest a course of action based on
reasonable evidence, rather than merely prescribe one. Herein, we investigate
means for learning part-prototypes (PPs) that enable interpretable models. Our
proposal suggests a classification for a kidney stone patch image and provides
explanations in a similar way as those used on the MCA method."
Hausa Visual Genome: A Dataset for Multi-Modal English to Hausa Machine Translation,0.52127,"Multi-modal Machine Translation (MMT) enables the use of visual information
to enhance the quality of translations. The visual information can serve as a
valuable piece of context information to decrease the ambiguity of input
sentences. Despite the increasing popularity of such a technique, good and
sizeable datasets are scarce, limiting the full extent of their potential.
Hausa, a Chadic language, is a member of the Afro-Asiatic language family. It
is estimated that about 100 to 150 million people speak the language, with more
than 80 million indigenous speakers. This is more than any of the other Chadic
languages. Despite a large number of speakers, the Hausa language is considered
low-resource in natural language processing (NLP). This is due to the absence
of sufficient resources to implement most NLP tasks. While some datasets exist,
they are either scarce, machine-generated, or in the religious domain.
Therefore, there is a need to create training and evaluation data for
implementing machine learning tasks and bridging the research gap in the
language. This work presents the Hausa Visual Genome (HaVG), a dataset that
contains the description of an image or a section within the image in Hausa and
its equivalent in English. To prepare the dataset, we started by translating
the English description of the images in the Hindi Visual Genome (HVG) into
Hausa automatically. Afterward, the synthetic Hausa data was carefully
post-edited considering the respective images. The dataset comprises 32,923
images and their descriptions that are divided into training, development,
test, and challenge test set. The Hausa Visual Genome is the first dataset of
its kind and can be used for Hausa-English machine translation, multi-modal
research, and image description, among various other natural language
processing and generation tasks."
Piloting Diversity and Inclusion Workshops in Artificial Intelligence and Robotics for Children,0.32968,"In this paper, we present preliminary work from a pilot workshop that aimed
to promote diversity and inclusion for fundamentals of Artificial Intelligence
and Robotics for Children (air4children) in the context of developing
countries. Considering the scarcity of funding and the little to none
availability of specialised professionals to teach AI and robotics in
developing countries, we present resources based on free open-source hardware
and software, open educational resources, and alternative education programs.
That said, the contribution of this work is the pilot workshop of four lessons
that promote diversity and inclusion on teaching AI and Robotics for children
to a small gender-balanced sample of 14 children of an average age of 7.64
years old. We conclude that participant, instructors, coordinators and parents
engaged well in the pilot workshop noting the various challenges of having the
right resources for the workshops in developing countries and posing future
work. The resources to reproduce this work are available at
https://github.com/air4children/hri2022."
LgTS: Dynamic Task Sampling using LLM-generated sub-goals for Reinforcement Learning Agents,0.0460174,"Recent advancements in reasoning abilities of Large Language Models (LLM) has
promoted their usage in problems that require high-level planning for robots
and artificial agents. However, current techniques that utilize LLMs for such
planning tasks make certain key assumptions such as, access to datasets that
permit finetuning, meticulously engineered prompts that only provide relevant
and essential information to the LLM, and most importantly, a deterministic
approach to allow execution of the LLM responses either in the form of existing
policies or plan operators. In this work, we propose LgTS (LLM-guided
Teacher-Student learning), a novel approach that explores the planning
abilities of LLMs to provide a graphical representation of the sub-goals to a
reinforcement learning (RL) agent that does not have access to the transition
dynamics of the environment. The RL agent uses Teacher-Student learning
algorithm to learn a set of successful policies for reaching the goal state
from the start state while simultaneously minimizing the number of
environmental interactions. Unlike previous methods that utilize LLMs, our
approach does not assume access to a propreitary or a fine-tuned LLM, nor does
it require pre-trained policies that achieve the sub-goals proposed by the LLM.
Through experiments on a gridworld based DoorKey domain and a search-and-rescue
inspired domain, we show that generating a graphical structure of sub-goals
helps in learning policies for the LLM proposed sub-goals and the
Teacher-Student learning algorithm minimizes the number of environment
interactions when the transition dynamics are unknown."
User Friendly and Adaptable Discriminative AI: Using the Lessons from the Success of LLMs and Image Generation Models,0.326914,"While there is significant interest in using generative AI tools as
general-purpose models for specific ML applications, discriminative models are
much more widely deployed currently. One of the key shortcomings of these
discriminative AI tools that have been already deployed is that they are not
adaptable and user-friendly compared to generative AI tools (e.g., GPT4, Stable
Diffusion, Bard, etc.), where a non-expert user can iteratively refine model
inputs and give real-time feedback that can be accounted for immediately,
allowing users to build trust from the start. Inspired by this emerging
collaborative workflow, we develop a new system architecture that enables users
to work with discriminative models (such as for object detection, sentiment
classification, etc.) in a fashion similar to generative AI tools, where they
can easily provide immediate feedback as well as adapt the deployed models as
desired. Our approach has implications on improving trust, user-friendliness,
and adaptability of these versatile but traditional prediction models."
SGP-TOD: Building Task Bots Effortlessly via Schema-Guided LLM Prompting,0.996609,"Building end-to-end task bots and maintaining their integration with new
functionalities using minimal human efforts is a long-standing challenge in
dialog research. Recently large language models (LLMs) have demonstrated
exceptional proficiency in conversational engagement and adherence to
instructions across various downstream tasks. In this work, we introduce
SGP-TOD, Schema-Guided Prompting for building Task-Oriented Dialog systems
effortlessly based on LLMs. Utilizing the symbolic knowledge -- task schema, we
instruct fixed LLMs to generate appropriate responses on novel tasks,
circumventing the need for training data. Specifically, SGP-TOD comprises three
components: a LLM for engaging with users, a DST Prompter to aid the LLM with
dialog state tracking, which is then used to retrieve database items, and a
Policy Prompter to elicit proper responses adhering to the provided dialog
policy. Experimental results on Multiwoz, RADDLE and STAR datasets show that
our training-free strategy SGP-TOD, without any task-specific data, yields
state-of-the-art (SOTA) zero-shot performance, greatly surpasses the few-shot
approaches. In a domain-extension setting, SGP-TOD aptly adapts to new
functionalities by merely adding supplementary schema rules. We make our code
and data publicly available."
Teacher-student curriculum learning for reinforcement learning,0.032167,"Reinforcement learning (rl) is a popular paradigm for sequential decision
making problems. The past decade's advances in rl have led to breakthroughs in
many challenging domains such as video games, board games, robotics, and chip
design. The sample inefficiency of deep reinforcement learning methods is a
significant obstacle when applying rl to real-world problems. Transfer learning
has been applied to reinforcement learning such that the knowledge gained in
one task can be applied when training in a new task. Curriculum learning is
concerned with sequencing tasks or data samples such that knowledge can be
transferred between those tasks to learn a target task that would otherwise be
too difficult to solve. Designing a curriculum that improves sample efficiency
is a complex problem. In this thesis, we propose a teacher-student curriculum
learning setting where we simultaneously train a teacher that selects tasks for
the student while the student learns how to solve the selected task. Our method
is independent of human domain knowledge and manual curriculum design. We
evaluated our methods on two reinforcement learning benchmarks: grid world and
the challenging Google Football environment. With our method, we can improve
the sample efficiency and generality of the student compared to tabula-rasa
reinforcement learning."
Researching Alignment Research: Unsupervised Analysis,0.0776193,"AI alignment research is the field of study dedicated to ensuring that
artificial intelligence (AI) benefits humans. As machine intelligence gets more
advanced, this research is becoming increasingly important. Researchers in the
field share ideas across different media to speed up the exchange of
information. However, this focus on speed means that the research landscape is
opaque, making it difficult for young researchers to enter the field. In this
project, we collected and analyzed existing AI alignment research. We found
that the field is growing quickly, with several subfields emerging in parallel.
We looked at the subfields and identified the prominent researchers, recurring
topics, and different modes of communication in each. Furthermore, we found
that a classifier trained on AI alignment research articles can detect relevant
articles that we did not originally include in the dataset. We are sharing the
dataset with the research community and hope to develop tools in the future
that will help both established researchers and young researchers get more
involved in the field."
Implicit Identity Leakage: The Stumbling Block to Improving Deepfake Detection Generalization,0.812585,"In this paper, we analyse the generalization ability of binary classifiers
for the task of deepfake detection. We find that the stumbling block to their
generalization is caused by the unexpected learned identity representation on
images. Termed as the Implicit Identity Leakage, this phenomenon has been
qualitatively and quantitatively verified among various DNNs. Furthermore,
based on such understanding, we propose a simple yet effective method named the
ID-unaware Deepfake Detection Model to reduce the influence of this phenomenon.
Extensive experimental results demonstrate that our method outperforms the
state-of-the-art in both in-dataset and cross-dataset evaluation. The code is
available at https://github.com/megvii-research/CADDM."
Self-Supervised Pretraining Improves Performance and Inference Efficiency in Multiple Lung Ultrasound Interpretation Tasks,0.703159,"In this study, we investigated whether self-supervised pretraining could
produce a neural network feature extractor applicable to multiple
classification tasks in B-mode lung ultrasound analysis. When fine-tuning on
three lung ultrasound tasks, pretrained models resulted in an improvement of
the average across-task area under the receiver operating curve (AUC) by 0.032
and 0.061 on local and external test sets respectively. Compact nonlinear
classifiers trained on features outputted by a single pretrained model did not
improve performance across all tasks; however, they did reduce inference time
by 49% compared to serial execution of separate fine-tuned models. When
training using 1% of the available labels, pretrained models consistently
outperformed fully supervised models, with a maximum observed test AUC increase
of 0.396 for the task of view classification. Overall, the results indicate
that self-supervised pretraining is useful for producing initial weights for
lung ultrasound classifiers."
Automatic Evaluation of Generative Models with Instruction Tuning,0.0664111,"Automatic evaluation of natural language generation has long been an elusive
goal in NLP.A recent paradigm fine-tunes pre-trained language models to emulate
human judgements for a particular task and evaluation criterion. Inspired by
the generalization ability of instruction-tuned models, we propose a learned
metric based on instruction tuning. To test our approach, we collected HEAP, a
dataset of human judgements across various NLG tasks and evaluation criteria.
Our findings demonstrate that instruction tuning language models on HEAP yields
good performance on many evaluation tasks, though some criteria are less
trivial to learn than others. Further, jointly training on multiple tasks can
yield additional performance improvements, which can be beneficial for future
tasks with little to no human annotated data."
50 Ways to Bake a Cookie: Mapping the Landscape of Procedural Texts,0.179005,"The web is full of guidance on a wide variety of tasks, from changing the oil
in your car to baking an apple pie. However, as content is created
independently, a single task could have thousands of corresponding procedural
texts. This makes it difficult for users to view the bigger picture and
understand the multiple ways the task could be accomplished. In this work we
propose an unsupervised learning approach for summarizing multiple procedural
texts into an intuitive graph representation, allowing users to easily explore
commonalities and differences. We demonstrate our approach on recipes, a
prominent example of procedural texts. User studies show that our
representation is intuitive and coherent and that it has the potential to help
users with several sensemaking tasks, including adapting recipes for a novice
cook and finding creative ways to spice up a dish."
Center Feature Fusion: Selective Multi-Sensor Fusion of Center-based Objects,0.438579,"Leveraging multi-modal fusion, especially between camera and LiDAR, has
become essential for building accurate and robust 3D object detection systems
for autonomous vehicles. Until recently, point decorating approaches, in which
point clouds are augmented with camera features, have been the dominant
approach in the field. However, these approaches fail to utilize the higher
resolution images from cameras. Recent works projecting camera features to the
bird's-eye-view (BEV) space for fusion have also been proposed, however they
require projecting millions of pixels, most of which only contain background
information. In this work, we propose a novel approach Center Feature Fusion
(CFF), in which we leverage center-based detection networks in both the camera
and LiDAR streams to identify relevant object locations. We then use the
center-based detection to identify the locations of pixel features relevant to
object locations, a small fraction of the total number in the image. These are
then projected and fused in the BEV frame. On the nuScenes dataset, we
outperform the LiDAR-only baseline by 4.9% mAP while fusing up to 100x fewer
features than other fusion methods."
Diffusion Models as Artists: Are we Closing the Gap between Humans and Machines?,0.203153,"An important milestone for AI is the development of algorithms that can
produce drawings that are indistinguishable from those of humans. Here, we
adapt the 'diversity vs. recognizability' scoring framework from Boutin et al,
2022 and find that one-shot diffusion models have indeed started to close the
gap between humans and machines. However, using a finer-grained measure of the
originality of individual samples, we show that strengthening the guidance of
diffusion models helps improve the humanness of their drawings, but they still
fall short of approximating the originality and recognizability of human
drawings. Comparing human category diagnostic features, collected through an
online psychophysics experiment, against those derived from diffusion models
reveals that humans rely on fewer and more localized features. Overall, our
study suggests that diffusion models have significantly helped improve the
quality of machine-generated drawings; however, a gap between humans and
machines remains -- in part explainable by discrepancies in visual strategies."
Multimodal Subtask Graph Generation from Instructional Videos,0.694446,"Real-world tasks consist of multiple inter-dependent subtasks (e.g., a dirty
pan needs to be washed before it can be used for cooking). In this work, we aim
to model the causal dependencies between such subtasks from instructional
videos describing the task. This is a challenging problem since complete
information about the world is often inaccessible from videos, which demands
robust learning mechanisms to understand the causal structure of events. We
present Multimodal Subtask Graph Generation (MSG2), an approach that constructs
a Subtask Graph defining the dependency between a task's subtasks relevant to a
task from noisy web videos. Graphs generated by our multimodal approach are
closer to human-annotated graphs compared to prior approaches. MSG2 further
performs the downstream task of next subtask prediction 85% and 30% more
accurately than recent video transformer models in the ProceL and CrossTask
datasets, respectively."
Generating Representative Samples for Few-Shot Classification,0.804298,"Few-shot learning (FSL) aims to learn new categories with a few visual
samples per class. Few-shot class representations are often biased due to data
scarcity. To mitigate this issue, we propose to generate visual samples based
on semantic embeddings using a conditional variational autoencoder (CVAE)
model. We train this CVAE model on base classes and use it to generate features
for novel classes. More importantly, we guide this VAE to strictly generate
representative samples by removing non-representative samples from the base
training set when training the CVAE model. We show that this training scheme
enhances the representativeness of the generated samples and therefore,
improves the few-shot classification results. Experimental results show that
our method improves three FSL baseline methods by substantial margins,
achieving state-of-the-art few-shot classification performance on miniImageNet
and tieredImageNet datasets for both 1-shot and 5-shot settings. Code is
available at: https://github.com/cvlab-stonybrook/fsl-rsvae."
Vehicle-road Cooperative Simulation and 3D Visualization System,0.0983417,"The safety of single-vehicle autonomous driving technology is limited due to
the limits of perception capability of on-board sensors. In contrast,
vehicle-road collaboration technology can overcome those limits and improve the
traffic safety and efficiency, by expanding the sensing range, improving the
perception accuracy, and reducing the response time. However, such a technology
is still under development; it requires rigorous testing and verification
methods to ensure the reliability and trustworthiness of the technology. In
this thesis, we focus on three major tasks: (1) analyze the functional
characteristics related to the scenarios of vehicle-road cooperations,
highlightening the differences between vehicle-road cooperative systems and
traditional single-vehicle autonomous driving systems; (2) refine and classifiy
the functional characteristics of vehicle-road cooperative systems; (3) design
and develop a simulation system, and provide a visual interface to facilitate
development and analysis. The efficiency and effectiveness the proposed method
are verfied by experiments."
CCpdf: Building a High Quality Corpus for Visually Rich Documents from Web Crawl Data,0.389912,"In recent years, the field of document understanding has progressed a lot. A
significant part of this progress has been possible thanks to the use of
language models pretrained on large amounts of documents. However, pretraining
corpora used in the domain of document understanding are single domain,
monolingual, or nonpublic. Our goal in this paper is to propose an efficient
pipeline for creating a big-scale, diverse, multilingual corpus of PDF files
from all over the Internet using Common Crawl, as PDF files are the most
canonical types of documents as considered in document understanding. We
analysed extensively all of the steps of the pipeline and proposed a solution
which is a trade-off between data quality and processing time. We also share a
CCpdf corpus in a form or an index of PDF files along with a script for
downloading them, which produces a collection useful for language model
pretraining. The dataset and tools published with this paper offer researchers
the opportunity to develop even better multilingual language models."
HDGT: Heterogeneous Driving Graph Transformer for Multi-Agent Trajectory Prediction via Scene Encoding,0.999656,"Encoding a driving scene into vector representations has been an essential
task for autonomous driving that can benefit downstream tasks e.g. trajectory
prediction. The driving scene often involves heterogeneous elements such as the
different types of objects (agents, lanes, traffic signs) and the semantic
relations between objects are rich and diverse. Meanwhile, there also exist
relativity across elements, which means that the spatial relation is a relative
concept and need be encoded in a ego-centric manner instead of in a global
coordinate system. Based on these observations, we propose Heterogeneous
Driving Graph Transformer (HDGT), a backbone modelling the driving scene as a
heterogeneous graph with different types of nodes and edges. For heterogeneous
graph construction, we connect different types of nodes according to diverse
semantic relations. For spatial relation encoding, the coordinates of the node
as well as its in-edges are in the local node-centric coordinate system. For
the aggregation module in the graph neural network (GNN), we adopt the
transformer structure in a hierarchical way to fit the heterogeneous nature of
inputs. Experimental results show that HDGT achieves state-of-the-art
performance for the task of trajectory prediction, on INTERACTION Prediction
Challenge and Waymo Open Motion Challenge."
A Hierarchical Destroy and Repair Approach for Solving Very Large-Scale Travelling Salesman Problem,0.414693,"For prohibitively large-scale Travelling Salesman Problems (TSPs), existing
algorithms face big challenges in terms of both computational efficiency and
solution quality. To address this issue, we propose a hierarchical
destroy-and-repair (HDR) approach, which attempts to improve an initial
solution by applying a series of carefully designed destroy-and-repair
operations. A key innovative concept is the hierarchical search framework,
which recursively fixes partial edges and compresses the input instance into a
small-scale TSP under some equivalence guarantee. This neat search framework is
able to deliver highly competitive solutions within a reasonable time. Fair
comparisons based on nineteen famous large-scale instances (with 10,000 to
10,000,000 cities) show that HDR is highly competitive against existing
state-of-the-art TSP algorithms, in terms of both efficiency and solution
quality. Notably, on two large instances with 3,162,278 and 10,000,000 cities,
HDR breaks the world records (i.e., best-known results regardless of
computation time), which were previously achieved by LKH and its variants,
while HDR is completely independent of LKH. Finally, ablation studies are
performed to certify the importance and validity of the hierarchical search
framework."
Multi-Objective Coordination Graphs for the Expected Scalarised Returns with Generative Flow Models,0.27393,"Many real-world problems contain multiple objectives and agents, where a
trade-off exists between objectives. Key to solving such problems is to exploit
sparse dependency structures that exist between agents. For example, in wind
farm control a trade-off exists between maximising power and minimising stress
on the systems components. Dependencies between turbines arise due to the wake
effect. We model such sparse dependencies between agents as a multi-objective
coordination graph (MO-CoG). In multi-objective reinforcement learning a
utility function is typically used to model a users preferences over
objectives, which may be unknown a priori. In such settings a set of optimal
policies must be computed. Which policies are optimal depends on which
optimality criterion applies. If the utility function of a user is derived from
multiple executions of a policy, the scalarised expected returns (SER) must be
optimised. If the utility of a user is derived from a single execution of a
policy, the expected scalarised returns (ESR) criterion must be optimised. For
example, wind farms are subjected to constraints and regulations that must be
adhered to at all times, therefore the ESR criterion must be optimised. For
MO-CoGs, the state-of-the-art algorithms can only compute a set of optimal
policies for the SER criterion, leaving the ESR criterion understudied. To
compute a set of optimal polices under the ESR criterion, also known as the ESR
set, distributions over the returns must be maintained. Therefore, to compute a
set of optimal policies under the ESR criterion for MO-CoGs, we present a novel
distributional multi-objective variable elimination (DMOVE) algorithm. We
evaluate DMOVE in realistic wind farm simulations. Given the returns in
real-world wind farm settings are continuous, we utilise a model known as
real-NVP to learn the continuous return distributions to calculate the ESR set."
Give and Take: Federated Transfer Learning for Industrial IoT Network Intrusion Detection,0.958766,"The rapid growth in Internet of Things (IoT) technology has become an
integral part of today's industries forming the Industrial IoT (IIoT)
initiative, where industries are leveraging IoT to improve communication and
connectivity via emerging solutions like data analytics and cloud computing.
Unfortunately, the rapid use of IoT has made it an attractive target for
cybercriminals. Therefore, protecting these systems is of utmost importance. In
this paper, we propose a federated transfer learning (FTL) approach to perform
IIoT network intrusion detection. As part of the research, we also propose a
combinational neural network as the centerpiece for performing FTL. The
proposed technique splits IoT data between the client and server devices to
generate corresponding models, and the weights of the client models are
combined to update the server model. Results showcase high performance for the
FTL setup between iterations on both the IIoT clients and the server.
Additionally, the proposed FTL setup achieves better overall performance than
contemporary machine learning algorithms at performing network intrusion
detection."
Can We Trust Explainable AI Methods on ASR? An Evaluation on Phoneme Recognition,0.223909,"Explainable AI (XAI) techniques have been widely used to help explain and
understand the output of deep learning models in fields such as image
classification and Natural Language Processing. Interest in using XAI
techniques to explain deep learning-based automatic speech recognition (ASR) is
emerging. but there is not enough evidence on whether these explanations can be
trusted. To address this, we adapt a state-of-the-art XAI technique from the
image classification domain, Local Interpretable Model-Agnostic Explanations
(LIME), to a model trained for a TIMIT-based phoneme recognition task. This
simple task provides a controlled setting for evaluation while also providing
expert annotated ground truth to assess the quality of explanations. We find a
variant of LIME based on time partitioned audio segments, that we propose in
this paper, produces the most reliable explanations, containing the ground
truth 96% of the time in its top three audio segments."
Understanding Toxicity Triggers on Reddit in the Context of Singapore,0.238775,"While the contagious nature of online toxicity sparked increasing interest in
its early detection and prevention, most of the literature focuses on the
Western world. In this work, we demonstrate that 1) it is possible to detect
toxicity triggers in an Asian online community, and 2) toxicity triggers can be
strikingly different between Western and Eastern contexts."
Learning Non-Autoregressive Models from Search for Unsupervised Sentence Summarization,0.459192,"Text summarization aims to generate a short summary for an input text. In
this work, we propose a Non-Autoregressive Unsupervised Summarization (NAUS)
approach, which does not require parallel data for training. Our NAUS first
performs edit-based search towards a heuristically defined score, and generates
a summary as pseudo-groundtruth. Then, we train an encoder-only
non-autoregressive Transformer based on the search result. We also propose a
dynamic programming approach for length-control decoding, which is important
for the summarization task. Experiments on two datasets show that NAUS achieves
state-of-the-art performance for unsupervised summarization, yet largely
improving inference efficiency. Further, our algorithm is able to perform
explicit length-transfer summary generation."
Improving Metrics for Speech Translation,0.142535,"We introduce Parallel Paraphrasing ($\text{Para}_\text{both}$), an
augmentation method for translation metrics making use of automatic
paraphrasing of both the reference and hypothesis. This method counteracts the
typically misleading results of speech translation metrics such as WER, CER,
and BLEU if only a single reference is available. We introduce two new datasets
explicitly created to measure the quality of metrics intended to be applied to
Swiss German speech-to-text systems. Based on these datasets, we show that we
are able to significantly improve the correlation with human quality perception
if our method is applied to commonly used metrics."
FoodGPT: A Large Language Model in Food Testing Domain with Incremental Pre-training and Knowledge Graph Prompt,0.982352,"Currently, the construction of large language models in specific domains is
done by fine-tuning on a base model. Some models also incorporate knowledge
bases without the need for pre-training. This is because the base model already
contains domain-specific knowledge during the pre-training process. We build a
large language model for food testing. Unlike the above approach, a significant
amount of data in this domain exists in Scanning format for domain standard
documents. In addition, there is a large amount of untrained structured
knowledge. Therefore, we introduce an incremental pre-training step to inject
this knowledge into a large language model. In this paper, we propose a method
for handling structured knowledge and scanned documents in incremental
pre-training. To overcome the problem of machine hallucination, we constructe a
knowledge graph to serve as an external knowledge base for supporting retrieval
in the large language model. It is worth mentioning that this paper is a
technical report of our pre-release version, and we will report our specific
experimental data in future versions."
From Discrimination to Generation: Knowledge Graph Completion with Generative Transformer,0.939238,"Knowledge graph completion aims to address the problem of extending a KG with
missing triples. In this paper, we provide an approach GenKGC, which converts
knowledge graph completion to sequence-to-sequence generation task with the
pre-trained language model. We further introduce relation-guided demonstration
and entity-aware hierarchical decoding for better representation learning and
fast inference. Experimental results on three datasets show that our approach
can obtain better or comparable performance than baselines and achieve faster
inference speed compared with previous methods with pre-trained language
models. We also release a new large-scale Chinese knowledge graph dataset
AliopenKG500 for research purpose. Code and datasets are available in
https://github.com/zjunlp/PromptKG/tree/main/GenKGC."
Fast-R2D2: A Pretrained Recursive Neural Network based on Pruned CKY for Grammar Induction and Text Representation,0.733806,"Recently CKY-based models show great potential in unsupervised grammar
induction thanks to their human-like encoding paradigm, which runs recursively
and hierarchically, but requires $O(n^3)$ time-complexity. Recursive
Transformer based on Differentiable Trees (R2D2) makes it possible to scale to
large language model pre-training even with complex tree encoder by introducing
a heuristic pruning method. However, the rule-based pruning approach suffers
from local optimum and slow inference issues. In this paper, we fix those
issues in a unified method. We propose to use a top-down parser as a
model-based pruning method, which also enables parallel encoding during
inference. Typically, our parser casts parsing as a split point scoring task,
which first scores all split points for a given sentence, and then recursively
splits a span into two by picking a split point with the highest score in the
current span. The reverse order of the splits is considered as the order of
pruning in R2D2 encoder. Beside the bi-directional language model loss, we also
optimize the parser by minimizing the KL distance between tree probabilities
from parser and R2D2. Our experiments show that our Fast-R2D2 improves
performance significantly in grammar induction and achieves competitive results
in downstream classification tasks."
Hunting Group Clues with Transformers for Social Group Activity Recognition,0.9604,"This paper presents a novel framework for social group activity recognition.
As an expanded task of group activity recognition, social group activity
recognition requires recognizing multiple sub-group activities and identifying
group members. Most existing methods tackle both tasks by refining region
features and then summarizing them into activity features. Such heuristic
feature design renders the effectiveness of features susceptible to incomplete
person localization and disregards the importance of scene contexts.
Furthermore, region features are sub-optimal to identify group members because
the features may be dominated by those of people in the regions and have
different semantics. To overcome these drawbacks, we propose to leverage
attention modules in transformers to generate effective social group features.
Our method is designed in such a way that the attention modules identify and
then aggregate features relevant to social group activities, generating an
effective feature for each social group. Group member information is embedded
into the features and thus accessed by feed-forward networks. The outputs of
feed-forward networks represent groups so concisely that group members can be
identified with simple Hungarian matching between groups and individuals.
Experimental results show that our method outperforms state-of-the-art methods
on the Volleyball and Collective Activity datasets."
Unnatural Instructions: Tuning Language Models with (Almost) No Human Labor,0.92369,"Instruction tuning enables pretrained language models to perform new tasks
from inference-time natural language descriptions. These approaches rely on
vast amounts of human supervision in the form of crowdsourced datasets or user
interactions. In this work, we introduce Unnatural Instructions: a large
dataset of creative and diverse instructions, collected with virtually no human
labor. We collect 64,000 examples by prompting a language model with three seed
examples of instructions and eliciting a fourth. This set is then expanded by
prompting the model to rephrase each instruction, creating a total of
approximately 240,000 examples of instructions, inputs, and outputs.
Experiments show that despite containing a fair amount of noise, training on
Unnatural Instructions rivals the effectiveness of training on open-source
manually-curated datasets, surpassing the performance of models such as T0++
and Tk-Instruct across various benchmarks. These results demonstrate the
potential of model-generated data as a cost-effective alternative to
crowdsourcing for dataset expansion and diversification."
Hyperspherical Consistency Regularization,0.868667,"Recent advances in contrastive learning have enlightened diverse applications
across various semi-supervised fields. Jointly training supervised learning and
unsupervised learning with a shared feature encoder becomes a common scheme.
Though it benefits from taking advantage of both feature-dependent information
from self-supervised learning and label-dependent information from supervised
learning, this scheme remains suffering from bias of the classifier. In this
work, we systematically explore the relationship between self-supervised
learning and supervised learning, and study how self-supervised learning helps
robust data-efficient deep learning. We propose hyperspherical consistency
regularization (HCR), a simple yet effective plug-and-play method, to
regularize the classifier using feature-dependent information and thus avoid
bias from labels. Specifically, HCR first projects logits from the classifier
and feature projections from the projection head on the respective hypersphere,
then it enforces data points on hyperspheres to have similar structures by
minimizing binary cross entropy of pairwise distances' similarity metrics.
Extensive experiments on semi-supervised and weakly-supervised learning
demonstrate the effectiveness of our method, by showing superior performance
with HCR."
Online Dynamic Reliability Evaluation of Wind Turbines based on Drone-assisted Monitoring,0.167217,"The offshore wind energy is increasingly becoming an attractive source of
energy due to having lower environmental impact. Effective operation and
maintenance that ensures the maximum availability of the energy generation
process using offshore facilities and minimal production cost are two key
factors to improve the competitiveness of this energy source over other
traditional sources of energy. Condition monitoring systems are widely used for
health management of offshore wind farms to have improved operation and
maintenance. Reliability of the wind farms are increasingly being evaluated to
aid in the maintenance process and thereby to improve the availability of the
farms. However, much of the reliability analysis is performed offline based on
statistical data. In this article, we propose a drone-assisted monitoring based
method for online reliability evaluation of wind turbines. A blade system of a
wind turbine is used as an illustrative example to demonstrate the proposed
approach."
Characterizing Financial Market Coverage using Artificial Intelligence,0.377661,"This paper scrutinizes a database of over 4900 YouTube videos to characterize
financial market coverage. Financial market coverage generates a large number
of videos. Therefore, watching these videos to derive actionable insights could
be challenging and complex. In this paper, we leverage Whisper, a
speech-to-text model from OpenAI, to generate a text corpus of market coverage
videos from Bloomberg and Yahoo Finance. We employ natural language processing
to extract insights regarding language use from the market coverage. Moreover,
we examine the prominent presence of trending topics and their evolution over
time, and the impacts that some individuals and organizations have on the
financial market. Our characterization highlights the dynamics of the financial
market coverage and provides valuable insights reflecting broad discussions
regarding recent financial events and the world economy."
DoCoGen: Domain Counterfactual Generation for Low Resource Domain Adaptation,0.771033,"Natural language processing (NLP) algorithms have become very successful, but
they still struggle when applied to out-of-distribution examples. In this paper
we propose a controllable generation approach in order to deal with this domain
adaptation (DA) challenge. Given an input text example, our DoCoGen algorithm
generates a domain-counterfactual textual example (D-con) - that is similar to
the original in all aspects, including the task label, but its domain is
changed to a desired one. Importantly, DoCoGen is trained using only unlabeled
examples from multiple domains - no NLP task labels or parallel pairs of
textual examples and their domain-counterfactuals are required. We show that
DoCoGen can generate coherent counterfactuals consisting of multiple sentences.
We use the D-cons generated by DoCoGen to augment a sentiment classifier and a
multi-label intent classifier in 20 and 78 DA setups, respectively, where
source-domain labeled data is scarce. Our model outperforms strong baselines
and improves the accuracy of a state-of-the-art unsupervised DA algorithm."
CLIPVG: Text-Guided Image Manipulation Using Differentiable Vector Graphics,0.373397,"Considerable progress has recently been made in leveraging CLIP (Contrastive
Language-Image Pre-Training) models for text-guided image manipulation.
However, all existing works rely on additional generative models to ensure the
quality of results, because CLIP alone cannot provide enough guidance
information for fine-scale pixel-level changes. In this paper, we introduce
CLIPVG, a text-guided image manipulation framework using differentiable vector
graphics, which is also the first CLIP-based general image manipulation
framework that does not require any additional generative models. We
demonstrate that CLIPVG can not only achieve state-of-art performance in both
semantic correctness and synthesis quality, but also is flexible enough to
support various applications far beyond the capability of all existing methods."
OOD Augmentation May Be at Odds with Open-Set Recognition,0.266337,"Despite advances in image classification methods, detecting the samples not
belonging to the training classes is still a challenging problem. There has
been a burst of interest in this subject recently, which is called Open-Set
Recognition (OSR). In OSR, the goal is to achieve both the classification and
detecting out-of-distribution (OOD) samples. Several ideas have been proposed
to push the empirical result further through complicated techniques. We believe
that such complication is indeed not necessary. To this end, we have shown that
Maximum Softmax Probability (MSP), as the simplest baseline for OSR, applied on
Vision Transformers (ViTs) as the base classifier that is trained with non-OOD
augmentations can surprisingly outperform many recent methods. Non-OOD
augmentations are the ones that do not alter the data distribution by much. Our
results outperform state-of-the-art in CIFAR-10 datasets, and is also better
than most of the current methods in SVHN and MNIST. We show that training
augmentation has a significant effect on the performance of ViTs in the OSR
tasks, and while they should produce significant diversity in the augmented
samples, the generated sample OOD-ness must remain limited."
PropSegmEnt: A Large-Scale Corpus for Proposition-Level Segmentation and Entailment Recognition,0.929234,"The widely studied task of Natural Language Inference (NLI) requires a system
to recognize whether one piece of text is textually entailed by another, i.e.
whether the entirety of its meaning can be inferred from the other. In current
NLI datasets and models, textual entailment relations are typically defined on
the sentence- or paragraph-level. However, even a simple sentence often
contains multiple propositions, i.e. distinct units of meaning conveyed by the
sentence. As these propositions can carry different truth values in the context
of a given premise, we argue for the need to recognize the textual entailment
relation of each proposition in a sentence individually.
  We propose PropSegmEnt, a corpus of over 45K propositions annotated by expert
human raters. Our dataset structure resembles the tasks of (1) segmenting
sentences within a document to the set of propositions, and (2) classifying the
entailment relation of each proposition with respect to a different yet
topically-aligned document, i.e. documents describing the same event or entity.
We establish strong baselines for the segmentation and entailment tasks.
Through case studies on summary hallucination detection and document-level NLI,
we demonstrate that our conceptual framework is potentially useful for
understanding and explaining the compositionality of NLI labels."
TSAM: A Two-Stream Attention Model for Causal Emotion Entailment,0.582973,"Causal Emotion Entailment (CEE) aims to discover the potential causes behind
an emotion in a conversational utterance. Previous works formalize CEE as
independent utterance pair classification problems, with emotion and speaker
information neglected. From a new perspective, this paper considers CEE in a
joint framework. We classify multiple utterances synchronously to capture the
correlations between utterances in a global view and propose a Two-Stream
Attention Model (TSAM) to effectively model the speaker's emotional influences
in the conversational history. Specifically, the TSAM comprises three modules:
Emotion Attention Network (EAN), Speaker Attention Network (SAN), and
interaction module. The EAN and SAN incorporate emotion and speaker information
in parallel, and the subsequent interaction module effectively interchanges
relevant information between the EAN and SAN via a mutual BiAffine
transformation. Extensive experimental results demonstrate that our model
achieves new State-Of-The-Art (SOTA) performance and outperforms baselines
remarkably."
Learning Point Processes using Recurrent Graph Network,0.075783,"We present a novel Recurrent Graph Network (RGN) approach for predicting
discrete marked event sequences by learning the underlying complex stochastic
process. Using the framework of Point Processes, we interpret a marked discrete
event sequence as the superposition of different sequences each of a unique
type. The nodes of the Graph Network use LSTM to incorporate past information
whereas a Graph Attention Network (GAT Network) introduces strong inductive
biases to capture the interaction between these different types of events. By
changing the self-attention mechanism from attending over past events to
attending over event types, we obtain a reduction in time and space complexity
from $\mathcal{O}(N^2)$ (total number of events) to
$\mathcal{O}(|\mathcal{Y}|^2)$ (number of event types). Experiments show that
the proposed approach improves performance in log-likelihood, prediction and
goodness-of-fit tasks with lower time and space complexity compared to
state-of-the art Transformer based architectures."
Route Planning for Last-Mile Deliveries Using Mobile Parcel Lockers: A Hybrid Q-Learning Network Approach,0.482134,"Mobile parcel lockers have been recently proposed by logistics operators as a
technology that could help reduce traffic congestion and operational costs in
urban freight distribution. Given their ability to relocate throughout their
area of deployment, they hold the potential to improve customer accessibility
and convenience. In this study, we formulate the Mobile Parcel Locker Problem
(MPLP) , a special case of the Location-Routing Problem (LRP) which determines
the optimal stopover location for MPLs throughout the day and plans
corresponding delivery routes. A Hybrid Q Learning Network based Method (HQM)
is developed to resolve the computational complexity of the resulting large
problem instances while escaping local optima. In addition, the HQM is
integrated with global and local search mechanisms to resolve the dilemma of
exploration and exploitation faced by classic reinforcement learning methods.
We examine the performance of HQM under different problem sizes (up to 200
nodes) and benchmarked it against the exact approach and Genetic Algorithm
(GA). Our results indicate that HQM achieves better optimisation performance
with shorter computation time than the exact approach solved by the Gurobi
solver in large problem instances. Additionally, the average reward obtained by
HQM is 1.96 times greater than GA, which demonstrates that HQM has a better
optimisation ability. Further, we identify critical factors that contribute to
fleet size requirements, travel distances, and service delays. Our findings
outline that the efficiency of MPLs is mainly contingent on the length of time
windows and the deployment of MPL stopovers. Finally, we highlight managerial
implications based on parametric analysis to provide guidance for logistics
operators in the context of efficient last-mile distribution operations."
Token-level Sequence Labeling for Spoken Language Understanding using Compositional End-to-End Models,0.682942,"End-to-end spoken language understanding (SLU) systems are gaining popularity
over cascaded approaches due to their simplicity and ability to avoid error
propagation. However, these systems model sequence labeling as a sequence
prediction task causing a divergence from its well-established token-level
tagging formulation. We build compositional end-to-end SLU systems that
explicitly separate the added complexity of recognizing spoken mentions in SLU
from the NLU task of sequence labeling. By relying on intermediate decoders
trained for ASR, our end-to-end systems transform the input modality from
speech to token-level representations that can be used in the traditional
sequence labeling framework. This composition of ASR and NLU formulations in
our end-to-end SLU system offers direct compatibility with pre-trained ASR and
NLU systems, allows performance monitoring of individual components and enables
the use of globally normalized losses like CRF, making them attractive in
practical scenarios. Our models outperform both cascaded and direct end-to-end
models on a labeling task of named entity recognition across SLU benchmarks."
DesNet: Decomposed Scale-Consistent Network for Unsupervised Depth Completion,0.42269,"Unsupervised depth completion aims to recover dense depth from the sparse one
without using the ground-truth annotation. Although depth measurement obtained
from LiDAR is usually sparse, it contains valid and real distance information,
i.e., scale-consistent absolute depth values. Meanwhile, scale-agnostic
counterparts seek to estimate relative depth and have achieved impressive
performance. To leverage both the inherent characteristics, we thus suggest to
model scale-consistent depth upon unsupervised scale-agnostic frameworks.
Specifically, we propose the decomposed scale-consistent learning (DSCL)
strategy, which disintegrates the absolute depth into relative depth prediction
and global scale estimation, contributing to individual learning benefits. But
unfortunately, most existing unsupervised scale-agnostic frameworks heavily
suffer from depth holes due to the extremely sparse depth input and weak
supervised signal. To tackle this issue, we introduce the global depth guidance
(GDG) module, which attentively propagates dense depth reference into the
sparse target via novel dense-to-sparse attention. Extensive experiments show
the superiority of our method on outdoor KITTI benchmark, ranking 1st and
outperforming the best KBNet more than 12% in RMSE. In addition, our approach
achieves state-of-the-art performance on indoor NYUv2 dataset."
Anomaly Detection via Reverse Distillation from One-Class Embedding,0.999872,"Knowledge distillation (KD) achieves promising results on the challenging
problem of unsupervised anomaly detection (AD).The representation discrepancy
of anomalies in the teacher-student (T-S) model provides essential evidence for
AD. However, using similar or identical architectures to build the teacher and
student models in previous studies hinders the diversity of anomalous
representations. To tackle this problem, we propose a novel T-S model
consisting of a teacher encoder and a student decoder and introduce a simple
yet effective ""reverse distillation"" paradigm accordingly. Instead of receiving
raw images directly, the student network takes teacher model's one-class
embedding as input and targets to restore the teacher's multiscale
representations. Inherently, knowledge distillation in this study starts from
abstract, high-level presentations to low-level features. In addition, we
introduce a trainable one-class bottleneck embedding (OCBE) module in our T-S
model. The obtained compact embedding effectively preserves essential
information on normal patterns, but abandons anomaly perturbations. Extensive
experimentation on AD and one-class novelty detection benchmarks shows that our
method surpasses SOTA performance, demonstrating our proposed approach's
effectiveness and generalizability."
ZEROTOP: Zero-Shot Task-Oriented Semantic Parsing using Large Language Models,0.209251,"We explore the use of large language models (LLMs) for zero-shot semantic
parsing. Semantic parsing involves mapping natural language utterances to
task-specific meaning representations. Language models are generally trained on
the publicly available text and code and cannot be expected to directly
generalize to domain-specific parsing tasks in a zero-shot setting. In this
work, we propose ZEROTOP, a zero-shot task-oriented parsing method that
decomposes a semantic parsing problem into a set of abstractive and extractive
question-answering (QA) problems, enabling us to leverage the ability of LLMs
to zero-shot answer reading comprehension questions. For each utterance, we
prompt the LLM with questions corresponding to its top-level intent and a set
of slots and use the LLM generations to construct the target meaning
representation. We observe that current LLMs fail to detect unanswerable
questions; and as a result, cannot handle questions corresponding to missing
slots. To address this problem, we fine-tune a language model on public QA
datasets using synthetic negative samples. Experimental results show that our
QA-based decomposition paired with the fine-tuned LLM can correctly parse ~16%
of utterances in the MTOP dataset without requiring any annotated data."
EfficientRep:An Efficient Repvgg-style ConvNets with Hardware-aware Neural Network Design,0.406039,"We present a hardware-efficient architecture of convolutional neural network,
which has a repvgg-like architecture. Flops or parameters are traditional
metrics to evaluate the efficiency of networks which are not sensitive to
hardware including computing ability and memory bandwidth. Thus, how to design
a neural network to efficiently use the computing ability and memory bandwidth
of hardware is a critical problem. This paper proposes a method how to design
hardware-aware neural network. Based on this method, we designed EfficientRep
series convolutional networks, which are high-computation hardware(e.g. GPU)
friendly and applied in YOLOv6 object detection framework. YOLOv6 has published
YOLOv6N/YOLOv6S/YOLOv6M/YOLOv6L models in v1 and v2 versions."
A Robust Document Image Watermarking Scheme using Deep Neural Network,0.610994,"Watermarking is an important copyright protection technology which generally
embeds the identity information into the carrier imperceptibly. Then the
identity can be extracted to prove the copyright from the watermarked carrier
even after suffering various attacks. Most of the existing watermarking
technologies take the nature images as carriers. Different from the natural
images, document images are not so rich in color and texture, and thus have
less redundant information to carry watermarks. This paper proposes an
end-to-end document image watermarking scheme using the deep neural network.
Specifically, an encoder and a decoder are designed to embed and extract the
watermark. A noise layer is added to simulate the various attacks that could be
encountered in reality, such as the Cropout, Dropout, Gaussian blur, Gaussian
noise, Resize, and JPEG Compression. A text-sensitive loss function is designed
to limit the embedding modification on characters. An embedding strength
adjustment strategy is proposed to improve the quality of watermarked image
with little loss of extraction accuracy. Experimental results show that the
proposed document image watermarking technology outperforms three
state-of-the-arts in terms of the robustness and image quality."
Span Classification with Structured Information for Disfluency Detection in Spoken Utterances,0.0460582,"Existing approaches in disfluency detection focus on solving a token-level
classification task for identifying and removing disfluencies in text.
Moreover, most works focus on leveraging only contextual information captured
by the linear sequences in text, thus ignoring the structured information in
text which is efficiently captured by dependency trees. In this paper, building
on the span classification paradigm of entity recognition, we propose a novel
architecture for detecting disfluencies in transcripts from spoken utterances,
incorporating both contextual information through transformers and
long-distance structured information captured by dependency trees, through
graph convolutional networks (GCNs). Experimental results show that our
proposed model achieves state-of-the-art results on the widely used English
Switchboard for disfluency detection and outperforms prior-art by a significant
margin. We make all our codes publicly available on GitHub
(https://github.com/Sreyan88/Disfluency-Detection-with-Span-Classification)"
Knowledge Graph Question Answering Leaderboard: A Community Resource to Prevent a Replication Crisis,0.613529,"Data-driven systems need to be evaluated to establish trust in the scientific
approach and its applicability. In particular, this is true for Knowledge Graph
(KG) Question Answering (QA), where complex data structures are made accessible
via natural-language interfaces. Evaluating the capabilities of these systems
has been a driver for the community for more than ten years while establishing
different KGQA benchmark datasets. However, comparing different approaches is
cumbersome. The lack of existing and curated leaderboards leads to a missing
global view over the research field and could inject mistrust into the results.
In particular, the latest and most-used datasets in the KGQA community, LC-QuAD
and QALD, miss providing central and up-to-date points of trust. In this paper,
we survey and analyze a wide range of evaluation results with significant
coverage of 100 publications and 98 systems from the last decade. We provide a
new central and open leaderboard for any KGQA benchmark dataset as a focal
point for the community - https://kgqa.github.io/leaderboard. Our analysis
highlights existing problems during the evaluation of KGQA systems. Thus, we
will point to possible improvements for future evaluations."
PartSLIP: Low-Shot Part Segmentation for 3D Point Clouds via Pretrained Image-Language Models,0.986813,"Generalizable 3D part segmentation is important but challenging in vision and
robotics. Training deep models via conventional supervised methods requires
large-scale 3D datasets with fine-grained part annotations, which are costly to
collect. This paper explores an alternative way for low-shot part segmentation
of 3D point clouds by leveraging a pretrained image-language model, GLIP, which
achieves superior performance on open-vocabulary 2D detection. We transfer the
rich knowledge from 2D to 3D through GLIP-based part detection on point cloud
rendering and a novel 2D-to-3D label lifting algorithm. We also utilize
multi-view 3D priors and few-shot prompt tuning to boost performance
significantly. Extensive evaluation on PartNet and PartNet-Mobility datasets
shows that our method enables excellent zero-shot 3D part segmentation. Our
few-shot version not only outperforms existing few-shot approaches by a large
margin but also achieves highly competitive results compared to the fully
supervised counterpart. Furthermore, we demonstrate that our method can be
directly applied to iPhone-scanned point clouds without significant domain
gaps."
Phase-Shifting Coder: Predicting Accurate Orientation in Oriented Object Detection,0.623653,"With the vigorous development of computer vision, oriented object detection
has gradually been featured. In this paper, a novel differentiable angle coder
named phase-shifting coder (PSC) is proposed to accurately predict the
orientation of objects, along with a dual-frequency version (PSCD). By mapping
the rotational periodicity of different cycles into the phase of different
frequencies, we provide a unified framework for various periodic fuzzy problems
caused by rotational symmetry in oriented object detection. Upon such a
framework, common problems in oriented object detection such as boundary
discontinuity and square-like problems are elegantly solved in a unified form.
Visual analysis and experiments on three datasets prove the effectiveness and
the potentiality of our approach. When facing scenarios requiring high-quality
bounding boxes, the proposed methods are expected to give a competitive
performance. The codes are publicly available at
https://github.com/open-mmlab/mmrotate."
On Designing Data Models for Energy Feature Stores,0.0243273,"The digital transformation of the energy infrastructure enables new, data
driven, applications often supported by machine learning models. However,
domain specific data transformations, pre-processing and management in modern
data driven pipelines is yet to be addressed.
  In this paper we perform a first time study on generic data models that are
able to support designing feature management solutions that are the most
important component in developing ML-based energy applications. We first
propose a taxonomy for designing data models suitable for energy applications,
explain how this model can support the design of features and their subsequent
management by specialized feature stores. Using a short-term forecasting
dataset, we show the benefits of designing richer data models and engineering
the features on the performance of the resulting models. Finally, we benchmark
three complementary feature management solutions, including an open-source
feature store suitable for time series."
MC$^2$: Towards Transparent and Culturally-Aware NLP for Minority Languages in China,0.998497,"Current large language models demonstrate deficiencies in understanding
low-resource languages, particularly the minority languages in China. This
limitation stems from the scarcity of available pre-training data. To address
this accessibility challenge, we present MC$^2$, a Multilingual Corpus of
Minority Languages in China, which is the largest open-source corpus of its
kind so far. MC$^2$ includes four underrepresented languages: Tibetan, Uyghur,
Kazakh, and Mongolian. Notably, we focus on the less common writing systems of
Kazakh and Mongolian, i.e., Kazakh Arabic script and traditional Mongolian
script, respectively, which have been long neglected in previous corpus
construction efforts. Recognizing the prevalence of language contamination
within existing corpora, we adopt a quality-centric solution for collecting
MC$^2$, prioritizing accuracy while enhancing diversity. Furthermore, we
underscore the importance of attending to the multiplicity of writing systems,
which is closely related to the cultural awareness of the resulting models. The
MC$^2$ corpus and related models are made public to the community."
Robot Vitals and Robot Health: Towards Systematically Quantifying Runtime Performance Degradation in Robots Under Adverse Conditions,0.594093,"This paper addresses the problem of automatically detecting and quantifying
performance degradation in remote mobile robots during task execution. A robot
may encounter a variety of uncertainties and adversities during task execution,
which can impair its ability to carry out tasks effectively and cause its
performance to degrade. Such situations can be mitigated or averted by timely
detection and intervention (e.g., by a remote human supervisor taking over
control in teleoperation mode). Inspired by patient triaging systems in
hospitals, we introduce the framework of ""robot vitals"" for estimating overall
""robot health"". A robot's vitals are a set of indicators that estimate the
extent of performance degradation faced by a robot at a given point in time.
Robot health is a metric that combines robot vitals into a single scalar value
estimate of performance degradation. Experiments, both in simulation and on a
real mobile robot, demonstrate that the proposed robot vitals and robot health
can be used effectively to estimate robot performance degradation during
runtime."
SegViT: Semantic Segmentation with Plain Vision Transformers,0.905516,"We explore the capability of plain Vision Transformers (ViTs) for semantic
segmentation and propose the SegVit. Previous ViT-based segmentation networks
usually learn a pixel-level representation from the output of the ViT.
Differently, we make use of the fundamental component -- attention mechanism,
to generate masks for semantic segmentation. Specifically, we propose the
Attention-to-Mask (ATM) module, in which the similarity maps between a set of
learnable class tokens and the spatial feature maps are transferred to the
segmentation masks. Experiments show that our proposed SegVit using the ATM
module outperforms its counterparts using the plain ViT backbone on the ADE20K
dataset and achieves new state-of-the-art performance on COCO-Stuff-10K and
PASCAL-Context datasets. Furthermore, to reduce the computational cost of the
ViT backbone, we propose query-based down-sampling (QD) and query-based
up-sampling (QU) to build a Shrunk structure. With the proposed Shrunk
structure, the model can save up to $40\%$ computations while maintaining
competitive performance."
Dynamic Global Memory for Document-level Argument Extraction,0.97874,"Extracting informative arguments of events from news articles is a
challenging problem in information extraction, which requires a global
contextual understanding of each document. While recent work on document-level
extraction has gone beyond single-sentence and increased the cross-sentence
inference capability of end-to-end models, they are still restricted by certain
input sequence length constraints and usually ignore the global context between
events. To tackle this issue, we introduce a new global neural generation-based
framework for document-level event argument extraction by constructing a
document memory store to record the contextual event information and leveraging
it to implicitly and explicitly help with decoding of arguments for later
events. Empirical results show that our framework outperforms prior methods
substantially and it is more robust to adversarially annotated examples with
our constrained decoding design. (Our code and resources are available at
https://github.com/xinyadu/memory_docie for research purpose.)"
Unsupervised Scene Sketch to Photo Synthesis,0.798104,"Sketches make an intuitive and powerful visual expression as they are fast
executed freehand drawings. We present a method for synthesizing realistic
photos from scene sketches. Without the need for sketch and photo pairs, our
framework directly learns from readily available large-scale photo datasets in
an unsupervised manner. To this end, we introduce a standardization module that
provides pseudo sketch-photo pairs during training by converting photos and
sketches to a standardized domain, i.e. the edge map. The reduced domain gap
between sketch and photo also allows us to disentangle them into two
components: holistic scene structures and low-level visual styles such as color
and texture. Taking this advantage, we synthesize a photo-realistic image by
combining the structure of a sketch and the visual style of a reference photo.
Extensive experimental results on perceptual similarity metrics and human
perceptual studies show the proposed method could generate realistic photos
with high fidelity from scene sketches and outperform state-of-the-art photo
synthesis baselines. We also demonstrate that our framework facilitates a
controllable manipulation of photo synthesis by editing strokes of
corresponding sketches, delivering more fine-grained details than previous
approaches that rely on region-level editing."
A Multi-label Continual Learning Framework to Scale Deep Learning Approaches for Packaging Equipment Monitoring,0.336297,"Continual Learning aims to learn from a stream of tasks, being able to
remember at the same time both new and old tasks. While many approaches were
proposed for single-class classification, multi-label classification in the
continual scenario remains a challenging problem. For the first time, we study
multi-label classification in the Domain Incremental Learning scenario.
Moreover, we propose an efficient approach that has a logarithmic complexity
with regard to the number of tasks, and can be applied also in the Class
Incremental Learning scenario. We validate our approach on a real-world
multi-label Alarm Forecasting problem from the packaging industry. For the sake
of reproducibility, the dataset and the code used for the experiments are
publicly available."
Instance-Specific Image Goal Navigation: Training Embodied Agents to Find Object Instances,0.797243,"We consider the problem of embodied visual navigation given an image-goal
(ImageNav) where an agent is initialized in an unfamiliar environment and
tasked with navigating to a location 'described' by an image. Unlike related
navigation tasks, ImageNav does not have a standardized task definition which
makes comparison across methods difficult. Further, existing formulations have
two problematic properties; (1) image-goals are sampled from random locations
which can lead to ambiguity (e.g., looking at walls), and (2) image-goals match
the camera specification and embodiment of the agent; this rigidity is limiting
when considering user-driven downstream applications. We present the
Instance-specific ImageNav task (InstanceImageNav) to address these
limitations. Specifically, the goal image is 'focused' on some particular
object instance in the scene and is taken with camera parameters independent of
the agent. We instantiate InstanceImageNav in the Habitat Simulator using
scenes from the Habitat-Matterport3D dataset (HM3D) and release a standardized
benchmark to measure community progress."
Causal Strategic Learning with Competitive Selection,0.164071,"We study the problem of agent selection in causal strategic learning under
multiple decision makers and address two key challenges that come with it.
Firstly, while much of prior work focuses on studying a fixed pool of agents
that remains static regardless of their evaluations, we consider the impact of
selection procedure by which agents are not only evaluated, but also selected.
When each decision maker unilaterally selects agents by maximising their own
utility, we show that the optimal selection rule is a trade-off between
selecting the best agents and providing incentives to maximise the agents'
improvement. Furthermore, this optimal selection rule relies on incorrect
predictions of agents' outcomes. Hence, we study the conditions under which a
decision maker's optimal selection rule will not lead to deterioration of
agents' outcome nor cause unjust reduction in agents' selection chance. To that
end, we provide an analytical form of the optimal selection rule and a
mechanism to retrieve the causal parameters from observational data, under
certain assumptions on agents' behaviour. Secondly, when there are multiple
decision makers, the interference between selection rules introduces another
source of biases in estimating the underlying causal parameters. To address
this problem, we provide a cooperative protocol which all decision makers must
collectively adopt to recover the true causal parameters. Lastly, we complement
our theoretical results with simulation studies. Our results highlight not only
the importance of causal modeling as a strategy to mitigate the effect of
gaming, as suggested by previous work, but also the need of a benevolent
regulator to enable it."
CipherDAug: Ciphertext based Data Augmentation for Neural Machine Translation,0.645524,"We propose a novel data-augmentation technique for neural machine translation
based on ROT-$k$ ciphertexts. ROT-$k$ is a simple letter substitution cipher
that replaces a letter in the plaintext with the $k$th letter after it in the
alphabet. We first generate multiple ROT-$k$ ciphertexts using different values
of $k$ for the plaintext which is the source side of the parallel data. We then
leverage this enciphered training data along with the original parallel data
via multi-source training to improve neural machine translation. Our method,
CipherDAug, uses a co-regularization-inspired training procedure, requires no
external data sources other than the original training data, and uses a
standard Transformer to outperform strong data augmentation techniques on
several datasets by a significant margin. This technique combines easily with
existing approaches to data augmentation, and yields particularly strong
results in low-resource settings."
The Stanford Drone Dataset is More Complex than We Think: An Analysis of Key Characteristics,0.147584,"Several datasets exist which contain annotated information of individuals'
trajectories. Such datasets are vital for many real-world applications,
including trajectory prediction and autonomous navigation. One prominent
dataset currently in use is the Stanford Drone Dataset (SDD). Despite its
prominence, discussion surrounding the characteristics of this dataset is
insufficient. We demonstrate how this insufficiency reduces the information
available to users and can impact performance. Our contributions include the
outlining of key characteristics in the SDD, employment of an
information-theoretic measure and custom metric to clearly visualize those
characteristics, the implementation of the PECNet and Y-Net trajectory
prediction models to demonstrate the outlined characteristics' impact on
predictive performance, and lastly we provide a comparison between the SDD and
Intersection Drone (inD) Dataset. Our analysis of the SDD's key characteristics
is important because without adequate information about available datasets a
user's ability to select the most suitable dataset for their methods, to
reproduce one another's results, and to interpret their own results are
hindered. The observations we make through this analysis provide a readily
accessible and interpretable source of information for those planning to use
the SDD. Our intention is to increase the performance and reproducibility of
methods applied to this dataset going forward, while also clearly detailing
less obvious features of the dataset for new users."
Multilingual context-based pronunciation learning for Text-to-Speech,0.133069,"Phonetic information and linguistic knowledge are an essential component of a
Text-to-speech (TTS) front-end. Given a language, a lexicon can be collected
offline and Grapheme-to-Phoneme (G2P) relationships are usually modeled in
order to predict the pronunciation for out-of-vocabulary (OOV) words.
Additionally, post-lexical phonology, often defined in the form of rule-based
systems, is used to correct pronunciation within or between words. In this work
we showcase a multilingual unified front-end system that addresses any
pronunciation related task, typically handled by separate modules. We evaluate
the proposed model on G2P conversion and other language-specific challenges,
such as homograph and polyphones disambiguation, post-lexical rules and
implicit diacritization. We find that the multilingual model is competitive
across languages and tasks, however, some trade-offs exists when compared to
equivalent monolingual solutions."
Make-A-Scene: Scene-Based Text-to-Image Generation with Human Priors,0.990246,"Recent text-to-image generation methods provide a simple yet exciting
conversion capability between text and image domains. While these methods have
incrementally improved the generated image fidelity and text relevancy, several
pivotal gaps remain unanswered, limiting applicability and quality. We propose
a novel text-to-image method that addresses these gaps by (i) enabling a simple
control mechanism complementary to text in the form of a scene, (ii)
introducing elements that substantially improve the tokenization process by
employing domain-specific knowledge over key image regions (faces and salient
objects), and (iii) adapting classifier-free guidance for the transformer use
case. Our model achieves state-of-the-art FID and human evaluation results,
unlocking the ability to generate high fidelity images in a resolution of
512x512 pixels, significantly improving visual quality. Through scene
controllability, we introduce several new capabilities: (i) Scene editing, (ii)
text editing with anchor scenes, (iii) overcoming out-of-distribution text
prompts, and (iv) story illustration generation, as demonstrated in the story
we wrote."
Self-Supervised Video Forensics by Audio-Visual Anomaly Detection,0.975879,"Manipulated videos often contain subtle inconsistencies between their visual
and audio signals. We propose a video forensics method, based on anomaly
detection, that can identify these inconsistencies, and that can be trained
solely using real, unlabeled data. We train an autoregressive model to generate
sequences of audio-visual features, using feature sets that capture the
temporal synchronization between video frames and sound. At test time, we then
flag videos that the model assigns low probability. Despite being trained
entirely on real videos, our model obtains strong performance on the task of
detecting manipulated speech videos. Project site:
https://cfeng16.github.io/audio-visual-forensics"
Combinatorial Civic Crowdfunding with Budgeted Agents: Welfare Optimality at Equilibrium and Optimal Deviation,0.342131,"Civic Crowdfunding (CC) uses the ``power of the crowd'' to garner
contributions towards public projects. As these projects are non-excludable,
agents may prefer to ``free-ride,'' resulting in the project not being funded.
For single project CC, researchers propose to provide refunds to incentivize
agents to contribute, thereby guaranteeing the project's funding. These funding
guarantees are applicable only when agents have an unlimited budget. This work
focuses on a combinatorial setting, where multiple projects are available for
CC and agents have a limited budget. We study certain specific conditions where
funding can be guaranteed. Further, funding the optimal social welfare subset
of projects is desirable when every available project cannot be funded due to
budget restrictions. We prove the impossibility of achieving optimal welfare at
equilibrium for any monotone refund scheme. We then study different heuristics
that the agents can use to contribute to the projects in practice. Through
simulations, we demonstrate the heuristics' performance as the average-case
trade-off between welfare obtained and agent utility."
Development of a Modular and Submersible Soft Robotic Arm and Corresponding Learned Kinematics Models,0.509654,"Many soft-body organisms found in nature flourish underwater. Similarly, soft
robots are potentially well-suited for underwater environments partly because
the problematic effects of gravity, friction, and harmonic oscillations are
less severe underwater. However, it remains a challenge to design, fabricate,
waterproof, model, and control underwater soft robotic systems. Furthermore,
submersible robots usually do not have configurable components because of the
need for sealed electronics and mechanical elements. This work presents the
development of a modular and submersible soft robotic arm driven by hydraulic
actuators which consists of mostly 3D printable parts which can be assembled or
modified in a relatively short amount of time. Its modular design enables
multiple shape configurations and easy swapping of soft actuators. As a first
step to exploring machine learning control algorithms on this system, we also
present preliminary forward and inverse kinematics models developed using deep
neural networks."
Project proposal: A modular reinforcement learning based automated theorem prover,0.0317988,"We propose to build a reinforcement learning prover of independent
components: a deductive system (an environment), the proof state representation
(how an agent sees the environment), and an agent training algorithm. To that
purpose, we contribute an additional Vampire-based environment to
$\texttt{gym-saturation}$ package of OpenAI Gym environments for saturation
provers. We demonstrate a prototype of using $\texttt{gym-saturation}$ together
with a popular reinforcement learning framework (Ray $\texttt{RLlib}$).
Finally, we discuss our plans for completing this work in progress to a
competitive automated theorem prover."
ViewNet: Unsupervised Viewpoint Estimation from Conditional Generation,0.125114,"Understanding the 3D world without supervision is currently a major challenge
in computer vision as the annotations required to supervise deep networks for
tasks in this domain are expensive to obtain on a large scale. In this paper,
we address the problem of unsupervised viewpoint estimation. We formulate this
as a self-supervised learning task, where image reconstruction provides the
supervision needed to predict the camera viewpoint. Specifically, we make use
of pairs of images of the same object at training time, from unknown
viewpoints, to self-supervise training by combining the viewpoint information
from one image with the appearance information from the other. We demonstrate
that using a perspective spatial transformer allows efficient viewpoint
learning, outperforming existing unsupervised approaches on synthetic data, and
obtains competitive results on the challenging PASCAL3D+ dataset."
PSP: Pre-trained Soft Prompts for Few-Shot Abstractive Summarization,0.821903,"Few-shot abstractive summarization has become a challenging task in natural
language generation. To support it, we designed a novel soft prompts
architecture coupled with a prompt pre-training plus fine-tuning paradigm that
is effective and tunes only extremely light parameters. The soft prompts
include continuous input embeddings across an encoder and a decoder to fit the
structure of the generation models. Importantly, a novel inner-prompt placed in
the text is introduced to capture document-level information. The aim is to
devote attention to understanding the document that better prompts the model to
generate document-related content. The first step in the summarization
procedure is to conduct prompt pre-training with self-supervised pseudo-data.
This teaches the model basic summarizing capabilities. The model is then
fine-tuned with few-shot examples. Experimental results on the CNN/DailyMail
and XSum datasets show that our method, with only 0.1% of the parameters,
outperforms full-model tuning where all model parameters are tuned. It also
surpasses Prompt Tuning by a large margin and delivers competitive results
against Prefix-Tuning with 3% of the parameters."
ToMChallenges: A Principle-Guided Dataset and Diverse Evaluation Tasks for Exploring Theory of Mind,0.942417,"Theory of Mind (ToM), the capacity to comprehend the mental states of
distinct individuals, is essential for numerous practical applications. With
the development of large language models (LLMs), there is a heated debate about
whether they are able to perform ToM tasks. Previous studies have used
different tasks and prompts to test the ToM on LLMs and the results are
inconsistent: some studies asserted these models are capable of exhibiting ToM,
while others suggest the opposite. In this study, We present ToMChallenges, a
dataset for comprehensively evaluating the Theory of Mind based on the
Sally-Anne and Smarties tests with a diverse set of tasks. In addition, we also
propose an auto-grader to streamline the answer evaluation process. We tested
three models: davinci, turbo, and gpt-4. Our evaluation results and error
analyses show that LLMs have inconsistent behaviors across prompts and tasks.
Performing the ToM tasks robustly remains a challenge for the LLMs. In
addition, our paper wants to raise awareness in evaluating the ToM in LLMs and
we want to invite more discussion on how to design the prompts and tasks for
ToM tasks that can better assess the LLMs' ability."
XAlign: Cross-lingual Fact-to-Text Alignment and Generation for Low-Resource Languages,0.554692,"Multiple critical scenarios (like Wikipedia text generation given English
Infoboxes) need automated generation of descriptive text in low resource (LR)
languages from English fact triples. Previous work has focused on English
fact-to-text (F2T) generation. To the best of our knowledge, there has been no
previous attempt on cross-lingual alignment or generation for LR languages.
Building an effective cross-lingual F2T (XF2T) system requires alignment
between English structured facts and LR sentences. We propose two unsupervised
methods for cross-lingual alignment. We contribute XALIGN, an XF2T dataset with
0.45M pairs across 8 languages, of which 5402 pairs have been manually
annotated. We also train strong baseline XF2T generation models on the XAlign
dataset."
Qualia as physical measurements: a mathematical model of qualia and pure concepts,0.664089,"A space of qualia is defined to be a sober topological space whose points are
the qualia and whose open sets are the pure concepts in the sense of Lewis,
carrying additional algebraic structure that conveys the conscious experience
of subjective time and logical abstraction. This structure is analogous to that
of a space of physical measurements. It is conjectured that qualia and
measurements have the same nature, corresponding to fundamental processes via
which classical information is produced and physically stored, and that
therefore the hard problem of consciousness and the measurement problem are two
facets of the same problem. The space of qualia is independent from any
preexisting notions of spacetime and conscious agent, but its structure caters
for a derived geometric model of observer. Intersubjectivity is based on
relating different observers in a way that leads to a logical version of
quantum superposition."
Robust and Accurate -- Compositional Architectures for Randomized Smoothing,0.282253,"Randomized Smoothing (RS) is considered the state-of-the-art approach to
obtain certifiably robust models for challenging tasks. However, current RS
approaches drastically decrease standard accuracy on unperturbed data, severely
limiting their real-world utility. To address this limitation, we propose a
compositional architecture, ACES, which certifiably decides on a per-sample
basis whether to use a smoothed model yielding predictions with guarantees or a
more accurate standard model without guarantees. This, in contrast to prior
approaches, enables both high standard accuracies and significant provable
robustness. On challenging tasks such as ImageNet, we obtain, e.g., $80.0\%$
natural accuracy and $28.2\%$ certifiable accuracy against $\ell_2$
perturbations with $r=1.0$. We release our code and models at
https://github.com/eth-sri/aces."
Learning Language-Specific Layers for Multilingual Machine Translation,0.721236,"Multilingual Machine Translation promises to improve translation quality
between non-English languages. This is advantageous for several reasons, namely
lower latency (no need to translate twice), and reduced error cascades (e.g.,
avoiding losing gender and formality information when translating through
English). On the downside, adding more languages reduces model capacity per
language, which is usually countered by increasing the overall model size,
making training harder and inference slower. In this work, we introduce
Language-Specific Transformer Layers (LSLs), which allow us to increase model
capacity, while keeping the amount of computation and the number of parameters
used in the forward pass constant. The key idea is to have some layers of the
encoder be source or target language-specific, while keeping the remaining
layers shared. We study the best way to place these layers using a neural
architecture search inspired approach, and achieve an improvement of 1.3 chrF
(1.5 spBLEU) points over not using LSLs on a separate decoder architecture, and
1.9 chrF (2.2 spBLEU) on a shared decoder one."
Spiking Graph Convolutional Networks,0.831234,"Graph Convolutional Networks (GCNs) achieve an impressive performance due to
the remarkable representation ability in learning the graph information.
However, GCNs, when implemented on a deep network, require expensive
computation power, making them difficult to be deployed on battery-powered
devices. In contrast, Spiking Neural Networks (SNNs), which perform a
bio-fidelity inference process, offer an energy-efficient neural architecture.
In this work, we propose SpikingGCN, an end-to-end framework that aims to
integrate the embedding of GCNs with the biofidelity characteristics of SNNs.
The original graph data are encoded into spike trains based on the
incorporation of graph convolution. We further model biological information
processing by utilizing a fully connected layer combined with neuron nodes. In
a wide range of scenarios (e.g. citation networks, image graph classification,
and recommender systems), our experimental results show that the proposed
method could gain competitive performance against state-of-the-art approaches.
Furthermore, we show that SpikingGCN on a neuromorphic chip can bring a clear
advantage of energy efficiency into graph data analysis, which demonstrates its
great potential to construct environment-friendly machine learning models."
Efficient yet Competitive Speech Translation: FBK@IWSLT2022,0.688462,"The primary goal of this FBK's systems submission to the IWSLT 2022 offline
and simultaneous speech translation tasks is to reduce model training costs
without sacrificing translation quality. As such, we first question the need of
ASR pre-training, showing that it is not essential to achieve competitive
results. Second, we focus on data filtering, showing that a simple method that
looks at the ratio between source and target characters yields a quality
improvement of 1 BLEU. Third, we compare different methods to reduce the
detrimental effect of the audio segmentation mismatch between training data
manually segmented at sentence level and inference data that is automatically
segmented. Towards the same goal of training cost reduction, we participate in
the simultaneous task with the same model trained for offline ST. The
effectiveness of our lightweight training strategy is shown by the high score
obtained on the MuST-C en-de corpus (26.7 BLEU) and is confirmed in
high-resource data conditions by a 1.6 BLEU improvement on the IWSLT2020 test
set over last year's winning system."
Randomized Sharpness-Aware Training for Boosting Computational Efficiency in Deep Learning,0.0419788,"By driving models to converge to flat minima, sharpness-aware learning
algorithms (such as SAM) have shown the power to achieve state-of-the-art
performances. However, these algorithms will generally incur one extra
forward-backward propagation at each training iteration, which largely burdens
the computation especially for scalable models. To this end, we propose a
simple yet efficient training scheme, called Randomized Sharpness-Aware
Training (RST). Optimizers in RST would perform a Bernoulli trial at each
iteration to choose randomly from base algorithms (SGD) and sharpness-aware
algorithms (SAM) with a probability arranged by a predefined scheduling
function. Due to the mixture of base algorithms, the overall count of
propagation pairs could be largely reduced. Also, we give theoretical analysis
on the convergence of RST. Then, we empirically study the computation cost and
effect of various types of scheduling functions, and give directions on setting
appropriate scheduling functions. Further, we extend the RST to a general
framework (G-RST), where we can adjust regularization degree on sharpness
freely for any scheduling function. We show that G-RST can outperform SAM in
most cases while saving 50\% extra computation cost."
Variable Functioning and Its Application to Large Scale Steel Frame Design Optimization,0.117122,"To solve complex real-world problems, heuristics and concept-based approaches
can be used in order to incorporate information into the problem. In this
study, a concept-based approach called variable functioning Fx is introduced to
reduce the optimization variables and narrow down the search space. In this
method, the relationships among one or more subset of variables are defined
with functions using information prior to optimization; thus, instead of
modifying the variables in the search process, the function variables are
optimized. By using problem structure analysis technique and engineering expert
knowledge, the $Fx$ method is used to enhance the steel frame design
optimization process as a complex real-world problem. The proposed approach is
coupled with particle swarm optimization and differential evolution algorithms
and used for three case studies. The algorithms are applied to optimize the
case studies by considering the relationships among column cross-section areas.
The results show that $Fx$ can significantly improve both the convergence rate
and the final design of a frame structure, even if it is only used for seeding."
M3ST: Mix at Three Levels for Speech Translation,0.990431,"How to solve the data scarcity problem for end-to-end speech-to-text
translation (ST)? It's well known that data augmentation is an efficient method
to improve performance for many tasks by enlarging the dataset. In this paper,
we propose Mix at three levels for Speech Translation (M^3ST) method to
increase the diversity of the augmented training corpus. Specifically, we
conduct two phases of fine-tuning based on a pre-trained model using external
machine translation (MT) data. In the first stage of fine-tuning, we mix the
training corpus at three levels, including word level, sentence level and frame
level, and fine-tune the entire model with mixed data. At the second stage of
fine-tuning, we take both original speech sequences and original text sequences
in parallel into the model to fine-tune the network, and use Jensen-Shannon
divergence to regularize their outputs. Experiments on MuST-C speech
translation benchmark and analysis show that M^3ST outperforms current strong
baselines and achieves state-of-the-art results on eight directions with an
average BLEU of 29.9."
Incentives to Offer Algorithmic Recourse,0.159465,"Due to the importance of artificial intelligence (AI) in a variety of
high-stakes decisions, such as loan approval, job hiring, and criminal bail,
researchers in Explainable AI (XAI) have developed algorithms to provide users
with recourse for an unfavorable outcome. We analyze the incentives for a
decision-maker to offer recourse to a set of applicants. Does the
decision-maker have the incentive to offer recourse to all rejected applicants?
We show that the decision-maker only offers recourse to all applicants in
extreme cases, such as when the recourse process is impossible to manipulate.
Some applicants may be worse off when the decision-maker can offer recourse."
Explaining Classifications to Non Experts: An XAI User Study of Post Hoc Explanations for a Classifier When People Lack Expertise,0.220738,"Very few eXplainable AI (XAI) studies consider how users understanding of
explanations might change depending on whether they know more or less about the
to be explained domain (i.e., whether they differ in their expertise). Yet,
expertise is a critical facet of most high stakes, human decision making (e.g.,
understanding how a trainee doctor differs from an experienced consultant).
Accordingly, this paper reports a novel, user study (N=96) on how peoples
expertise in a domain affects their understanding of post-hoc explanations by
example for a deep-learning, black box classifier. The results show that
peoples understanding of explanations for correct and incorrect classifications
changes dramatically, on several dimensions (e.g., response times, perceptions
of correctness and helpfulness), when the image-based domain considered is
familiar (i.e., MNIST) as opposed to unfamiliar (i.e., Kannada MNIST). The
wider implications of these new findings for XAI strategies are discussed."
Speech-to-Speech Translation For A Real-world Unwritten Language,0.896665,"We study speech-to-speech translation (S2ST) that translates speech from one
language into another language and focuses on building systems to support
languages without standard text writing systems. We use English-Taiwanese
Hokkien as a case study, and present an end-to-end solution from training data
collection, modeling choices to benchmark dataset release. First, we present
efforts on creating human annotated data, automatically mining data from large
unlabeled speech datasets, and adopting pseudo-labeling to produce weakly
supervised data. On the modeling, we take advantage of recent advances in
applying self-supervised discrete representations as target for prediction in
S2ST and show the effectiveness of leveraging additional text supervision from
Mandarin, a language similar to Hokkien, in model training. Finally, we release
an S2ST benchmark set to facilitate future research in this field. The demo can
be found at https://huggingface.co/spaces/facebook/Hokkien_Translation ."
Codec at SemEval-2022 Task 5: Multi-Modal Multi-Transformer Misogynous Meme Classification Framework,0.0467836,"In this paper we describe our work towards building a generic framework for
both multi-modal embedding and multi-label binary classification tasks, while
participating in task 5 (Multimedia Automatic Misogyny Identification) of
SemEval 2022 competition.
  Since pretraining deep models from scratch is a resource and data hungry
task, our approach is based on three main strategies. We combine different
state-of-the-art architectures to capture a wide spectrum of semantic signals
from the multi-modal input. We employ a multi-task learning scheme to be able
to use multiple datasets from the same knowledge domain to help increase the
model's performance. We also use multiple objectives to regularize and fine
tune different system components."
Distill or Annotate? Cost-Efficient Fine-Tuning of Compact Models,0.688304,"Fine-tuning large models is highly effective, however, inference can be
expensive and produces carbon emissions. Knowledge distillation has been shown
to be a practical solution to reduce inference costs, but the distillation
process itself requires significant computational resources. Rather than buying
or renting GPUs to fine-tune, then distill a large model, an NLP practitioner
might instead choose to allocate the available budget to hire annotators and
manually label additional fine-tuning data. In this paper, we investigate how
to most efficiently use a fixed budget to build a compact model. Through
extensive experiments on six diverse tasks, we show that distilling from T5-XXL
(11B) to T5-Small (60M) is almost always a cost-efficient strategy compared to
annotating more data to directly train a compact model (T5-Small). We further
investigate how the optimal budget allocated towards computation varies across
scenarios. We will make our code, datasets, annotation cost estimates, and
baseline models available as a benchmark to support further work on
cost-efficient training of compact models."
Clustered Embedding Learning for Recommender Systems,0.304649,"In recent years, recommender systems have advanced rapidly, where embedding
learning for users and items plays a critical role. A standard method learns a
unique embedding vector for each user and item. However, such a method has two
important limitations in real-world applications: 1) it is hard to learn
embeddings that generalize well for users and items with rare interactions on
their own; and 2) it may incur unbearably high memory costs when the number of
users and items scales up. Existing approaches either can only address one of
the limitations or have flawed overall performances. In this paper, we propose
Clustered Embedding Learning (CEL) as an integrated solution to these two
problems. CEL is a plug-and-play embedding learning framework that can be
combined with any differentiable feature interaction model. It is capable of
achieving improved performance, especially for cold users and items, with
reduced memory cost. CEL enables automatic and dynamic clustering of users and
items in a top-down fashion, where clustered entities jointly learn a shared
embedding. The accelerated version of CEL has an optimal time complexity, which
supports efficient online updates. Theoretically, we prove the identifiability
and the existence of a unique optimal number of clusters for CEL in the context
of nonnegative matrix factorization. Empirically, we validate the effectiveness
of CEL on three public datasets and one business dataset, showing its
consistently superior performance against current state-of-the-art methods. In
particular, when incorporating CEL into the business model, it brings an
improvement of $+0.6\%$ in AUC, which translates into a significant revenue
gain; meanwhile, the size of the embedding table gets $2650$ times smaller."
Steps towards prompt-based creation of virtual worlds,0.58646,"Large language models trained for code generation can be applied to speaking
virtual worlds into existence (creating virtual worlds). In this work we show
that prompt-based methods can both accelerate in-VR level editing, as well as
can become part of gameplay rather than just part of game development. As an
example, we present Codex VR Pong which shows non-deterministic game mechanics
using generative processes to not only create static content but also
non-trivial interactions between 3D objects. This demonstration naturally leads
to an integral discussion on how one would evaluate and benchmark experiences
created by generative models - as there are no qualitative or quantitative
metrics that apply in these scenarios. We conclude by discussing impending
challenges of AI-assisted co-creation in VR."
Householder Projector for Unsupervised Latent Semantics Discovery,0.733369,"Generative Adversarial Networks (GANs), especially the recent style-based
generators (StyleGANs), have versatile semantics in the structured latent
space. Latent semantics discovery methods emerge to move around the latent code
such that only one factor varies during the traversal. Recently, an
unsupervised method proposed a promising direction to directly use the
eigenvectors of the projection matrix that maps latent codes to features as the
interpretable directions. However, one overlooked fact is that the projection
matrix is non-orthogonal and the number of eigenvectors is too large. The
non-orthogonality would entangle semantic attributes in the top few
eigenvectors, and the large dimensionality might result in meaningless
variations among the directions even if the matrix is orthogonal. To avoid
these issues, we propose Householder Projector, a flexible and general low-rank
orthogonal matrix representation based on Householder transformations, to
parameterize the projection matrix. The orthogonality guarantees that the
eigenvectors correspond to disentangled interpretable semantics, while the
low-rank property encourages that each identified direction has meaningful
variations. We integrate our projector into pre-trained StyleGAN2/StyleGAN3 and
evaluate the models on several benchmarks. Within only $1\%$ of the original
training steps for fine-tuning, our projector helps StyleGANs to discover more
disentangled and precise semantic attributes without sacrificing image
fidelity."
Learn From All: Erasing Attention Consistency for Noisy Label Facial Expression Recognition,0.999987,"Noisy label Facial Expression Recognition (FER) is more challenging than
traditional noisy label classification tasks due to the inter-class similarity
and the annotation ambiguity. Recent works mainly tackle this problem by
filtering out large-loss samples. In this paper, we explore dealing with noisy
labels from a new feature-learning perspective. We find that FER models
remember noisy samples by focusing on a part of the features that can be
considered related to the noisy labels instead of learning from the whole
features that lead to the latent truth. Inspired by that, we propose a novel
Erasing Attention Consistency (EAC) method to suppress the noisy samples during
the training process automatically. Specifically, we first utilize the flip
semantic consistency of facial images to design an imbalanced framework. We
then randomly erase input images and use flip attention consistency to prevent
the model from focusing on a part of the features. EAC significantly
outperforms state-of-the-art noisy label FER methods and generalizes well to
other tasks with a large number of classes like CIFAR100 and Tiny-ImageNet. The
code is available at
https://github.com/zyh-uaiaaaa/Erasing-Attention-Consistency."
Classifying COVID-19 vaccine narratives,0.172422,"Vaccine hesitancy is widespread, despite the government's information
campaigns and the efforts of the World Health Organisation (WHO). Categorising
the topics within vaccine-related narratives is crucial to understand the
concerns expressed in discussions and identify the specific issues that
contribute to vaccine hesitancy. This paper addresses the need for monitoring
and analysing vaccine narratives online by introducing a novel vaccine
narrative classification task, which categorises COVID-19 vaccine claims into
one of seven categories. Following a data augmentation approach, we first
construct a novel dataset for this new classification task, focusing on the
minority classes. We also make use of fact-checker annotated data. The paper
also presents a neural vaccine narrative classifier that achieves an accuracy
of 84% under cross-validation. The classifier is publicly available for
researchers and journalists."
Towards Multi-Modal Sarcasm Detection via Hierarchical Congruity Modeling with Knowledge Enhancement,0.884042,"Sarcasm is a linguistic phenomenon indicating a discrepancy between literal
meanings and implied intentions. Due to its sophisticated nature, it is usually
challenging to be detected from the text itself. As a result, multi-modal
sarcasm detection has received more attention in both academia and industries.
However, most existing techniques only modeled the atomic-level inconsistencies
between the text input and its accompanying image, ignoring more complex
compositions for both modalities. Moreover, they neglected the rich information
contained in external knowledge, e.g., image captions. In this paper, we
propose a novel hierarchical framework for sarcasm detection by exploring both
the atomic-level congruity based on multi-head cross attention mechanism and
the composition-level congruity based on graph neural networks, where a post
with low congruity can be identified as sarcasm. In addition, we exploit the
effect of various knowledge resources for sarcasm detection. Evaluation results
on a public multi-modal sarcasm detection dataset based on Twitter demonstrate
the superiority of our proposed model."
JSEEGraph: Joint Structured Event Extraction as Graph Parsing,0.659386,"We propose a graph-based event extraction framework JSEEGraph that approaches
the task of event extraction as general graph parsing in the tradition of
Meaning Representation Parsing. It explicitly encodes entities and events in a
single semantic graph, and further has the flexibility to encode a wider range
of additional IE relations and jointly infer individual tasks. JSEEGraph
performs in an end-to-end manner via general graph parsing: (1) instead of flat
sequence labelling, nested structures between entities/triggers are efficiently
encoded as separate nodes in the graph, allowing for nested and overlapping
entities and triggers; (2) both entities, relations, and events can be encoded
in the same graph, where entities and event triggers are represented as nodes
and entity relations and event arguments are constructed via edges; (3) joint
inference avoids error propagation and enhances the interpolation of different
IE tasks. We experiment on two benchmark datasets of varying structural
complexities; ACE05 and Rich ERE, covering three languages: English, Chinese,
and Spanish. Experimental results show that JSEEGraph can handle nested event
structures, that it is beneficial to solve different IE tasks jointly, and that
event argument extraction in particular benefits from entity extraction. Our
code and models are released as open-source."
Data Quality-aware Mixed-precision Quantization via Hybrid Reinforcement Learning,0.905327,"Mixed-precision quantization mostly predetermines the model bit-width
settings before actual training due to the non-differential bit-width sampling
process, obtaining sub-optimal performance. Worse still, the conventional
static quality-consistent training setting, i.e., all data is assumed to be of
the same quality across training and inference, overlooks data quality changes
in real-world applications which may lead to poor robustness of the quantized
models. In this paper, we propose a novel Data Quality-aware Mixed-precision
Quantization framework, dubbed DQMQ, to dynamically adapt quantization
bit-widths to different data qualities. The adaption is based on a bit-width
decision policy that can be learned jointly with the quantization training.
Concretely, DQMQ is modeled as a hybrid reinforcement learning (RL) task that
combines model-based policy optimization with supervised quantization training.
By relaxing the discrete bit-width sampling to a continuous probability
distribution that is encoded with few learnable parameters, DQMQ is
differentiable and can be directly optimized end-to-end with a hybrid
optimization target considering both task performance and quantization
benefits. Trained on mixed-quality image datasets, DQMQ can implicitly select
the most proper bit-width for each layer when facing uneven input qualities.
Extensive experiments on various benchmark datasets and networks demonstrate
the superiority of DQMQ against existing fixed/mixed-precision quantization
methods."
Neural combinatorial optimization beyond the TSP: Existing architectures under-represent graph structure,0.453021,"Recent years have witnessed the promise that reinforcement learning, coupled
with Graph Neural Network (GNN) architectures, could learn to solve hard
combinatorial optimization problems: given raw input data and an evaluator to
guide the process, the idea is to automatically learn a policy able to return
feasible and high-quality outputs. Recent work have shown promising results but
the latter were mainly evaluated on the travelling salesman problem (TSP) and
similar abstract variants such as Split Delivery Vehicle Routing Problem
(SDVRP). In this paper, we analyze how and whether recent neural architectures
can be applied to graph problems of practical importance. We thus set out to
systematically ""transfer"" these architectures to the Power and Channel
Allocation Problem (PCAP), which has practical relevance for, e.g., radio
resource allocation in wireless networks. Our experimental results suggest that
existing architectures (i) are still incapable of capturing graph structural
features and (ii) are not suitable for problems where the actions on the graph
change the graph attributes. On a positive note, we show that augmenting the
structural representation of problems with Distance Encoding is a promising
step towards the still-ambitious goal of learning multi-purpose autonomous
solvers."
How Does SimSiam Avoid Collapse Without Negative Samples? A Unified Understanding with Self-supervised Contrastive Learning,0.832809,"To avoid collapse in self-supervised learning (SSL), a contrastive loss is
widely used but often requires a large number of negative samples. Without
negative samples yet achieving competitive performance, a recent work has
attracted significant attention for providing a minimalist simple Siamese
(SimSiam) method to avoid collapse. However, the reason for how it avoids
collapse without negative samples remains not fully clear and our investigation
starts by revisiting the explanatory claims in the original SimSiam. After
refuting their claims, we introduce vector decomposition for analyzing the
collapse based on the gradient analysis of the $l_2$-normalized representation
vector. This yields a unified perspective on how negative samples and SimSiam
alleviate collapse. Such a unified perspective comes timely for understanding
the recent progress in SSL."
Improving the Domain Adaptation of Retrieval Augmented Generation (RAG) Models for Open Domain Question Answering,0.901094,"Retrieval Augment Generation (RAG) is a recent advancement in Open-Domain
Question Answering (ODQA). RAG has only been trained and explored with a
Wikipedia-based external knowledge base and is not optimized for use in other
specialized domains such as healthcare and news. In this paper, we evaluate the
impact of joint training of the retriever and generator components of RAG for
the task of domain adaptation in ODQA. We propose \textit{RAG-end2end}, an
extension to RAG, that can adapt to a domain-specific knowledge base by
updating all components of the external knowledge base during training. In
addition, we introduce an auxiliary training signal to inject more
domain-specific knowledge. This auxiliary signal forces \textit{RAG-end2end} to
reconstruct a given sentence by accessing the relevant information from the
external knowledge base. Our novel contribution is unlike RAG, RAG-end2end does
joint training of the retriever and generator for the end QA task and domain
adaptation. We evaluate our approach with datasets from three domains:
COVID-19, News, and Conversations, and achieve significant performance
improvements compared to the original RAG model. Our work has been open-sourced
through the Huggingface Transformers library, attesting to our work's
credibility and technical consistency."
Making Metadata More FAIR Using Large Language Models,0.280008,"With the global increase in experimental data artifacts, harnessing them in a
unified fashion leads to a major stumbling block - bad metadata. To bridge this
gap, this work presents a Natural Language Processing (NLP) informed
application, called FAIRMetaText, that compares metadata. Specifically,
FAIRMetaText analyzes the natural language descriptions of metadata and
provides a mathematical similarity measure between two terms. This measure can
then be utilized for analyzing varied metadata, by suggesting terms for
compliance or grouping similar terms for identification of replaceable terms.
The efficacy of the algorithm is presented qualitatively and quantitatively on
publicly available research artifacts and demonstrates large gains across
metadata related tasks through an in-depth study of a wide variety of Large
Language Models (LLMs). This software can drastically reduce the human effort
in sifting through various natural language metadata while employing several
experimental datasets on the same topic."
Improving Cascaded Unsupervised Speech Translation with Denoising Back-translation,0.662958,"Most of the speech translation models heavily rely on parallel data, which is
hard to collect especially for low-resource languages. To tackle this issue, we
propose to build a cascaded speech translation system without leveraging any
kind of paired data. We use fully unpaired data to train our unsupervised
systems and evaluate our results on CoVoST 2 and CVSS. The results show that
our work is comparable with some other early supervised methods in some
language pairs. While cascaded systems always suffer from severe error
propagation problems, we proposed denoising back-translation (DBT), a novel
approach to building robust unsupervised neural machine translation (UNMT). DBT
successfully increases the BLEU score by 0.7--0.9 in all three translation
directions. Moreover, we simplified the pipeline of our cascaded system to
reduce inference latency and conducted a comprehensive analysis of every part
of our work. We also demonstrate our unsupervised speech translation results on
the established website."
Segment Anything,1.0,"We introduce the Segment Anything (SA) project: a new task, model, and
dataset for image segmentation. Using our efficient model in a data collection
loop, we built the largest segmentation dataset to date (by far), with over 1
billion masks on 11M licensed and privacy respecting images. The model is
designed and trained to be promptable, so it can transfer zero-shot to new
image distributions and tasks. We evaluate its capabilities on numerous tasks
and find that its zero-shot performance is impressive -- often competitive with
or even superior to prior fully supervised results. We are releasing the
Segment Anything Model (SAM) and corresponding dataset (SA-1B) of 1B masks and
11M images at https://segment-anything.com to foster research into foundation
models for computer vision."
Art or Artifice? Large Language Models and the False Promise of Creativity,0.274,"Researchers have argued that large language models (LLMs) exhibit
high-quality writing capabilities from blogs to stories. However, evaluating
objectively the creativity of a piece of writing is challenging. Inspired by
the Torrance Test of Creative Thinking (TTCT), which measures creativity as a
process, we use the Consensual Assessment Technique [3] and propose the
Torrance Test of Creative Writing (TTCW) to evaluate creativity as a product.
TTCW consists of 14 binary tests organized into the original dimensions of
Fluency, Flexibility, Originality, and Elaboration. We recruit 10 creative
writers and implement a human assessment of 48 stories written either by
professional authors or LLMs using TTCW. Our analysis shows that LLM-generated
stories pass 3-10X less TTCW tests than stories written by professionals. In
addition, we explore the use of LLMs as assessors to automate the TTCW
evaluation, revealing that none of the LLMs positively correlate with the
expert assessments."
Everyone Deserves A Reward: Learning Customized Human Preferences,0.750768,"Reward models (RMs) are essential for aligning large language models (LLMs)
with human preferences to improve interaction quality. However, the real world
is pluralistic, which leads to diversified human preferences with respect to
different religions, politics, cultures, etc. Moreover, each individual can
have their unique preferences on various topics. Neglecting the diversity of
human preferences, current human feedback aligning methods only consider a
general reward model, which is below satisfaction for customized or
personalized application scenarios. To explore customized preference learning,
we collect a domain-specific preference (DSP) dataset, which includes preferred
responses for each given query from four practical domains. Besides, from the
perspective of data efficiency, we propose a three-stage customized RM learning
scheme, then empirically verify its effectiveness on both general preference
datasets and our DSP set. Furthermore, we test multiple training and data
strategies on the three learning stages. We find several ways to better
preserve the general preferring ability while training the customized RMs,
especially general preference enrichment, and customized preference imitation
learning. The DSP dataset and code are available at
https://github.com/Linear95/DSP."
DreamFusion: Text-to-3D using 2D Diffusion,1.0,"Recent breakthroughs in text-to-image synthesis have been driven by diffusion
models trained on billions of image-text pairs. Adapting this approach to 3D
synthesis would require large-scale datasets of labeled 3D data and efficient
architectures for denoising 3D data, neither of which currently exist. In this
work, we circumvent these limitations by using a pretrained 2D text-to-image
diffusion model to perform text-to-3D synthesis. We introduce a loss based on
probability density distillation that enables the use of a 2D diffusion model
as a prior for optimization of a parametric image generator. Using this loss in
a DeepDream-like procedure, we optimize a randomly-initialized 3D model (a
Neural Radiance Field, or NeRF) via gradient descent such that its 2D
renderings from random angles achieve a low loss. The resulting 3D model of the
given text can be viewed from any angle, relit by arbitrary illumination, or
composited into any 3D environment. Our approach requires no 3D training data
and no modifications to the image diffusion model, demonstrating the
effectiveness of pretrained image diffusion models as priors."
Camera-Conditioned Stable Feature Generation for Isolated Camera Supervised Person Re-IDentification,0.675348,"To learn camera-view invariant features for person Re-IDentification (Re-ID),
the cross-camera image pairs of each person play an important role. However,
such cross-view training samples could be unavailable under the ISolated Camera
Supervised (ISCS) setting, e.g., a surveillance system deployed across distant
scenes. To handle this challenging problem, a new pipeline is introduced by
synthesizing the cross-camera samples in the feature space for model training.
Specifically, the feature encoder and generator are end-to-end optimized under
a novel method, Camera-Conditioned Stable Feature Generation (CCSFG). Its joint
learning procedure raises concern on the stability of generative model
training. Therefore, a new feature generator, $\sigma$-Regularized Conditional
Variational Autoencoder ($\sigma$-Reg.~CVAE), is proposed with theoretical and
experimental analysis on its robustness. Extensive experiments on two ISCS
person Re-ID datasets demonstrate the superiority of our CCSFG to the
competitors."
"Deep Causal Learning: Representation, Discovery and Inference",0.333696,"Causal learning has attracted much attention in recent years because
causality reveals the essential relationship between things and indicates how
the world progresses. However, there are many problems and bottlenecks in
traditional causal learning methods, such as high-dimensional unstructured
variables, combinatorial optimization problems, unknown intervention,
unobserved confounders, selection bias and estimation bias. Deep causal
learning, that is, causal learning based on deep neural networks, brings new
insights for addressing these problems. While many deep learning-based causal
discovery and causal inference methods have been proposed, there is a lack of
reviews exploring the internal mechanism of deep learning to improve causal
learning. In this article, we comprehensively review how deep learning can
contribute to causal learning by addressing conventional challenges from three
aspects: representation, discovery, and inference. We point out that deep
causal learning is important for the theoretical extension and application
expansion of causal science and is also an indispensable part of general
artificial intelligence. We conclude the article with a summary of open issues
and potential directions for future work."
Finite-rate sparse quantum codes aplenty,0.159592,"We introduce a methodology for generating random multi-qubit stabilizer codes
based on solving a constraint satisfaction problem (CSP) on random bipartite
graphs. This framework allows us to enforce stabilizer commutation, $X/Z$
balancing, finite rate, sparsity, and maximum-degree constraints simultaneously
in a CSP that we can then solve numerically. Using a state-of-the-art CSP
solver, we obtain convincing evidence for the existence of a satisfiability
threshold. Furthermore, the extent of the satisfiable phase increases with the
number of qubits. In that phase, finding sparse codes becomes an easy problem.
Moreover, we observe that the sparse codes found in the satisfiable phase
practically achieve the channel capacity for erasure noise. Our results show
that intermediate-size finite-rate sparse quantum codes are easy to find, while
also demonstrating a flexible methodology for generating good codes with custom
properties. We therefore establish a complete and customizable pipeline for
random quantum code discovery."
Generalized Parametric Contrastive Learning,0.537093,"In this paper, we propose the Generalized Parametric Contrastive Learning
(GPaCo/PaCo) which works well on both imbalanced and balanced data. Based on
theoretical analysis, we observe that supervised contrastive loss tends to bias
high-frequency classes and thus increases the difficulty of imbalanced
learning. We introduce a set of parametric class-wise learnable centers to
rebalance from an optimization perspective. Further, we analyze our GPaCo/PaCo
loss under a balanced setting. Our analysis demonstrates that GPaCo/PaCo can
adaptively enhance the intensity of pushing samples of the same class close as
more samples are pulled together with their corresponding centers and benefit
hard example learning. Experiments on long-tailed benchmarks manifest the new
state-of-the-art for long-tailed recognition. On full ImageNet, models from
CNNs to vision transformers trained with GPaCo loss show better generalization
performance and stronger robustness compared with MAE models. Moreover, GPaCo
can be applied to the semantic segmentation task and obvious improvements are
observed on the 4 most popular benchmarks. Our code is available at
https://github.com/dvlab-research/Parametric-Contrastive-Learning."
Overview of the Shared Task on Fake News Detection in Urdu at FIRE 2020,0.818603,"This overview paper describes the first shared task on fake news detection in
Urdu language. The task was posed as a binary classification task, in which the
goal is to differentiate between real and fake news. We provided a dataset
divided into 900 annotated news articles for training and 400 news articles for
testing. The dataset contained news in five domains: (i) Health, (ii) Sports,
(iii) Showbiz, (iv) Technology, and (v) Business. 42 teams from 6 different
countries (India, China, Egypt, Germany, Pakistan, and the UK) registered for
the task. 9 teams submitted their experimental results. The participants used
various machine learning methods ranging from feature-based traditional machine
learning to neural networks techniques. The best performing system achieved an
F-score value of 0.90, showing that the BERT-based approach outperforms other
machine learning techniques"
Retrieval augmentation of large language models for lay language generation,0.155465,"Recent lay language generation systems have used Transformer models trained
on a parallel corpus to increase health information accessibility. However, the
applicability of these models is constrained by the limited size and topical
breadth of available corpora. We introduce CELLS, the largest (63k pairs) and
broadest-ranging (12 journals) parallel corpus for lay language generation. The
abstract and the corresponding lay language summary are written by domain
experts, assuring the quality of our dataset. Furthermore, qualitative
evaluation of expert-authored plain language summaries has revealed background
explanation as a key strategy to increase accessibility. Such explanation is
challenging for neural models to generate because it goes beyond simplification
by adding content absent from the source. We derive two specialized paired
corpora from CELLS to address key challenges in lay language generation:
generating background explanations and simplifying the original abstract. We
adopt retrieval-augmented models as an intuitive fit for the task of background
explanation generation, and show improvements in summary quality and simplicity
while maintaining factual correctness. Taken together, this work presents the
first comprehensive study of background explanation for lay language
generation, paving the path for disseminating scientific knowledge to a broader
audience. CELLS is publicly available at:
https://github.com/LinguisticAnomalies/pls_retrieval."
Learning Visuo-Haptic Skewering Strategies for Robot-Assisted Feeding,0.996701,"Acquiring food items with a fork poses an immense challenge to a
robot-assisted feeding system, due to the wide range of material properties and
visual appearances present across food groups. Deformable foods necessitate
different skewering strategies than firm ones, but inferring such
characteristics for several previously unseen items on a plate remains
nontrivial. Our key insight is to leverage visual and haptic observations
during interaction with an item to rapidly and reactively plan skewering
motions. We learn a generalizable, multimodal representation for a food item
from raw sensory inputs which informs the optimal skewering strategy. Given
this representation, we propose a zero-shot framework to sense visuo-haptic
properties of a previously unseen item and reactively skewer it, all within a
single interaction. Real-robot experiments with foods of varying levels of
visual and textural diversity demonstrate that our multimodal policy
outperforms baselines which do not exploit both visual and haptic cues or do
not reactively plan. Across 6 plates of different food items, our proposed
framework achieves 71% success over 69 skewering attempts total. Supplementary
material, datasets, code, and videos are available on our website:
https://sites.google.com/view/hapticvisualnet-corl22/home"
KSG: Knowledge and Skill Graph,0.972676,"The knowledge graph (KG) is an essential form of knowledge representation
that has grown in prominence in recent years. Because it concentrates on
nominal entities and their relationships, traditional knowledge graphs are
static and encyclopedic in nature. On this basis, event knowledge graph (Event
KG) models the temporal and spatial dynamics by text processing to facilitate
downstream applications, such as question-answering, recommendation and
intelligent search. Existing KG research, on the other hand, mostly focuses on
text processing and static facts, ignoring the vast quantity of dynamic
behavioral information included in photos, movies, and pre-trained neural
networks. In addition, no effort has been done to include behavioral
intelligence information into the knowledge graph for deep reinforcement
learning (DRL) and robot learning. In this paper, we propose a novel dynamic
knowledge and skill graph (KSG), and then we develop a basic and specific KSG
based on CN-DBpedia. The nodes are divided into entity and attribute nodes,
with entity nodes containing the agent, environment, and skill (DRL policy or
policy representation), and attribute nodes containing the entity description,
pre-train network, and offline dataset. KSG can search for different agents'
skills in various environments and provide transferable information for
acquiring new skills. This is the first study that we are aware of that looks
into dynamic KSG for skill retrieval and learning. Extensive experimental
results on new skill learning show that KSG boosts new skill learning
efficiency."
Attentive Graph Enhanced Region Representation Learning,0.523219,"Representing urban regions accurately and comprehensively is essential for
various urban planning and analysis tasks. Recently, with the expansion of the
city, modeling long-range spatial dependencies with multiple data sources plays
an important role in urban region representation. In this paper, we propose the
Attentive Graph Enhanced Region Representation Learning (ATGRL) model, which
aims to capture comprehensive dependencies from multiple graphs and learn rich
semantic representations of urban regions. Specifically, we propose a
graph-enhanced learning module to construct regional graphs by incorporating
mobility flow patterns, point of interests (POIs) functions, and check-in
semantics with noise filtering. Then, we present a multi-graph aggregation
module to capture both local and global spatial dependencies between regions by
integrating information from multiple graphs. In addition, we design a
dual-stage fusion module to facilitate information sharing between different
views and efficiently fuse multi-view representations for urban region
embedding using an improved linear attention mechanism. Finally, extensive
experiments on real-world datasets for three downstream tasks demonstrate the
superior performance of our model compared to state-of-the-art methods."
Towards Fair Patient-Trial Matching via Patient-Criterion Level Fairness Constraint,0.627672,"Clinical trials are indispensable in developing new treatments, but they face
obstacles in patient recruitment and retention, hindering the enrollment of
necessary participants. To tackle these challenges, deep learning frameworks
have been created to match patients to trials. These frameworks calculate the
similarity between patients and clinical trial eligibility criteria,
considering the discrepancy between inclusion and exclusion criteria. Recent
studies have shown that these frameworks outperform earlier approaches.
However, deep learning models may raise fairness issues in patient-trial
matching when certain sensitive groups of individuals are underrepresented in
clinical trials, leading to incomplete or inaccurate data and potential harm.
To tackle the issue of fairness, this work proposes a fair patient-trial
matching framework by generating a patient-criterion level fairness constraint.
The proposed framework considers the inconsistency between the embedding of
inclusion and exclusion criteria among patients of different sensitive groups.
The experimental results on real-world patient-trial and patient-criterion
matching tasks demonstrate that the proposed framework can successfully
alleviate the predictions that tend to be biased."
Orca 2: Teaching Small Language Models How to Reason,0.846302,"Orca 1 learns from rich signals, such as explanation traces, allowing it to
outperform conventional instruction-tuned models on benchmarks like BigBench
Hard and AGIEval. In Orca 2, we continue exploring how improved training
signals can enhance smaller LMs' reasoning abilities. Research on training
small LMs has often relied on imitation learning to replicate the output of
more capable models. We contend that excessive emphasis on imitation may
restrict the potential of smaller models. We seek to teach small LMs to employ
different solution strategies for different tasks, potentially different from
the one used by the larger model. For example, while larger models might
provide a direct answer to a complex task, smaller models may not have the same
capacity. In Orca 2, we teach the model various reasoning techniques
(step-by-step, recall then generate, recall-reason-generate, direct answer,
etc.). More crucially, we aim to help the model learn to determine the most
effective solution strategy for each task. We evaluate Orca 2 using a
comprehensive set of 15 diverse benchmarks (corresponding to approximately 100
tasks and over 36,000 unique prompts). Orca 2 significantly surpasses models of
similar size and attains performance levels similar or better to those of
models 5-10x larger, as assessed on complex tasks that test advanced reasoning
abilities in zero-shot settings. make Orca 2 weights publicly available at
aka.ms/orca-lm to support research on the development, evaluation, and
alignment of smaller LMs"
Streamable Neural Fields,0.367445,"Neural fields have emerged as a new data representation paradigm and have
shown remarkable success in various signal representations. Since they preserve
signals in their network parameters, the data transfer by sending and receiving
the entire model parameters prevents this emerging technology from being used
in many practical scenarios. We propose streamable neural fields, a single
model that consists of executable sub-networks of various widths. The proposed
architectural and training techniques enable a single network to be streamable
over time and reconstruct different qualities and parts of signals. For
example, a smaller sub-network produces smooth and low-frequency signals, while
a larger sub-network can represent fine details. Experimental results have
shown the effectiveness of our method in various domains, such as 2D images,
videos, and 3D signed distance functions. Finally, we demonstrate that our
proposed method improves training stability, by exploiting parameter sharing."
MS-PS: A Multi-Scale Network for Photometric Stereo With a New Comprehensive Training Dataset,0.262171,"The photometric stereo (PS) problem consists in reconstructing the 3D-surface
of an object, thanks to a set of photographs taken under different lighting
directions. In this paper, we propose a multi-scale architecture for PS which,
combined with a new dataset, yields state-of-the-art results. Our proposed
architecture is flexible: it permits to consider a variable number of images as
well as variable image size without loss of performance. In addition, we define
a set of constraints to allow the generation of a relevant synthetic dataset to
train convolutional neural networks for the PS problem. Our proposed dataset is
much larger than pre-existing ones, and contains many objects with challenging
materials having anisotropic reflectance (e.g. metals, glass). We show on
publicly available benchmarks that the combination of both these contributions
drastically improves the accuracy of the estimated normal field, in comparison
with previous state-of-the-art methods."
Generative AI in the Construction Industry: Opportunities & Challenges,0.996744,"In the last decade, despite rapid advancements in artificial intelligence
(AI) transforming many industry practices, construction largely lags in
adoption. Recently, the emergence and rapid adoption of advanced large language
models (LLM) like OpenAI's GPT, Google's PaLM, and Meta's Llama have shown
great potential and sparked considerable global interest. However, the current
surge lacks a study investigating the opportunities and challenges of
implementing Generative AI (GenAI) in the construction sector, creating a
critical knowledge gap for researchers and practitioners. This underlines the
necessity to explore the prospects and complexities of GenAI integration.
Bridging this gap is fundamental to optimizing GenAI's early-stage adoption
within the construction sector. Given GenAI's unprecedented capabilities to
generate human-like content based on learning from existing content, we reflect
on two guiding questions: What will the future bring for GenAI in the
construction industry? What are the potential opportunities and challenges in
implementing GenAI in the construction industry? This study delves into
reflected perception in literature, analyzes the industry perception using
programming-based word cloud and frequency analysis, and integrates authors'
opinions to answer these questions. This paper recommends a conceptual GenAI
implementation framework, provides practical recommendations, summarizes future
research questions, and builds foundational literature to foster subsequent
research expansion in GenAI within the construction and its allied architecture
& engineering domains."
Scaling Back-Translation with Domain Text Generation for Sign Language Gloss Translation,0.832176,"Sign language gloss translation aims to translate the sign glosses into
spoken language texts, which is challenging due to the scarcity of labeled
gloss-text parallel data. Back translation (BT), which generates
pseudo-parallel data by translating in-domain spoken language texts into sign
glosses, has been applied to alleviate the data scarcity problem. However, the
lack of large-scale high-quality domain spoken language text data limits the
effect of BT. In this paper, to overcome the limitation, we propose a Prompt
based domain text Generation (PGEN) approach to produce the large-scale
in-domain spoken language text data. Specifically, PGEN randomly concatenates
sentences from the original in-domain spoken language text data as prompts to
induce a pre-trained language model (i.e., GPT-2) to generate spoken language
texts in a similar style. Experimental results on three benchmarks of sign
language gloss translation in varied languages demonstrate that BT with spoken
language texts generated by PGEN significantly outperforms the compared
methods. In addition, as the scale of spoken language texts generated by PGEN
increases, the BT technique can achieve further improvements, demonstrating the
effectiveness of our approach. We release the code and data for facilitating
future research in this field."
NLNDE at SemEval-2023 Task 12: Adaptive Pretraining and Source Language Selection for Low-Resource Multilingual Sentiment Analysis,0.605777,"This paper describes our system developed for the SemEval-2023 Task 12
""Sentiment Analysis for Low-resource African Languages using Twitter Dataset"".
Sentiment analysis is one of the most widely studied applications in natural
language processing. However, most prior work still focuses on a small number
of high-resource languages. Building reliable sentiment analysis systems for
low-resource languages remains challenging, due to the limited training data in
this task. In this work, we propose to leverage language-adaptive and
task-adaptive pretraining on African texts and study transfer learning with
source language selection on top of an African language-centric pretrained
language model. Our key findings are: (1) Adapting the pretrained model to the
target language and task using a small yet relevant corpus improves performance
remarkably by more than 10 F1 score points. (2) Selecting source languages with
positive transfer gains during training can avoid harmful interference from
dissimilar languages, leading to better results in multilingual and
cross-lingual settings. In the shared task, our system wins 8 out of 15 tracks
and, in particular, performs best in the multilingual evaluation."
Foundations for Grassroots Democratic Metaverse,0.430934,"While the physical lives of many of us are in democracies (one person, one
vote - e.g., the EU and the US), our digital lives are mostly in autocracies
(one person, all votes - e.g., Facebook). Cryptocurrencies promise liberation
but stop short, at plutocracy (one coin, one vote). What would it take for us
to live our digital lives in a digital democracy? This paper offers a vision, a
theoretical framework, and an architecture for a grassroots network of
autonomous, people-owned, people-operated, and people-governed digital
communities, namely a grassroots democratic metaverse. It also charts a roadmap
towards realizing it, and identifies unexplored territory for further research."
Efficient Federated Learning on Knowledge Graphs via Privacy-preserving Relation Embedding Aggregation,0.641134,"Federated learning (FL) can be essential in knowledge representation,
reasoning, and data mining applications over multi-source knowledge graphs
(KGs). A recent study FedE first proposes an FL framework that shares entity
embeddings of KGs across all clients. However, entity embedding sharing from
FedE would incur a severe privacy leakage. Specifically, the known entity
embedding can be used to infer whether a specific relation between two entities
exists in a private client. In this paper, we introduce a novel attack method
that aims to recover the original data based on the embedding information,
which is further used to evaluate the vulnerabilities of FedE. Furthermore, we
propose a Federated learning paradigm with privacy-preserving Relation
embedding aggregation (FedR) to tackle the privacy issue in FedE. Besides,
relation embedding sharing can significantly reduce the communication cost due
to its smaller size of queries. We conduct extensive experiments to evaluate
FedR with five different KG embedding models and three datasets. Compared to
FedE, FedR achieves similar utility and significant improvements regarding
privacy-preserving effect and communication efficiency on the link prediction
task."
Test-Time Prompt Tuning for Zero-Shot Generalization in Vision-Language Models,0.907968,"Pre-trained vision-language models (e.g., CLIP) have shown promising
zero-shot generalization in many downstream tasks with properly designed text
prompts. Instead of relying on hand-engineered prompts, recent works learn
prompts using the training data from downstream tasks. While effective,
training on domain-specific data reduces a model's generalization capability to
unseen new domains. In this work, we propose test-time prompt tuning (TPT), a
method that can learn adaptive prompts on the fly with a single test sample.
For image classification, TPT optimizes the prompt by minimizing the entropy
with confidence selection so that the model has consistent predictions across
different augmented views of each test sample. In evaluating generalization to
natural distribution shifts, TPT improves the zero-shot top-1 accuracy of CLIP
by 3.6% on average, surpassing previous prompt tuning approaches that require
additional task-specific training data. In evaluating cross-dataset
generalization with unseen categories, TPT performs on par with the
state-of-the-art approaches that use additional training data. Project page:
https://azshue.github.io/TPT."
CTM -- A Model for Large-Scale Multi-View Tweet Topic Classification,0.368056,"Automatically associating social media posts with topics is an important
prerequisite for effective search and recommendation on many social media
platforms. However, topic classification of such posts is quite challenging
because of (a) a large topic space (b) short text with weak topical cues, and
(c) multiple topic associations per post. In contrast to most prior work which
only focuses on post classification into a small number of topics ($10$-$20$),
we consider the task of large-scale topic classification in the context of
Twitter where the topic space is $10$ times larger with potentially multiple
topic associations per Tweet. We address the challenges above by proposing a
novel neural model, CTM that (a) supports a large topic space of $300$ topics
and (b) takes a holistic approach to tweet content modeling -- leveraging
multi-modal content, author context, and deeper semantic cues in the Tweet. Our
method offers an effective way to classify Tweets into topics at scale by
yielding superior performance to other approaches (a relative lift of
$\mathbf{20}\%$ in median average precision score) and has been successfully
deployed in production at Twitter."
Improved Input Reprogramming for GAN Conditioning,0.0863242,"We study the GAN conditioning problem, whose goal is to convert a pretrained
unconditional GAN into a conditional GAN using labeled data. We first identify
and analyze three approaches to this problem -- conditional GAN training from
scratch, fine-tuning, and input reprogramming. Our analysis reveals that when
the amount of labeled data is small, input reprogramming performs the best.
Motivated by real-world scenarios with scarce labeled data, we focus on the
input reprogramming approach and carefully analyze the existing algorithm.
After identifying a few critical issues of the previous input reprogramming
approach, we propose a new algorithm called InRep+. Our algorithm InRep+
addresses the existing issues with the novel uses of invertible neural networks
and Positive-Unlabeled (PU) learning. Via extensive experiments, we show that
InRep+ outperforms all existing methods, particularly when label information is
scarce, noisy, and/or imbalanced. For instance, for the task of conditioning a
CIFAR10 GAN with 1% labeled data, InRep+ achieves an average Intra-FID of
76.24, whereas the second-best method achieves 114.51."
Interactive Grounded Language Understanding in a Collaborative Environment: IGLU 2021,0.794019,"Human intelligence has the remarkable ability to quickly adapt to new tasks
and environments. Starting from a very young age, humans acquire new skills and
learn how to solve new tasks either by imitating the behavior of others or by
following provided natural language instructions. To facilitate research in
this direction, we propose \emph{IGLU: Interactive Grounded Language
Understanding in a Collaborative Environment}.
  The primary goal of the competition is to approach the problem of how to
build interactive agents that learn to solve a task while provided with
grounded natural language instructions in a collaborative environment.
Understanding the complexity of the challenge, we split it into sub-tasks to
make it feasible for participants."
Causal Inference in Gene Regulatory Networks with GFlowNet: Towards Scalability in Large Systems,0.37019,"Understanding causal relationships within Gene Regulatory Networks (GRNs) is
essential for unraveling the gene interactions in cellular processes. However,
causal discovery in GRNs is a challenging problem for multiple reasons
including the existence of cyclic feedback loops and uncertainty that yields
diverse possible causal structures. Previous works in this area either ignore
cyclic dynamics (assume acyclic structure) or struggle with scalability. We
introduce Swift-DynGFN as a novel framework that enhances causal structure
learning in GRNs while addressing scalability concerns. Specifically,
Swift-DynGFN exploits gene-wise independence to boost parallelization and to
lower computational cost. Experiments on real single-cell RNA velocity and
synthetic GRN datasets showcase the advancement in learning causal structure in
GRNs and scalability in larger systems."
Federated Unsupervised Domain Adaptation for Face Recognition,0.551639,"Given labeled data in a source domain, unsupervised domain adaptation has
been widely adopted to generalize models for unlabeled data in a target domain,
whose data distributions are different. However, existing works are
inapplicable to face recognition under privacy constraints because they require
sharing of sensitive face images between domains. To address this problem, we
propose federated unsupervised domain adaptation for face recognition, FedFR.
FedFR jointly optimizes clustering-based domain adaptation and federated
learning to elevate performance on the target domain. Specifically, for
unlabeled data in the target domain, we enhance a clustering algorithm with
distance constrain to improve the quality of predicted pseudo labels. Besides,
we propose a new domain constraint loss (DCL) to regularize source domain
training in federated learning. Extensive experiments on a newly constructed
benchmark demonstrate that FedFR outperforms the baseline and classic methods
on the target domain by 3% to 14% on different evaluation metrics."
ECSAS: Exploring Critical Scenarios from Action Sequence in Autonomous Driving,0.260275,"Critical scenario generation requires the ability of sampling critical
combinations from the infinite parameter space in the logic scenario. Existing
solutions aim to explore the correlation of action parameters in the initial
scenario rather than action sequences. How to model action sequences so that
one can further consider the effects of different action parameters in the
scenario is the bottleneck of the problem. In this paper, we attack the problem
by proposing the ECSAS framework. Specifically, we first propose a description
language, BTScenario, allowing us to model action sequences of the scenarios.
We then use reinforcement learning to search for combinations of critical
action parameters. To increase efficiency, we further propose several
optimizations, including action masking and replay buffer. We have implemented
ECSAS, and experimental results show that it is more efficient than native
approaches such as random and combination testing in various nontrivial
scenarios."
AdaSfM: From Coarse Global to Fine Incremental Adaptive Structure from Motion,0.634853,"Despite the impressive results achieved by many existing Structure from
Motion (SfM) approaches, there is still a need to improve the robustness,
accuracy, and efficiency on large-scale scenes with many outlier matches and
sparse view graphs. In this paper, we propose AdaSfM: a coarse-to-fine adaptive
SfM approach that is scalable to large-scale and challenging datasets. Our
approach first does a coarse global SfM which improves the reliability of the
view graph by leveraging measurements from low-cost sensors such as Inertial
Measurement Units (IMUs) and wheel encoders. Subsequently, the view graph is
divided into sub-scenes that are refined in parallel by a fine local
incremental SfM regularised by the result from the coarse global SfM to improve
the camera registration accuracy and alleviate scene drifts. Finally, our
approach uses a threshold-adaptive strategy to align all local reconstructions
to the coordinate frame of global SfM. Extensive experiments on large-scale
benchmark datasets show that our approach achieves state-of-the-art accuracy
and efficiency."
TeST: Test-time Self-Training under Distribution Shift,0.641119,"Despite their recent success, deep neural networks continue to perform poorly
when they encounter distribution shifts at test time. Many recently proposed
approaches try to counter this by aligning the model to the new distribution
prior to inference. With no labels available this requires unsupervised
objectives to adapt the model on the observed test data. In this paper, we
propose Test-Time Self-Training (TeST): a technique that takes as input a model
trained on some source data and a novel data distribution at test time, and
learns invariant and robust representations using a student-teacher framework.
We find that models adapted using TeST significantly improve over baseline
test-time adaptation algorithms. TeST achieves competitive performance to
modern domain adaptation algorithms, while having access to 5-10x less data at
time of adaption. We thoroughly evaluate a variety of baselines on two tasks:
object detection and image segmentation and find that models adapted with TeST.
We find that TeST sets the new state-of-the art for test-time domain adaptation
algorithms."
Contrastive Positive Mining for Unsupervised 3D Action Representation Learning,0.793449,"Recent contrastive based 3D action representation learning has made great
progress. However, the strict positive/negative constraint is yet to be relaxed
and the use of non-self positive is yet to be explored. In this paper, a
Contrastive Positive Mining (CPM) framework is proposed for unsupervised
skeleton 3D action representation learning. The CPM identifies non-self
positives in a contextual queue to boost learning. Specifically, the siamese
encoders are adopted and trained to match the similarity distributions of the
augmented instances in reference to all instances in the contextual queue. By
identifying the non-self positive instances in the queue, a positive-enhanced
learning strategy is proposed to leverage the knowledge of mined positives to
boost the robustness of the learned latent space against intra-class and
inter-class diversity. Experimental results have shown that the proposed CPM is
effective and outperforms the existing state-of-the-art unsupervised methods on
the challenging NTU and PKU-MMD datasets."
e-CARE: a New Dataset for Exploring Explainable Causal Reasoning,0.55242,"Understanding causality has vital importance for various Natural Language
Processing (NLP) applications. Beyond the labeled instances, conceptual
explanations of the causality can provide deep understanding of the causal
facts to facilitate the causal reasoning process. However, such explanation
information still remains absent in existing causal reasoning resources. In
this paper, we fill this gap by presenting a human-annotated explainable CAusal
REasoning dataset (e-CARE), which contains over 21K causal reasoning questions,
together with natural language formed explanations of the causal questions.
Experimental results show that generating valid explanations for causal facts
still remains especially challenging for the state-of-the-art models, and the
explanation information can be helpful for promoting the accuracy and stability
of causal reasoning models."
Transfusor: Transformer Diffusor for Controllable Human-like Generation of Vehicle Lane Changing Trajectories,0.130249,"With ongoing development of autonomous driving systems and increasing desire
for deployment, researchers continue to seek reliable approaches for ADS
systems. The virtual simulation test (VST) has become a prominent approach for
testing autonomous driving systems (ADS) and advanced driver assistance systems
(ADAS) due to its advantages of fast execution, low cost, and high
repeatability. However, the success of these simulation-based experiments
heavily relies on the realism of the testing scenarios. It is needed to create
more flexible and high-fidelity testing scenarios in VST in order to increase
the safety and reliabilityof ADS and ADAS.To address this challenge, this paper
introduces the ""Transfusor"" model, which leverages the transformer and diffusor
models (two cutting-edge deep learning generative technologies). The primary
objective of the Transfusor model is to generate highly realistic and
controllable human-like lane-changing trajectories in highway scenarios.
Extensive experiments were carried out, and the results demonstrate that the
proposed model effectively learns the spatiotemporal characteristics of humans'
lane-changing behaviors and successfully generates trajectories that closely
mimic real-world human driving. As such, the proposed model can play a critical
role of creating more flexible and high-fidelity testing scenarios in the VST,
ultimately leading to safer and more reliable ADS and ADAS."
Prospect Theory-inspired Automated P2P Energy Trading with Q-learning-based Dynamic Pricing,0.424893,"The widespread adoption of distributed energy resources, and the advent of
smart grid technologies, have allowed traditionally passive power system users
to become actively involved in energy trading. Recognizing the fact that the
traditional centralized grid-driven energy markets offer minimal profitability
to these users, recent research has shifted focus towards decentralized
peer-to-peer (P2P) energy markets. In these markets, users trade energy with
each other, with higher benefits than buying or selling to the grid. However,
most researches in P2P energy trading largely overlook the user perception in
the trading process, assuming constant availability, participation, and full
compliance. As a result, these approaches may result in negative attitudes and
reduced engagement over time. In this paper, we design an automated P2P energy
market that takes user perception into account. We employ prospect theory to
model the user perception and formulate an optimization framework to maximize
the buyer's perception while matching demand and production. Given the
non-linear and non-convex nature of the optimization problem, we propose
Differential Evolution-based Algorithm for Trading Energy called DEbATE.
Additionally, we introduce a risk-sensitive Q-learning algorithm, named Pricing
mechanism with Q-learning and Risk-sensitivity (PQR), which learns the optimal
price for sellers considering their perceived utility. Results based on real
traces of energy consumption and production, as well as realistic prospect
theory functions, show that our approach achieves a 26% higher perceived value
for buyers and generates 7% more reward for sellers, compared to a recent state
of the art approach."
Towards Automatic Construction of Filipino WordNet: Word Sense Induction and Synset Induction Using Sentence Embeddings,0.203829,"Wordnets are indispensable tools for various natural language processing
applications. Unfortunately, wordnets get outdated, and producing or updating
wordnets can be slow and costly in terms of time and resources. This problem
intensifies for low-resource languages. This study proposes a method for word
sense induction and synset induction using only two linguistic resources,
namely, an unlabeled corpus and a sentence embeddings-based language model. The
resulting sense inventory and synonym sets can be used in automatically
creating a wordnet. We applied this method on a corpus of Filipino text. The
sense inventory and synsets were evaluated by matching them with the sense
inventory of the machine translated Princeton WordNet, as well as comparing the
synsets to the Filipino WordNet. This study empirically shows that the 30% of
the induced word senses are valid and 40% of the induced synsets are valid in
which 20% are novel synsets."
MASER: Multi-Agent Reinforcement Learning with Subgoals Generated from Experience Replay Buffer,0.860334,"In this paper, we consider cooperative multi-agent reinforcement learning
(MARL) with sparse reward. To tackle this problem, we propose a novel method
named MASER: MARL with subgoals generated from experience replay buffer. Under
the widely-used assumption of centralized training with decentralized execution
and consistent Q-value decomposition for MARL, MASER automatically generates
proper subgoals for multiple agents from the experience replay buffer by
considering both individual Q-value and total Q-value. Then, MASER designs
individual intrinsic reward for each agent based on actionable representation
relevant to Q-learning so that the agents reach their subgoals while maximizing
the joint action value. Numerical results show that MASER significantly
outperforms StarCraft II micromanagement benchmark compared to other
state-of-the-art MARL algorithms."
ODSmoothGrad: Generating Saliency Maps for Object Detectors,0.0394472,"Techniques for generating saliency maps continue to be used for
explainability of deep learning models, with efforts primarily applied to the
image classification task. Such techniques, however, can also be applied to
object detectors, not only with the classification scores, but also for the
bounding box parameters, which are regressed values for which the relevant
pixels contributing to these parameters can be identified. In this paper, we
present ODSmoothGrad, a tool for generating saliency maps for the
classification and the bounding box parameters in object detectors. Given the
noisiness of saliency maps, we also apply the SmoothGrad algorithm to visually
enhance the pixels of interest. We demonstrate these capabilities on one-stage
and two-stage object detectors, with comparisons using classifier-based
techniques."
ICICLE: Interpretable Class Incremental Continual Learning,0.676481,"Continual learning enables incremental learning of new tasks without
forgetting those previously learned, resulting in positive knowledge transfer
that can enhance performance on both new and old tasks. However, continual
learning poses new challenges for interpretability, as the rationale behind
model predictions may change over time, leading to interpretability concept
drift. We address this problem by proposing Interpretable Class-InCremental
LEarning (ICICLE), an exemplar-free approach that adopts a prototypical
part-based approach. It consists of three crucial novelties: interpretability
regularization that distills previously learned concepts while preserving
user-friendly positive reasoning; proximity-based prototype initialization
strategy dedicated to the fine-grained setting; and task-recency bias
compensation devoted to prototypical parts. Our experimental results
demonstrate that ICICLE reduces the interpretability concept drift and
outperforms the existing exemplar-free methods of common class-incremental
learning when applied to concept-based models."
Video Swin Transformers for Egocentric Video Understanding @ Ego4D Challenges 2022,0.277187,"We implemented Video Swin Transformer as a base architecture for the tasks of
Point-of-No-Return temporal localization and Object State Change
Classification. Our method achieved competitive performance on both challenges."
Solving ImageNet: a Unified Scheme for Training any Backbone to Top Results,0.305368,"ImageNet serves as the primary dataset for evaluating the quality of
computer-vision models. The common practice today is training each architecture
with a tailor-made scheme, designed and tuned by an expert. In this paper, we
present a unified scheme for training any backbone on ImageNet. The scheme,
named USI (Unified Scheme for ImageNet), is based on knowledge distillation and
modern tricks. It requires no adjustments or hyper-parameters tuning between
different models, and is efficient in terms of training times. We test USI on a
wide variety of architectures, including CNNs, Transformers, Mobile-oriented
and MLP-only. On all models tested, USI outperforms previous state-of-the-art
results. Hence, we are able to transform training on ImageNet from an
expert-oriented task to an automatic seamless routine. Since USI accepts any
backbone and trains it to top results, it also enables to perform methodical
comparisons, and identify the most efficient backbones along the speed-accuracy
Pareto curve. Implementation is available
at:https://github.com/Alibaba-MIIL/Solving_ImageNet"
Increasing Adverse Drug Events extraction robustness on social media: case study on negation and speculation,0.58376,"In the last decade, an increasing number of users have started reporting
Adverse Drug Events (ADE) on social media platforms, blogs, and health forums.
Given the large volume of reports, pharmacovigilance has focused on ways to use
Natural Language Processing (NLP) techniques to rapidly examine these large
collections of text, detecting mentions of drug-related adverse reactions to
trigger medical investigations. However, despite the growing interest in the
task and the advances in NLP, the robustness of these models in face of
linguistic phenomena such as negations and speculations is an open research
question. Negations and speculations are pervasive phenomena in natural
language, and can severely hamper the ability of an automated system to
discriminate between factual and nonfactual statements in text. In this paper
we take into consideration four state-of-the-art systems for ADE detection on
social media texts. We introduce SNAX, a benchmark to test their performance
against samples containing negated and speculated ADEs, showing their fragility
against these phenomena. We then introduce two possible strategies to increase
the robustness of these models, showing that both of them bring significant
increases in performance, lowering the number of spurious entities predicted by
the models by 60% for negation and 80% for speculations."
Applying Automated Machine Translation to Educational Video Courses,0.0691373,"We studied the capability of automated machine translation in the online
video education space by automatically translating Khan Academy videos with
state-of-the-art translation models and applying text-to-speech synthesis and
audio/video synchronization to build engaging videos in target languages. We
also analyzed and established two reliable translation confidence estimators
based on round-trip translations in order to efficiently manage translation
quality and reduce human translation effort. Finally, we developed a deployable
system to deliver translated videos to end users and collect user corrections
for iterative improvement."
RecursiveDet: End-to-End Region-based Recursive Object Detection,0.0917556,"End-to-end region-based object detectors like Sparse R-CNN usually have
multiple cascade bounding box decoding stages, which refine the current
predictions according to their previous results. Model parameters within each
stage are independent, evolving a huge cost. In this paper, we find the general
setting of decoding stages is actually redundant. By simply sharing parameters
and making a recursive decoder, the detector already obtains a significant
improvement. The recursive decoder can be further enhanced by positional
encoding (PE) of the proposal box, which makes it aware of the exact locations
and sizes of input bounding boxes, thus becoming adaptive to proposals from
different stages during the recursion. Moreover, we also design
centerness-based PE to distinguish the RoI feature element and dynamic
convolution kernels at different positions within the bounding box. To validate
the effectiveness of the proposed method, we conduct intensive ablations and
build the full model on three recent mainstream region-based detectors. The
RecusiveDet is able to achieve obvious performance boosts with even fewer model
parameters and slightly increased computation cost. Codes are available at
https://github.com/bravezzzzzz/RecursiveDet."
A Frustratingly Easy Improvement for Position Embeddings via Random Padding,0.761132,"Position embeddings, encoding the positional relationships among tokens in
text sequences, make great contributions to modeling local context features in
Transformer-based pre-trained language models. However, in Extractive Question
Answering, position embeddings trained with instances of varied context lengths
may not perform well as we expect. Since the embeddings of rear positions are
updated fewer times than the front position embeddings, the rear ones may not
be properly trained. In this paper, we propose a simple but effective strategy,
Random Padding, without any modifications to architectures of existing
pre-trained language models. We adjust the token order of input sequences when
fine-tuning, to balance the number of updating times of every position
embedding. Experiments show that Random Padding can significantly improve model
performance on the instances whose answers are located at rear positions,
especially when models are trained on short contexts but evaluated on long
contexts. Our code and data will be released for future research."
Personalized Interventions for Online Moderation,0.616042,"Current online moderation follows a one-size-fits-all approach, where each
intervention is applied in the same way to all users. This naive approach is
challenged by established socio-behavioral theories and by recent empirical
results that showed the limited effectiveness of such interventions. We propose
a paradigm-shift in online moderation by moving towards a personalized and
user-centered approach. Our multidisciplinary vision combines state-of-the-art
theories and practices in diverse fields such as computer science, sociology
and psychology, to design personalized moderation interventions (PMIs). In
outlining the path leading to the next-generation of moderation interventions,
we also discuss the most prominent challenges introduced by such a disruptive
change."
Enhance Incomplete Utterance Restoration by Joint Learning Token Extraction and Text Generation,0.807633,"This paper introduces a model for incomplete utterance restoration (IUR)
called JET (\textbf{J}oint learning token \textbf{E}xtraction and \textbf{T}ext
generation). Different from prior studies that only work on extraction or
abstraction datasets, we design a simple but effective model, working for both
scenarios of IUR. Our design simulates the nature of IUR, where omitted tokens
from the context contribute to restoration. From this, we construct a Picker
that identifies the omitted tokens. To support the picker, we design two label
creation methods (soft and hard labels), which can work in cases of no
annotation data for the omitted tokens. The restoration is done by using a
Generator with the help of the Picker on joint learning. Promising results on
four benchmark datasets in extraction and abstraction scenarios show that our
model is better than the pretrained T5 and non-generative language model
methods in both rich and limited training data settings.\footnote{The code is
available at \url{https://github.com/shumpei19/JET}}"
Weakly-supervised segmentation of referring expressions,0.463169,"Visual grounding localizes regions (boxes or segments) in the image
corresponding to given referring expressions. In this work we address image
segmentation from referring expressions, a problem that has so far only been
addressed in a fully-supervised setting. A fully-supervised setup, however,
requires pixel-wise supervision and is hard to scale given the expense of
manual annotation. We therefore introduce a new task of weakly-supervised image
segmentation from referring expressions and propose Text grounded semantic
SEGgmentation (TSEG) that learns segmentation masks directly from image-level
referring expressions without pixel-level annotations. Our transformer-based
method computes patch-text similarities and guides the classification objective
during training with a new multi-label patch assignment mechanism. The
resulting visual grounding model segments image regions corresponding to given
natural language expressions. Our approach TSEG demonstrates promising results
for weakly-supervised referring expression segmentation on the challenging
PhraseCut and RefCOCO datasets. TSEG also shows competitive performance when
evaluated in a zero-shot setting for semantic segmentation on Pascal VOC."
Incorporating Task-specific Concept Knowledge into Script Learning,0.316889,"In this paper, we present Tetris, a new task of Goal-Oriented Script
Completion. Unlike previous work, it considers a more realistic and general
setting, where the input includes not only the goal but also additional user
context, including preferences and history. To address this problem, we propose
a novel approach, which uses two techniques to improve performance: (1) concept
prompting, and (2) script-oriented contrastive learning that addresses step
repetition and hallucination problems. On our WikiHow-based dataset, we find
that both methods improve performance. The dataset, repository, and models will
be publicly available to facilitate further research on this new task."
SNCSE: Contrastive Learning for Unsupervised Sentence Embedding with Soft Negative Samples,0.533139,"Unsupervised sentence embedding aims to obtain the most appropriate embedding
for a sentence to reflect its semantic. Contrastive learning has been
attracting developing attention. For a sentence, current models utilize diverse
data augmentation methods to generate positive samples, while consider other
independent sentences as negative samples. Then they adopt InfoNCE loss to pull
the embeddings of positive pairs gathered, and push those of negative pairs
scattered. Although these models have made great progress on sentence
embedding, we argue that they may suffer from feature suppression. The models
fail to distinguish and decouple textual similarity and semantic similarity.
And they may overestimate the semantic similarity of any pairs with similar
textual regardless of the actual semantic difference between them. This is
because positive pairs in unsupervised contrastive learning come with similar
and even the same textual through data augmentation. To alleviate feature
suppression, we propose contrastive learning for unsupervised sentence
embedding with soft negative samples (SNCSE). Soft negative samples share
highly similar textual but have surely and apparently different semantic with
the original samples. Specifically, we take the negation of original sentences
as soft negative samples, and propose Bidirectional Margin Loss (BML) to
introduce them into traditional contrastive learning framework, which merely
involves positive and negative samples. Our experimental results show that
SNCSE can obtain state-of-the-art performance on semantic textual similarity
(STS) task with average Spearman's correlation coefficient of 78.97% on
BERTbase and 79.23% on RoBERTabase. Besides, we adopt rank-based error analysis
method to detect the weakness of SNCSE for future study."
HLT-MT: High-resource Language-specific Training for Multilingual Neural Machine Translation,0.620594,"Multilingual neural machine translation (MNMT) trained in multiple language
pairs has attracted considerable attention due to fewer model parameters and
lower training costs by sharing knowledge among multiple languages.
Nonetheless, multilingual training is plagued by language interference
degeneration in shared parameters because of the negative interference among
different translation directions, especially on high-resource languages. In
this paper, we propose the multilingual translation model with the
high-resource language-specific training (HLT-MT) to alleviate the negative
interference, which adopts the two-stage training with the language-specific
selection mechanism. Specifically, we first train the multilingual model only
with the high-resource pairs and select the language-specific modules at the
top of the decoder to enhance the translation quality of high-resource
directions. Next, the model is further trained on all available corpora to
transfer knowledge from high-resource languages (HRLs) to low-resource
languages (LRLs). Experimental results show that HLT-MT outperforms various
strong baselines on WMT-10 and OPUS-100 benchmarks. Furthermore, the analytic
experiments validate the effectiveness of our method in mitigating the negative
interference in multilingual training."
Optimizing Video Prediction via Video Frame Interpolation,0.782221,"Video prediction is an extrapolation task that predicts future frames given
past frames, and video frame interpolation is an interpolation task that
estimates intermediate frames between two frames. We have witnessed the
tremendous advancement of video frame interpolation, but the general video
prediction in the wild is still an open question. Inspired by the
photo-realistic results of video frame interpolation, we present a new
optimization framework for video prediction via video frame interpolation, in
which we solve an extrapolation problem based on an interpolation model. Our
video prediction framework is based on optimization with a pretrained
differentiable video frame interpolation module without the need for a training
dataset, and thus there is no domain gap issue between training and test data.
Also, our approach does not need any additional information such as semantic or
instance maps, which makes our framework applicable to any video. Extensive
experiments on the Cityscapes, KITTI, DAVIS, Middlebury, and Vimeo90K datasets
show that our video prediction results are robust in general scenarios, and our
approach outperforms other video prediction methods that require a large amount
of training data or extra semantic information."
Flesch or Fumble? Evaluating Readability Standard Alignment of Instruction-Tuned Language Models,0.257449,"Readability metrics and standards such as Flesch Kincaid Grade Level (FKGL)
and the Common European Framework of Reference for Languages (CEFR) exist to
guide teachers and educators to properly assess the complexity of educational
materials before administering them for classroom use. In this study, we select
a diverse set of open and closed-source instruction-tuned language models and
investigate their performances in writing story completions and simplifying
narratives--tasks that teachers perform--using standard-guided prompts
controlling text readability. Our extensive findings provide empirical proof of
how globally recognized models like ChatGPT may be considered less effective
and may require more refined prompts for these generative tasks compared to
other open-sourced models such as BLOOMZ and FlanT5--which have shown promising
results."
Comparative layer-wise analysis of self-supervised speech models,0.837552,"Many self-supervised speech models, varying in their pre-training objective,
input modality, and pre-training data, have been proposed in the last few
years. Despite impressive successes on downstream tasks, we still have a
limited understanding of the properties encoded by the models and the
differences across models. In this work, we examine the intermediate
representations for a variety of recent models. Specifically, we measure
acoustic, phonetic, and word-level properties encoded in individual layers,
using a lightweight analysis tool based on canonical correlation analysis
(CCA). We find that these properties evolve across layers differently depending
on the model, and the variations relate to the choice of pre-training
objective. We further investigate the utility of our analyses for downstream
tasks by comparing the property trends with performance on speech recognition
and spoken language understanding tasks. We discover that CCA trends provide
reliable guidance to choose layers of interest for downstream tasks and that
single-layer performance often matches or improves upon using all layers,
suggesting implications for more efficient use of pre-trained models."
Analyzing Process-Aware Information System Updates Using Digital Twins of Organizations,0.128814,"Digital transformation often entails small-scale changes to information
systems supporting the execution of business processes. These changes may
increase the operational frictions in process execution, which decreases the
process performance. The contributions in the literature providing support to
the tracking and impact analysis of small-scale changes are limited in scope
and functionality. In this paper, we use the recently developed Digital Twins
of Organizations (DTOs) to assess the impact of (process-aware) information
systems updates. More in detail, we model the updates using the configuration
of DTOs and quantitatively assess different types of impacts of information
system updates (structural, operational, and performance-related). We
implemented a prototype of the proposed approach. Moreover, we discuss a case
study involving a standard ERP procure-to-pay business process."
Visualizing Automatic Speech Recognition -- Means for a Better Understanding?,0.225079,"Automatic speech recognition (ASR) is improving ever more at mimicking human
speech processing. The functioning of ASR, however, remains to a large extent
obfuscated by the complex structure of the deep neural networks (DNNs) they are
based on. In this paper, we show how so-called attribution methods, that we
import from image recognition and suitably adapt to handle audio data, can help
to clarify the working of ASR. Taking DeepSpeech, an end-to-end model for ASR,
as a case study, we show how these techniques help to visualize which features
of the input are the most influential in determining the output. We focus on
three visualization techniques: Layer-wise Relevance Propagation (LRP),
Saliency Maps, and Shapley Additive Explanations (SHAP). We compare these
methods and discuss potential further applications, such as in the detection of
adversarial examples."
Multilevel Hierarchical Network with Multiscale Sampling for Video Question Answering,0.655592,"Video question answering (VideoQA) is challenging given its multimodal
combination of visual understanding and natural language processing. While most
existing approaches ignore the visual appearance-motion information at
different temporal scales, it is unknown how to incorporate the multilevel
processing capacity of a deep learning model with such multiscale information.
Targeting these issues, this paper proposes a novel Multilevel Hierarchical
Network (MHN) with multiscale sampling for VideoQA. MHN comprises two modules,
namely Recurrent Multimodal Interaction (RMI) and Parallel Visual Reasoning
(PVR). With a multiscale sampling, RMI iterates the interaction of
appearance-motion information at each scale and the question embeddings to
build the multilevel question-guided visual representations. Thereon, with a
shared transformer encoder, PVR infers the visual cues at each level in
parallel to fit with answering different question types that may rely on the
visual information at relevant levels. Through extensive experiments on three
VideoQA datasets, we demonstrate improved performances than previous
state-of-the-arts and justify the effectiveness of each part of our method."
EA$^2$E: Improving Consistency with Event Awareness for Document-Level Argument Extraction,0.771406,"Events are inter-related in documents. Motivated by the
one-sense-per-discourse theory, we hypothesize that a participant tends to play
consistent roles across multiple events in the same document. However recent
work on document-level event argument extraction models each individual event
in isolation and therefore causes inconsistency among extracted arguments
across events, which will further cause discrepancy for downstream applications
such as event knowledge base population, question answering, and hypothesis
generation. In this work, we formulate event argument consistency as the
constraints from event-event relations under the document-level setting. To
improve consistency we introduce the Event-Aware Argument Extraction (EA$^2$E)
model with augmented context for training and inference. Experiment results on
WIKIEVENTS and ACE2005 datasets demonstrate the effectiveness of EA$^2$E
compared to baseline methods."
Backpropagation of Unrolled Solvers with Folded Optimization,0.61748,"The integration of constrained optimization models as components in deep
networks has led to promising advances on many specialized learning tasks. A
central challenge in this setting is backpropagation through the solution of an
optimization problem, which typically lacks a closed form. One typical strategy
is algorithm unrolling, which relies on automatic differentiation through the
operations of an iterative solver. While flexible and general, unrolling can
encounter accuracy and efficiency issues in practice. These issues can be
avoided by analytical differentiation of the optimization, but current
frameworks impose rigid requirements on the optimization problem's form. This
paper provides theoretical insights into the backward pass of unrolled
optimization, leading to a system for generating efficiently solvable
analytical models of backpropagation. Additionally, it proposes a unifying view
of unrolling and analytical differentiation through optimization mappings.
Experiments over various model-based learning tasks demonstrate the advantages
of the approach both computationally and in terms of enhanced expressiveness."
Empathetic Response Generation via Emotion Cause Transition Graph,0.53496,"Empathetic dialogue is a human-like behavior that requires the perception of
both affective factors (e.g., emotion status) and cognitive factors (e.g.,
cause of the emotion). Besides concerning emotion status in early work, the
latest approaches study emotion causes in empathetic dialogue. These approaches
focus on understanding and duplicating emotion causes in the context to show
empathy for the speaker. However, instead of only repeating the contextual
causes, the real empathic response often demonstrate a logical and
emotion-centered transition from the causes in the context to those in the
responses. In this work, we propose an emotion cause transition graph to
explicitly model the natural transition of emotion causes between two adjacent
turns in empathetic dialogue. With this graph, the concept words of the emotion
causes in the next turn can be predicted and used by a specifically designed
concept-aware decoder to generate the empathic response. Automatic and human
experimental results on the benchmark dataset demonstrate that our method
produces more empathetic, coherent, informative, and specific responses than
existing models."
Adversarial Laser Spot: Robust and Covert Physical-World Attack to DNNs,0.918276,"Most existing deep neural networks (DNNs) are easily disturbed by slight
noise. However, there are few researches on physical attacks by deploying
lighting equipment. The light-based physical attacks has excellent covertness,
which brings great security risks to many vision-based applications (such as
self-driving). Therefore, we propose a light-based physical attack, called
adversarial laser spot (AdvLS), which optimizes the physical parameters of
laser spots through genetic algorithm to perform physical attacks. It realizes
robust and covert physical attack by using low-cost laser equipment. As far as
we know, AdvLS is the first light-based physical attack that perform physical
attacks in the daytime. A large number of experiments in the digital and
physical environments show that AdvLS has excellent robustness and covertness.
In addition, through in-depth analysis of the experimental data, we find that
the adversarial perturbations generated by AdvLS have superior adversarial
attack migration. The experimental results show that AdvLS impose serious
interference to advanced DNNs, we call for the attention of the proposed AdvLS.
The code of AdvLS is available at: https://github.com/ChengYinHu/AdvLS"
Retrieval-Augmented Transformer for Image Captioning,0.889937,"Image captioning models aim at connecting Vision and Language by providing
natural language descriptions of input images. In the past few years, the task
has been tackled by learning parametric models and proposing visual feature
extraction advancements or by modeling better multi-modal connections. In this
paper, we investigate the development of an image captioning approach with a
kNN memory, with which knowledge can be retrieved from an external corpus to
aid the generation process. Our architecture combines a knowledge retriever
based on visual similarities, a differentiable encoder, and a kNN-augmented
attention layer to predict tokens based on the past context and on text
retrieved from the external memory. Experimental results, conducted on the COCO
dataset, demonstrate that employing an explicit external memory can aid the
generation process and increase caption quality. Our work opens up new avenues
for improving image captioning models at larger scale."
Quantitative Metrics for Evaluating Explanations of Video DeepFake Detectors,0.176735,"The proliferation of DeepFake technology is a rising challenge in today's
society, owing to more powerful and accessible generation methods. To counter
this, the research community has developed detectors of ever-increasing
accuracy. However, the ability to explain the decisions of such models to users
is lacking behind and is considered an accessory in large-scale benchmarks,
despite being a crucial requirement for the correct deployment of automated
tools for content moderation. We attribute the issue to the reliance on
qualitative comparisons and the lack of established metrics. We describe a
simple set of metrics to evaluate the visual quality and informativeness of
explanations of video DeepFake classifiers from a human-centric perspective.
With these metrics, we compare common approaches to improve explanation quality
and discuss their effect on both classification and explanation performance on
the recent DFDC and DFD datasets."
FV-MgNet: Fully Connected V-cycle MgNet for Interpretable Time Series Forecasting,0.19287,"By investigating iterative methods for a constrained linear model, we propose
a new class of fully connected V-cycle MgNet for long-term time series
forecasting, which is one of the most difficult tasks in forecasting. MgNet is
a CNN model that was proposed for image classification based on the multigrid
(MG) methods for solving discretized partial differential equations (PDEs). We
replace the convolutional operations with fully connected operations in the
existing MgNet and then apply them to forecasting problems. Motivated by the
V-cycle structure in MG, we further propose the FV-MgNet, a V-cycle version of
the fully connected MgNet, to extract features hierarchically. By evaluating
the performance of FV-MgNet on popular data sets and comparing it with
state-of-the-art models, we show that the FV-MgNet achieves better results with
less memory usage and faster inference speed. In addition, we develop ablation
experiments to demonstrate that the structure of FV-MgNet is the best choice
among the many variants."
Thistle: A Vector Database in Rust,0.222669,"We present Thistle, a fully functional vector database. Thistle is an entry
into the domain of latent knowledge use in answering search queries, an ongoing
research topic at both start-ups and search engine companies. We implement
Thistle with several well-known algorithms, and benchmark results on the MS
MARCO dataset. Results help clarify the latent knowledge domain as well as the
growing Rust ML ecosystem."
Adversarial Robustness through the Lens of Convolutional Filters,0.54567,"Deep learning models are intrinsically sensitive to distribution shifts in
the input data. In particular, small, barely perceivable perturbations to the
input data can force models to make wrong predictions with high confidence. An
common defense mechanism is regularization through adversarial training which
injects worst-case perturbations back into training to strengthen the decision
boundaries, and to reduce overfitting. In this context, we perform an
investigation of 3x3 convolution filters that form in adversarially-trained
models. Filters are extracted from 71 public models of the linf-RobustBench
CIFAR-10/100 and ImageNet1k leaderboard and compared to filters extracted from
models built on the same architectures but trained without robust
regularization. We observe that adversarially-robust models appear to form more
diverse, less sparse, and more orthogonal convolution filters than their normal
counterparts. The largest differences between robust and normal models are
found in the deepest layers, and the very first convolution layer, which
consistently and predominantly forms filters that can partially eliminate
perturbations, irrespective of the architecture. Data & Project website:
https://github.com/paulgavrikov/cvpr22w_RobustnessThroughTheLens"
Enhancing conversational quality in language learning chatbots: An evaluation of GPT4 for ASR error correction,0.0431152,"The integration of natural language processing (NLP) technologies into
educational applications has shown promising results, particularly in the
language learning domain. Recently, many spoken open-domain chatbots have been
used as speaking partners, helping language learners improve their language
skills. However, one of the significant challenges is the high word-error-rate
(WER) when recognizing non-native/non-fluent speech, which interrupts
conversation flow and leads to disappointment for learners. This paper explores
the use of GPT4 for ASR error correction in conversational settings. In
addition to WER, we propose to use semantic textual similarity (STS) and next
response sensibility (NRS) metrics to evaluate the impact of error correction
models on the quality of the conversation. We find that transcriptions
corrected by GPT4 lead to higher conversation quality, despite an increase in
WER. GPT4 also outperforms standard error correction methods without the need
for in-domain training data."
Multi-View Consistent Generative Adversarial Networks for 3D-aware Image Synthesis,0.75819,"3D-aware image synthesis aims to generate images of objects from multiple
views by learning a 3D representation. However, one key challenge remains:
existing approaches lack geometry constraints, hence usually fail to generate
multi-view consistent images. To address this challenge, we propose Multi-View
Consistent Generative Adversarial Networks (MVCGAN) for high-quality 3D-aware
image synthesis with geometry constraints. By leveraging the underlying 3D
geometry information of generated images, i.e., depth and camera transformation
matrix, we explicitly establish stereo correspondence between views to perform
multi-view joint optimization. In particular, we enforce the photometric
consistency between pairs of views and integrate a stereo mixup mechanism into
the training process, encouraging the model to reason about the correct 3D
shape. Besides, we design a two-stage training strategy with feature-level
multi-view joint optimization to improve the image quality. Extensive
experiments on three datasets demonstrate that MVCGAN achieves the
state-of-the-art performance for 3D-aware image synthesis."
A DSEL for High Throughput and Low Latency Software-Defined Radio on Multicore CPUs,0.384137,"This article presents a new Domain Specific Embedded Language (DSEL)
dedicated to Software-Defined Radio (SDR). From a set of carefully designed
components, it enables to build efficient software digital communication
systems, able to take advantage of the parallelism of modern processor
architectures, in a straightforward and safe manner for the programmer. In
particular, proposed DSEL enables the combination of pipelining and sequence
duplication techniques to extract both temporal and spatial parallelism from
digital communication systems. We leverage the DSEL capabilities on a real use
case: a fully digital transceiver for the widely used DVB-S2 standard designed
entirely in software. Through evaluation, we show how proposed software DVB-S2
transceiver is able to get the most from modern, high-end multicore CPU
targets."
OptiMUS: Optimization Modeling Using MIP Solvers and large language models,0.25695,"Optimization problems are pervasive across various sectors, from
manufacturing and distribution to healthcare. However, most such problems are
still solved heuristically by hand rather than optimally by state-of-the-art
solvers, as the expertise required to formulate and solve these problems limits
the widespread adoption of optimization tools and techniques. We introduce
OptiMUS, a Large Language Model (LLM)-based agent designed to formulate and
solve MILP problems from their natural language descriptions. OptiMUS is
capable of developing mathematical models, writing and debugging solver code,
developing tests, and checking the validity of generated solutions. To
benchmark our agent, we present NLP4LP, a novel dataset of linear programming
(LP) and mixed integer linear programming (MILP) problems. Our experiments
demonstrate that OptiMUS solves nearly twice as many problems as a basic LLM
prompting strategy. OptiMUS code and NLP4LP dataset are available at
\href{https://github.com/teshnizi/OptiMUS}{https://github.com/teshnizi/OptiMUS}"
Object Detection in Aerial Images: What Improves the Accuracy?,0.0215421,"Object detection is a challenging and popular computer vision problem. The
problem is even more challenging in aerial images due to significant variation
in scale and viewpoint in a diverse set of object categories. Recently, deep
learning-based object detection approaches have been actively explored for the
problem of object detection in aerial images. In this work, we investigate the
impact of Faster R-CNN for aerial object detection and explore numerous
strategies to improve its performance for aerial images. We conduct extensive
experiments on the challenging iSAID dataset. The resulting adapted Faster
R-CNN obtains a significant mAP gain of 4.96% over its vanilla baseline
counterpart on the iSAID validation set, demonstrating the impact of different
strategies investigated in this work."
Auto Machine Learning for Medical Image Analysis by Unifying the Search on Data Augmentation and Neural Architecture,0.0835333,"Automated data augmentation, which aims at engineering augmentation policy
automatically, recently draw a growing research interest. Many previous
auto-augmentation methods utilized a Density Matching strategy by evaluating
policies in terms of the test-time augmentation performance. In this paper, we
theoretically and empirically demonstrated the inconsistency between the train
and validation set of small-scale medical image datasets, referred to as
in-domain sampling bias. Next, we demonstrated that the in-domain sampling bias
might cause the inefficiency of Density Matching. To address the problem, an
improved augmentation search strategy, named Augmented Density Matching, was
proposed by randomly sampling policies from a prior distribution for training.
Moreover, an efficient automatical machine learning(AutoML) algorithm was
proposed by unifying the search on data augmentation and neural architecture.
Experimental results indicated that the proposed methods outperformed
state-of-the-art approaches on MedMNIST, a pioneering benchmark designed for
AutoML in medical image analysis."
Compound Tokens: Channel Fusion for Vision-Language Representation Learning,0.0293552,"We present an effective method for fusing visual-and-language representations
for several question answering tasks including visual question answering and
visual entailment. In contrast to prior works that concatenate unimodal
representations or use only cross-attention, we compose multimodal
representations via channel fusion. By fusing on the channels, the model is
able to more effectively align the tokens compared to standard methods. These
multimodal representations, which we call compound tokens are generated with
cross-attention transformer layers. First, vision tokens are used as queries to
retrieve compatible text tokens through cross-attention. We then chain the
vision tokens and the queried text tokens along the channel dimension. We call
the resulting representations compound tokens. A second group of compound
tokens are generated using an analogous process where the text tokens serve as
queries to the cross-attention layer. We concatenate all the compound tokens
for further processing with multimodal encoder. We demonstrate the
effectiveness of compound tokens using an encoder-decoder vision-language model
trained end-to-end in the open-vocabulary setting. Compound Tokens achieve
highly competitive performance across a range of question answering tasks
including GQA, VQA2.0, and SNLI-VE."
Self-Supervised Learning for Multimodal Non-Rigid 3D Shape Matching,0.441101,"The matching of 3D shapes has been extensively studied for shapes represented
as surface meshes, as well as for shapes represented as point clouds. While
point clouds are a common representation of raw real-world 3D data (e.g. from
laser scanners), meshes encode rich and expressive topological information, but
their creation typically requires some form of (often manual) curation. In
turn, methods that purely rely on point clouds are unable to meet the matching
quality of mesh-based methods that utilise the additional topological
structure. In this work we close this gap by introducing a self-supervised
multimodal learning strategy that combines mesh-based functional map
regularisation with a contrastive loss that couples mesh and point cloud data.
Our shape matching approach allows to obtain intramodal correspondences for
triangle meshes, complete point clouds, and partially observed point clouds, as
well as correspondences across these data modalities. We demonstrate that our
method achieves state-of-the-art results on several challenging benchmark
datasets even in comparison to recent supervised methods, and that our method
reaches previously unseen cross-dataset generalisation ability."
Learning to Decompose Visual Features with Latent Textual Prompts,0.783576,"Recent advances in pre-training vision-language models like CLIP have shown
great potential in learning transferable visual representations. Nonetheless,
for downstream inference, CLIP-like models suffer from either 1) degraded
accuracy and robustness in the case of inaccurate text descriptions during
retrieval-based inference (the challenge for zero-shot protocol); or 2)
breaking the well-established vision-language alignment (the challenge for
linear probing). To address them, we propose Decomposed Feature Prompting
(DeFo). DeFo leverages a flexible number of learnable embeddings as textual
input while maintaining the vision-language dual-model architecture, which
enables the model to learn decomposed visual features with the help of
feature-level textual prompts. We further use an additional linear layer to
perform classification, allowing a scalable size of language inputs. Our
empirical study shows DeFo's significance in improving the vision-language
models. For example, DeFo obtains 73.2% test accuracy on ImageNet with a
ResNet-50 backbone without tuning any pretrained weights of both the vision and
language encoder, outperforming zero-shot CLIP by a large margin of 15.0%, and
outperforming state-of-the-art vision-language prompt tuning method by 7.6%."
Influence-Based Mini-Batching for Graph Neural Networks,0.308518,"Using graph neural networks for large graphs is challenging since there is no
clear way of constructing mini-batches. To solve this, previous methods have
relied on sampling or graph clustering. While these approaches often lead to
good training convergence, they introduce significant overhead due to expensive
random data accesses and perform poorly during inference. In this work we
instead focus on model behavior during inference. We theoretically model batch
construction via maximizing the influence score of nodes on the outputs. This
formulation leads to optimal approximation of the output when we do not have
knowledge of the trained model. We call the resulting method influence-based
mini-batching (IBMB). IBMB accelerates inference by up to 130x compared to
previous methods that reach similar accuracy. Remarkably, with adaptive
optimization and the right training schedule IBMB can also substantially
accelerate training, thanks to precomputed batches and consecutive memory
accesses. This results in up to 18x faster training per epoch and up to 17x
faster convergence per runtime compared to previous methods."
"Towards Conceptualization of ""Fair Explanation"": Disparate Impacts of anti-Asian Hate Speech Explanations on Content Moderators",0.172302,"Recent research at the intersection of AI explainability and fairness has
focused on how explanations can improve human-plus-AI task performance as
assessed by fairness measures. We propose to characterize what constitutes an
explanation that is itself ""fair"" -- an explanation that does not adversely
impact specific populations. We formulate a novel evaluation method of ""fair
explanations"" using not just accuracy and label time, but also psychological
impact of explanations on different user groups across many metrics (mental
discomfort, stereotype activation, and perceived workload). We apply this
method in the context of content moderation of potential hate speech, and its
differential impact on Asian vs. non-Asian proxy moderators, across explanation
approaches (saliency map and counterfactual explanation). We find that saliency
maps generally perform better and show less evidence of disparate impact
(group) and individual unfairness than counterfactual explanations.
  Content warning: This paper contains examples of hate speech and racially
discriminatory language. The authors do not support such content. Please
consider your risk of discomfort carefully before continuing reading!"
Building Rearticulable Models for Arbitrary 3D Objects from 4D Point Clouds,0.215863,"We build rearticulable models for arbitrary everyday man-made objects
containing an arbitrary number of parts that are connected together in
arbitrary ways via 1 degree-of-freedom joints. Given point cloud videos of such
everyday objects, our method identifies the distinct object parts, what parts
are connected to what other parts, and the properties of the joints connecting
each part pair. We do this by jointly optimizing the part segmentation,
transformation, and kinematics using a novel energy minimization framework. Our
inferred animatable models, enables retargeting to novel poses with sparse
point correspondences guidance. We test our method on a new articulating robot
dataset, and the Sapiens dataset with common daily objects, as well as
real-world scans. Experiments show that our method outperforms two leading
prior works on various metrics."
Synthetic Point Cloud Generation for Class Segmentation Applications,0.0544524,"Maintenance of industrial facilities is a growing hazard due to the
cumbersome process needed to identify infrastructure degradation. Digital Twins
have the potential to improve maintenance by monitoring the continuous digital
representation of infrastructure. However, the time needed to map the existing
geometry makes their use prohibitive. We previously developed class
segmentation algorithms to automate digital twinning, however a vast amount of
annotated point clouds is needed. Currently, synthetic data generation for
automated segmentation is non-existent. We used Helios++ to automatically
segment point clouds from 3D models. Our research has the potential to pave the
ground for efficient industrial class segmentation."
ImageArg: A Multi-modal Tweet Dataset for Image Persuasiveness Mining,0.844932,"The growing interest in developing corpora of persuasive texts has promoted
applications in automated systems, e.g., debating and essay scoring systems;
however, there is little prior work mining image persuasiveness from an
argumentative perspective. To expand persuasiveness mining into a multi-modal
realm, we present a multi-modal dataset, ImageArg, consisting of annotations of
image persuasiveness in tweets. The annotations are based on a persuasion
taxonomy we developed to explore image functionalities and the means of
persuasion. We benchmark image persuasiveness tasks on ImageArg using
widely-used multi-modal learning methods. The experimental results show that
our dataset offers a useful resource for this rich and challenging topic, and
there is ample room for modeling improvement."
Social Assistive Robotics for Autistic Children,0.408895,"This paper introduces the project Social Assistive Robotics for Autistic
Children aimed at using robotic therapy for autism. The goal of the project is
testing autistic children's interactions with the social robot NAO. In
particular the robot will support the operators (psychologists, educators,
speech therapists etc.) in their work. The innovative aspect of the project is
that the children robot interaction will consider the children's emotions and
specific features and the robot will adapt its behavior accordingly."
Ontology-enhanced Prompt-tuning for Few-shot Learning,0.794797,"Few-shot Learning (FSL) is aimed to make predictions based on a limited
number of samples. Structured data such as knowledge graphs and ontology
libraries has been leveraged to benefit the few-shot setting in various tasks.
However, the priors adopted by the existing methods suffer from challenging
knowledge missing, knowledge noise, and knowledge heterogeneity, which hinder
the performance for few-shot learning. In this study, we explore knowledge
injection for FSL with pre-trained language models and propose
ontology-enhanced prompt-tuning (OntoPrompt). Specifically, we develop the
ontology transformation based on the external knowledge graph to address the
knowledge missing issue, which fulfills and converts structure knowledge to
text. We further introduce span-sensitive knowledge injection via a visible
matrix to select informative knowledge to handle the knowledge noise issue. To
bridge the gap between knowledge and text, we propose a collective training
algorithm to optimize representations jointly. We evaluate our proposed
OntoPrompt in three tasks, including relation extraction, event extraction, and
knowledge graph completion, with eight datasets. Experimental results
demonstrate that our approach can obtain better few-shot performance than
baselines."
ControlVideo: Training-free Controllable Text-to-Video Generation,0.991939,"Text-driven diffusion models have unlocked unprecedented abilities in image
generation, whereas their video counterpart still lags behind due to the
excessive training cost of temporal modeling. Besides the training burden, the
generated videos also suffer from appearance inconsistency and structural
flickers, especially in long video synthesis. To address these challenges, we
design a \emph{training-free} framework called \textbf{ControlVideo} to enable
natural and efficient text-to-video generation. ControlVideo, adapted from
ControlNet, leverages coarsely structural consistency from input motion
sequences, and introduces three modules to improve video generation. Firstly,
to ensure appearance coherence between frames, ControlVideo adds fully
cross-frame interaction in self-attention modules. Secondly, to mitigate the
flicker effect, it introduces an interleaved-frame smoother that employs frame
interpolation on alternated frames. Finally, to produce long videos
efficiently, it utilizes a hierarchical sampler that separately synthesizes
each short clip with holistic coherency. Empowered with these modules,
ControlVideo outperforms the state-of-the-arts on extensive motion-prompt pairs
quantitatively and qualitatively. Notably, thanks to the efficient designs, it
generates both short and long videos within several minutes using one NVIDIA
2080Ti. Code is available at https://github.com/YBYBZhang/ControlVideo."
What is Flagged in Uncertainty Quantification? Latent Density Models for Uncertainty Categorization,0.0389692,"Uncertainty Quantification (UQ) is essential for creating trustworthy machine
learning models. Recent years have seen a steep rise in UQ methods that can
flag suspicious examples, however, it is often unclear what exactly these
methods identify. In this work, we propose a framework for categorizing
uncertain examples flagged by UQ methods in classification tasks. We introduce
the confusion density matrix -- a kernel-based approximation of the
misclassification density -- and use this to categorize suspicious examples
identified by a given uncertainty method into three classes:
out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in
regions of high in-distribution misclassification (IDM). Through extensive
experiments, we show that our framework provides a new and distinct perspective
for assessing differences between uncertainty quantification methods, thereby
forming a valuable assessment benchmark."
Differential Privacy in Cooperative Multiagent Planning,0.496689,"Privacy-aware multiagent systems must protect agents' sensitive data while
simultaneously ensuring that agents accomplish their shared objectives. Towards
this goal, we propose a framework to privatize inter-agent communications in
cooperative multiagent decision-making problems. We study sequential
decision-making problems formulated as cooperative Markov games with
reach-avoid objectives. We apply a differential privacy mechanism to privatize
agents' communicated symbolic state trajectories, and then we analyze tradeoffs
between the strength of privacy and the team's performance. For a given level
of privacy, this tradeoff is shown to depend critically upon the total
correlation among agents' state-action processes. We synthesize policies that
are robust to privacy by reducing the value of the total correlation. Numerical
experiments demonstrate that the team's performance under these policies
decreases by only 3 percent when comparing private versus non-private
implementations of communication. By contrast, the team's performance decreases
by roughly 86 percent when using baseline policies that ignore total
correlation and only optimize team performance."
Towards Mitigating Hallucination in Large Language Models via Self-Reflection,0.940237,"Large language models (LLMs) have shown promise for generative and
knowledge-intensive tasks including question-answering (QA) tasks. However, the
practical deployment still faces challenges, notably the issue of
""hallucination"", where models generate plausible-sounding but unfaithful or
nonsensical information. This issue becomes particularly critical in the
medical domain due to the uncommon professional concepts and potential social
risks involved. This paper analyses the phenomenon of hallucination in medical
generative QA systems using widely adopted LLMs and datasets. Our investigation
centers on the identification and comprehension of common problematic answers,
with a specific emphasis on hallucination. To tackle this challenge, we present
an interactive self-reflection methodology that incorporates knowledge
acquisition and answer generation. Through this feedback process, our approach
steadily enhances the factuality, consistency, and entailment of the generated
answers. Consequently, we harness the interactivity and multitasking ability of
LLMs and produce progressively more precise and accurate answers. Experimental
results on both automatic and human evaluation demonstrate the superiority of
our approach in hallucination reduction compared to baselines."
Inferring Implicit Relations in Complex Questions with Language Models,0.0741694,"A prominent challenge for modern language understanding systems is the
ability to answer implicit reasoning questions, where the required reasoning
steps for answering the question are not mentioned in the text explicitly. In
this work, we investigate why current models struggle with implicit reasoning
question answering (QA) tasks, by decoupling inference of reasoning steps from
their execution. We define a new task of implicit relation inference and
construct a benchmark, IMPLICITRELATIONS, where given a question, a model
should output a list of concept-relation pairs, where the relations describe
the implicit reasoning steps required for answering the question. Using
IMPLICITRELATIONS, we evaluate models from the GPT-3 family and find that,
while these models struggle on the implicit reasoning QA task, they often
succeed at inferring implicit relations. This suggests that the challenge in
implicit reasoning questions does not stem from the need to plan a reasoning
strategy alone, but to do it while also retrieving and reasoning over relevant
information."
Bi-Directional Iterative Prompt-Tuning for Event Argument Extraction,0.758732,"Recently, prompt-tuning has attracted growing interests in event argument
extraction (EAE). However, the existing prompt-tuning methods have not achieved
satisfactory performance due to the lack of consideration of entity
information. In this paper, we propose a bi-directional iterative prompt-tuning
method for EAE, where the EAE task is treated as a cloze-style task to take
full advantage of entity information and pre-trained language models (PLMs).
Furthermore, our method explores event argument interactions by introducing the
argument roles of contextual entities into prompt construction. Since template
and verbalizer are two crucial components in a cloze-style prompt, we propose
to utilize the role label semantic knowledge to construct a semantic verbalizer
and design three kinds of templates for the EAE task. Experiments on the ACE
2005 English dataset with standard and low-resource settings show that the
proposed method significantly outperforms the peer state-of-the-art methods.
Our code is available at https://github.com/HustMinsLab/BIP."
Robust Ensemble Morph Detection with Domain Generalization,0.127517,"Although a substantial amount of studies is dedicated to morph detection,
most of them fail to generalize for morph faces outside of their training
paradigm. Moreover, recent morph detection methods are highly vulnerable to
adversarial attacks. In this paper, we intend to learn a morph detection model
with high generalization to a wide range of morphing attacks and high
robustness against different adversarial attacks. To this aim, we develop an
ensemble of convolutional neural networks (CNNs) and Transformer models to
benefit from their capabilities simultaneously. To improve the robust accuracy
of the ensemble model, we employ multi-perturbation adversarial training and
generate adversarial examples with high transferability for several single
models. Our exhaustive evaluations demonstrate that the proposed robust
ensemble model generalizes to several morphing attacks and face datasets. In
addition, we validate that our robust ensemble model gain better robustness
against several adversarial attacks while outperforming the state-of-the-art
studies."
ACPO: A Policy Optimization Algorithm for Average MDPs with Constraints,0.147032,"Reinforcement Learning (RL) for constrained MDPs (CMDPs) is an increasingly
important problem for various applications. Often, the average criterion is
more suitable than the discounted criterion. Yet, RL for average-CMDPs (ACMDPs)
remains a challenging problem. Algorithms designed for discounted constrained
RL problems often do not perform well for the average CMDP setting. In this
paper, we introduce a new policy optimization with function approximation
algorithm for constrained MDPs with the average criterion. The
Average-Constrained Policy Optimization (ACPO) algorithm is inspired by trust
region-based policy optimization algorithms. We develop basic sensitivity
theory for average CMDPs, and then use the corresponding bounds in the design
of the algorithm. We provide theoretical guarantees on its performance, and
through extensive experimental work in various challenging OpenAI Gym
environments, show its superior empirical performance when compared to other
state-of-the-art algorithms adapted for the ACMDPs."
A Self-Play Posterior Sampling Algorithm for Zero-Sum Markov Games,0.256152,"Existing studies on provably efficient algorithms for Markov games (MGs)
almost exclusively build on the ""optimism in the face of uncertainty"" (OFU)
principle. This work focuses on a different approach of posterior sampling,
which is celebrated in many bandits and reinforcement learning settings but
remains under-explored for MGs. Specifically, for episodic two-player zero-sum
MGs, a novel posterior sampling algorithm is developed with general function
approximation. Theoretical analysis demonstrates that the posterior sampling
algorithm admits a $\sqrt{T}$-regret bound for problems with a low multi-agent
decoupling coefficient, which is a new complexity measure for MGs, where $T$
denotes the number of episodes. When specialized to linear MGs, the obtained
regret bound matches the state-of-the-art results. To the best of our
knowledge, this is the first provably efficient posterior sampling algorithm
for MGs with frequentist regret guarantees, which enriches the toolbox for MGs
and promotes the broad applicability of posterior sampling."
Revisiting Discrete Soft Actor-Critic,0.815925,"We study the adaption of soft actor-critic (SAC) from continuous action space
to discrete action space. We revisit vanilla SAC and provide an in-depth
understanding of its Q value underestimation and performance instability issues
when applied to discrete settings. We thereby propose entropy-penalty and
double average Q-learning with Q-clip to address these issues. Extensive
experiments on typical benchmarks with discrete action space, including Atari
games and a large-scale MOBA game, show the efficacy of our proposed method.
Our code is at:https://github.com/coldsummerday/Revisiting-Discrete-SAC."
Higher-order Clustering and Pooling for Graph Neural Networks,0.560582,"Graph Neural Networks achieve state-of-the-art performance on a plethora of
graph classification tasks, especially due to pooling operators, which
aggregate learned node embeddings hierarchically into a final graph
representation. However, they are not only questioned by recent work showing on
par performance with random pooling, but also ignore completely higher-order
connectivity patterns. To tackle this issue, we propose HoscPool, a
clustering-based graph pooling operator that captures higher-order information
hierarchically, leading to richer graph representations. In fact, we learn a
probabilistic cluster assignment matrix end-to-end by minimising relaxed
formulations of motif spectral clustering in our objective function, and we
then extend it to a pooling operator. We evaluate HoscPool on graph
classification tasks and its clustering component on graphs with ground-truth
community structure, achieving best performance. Lastly, we provide a deep
empirical analysis of pooling operators' inner functioning."
Introducing BEREL: BERT Embeddings for Rabbinic-Encoded Language,0.615917,"We present a new pre-trained language model (PLM) for Rabbinic Hebrew, termed
Berel (BERT Embeddings for Rabbinic-Encoded Language). Whilst other PLMs exist
for processing Hebrew texts (e.g., HeBERT, AlephBert), they are all trained on
modern Hebrew texts, which diverges substantially from Rabbinic Hebrew in terms
of its lexicographical, morphological, syntactic and orthographic norms. We
demonstrate the superiority of Berel on Rabbinic texts via a challenge set of
Hebrew homographs. We release the new model and homograph challenge set for
unrestricted use."
Golfer: Trajectory Prediction with Masked Goal Conditioning MnM Network,0.341862,"Transformers have enabled breakthroughs in NLP and computer vision, and have
recently began to show promising performance in trajectory prediction for
Autonomous Vehicle (AV). How to efficiently model the interactive relationships
between the ego agent and other road and dynamic objects remains challenging
for the standard attention module. In this work we propose a general
Transformer-like architectural module MnM network equipped with novel masked
goal conditioning training procedures for AV trajectory prediction. The
resulted model, named golfer, achieves state-of-the-art performance, winning
the 2nd place in the 2022 Waymo Open Dataset Motion Prediction Challenge and
ranked 1st place according to minADE."
A Textless Metric for Speech-to-Speech Comparison,0.377973,"In this paper, we introduce a new and simple method for comparing speech
utterances without relying on text transcripts. Our speech-to-speech comparison
metric utilizes state-of-the-art speech2unit encoders like HuBERT to convert
speech utterances into discrete acoustic units. We then propose a simple and
easily replicable neural architecture that learns a speech-based metric that
closely corresponds to its text-based counterpart. This textless metric has
numerous potential applications, including evaluating speech-to-speech
translation for oral languages, languages without dependable ASR systems, or to
avoid the need for ASR transcription altogether. This paper also shows that for
speech-to-speech translation evaluation, ASR-BLEU (which consists in
automatically transcribing both speech hypothesis and reference and compute
sentence-level BLEU between transcripts) is a poor proxy to real text-BLEU even
when ASR system is strong."
LogicSolver: Towards Interpretable Math Word Problem Solving with Logical Prompt-enhanced Learning,0.817618,"Recently, deep learning models have made great progress in MWP solving on
answer accuracy. However, they are uninterpretable since they mainly rely on
shallow heuristics to achieve high performance without understanding and
reasoning the grounded math logic. To address this issue and make a step
towards interpretable MWP solving, we first construct a high-quality MWP
dataset named InterMWP which consists of 11,495 MWPs and annotates
interpretable logical formulas based on algebraic knowledge as the grounded
linguistic logic of each solution equation. Different from existing MWP
datasets, our InterMWP benchmark asks for a solver to not only output the
solution expressions but also predict the corresponding logical formulas. We
further propose a novel approach with logical prompt and interpretation
generation, called LogicSolver. For each MWP, our LogicSolver first retrieves
some highly-correlated algebraic knowledge and then passes them to the backbone
model as prompts to improve the semantic representations of MWPs. With these
improved semantic representations, our LogicSolver generates corresponding
solution expressions and interpretable knowledge formulas in accord with the
generated solution expressions, simultaneously. Experimental results show that
our LogicSolver has stronger logical formula-based interpretability than
baselines while achieving higher answer accuracy with the help of logical
prompts, simultaneously. The source code and dataset is available at
https://github.com/yangzhch6/InterMWP."
Human Evaluation of Conversations is an Open Problem: comparing the sensitivity of various methods for evaluating dialogue agents,0.715892,"At the heart of improving conversational AI is the open problem of how to
evaluate conversations. Issues with automatic metrics are well known (Liu et
al., 2016, arXiv:1603.08023), with human evaluations still considered the gold
standard. Unfortunately, how to perform human evaluations is also an open
problem: differing data collection methods have varying levels of human
agreement and statistical sensitivity, resulting in differing amounts of human
annotation hours and labor costs. In this work we compare five different
crowdworker-based human evaluation methods and find that different methods are
best depending on the types of models compared, with no clear winner across the
board. While this highlights the open problems in the area, our analysis leads
to advice of when to use which one, and possible future directions."
A Multi-agent Reinforcement Learning Approach for Efficient Client Selection in Federated Learning,0.926445,"Federated learning (FL) is a training technique that enables client devices
to jointly learn a shared model by aggregating locally-computed models without
exposing their raw data. While most of the existing work focuses on improving
the FL model accuracy, in this paper, we focus on the improving the training
efficiency, which is often a hurdle for adopting FL in real-world applications.
Specifically, we design an efficient FL framework which jointly optimizes model
accuracy, processing latency and communication efficiency, all of which are
primary design considerations for real implementation of FL. Inspired by the
recent success of Multi-Agent Reinforcement Learning (MARL) in solving complex
control problems, we present \textit{FedMarl}, an MARL-based FL framework which
performs efficient run-time client selection. Experiments show that FedMarl can
significantly improve model accuracy with much lower processing latency and
communication cost."
Dynamic Programming in Rank Space: Scaling Structured Inference with Low-Rank HMMs and PCFGs,0.333549,"Hidden Markov Models (HMMs) and Probabilistic Context-Free Grammars (PCFGs)
are widely used structured models, both of which can be represented as factor
graph grammars (FGGs), a powerful formalism capable of describing a wide range
of models. Recent research found it beneficial to use large state spaces for
HMMs and PCFGs. However, inference with large state spaces is computationally
demanding, especially for PCFGs. To tackle this challenge, we leverage tensor
rank decomposition (aka.\ CPD) to decrease inference computational complexities
for a subset of FGGs subsuming HMMs and PCFGs. We apply CPD on the factors of
an FGG and then construct a new FGG defined in the rank space. Inference with
the new FGG produces the same result but has a lower time complexity when the
rank size is smaller than the state size. We conduct experiments on HMM
language modeling and unsupervised PCFG parsing, showing better performance
than previous work. Our code is publicly available at
\url{https://github.com/VPeterV/RankSpace-Models}."
Qtrade AI at SemEval-2022 Task 11: An Unified Framework for Multilingual NER Task,0.562066,"This paper describes our system, which placed third in the Multilingual Track
(subtask 11), fourth in the Code-Mixed Track (subtask 12), and seventh in the
Chinese Track (subtask 9) in the SemEval 2022 Task 11: MultiCoNER Multilingual
Complex Named Entity Recognition. Our system's key contributions are as
follows: 1) For multilingual NER tasks, we offer an unified framework with
which one can easily execute single-language or multilingual NER tasks, 2) for
low-resource code-mixed NER task, one can easily enhance his or her dataset
through implementing several simple data augmentation methods and 3) for
Chinese tasks, we propose a model that can capture Chinese lexical semantic,
lexical border, and lexical graph structural information. Finally, our system
achieves macro-f1 scores of 77.66, 84.35, and 74.00 on subtasks 11, 12, and 9,
respectively, during the testing phase."
Extracting Biomedical Factual Knowledge Using Pretrained Language Model and Electronic Health Record Context,0.760349,"Language Models (LMs) have performed well on biomedical natural language
processing applications. In this study, we conducted some experiments to use
prompt methods to extract knowledge from LMs as new knowledge Bases (LMs as
KBs). However, prompting can only be used as a low bound for knowledge
extraction, and perform particularly poorly on biomedical domain KBs. In order
to make LMs as KBs more in line with the actual application scenarios of the
biomedical domain, we specifically add EHR notes as context to the prompt to
improve the low bound in the biomedical domain. We design and validate a series
of experiments for our Dynamic-Context-BioLAMA task. Our experiments show that
the knowledge possessed by those language models can distinguish the correct
knowledge from the noise knowledge in the EHR notes, and such distinguishing
ability can also be used as a new metric to evaluate the amount of knowledge
possessed by the model."
ConNER: Consistency Training for Cross-lingual Named Entity Recognition,0.855171,"Cross-lingual named entity recognition (NER) suffers from data scarcity in
the target languages, especially under zero-shot settings. Existing
translate-train or knowledge distillation methods attempt to bridge the
language gap, but often introduce a high level of noise. To solve this problem,
consistency training methods regularize the model to be robust towards
perturbations on data or hidden states. However, such methods are likely to
violate the consistency hypothesis, or mainly focus on coarse-grain
consistency. We propose ConNER as a novel consistency training framework for
cross-lingual NER, which comprises of: (1) translation-based consistency
training on unlabeled target-language data, and (2) dropoutbased consistency
training on labeled source-language data. ConNER effectively leverages
unlabeled target-language data and alleviates overfitting on the source
language to enhance the cross-lingual adaptability. Experimental results show
our ConNER achieves consistent improvement over various baseline methods."
Architecture and Knowledge Representation for Composable Inductive Programming,0.0425539,"We present an update on the current architecture of the Zoea knowledge-based,
Composable Inductive Programming system. The Zoea compiler is built using a
modern variant of the black-board architecture. Zoea integrates a large number
of knowledge sources that encode different aspects of programming language and
software development expertise. We describe the use of synthetic test cases as
a ubiquitous form of knowledge and hypothesis representation that sup-ports a
variety of reasoning strategies. Some future plans are also outlined."
Designing Participatory AI: Creative Professionals' Worries and Expectations about Generative AI,0.756395,"Generative AI, i.e., the group of technologies that automatically generate
visual or written content based on text prompts, has undergone a leap in
complexity and become widely available within just a few years. Such
technologies potentially introduce a massive disruption to creative fields.
This paper presents the results of a qualitative survey ($N$ = 23)
investigating how creative professionals think about generative AI. The results
show that the advancement of these AI models prompts important reflections on
what defines creativity and how creatives imagine using AI to support their
workflows. Based on these reflections, we discuss how we might design
\textit{participatory AI} in the domain of creative expertise with the goal of
empowering creative professionals in their present and future coexistence with
AI."
Making the case for audience design in conversational AI: Rapport expectations and language ideologies in a task-oriented chatbot,0.14825,"Chatbots are more and more prevalent in commercial and science contexts. They
help customers complain about a product or service or support them to find the
best travel deals. Other bots provide mental health support or help book
medical appointments. This paper argues that insights into users' language
ideologies and their rapport expectations can be used to inform the audience
design of the bot's language and interaction patterns and ensure equitable
access to the services provided by bots. The argument is underpinned by three
kinds of data: simulated user interactions with a chatbot facilitating health
appointment bookings, users' introspective comments on their interactions and
users' qualitative survey comments post engagement with the booking bot. In
closing, I will define audience design for conversational AI and discuss how
user-centred analyses of chatbot interactions and sociolinguistically informed
theoretical approaches, such as rapport management, can be used to support
audience design."
DeltaCNN: End-to-End CNN Inference of Sparse Frame Differences in Videos,0.455798,"Convolutional neural network inference on video data requires powerful
hardware for real-time processing. Given the inherent coherence across
consecutive frames, large parts of a video typically change little. By skipping
identical image regions and truncating insignificant pixel updates,
computational redundancy can in theory be reduced significantly. However, these
theoretical savings have been difficult to translate into practice, as sparse
updates hamper computational consistency and memory access coherence; which are
key for efficiency on real hardware. With DeltaCNN, we present a sparse
convolutional neural network framework that enables sparse frame-by-frame
updates to accelerate video inference in practice. We provide sparse
implementations for all typical CNN layers and propagate sparse feature updates
end-to-end - without accumulating errors over time. DeltaCNN is applicable to
all convolutional neural networks without retraining. To the best of our
knowledge, we are the first to significantly outperform the dense reference,
cuDNN, in practical settings, achieving speedups of up to 7x with only marginal
differences in accuracy."
Convolutional Neural Networks for Image Spam Detection,0.797376,"Spam can be defined as unsolicited bulk email. In an effort to evade
text-based filters, spammers sometimes embed spam text in an image, which is
referred to as image spam. In this research, we consider the problem of image
spam detection, based on image analysis. We apply convolutional neural networks
(CNN) to this problem, we compare the results obtained using CNNs to other
machine learning techniques, and we compare our results to previous related
work. We consider both real-world image spam and challenging image spam-like
datasets. Our results improve on previous work by employing CNNs based on a
novel feature set consisting of a combination of the raw image and Canny edges."
Fighting Fire with Fire: The Dual Role of LLMs in Crafting and Detecting Elusive Disinformation,0.566415,"Recent ubiquity and disruptive impacts of large language models (LLMs) have
raised concerns about their potential to be misused (.i.e, generating
large-scale harmful and misleading content). To combat this emerging risk of
LLMs, we propose a novel ""Fighting Fire with Fire"" (F3) strategy that harnesses
modern LLMs' generative and emergent reasoning capabilities to counter
human-written and LLM-generated disinformation. First, we leverage
GPT-3.5-turbo to synthesize authentic and deceptive LLM-generated content
through paraphrase-based and perturbation-based prefix-style prompts,
respectively. Second, we apply zero-shot in-context semantic reasoning
techniques with cloze-style prompts to discern genuine from deceptive posts and
news articles. In our extensive experiments, we observe GPT-3.5-turbo's
zero-shot superiority for both in-distribution and out-of-distribution
datasets, where GPT-3.5-turbo consistently achieved accuracy at 68-72%, unlike
the decline observed in previous customized and fine-tuned disinformation
detectors. Our codebase and dataset are available at
https://github.com/mickeymst/F3."
On the non-efficient PAC learnability of conjunctive queries,0.0494041,"This note serves three purposes: (i) we provide a self-contained exposition
of the fact that conjunctive queries are not efficiently learnable in the
Probably-Approximately-Correct (PAC) model, paying clear attention to the
complicating fact that this concept class lacks the polynomial-size fitting
property, a property that is tacitly assumed in much of the computational
learning theory literature; (ii) we establish a strong negative PAC
learnability result that applies to many restricted classes of conjunctive
queries (CQs), including acyclic CQs for a wide range of notions of
""acyclicity""; (iii) we show that CQs (and UCQs) are efficiently PAC learnable
with membership queries."
Differentiable Point-Based Radiance Fields for Efficient View Synthesis,0.556855,"We propose a differentiable rendering algorithm for efficient novel view
synthesis. By departing from volume-based representations in favor of a learned
point representation, we improve on existing methods more than an order of
magnitude in memory and runtime, both in training and inference. The method
begins with a uniformly-sampled random point cloud and learns per-point
position and view-dependent appearance, using a differentiable splat-based
renderer to evolve the model to match a set of input images. Our method is up
to 300x faster than NeRF in both training and inference, with only a marginal
sacrifice in quality, while using less than 10~MB of memory for a static scene.
For dynamic scenes, our method trains two orders of magnitude faster than
STNeRF and renders at near interactive rate, while maintaining high image
quality and temporal coherence even without imposing any temporal-coherency
regularizers."
Why is Winoground Hard? Investigating Failures in Visuolinguistic Compositionality,0.903804,"Recent visuolinguistic pre-trained models show promising progress on various
end tasks such as image retrieval and video captioning. Yet, they fail
miserably on the recently proposed Winoground dataset, which challenges models
to match paired images and English captions, with items constructed to overlap
lexically but differ in meaning (e.g., ""there is a mug in some grass"" vs.
""there is some grass in a mug""). By annotating the dataset using new
fine-grained tags, we show that solving the Winoground task requires not just
compositional language understanding, but a host of other abilities like
commonsense reasoning or locating small, out-of-focus objects in low-resolution
images. In this paper, we identify the dataset's main challenges through a
suite of experiments on related tasks (probing task, image retrieval task),
data augmentation, and manual inspection of the dataset. Our analysis suggests
that a main challenge in visuolinguistic models may lie in fusing visual and
textual representations, rather than in compositional language understanding.
We release our annotation and code at
https://github.com/ajd12342/why-winoground-hard ."
Can SAM Segment Polyps?,0.983868,"Recently, Meta AI Research releases a general Segment Anything Model (SAM),
which has demonstrated promising performance in several segmentation tasks. As
we know, polyp segmentation is a fundamental task in the medical imaging field,
which plays a critical role in the diagnosis and cure of colorectal cancer. In
particular, applying SAM to the polyp segmentation task is interesting. In this
report, we evaluate the performance of SAM in segmenting polyps, in which SAM
is under unprompted settings. We hope this report will provide insights to
advance this polyp segmentation field and promote more interesting works in the
future. This project is publicly at https://github.com/taozh2017/SAMPolyp."
Improved Masked Image Generation with Token-Critic,0.382738,"Non-autoregressive generative transformers recently demonstrated impressive
image generation performance, and orders of magnitude faster sampling than
their autoregressive counterparts. However, optimal parallel sampling from the
true joint distribution of visual tokens remains an open challenge. In this
paper we introduce Token-Critic, an auxiliary model to guide the sampling of a
non-autoregressive generative transformer. Given a masked-and-reconstructed
real image, the Token-Critic model is trained to distinguish which visual
tokens belong to the original image and which were sampled by the generative
transformer. During non-autoregressive iterative sampling, Token-Critic is used
to select which tokens to accept and which to reject and resample. Coupled with
Token-Critic, a state-of-the-art generative transformer significantly improves
its performance, and outperforms recent diffusion models and GANs in terms of
the trade-off between generated image quality and diversity, in the challenging
class-conditional ImageNet generation."
"Team QUST at SemEval-2023 Task 3: A Comprehensive Study of Monolingual and Multilingual Approaches for Detecting Online News Genre, Framing and Persuasion Techniques",0.516021,"This paper describes the participation of team QUST in the SemEval2023 task
3. The monolingual models are first evaluated with the under-sampling of the
majority classes in the early stage of the task. Then, the pre-trained
multilingual model is fine-tuned with a combination of the class weights and
the sample weights. Two different fine-tuning strategies, the task-agnostic and
the task-dependent, are further investigated. All experiments are conducted
under the 10-fold cross-validation, the multilingual approaches are superior to
the monolingual ones. The submitted system achieves the second best in Italian
and Spanish (zero-shot) in subtask-1."
Diffusion-SDF: Conditional Generative Modeling of Signed Distance Functions,0.996129,"Probabilistic diffusion models have achieved state-of-the-art results for
image synthesis, inpainting, and text-to-image tasks. However, they are still
in the early stages of generating complex 3D shapes. This work proposes
Diffusion-SDF, a generative model for shape completion, single-view
reconstruction, and reconstruction of real-scanned point clouds. We use neural
signed distance functions (SDFs) as our 3D representation to parameterize the
geometry of various signals (e.g., point clouds, 2D images) through neural
networks. Neural SDFs are implicit functions and diffusing them amounts to
learning the reversal of their neural network weights, which we solve using a
custom modulation module. Extensive experiments show that our method is capable
of both realistic unconditional generation and conditional generation from
partial inputs. This work expands the domain of diffusion models from learning
2D, explicit representations, to 3D, implicit representations."
Deep Surface Reconstruction from Point Clouds with Visibility Information,0.303985,"Most current neural networks for reconstructing surfaces from point clouds
ignore sensor poses and only operate on raw point locations. Sensor visibility,
however, holds meaningful information regarding space occupancy and surface
orientation. In this paper, we present two simple ways to augment raw point
clouds with visibility information, so it can directly be leveraged by surface
reconstruction networks with minimal adaptation. Our proposed modifications
consistently improve the accuracy of generated surfaces as well as the
generalization ability of the networks to unseen shape domains. Our code and
data is available at https://github.com/raphaelsulzer/dsrv-data."
VL-BEiT: Generative Vision-Language Pretraining,0.502403,"We introduce a vision-language foundation model called VL-BEiT, which is a
bidirectional multimodal Transformer learned by generative pretraining. Our
minimalist solution conducts masked prediction on both monomodal and multimodal
data with a shared Transformer. Specifically, we perform masked vision-language
modeling on image-text pairs, masked language modeling on texts, and masked
image modeling on images. VL-BEiT is learned from scratch with one unified
pretraining task, one shared backbone, and one-stage training. Our method is
conceptually simple and empirically effective. Experimental results show that
VL-BEiT obtains strong results on various vision-language benchmarks, such as
visual question answering, visual reasoning, and image-text retrieval.
Moreover, our method learns transferable visual features, achieving competitive
performance on image classification, and semantic segmentation."
Legal Case Document Summarization: Extractive and Abstractive Methods and their Evaluation,0.99341,"Summarization of legal case judgement documents is a challenging problem in
Legal NLP. However, not much analyses exist on how different families of
summarization models (e.g., extractive vs. abstractive) perform when applied to
legal case documents. This question is particularly important since many recent
transformer-based abstractive summarization models have restrictions on the
number of input tokens, and legal documents are known to be very long. Also, it
is an open question on how best to evaluate legal case document summarization
systems. In this paper, we carry out extensive experiments with several
extractive and abstractive summarization methods (both supervised and
unsupervised) over three legal summarization datasets that we have developed.
Our analyses, that includes evaluation by law practitioners, lead to several
interesting insights on legal summarization in specific and long document
summarization in general."
A Continual Learning Framework for Adaptive Defect Classification and Inspection,0.205678,"Machine-vision-based defect classification techniques have been widely
adopted for automatic quality inspection in manufacturing processes. This
article describes a general framework for classifying defects from high volume
data batches with efficient inspection of unlabelled samples. The concept is to
construct a detector to identify new defect types, send them to the inspection
station for labelling, and dynamically update the classifier in an efficient
manner that reduces both storage and computational needs imposed by data
samples of previously observed batches. Both a simulation study on image
classification and a case study on surface defect detection via 3D point clouds
are performed to demonstrate the effectiveness of the proposed method."
L3Cube-HindBERT and DevBERT: Pre-Trained BERT Transformer models for Devanagari based Hindi and Marathi Languages,0.545801,"The monolingual Hindi BERT models currently available on the model hub do not
perform better than the multi-lingual models on downstream tasks. We present
L3Cube-HindBERT, a Hindi BERT model pre-trained on Hindi monolingual corpus.
Further, since Indic languages, Hindi and Marathi share the Devanagari script,
we train a single model for both languages. We release DevBERT, a Devanagari
BERT model trained on both Marathi and Hindi monolingual datasets. We evaluate
these models on downstream Hindi and Marathi text classification and named
entity recognition tasks. The HindBERT and DevBERT-based models show
significant improvements over multi-lingual MuRIL, IndicBERT, and XLM-R. Based
on these observations we also release monolingual BERT models for other Indic
languages Kannada, Telugu, Malayalam, Tamil, Gujarati, Assamese, Odia, Bengali,
and Punjabi. These models are shared at https://huggingface.co/l3cube-pune ."
LoRAShear: Efficient Large Language Model Structured Pruning and Knowledge Recovery,0.643008,"Large Language Models (LLMs) have transformed the landscape of artificial
intelligence, while their enormous size presents significant challenges in
terms of computational costs. We introduce LoRAShear, a novel efficient
approach to structurally prune LLMs and recover knowledge. Given general LLMs,
LoRAShear at first creates the dependency graphs over LoRA modules to discover
minimally removal structures and analyze the knowledge distribution. It then
proceeds progressive structured pruning on LoRA adaptors and enables inherent
knowledge transfer to better preserve the information in the redundant
structures. To recover the lost knowledge during pruning, LoRAShear
meticulously studies and proposes a dynamic fine-tuning schemes with dynamic
data adaptors to effectively narrow down the performance gap to the full
models. Numerical results demonstrate that by only using one GPU within a
couple of GPU days, LoRAShear effectively reduced footprint of LLMs by 20% with
only 1.0% performance degradation and significantly outperforms
state-of-the-arts. The source code will be available at
https://github.com/microsoft/lorashear."
Frustratingly Simple but Effective Zero-shot Detection and Segmentation: Analysis and a Strong Baseline,0.272519,"Methods for object detection and segmentation often require abundant
instance-level annotations for training, which are time-consuming and expensive
to collect. To address this, the task of zero-shot object detection (or
segmentation) aims at learning effective methods for identifying and localizing
object instances for the categories that have no supervision available.
Constructing architectures for these tasks requires choosing from a myriad of
design options, ranging from the form of the class encoding used to transfer
information from seen to unseen categories, to the nature of the function being
optimized for learning. In this work, we extensively study these design
choices, and carefully construct a simple yet extremely effective zero-shot
recognition method. Through extensive experiments on the MSCOCO dataset on
object detection and segmentation, we highlight that our proposed method
outperforms existing, considerably more complex, architectures. Our findings
and method, which we propose as a competitive future baseline, point towards
the need to revisit some of the recent design trends in zero-shot detection /
segmentation."
A Summary of the ALQAC 2021 Competition,0.736064,"We summarize the evaluation of the first Automated Legal Question Answering
Competition (ALQAC 2021). The competition this year contains three tasks, which
aims at processing the statute law document, which are Legal Text Information
Retrieval (Task 1), Legal Text Entailment Prediction (Task 2), and Legal Text
Question Answering (Task 3). The final goal of these tasks is to build a system
that can automatically determine whether a particular statement is lawful.
There is no limit to the approaches of the participating teams. This year,
there are 5 teams participating in Task 1, 6 teams participating in Task 2, and
5 teams participating in Task 3. There are in total 36 runs submitted to the
organizer. In this paper, we summarize each team's approaches, official
results, and some discussion about the competition. Only results of the teams
who successfully submit their approach description paper are reported in this
paper."
A Causal Framework to Quantify the Robustness of Mathematical Reasoning with Language Models,0.612578,"We have recently witnessed a number of impressive results on hard
mathematical reasoning problems with language models. At the same time, the
robustness of these models has also been called into question; recent works
have shown that models can rely on shallow patterns in the problem description
when generating a solution. Building on the idea of behavioral testing, we
propose a novel framework, which pins down the causal effect of various factors
in the input, e.g., the surface form of the problem text, the operands, and
math operators on the output solution. By grounding the behavioral analysis in
a causal graph describing an intuitive reasoning process, we study the behavior
of language models in terms of robustness and sensitivity to direct
interventions in the input space. We apply our framework on a test bed of math
word problems. Our analysis shows that robustness does not appear to
continuously improve as a function of size, but the GPT-3 Davinci models (175B)
achieve a dramatic improvement in both robustness and sensitivity compared to
all other GPT variants."
Controllable 3D Generative Adversarial Face Model via Disentangling Shape and Appearance,0.403673,"3D face modeling has been an active area of research in computer vision and
computer graphics, fueling applications ranging from facial expression transfer
in virtual avatars to synthetic data generation. Existing 3D deep learning
generative models (e.g., VAE, GANs) allow generating compact face
representations (both shape and texture) that can model non-linearities in the
shape and appearance space (e.g., scatter effects, specularities, etc.).
However, they lack the capability to control the generation of subtle
expressions. This paper proposes a new 3D face generative model that can
decouple identity and expression and provides granular control over
expressions. In particular, we propose using a pair of supervised auto-encoder
and generative adversarial networks to produce high-quality 3D faces, both in
terms of appearance and shape. Experimental results in the generation of 3D
faces learned with holistic expression labels, or Action Unit labels, show how
we can decouple identity and expression; gaining fine-control over expressions
while preserving identity."
Continual Knowledge Distillation for Neural Machine Translation,0.0848149,"While many parallel corpora are not publicly accessible for data copyright,
data privacy and competitive differentiation reasons, trained translation
models are increasingly available on open platforms. In this work, we propose a
method called continual knowledge distillation to take advantage of existing
translation models to improve one model of interest. The basic idea is to
sequentially transfer knowledge from each trained model to the distilled model.
Extensive experiments on Chinese-English and German-English datasets show that
our method achieves significant and consistent improvements over strong
baselines under both homogeneous and heterogeneous trained model settings and
is robust to malicious models."
Fake News and Hate Speech: Language in Common,0.0378512,"In this paper we raise the research question of whether fake news and hate
speech spreaders share common patterns in language. We compute a novel index,
the ingroup vs outgroup index, in three different datasets and we show that
both phenomena share an ""us vs them"" narrative."
Testing the Reliability of ChatGPT for Text Annotation and Classification: A Cautionary Remark,0.994129,"Recent studies have demonstrated promising potential of ChatGPT for various
text annotation and classification tasks. However, ChatGPT is non-deterministic
which means that, as with human coders, identical input can lead to different
outputs. Given this, it seems appropriate to test the reliability of ChatGPT.
Therefore, this study investigates the consistency of ChatGPT's zero-shot
capabilities for text annotation and classification, focusing on different
model parameters, prompt variations, and repetitions of identical inputs. Based
on the real-world classification task of differentiating website texts into
news and not news, results show that consistency in ChatGPT's classification
output can fall short of scientific thresholds for reliability. For example,
even minor wording alterations in prompts or repeating the identical input can
lead to varying outputs. Although pooling outputs from multiple repetitions can
improve reliability, this study advises caution when using ChatGPT for
zero-shot text annotation and underscores the need for thorough validation,
such as comparison against human-annotated data. The unsupervised application
of ChatGPT for text annotation and classification is not recommended."
Rule Mining over Knowledge Graphs via Reinforcement Learning,0.487779,"Knowledge graphs (KGs) are an important source repository for a wide range of
applications and rule mining from KGs recently attracts wide research interest
in the KG-related research community. Many solutions have been proposed for the
rule mining from large-scale KGs, which however are limited in the inefficiency
of rule generation and ineffectiveness of rule evaluation. To solve these
problems, in this paper we propose a generation-then-evaluation rule mining
approach guided by reinforcement learning. Specifically, a two-phased framework
is designed. The first phase aims to train a reinforcement learning agent for
rule generation from KGs, and the second is to utilize the value function of
the agent to guide the step-by-step rule generation. We conduct extensive
experiments on several datasets and the results prove that our rule mining
solution achieves state-of-the-art performance in terms of efficiency and
effectiveness."
mSLAM: Massively multilingual joint pre-training for speech and text,0.998731,"We present mSLAM, a multilingual Speech and LAnguage Model that learns
cross-lingual cross-modal representations of speech and text by pre-training
jointly on large amounts of unlabeled speech and text in multiple languages.
mSLAM combines w2v-BERT pre-training on speech with SpanBERT pre-training on
character-level text, along with Connectionist Temporal Classification (CTC)
losses on paired speech and transcript data, to learn a single model capable of
learning from and representing both speech and text signals in a shared
representation space. We evaluate mSLAM on several downstream speech
understanding tasks and find that joint pre-training with text improves quality
on speech translation, speech intent classification and speech language-ID
while being competitive on multilingual ASR, when compared against speech-only
pre-training. Our speech translation model demonstrates zero-shot text
translation without seeing any text translation data, providing evidence for
cross-modal alignment of representations. mSLAM also benefits from multi-modal
fine-tuning, further improving the quality of speech translation by directly
leveraging text translation data during the fine-tuning process. Our empirical
analysis highlights several opportunities and challenges arising from
large-scale multimodal pre-training, suggesting directions for future research."
On the cross-lingual transferability of multilingual prototypical models across NLU tasks,0.41017,"Supervised deep learning-based approaches have been applied to task-oriented
dialog and have proven to be effective for limited domain and language
applications when a sufficient number of training examples are available. In
practice, these approaches suffer from the drawbacks of domain-driven design
and under-resourced languages. Domain and language models are supposed to grow
and change as the problem space evolves. On one hand, research on transfer
learning has demonstrated the cross-lingual ability of multilingual
Transformers-based models to learn semantically rich representations. On the
other, in addition to the above approaches, meta-learning have enabled the
development of task and language learning algorithms capable of far
generalization. Through this context, this article proposes to investigate the
cross-lingual transferability of using synergistically few-shot learning with
prototypical neural networks and multilingual Transformers-based models.
Experiments in natural language understanding tasks on MultiATIS++ corpus shows
that our approach substantially improves the observed transfer learning
performances between the low and the high resource languages. More generally
our approach confirms that the meaningful latent space learned in a given
language can be can be generalized to unseen and under-resourced ones using
meta-learning."
Evaluating Unsupervised Text Classification: Zero-shot and Similarity-based Approaches,0.64862,"Text classification of unseen classes is a challenging Natural Language
Processing task and is mainly attempted using two different types of
approaches. Similarity-based approaches attempt to classify instances based on
similarities between text document representations and class description
representations. Zero-shot text classification approaches aim to generalize
knowledge gained from a training task by assigning appropriate labels of
unknown classes to text documents. Although existing studies have already
investigated individual approaches to these categories, the experiments in
literature do not provide a consistent comparison. This paper addresses this
gap by conducting a systematic evaluation of different similarity-based and
zero-shot approaches for text classification of unseen classes. Different
state-of-the-art approaches are benchmarked on four text classification
datasets, including a new dataset from the medical domain. Additionally, novel
SimCSE and SBERT-based baselines are proposed, as other baselines used in
existing work yield weak classification results and are easily outperformed.
Finally, the novel similarity-based Lbl2TransformerVec approach is presented,
which outperforms previous state-of-the-art approaches in unsupervised text
classification. Our experiments show that similarity-based approaches
significantly outperform zero-shot approaches in most cases. Additionally,
using SimCSE or SBERT embeddings instead of simpler text representations
increases similarity-based classification results even further."
SRFormer: Permuted Self-Attention for Single Image Super-Resolution,0.932902,"Previous works have shown that increasing the window size for
Transformer-based image super-resolution models (e.g., SwinIR) can
significantly improve the model performance but the computation overhead is
also considerable. In this paper, we present SRFormer, a simple but novel
method that can enjoy the benefit of large window self-attention but introduces
even less computational burden. The core of our SRFormer is the permuted
self-attention (PSA), which strikes an appropriate balance between the channel
and spatial information for self-attention. Our PSA is simple and can be easily
applied to existing super-resolution networks based on window self-attention.
Without any bells and whistles, we show that our SRFormer achieves a 33.86dB
PSNR score on the Urban100 dataset, which is 0.46dB higher than that of SwinIR
but uses fewer parameters and computations. We hope our simple and effective
approach can serve as a useful tool for future research in super-resolution
model design."
MASALA: Modelling and Analysing the Semantics of Adpositions in Linguistic Annotation of Hindi,0.110732,"We present a completed, publicly available corpus of annotated semantic
relations of adpositions and case markers in Hindi. We used the multilingual
SNACS annotation scheme, which has been applied to a variety of typologically
diverse languages. Building on past work examining linguistic problems in SNACS
annotation, we use language models to attempt automatic labelling of SNACS
supersenses in Hindi and achieve results competitive with past work on English.
We look towards upstream applications in semantic role labelling and extension
to related languages such as Gujarati."
FewGAN: Generating from the Joint Distribution of a Few Images,0.0269612,"We introduce FewGAN, a generative model for generating novel, high-quality
and diverse images whose patch distribution lies in the joint patch
distribution of a small number of N>1 training samples. The method is, in
essence, a hierarchical patch-GAN that applies quantization at the first coarse
scale, in a similar fashion to VQ-GAN, followed by a pyramid of residual fully
convolutional GANs at finer scales. Our key idea is to first use quantization
to learn a fixed set of patch embeddings for training images. We then use a
separate set of side images to model the structure of generated images using an
autoregressive model trained on the learned patch embeddings of training
images. Using quantization at the coarsest scale allows the model to generate
both conditional and unconditional novel images. Subsequently, a patch-GAN
renders the fine details, resulting in high-quality images. In an extensive set
of experiments, it is shown that FewGAN outperforms baselines both
quantitatively and qualitatively."
GraphFit: Learning Multi-scale Graph-Convolutional Representation for Point Cloud Normal Estimation,0.838993,"We propose a precise and efficient normal estimation method that can deal
with noise and nonuniform density for unstructured 3D point clouds. Unlike
existing approaches that directly take patches and ignore the local
neighborhood relationships, which make them susceptible to challenging regions
such as sharp edges, we propose to learn graph convolutional feature
representation for normal estimation, which emphasizes more local neighborhood
geometry and effectively encodes intrinsic relationships. Additionally, we
design a novel adaptive module based on the attention mechanism to integrate
point features with their neighboring features, hence further enhancing the
robustness of the proposed normal estimator against point density variations.
To make it more distinguishable, we introduce a multi-scale architecture in the
graph block to learn richer geometric features. Our method outperforms
competitors with the state-of-the-art accuracy on various benchmark datasets,
and is quite robust against noise, outliers, as well as the density variations."
Human-to-Robot Imitation in the Wild,0.877126,"We approach the problem of learning by watching humans in the wild. While
traditional approaches in Imitation and Reinforcement Learning are promising
for learning in the real world, they are either sample inefficient or are
constrained to lab settings. Meanwhile, there has been a lot of success in
processing passive, unstructured human data. We propose tackling this problem
via an efficient one-shot robot learning algorithm, centered around learning
from a third-person perspective. We call our method WHIRL: In-the-Wild Human
Imitating Robot Learning. WHIRL extracts a prior over the intent of the human
demonstrator, using it to initialize our agent's policy. We introduce an
efficient real-world policy learning scheme that improves using interactions.
Our key contributions are a simple sampling-based policy optimization approach,
a novel objective function for aligning human and robot videos as well as an
exploration method to boost sample efficiency. We show one-shot generalization
and success in real-world settings, including 20 different manipulation tasks
in the wild. Videos and talk at https://human2robot.github.io"
NL2INTERFACE: Interactive Visualization Interface Generation from Natural Language Queries,0.609083,"We develop NL2INTERFACE to explore the potential of generating usable
interactive multi-visualization interfaces from natural language queries. With
NL2INTERFACE, users can directly write natural language queries to
automatically generate a fully interactive multi-visualization interface
without any extra effort of learning a tool or programming language. Further,
users can interact with the interfaces to easily transform the data and quickly
see the results in the visualizations."
How Many Demonstrations Do You Need for In-context Learning?,0.468882,"Large language models (LLMs) are capable to perform complex reasoning by
in-context learning (ICL) when provided with a few input-output demonstrations
(demos) and more powerful when intermediate reasoning steps (""chain of thoughts
(CoT)"") of the demos are given. Is it necessary to use multi-demo in ICL? In
this paper, we study ICL using fewer demos for each test query on the tasks
in~\cite{wei2022chain}. Surprisingly, we do not observe significant degradation
when using only one randomly chosen demo. To study this phenomenon, for each
test query, we categorize demos into ""correct demos"" leading to the correct
answer, and ""wrong demos"" resulting in wrong answers. Our analysis reveals an
inherent bias in those widely studied datasets: most demos are correct for a
majority of test queries, which explains the good performance of using one
random demo. Moreover, ICL (with and w/o CoT) using only one correct demo
significantly outperforms all-demo ICL adopted by most previous works,
indicating the weakness of LLMs in finding correct demo(s) for input queries,
which is difficult to evaluate on the biased datasets. Furthermore, we observe
a counterintuitive behavior of ICL using multi-demo, i.e., its accuracy
degrades(improves) when given more correct(wrong) demos. This implies that ICL
can be easily misguided by interference among demos and their spurious
correlations. Our analyses highlight several fundamental challenges that need
to be addressed in LLMs training, ICL, and benchmark design."
Uncertainty-Aware Bootstrap Learning for Joint Extraction on Distantly-Supervised Data,0.381859,"Jointly extracting entity pairs and their relations is challenging when
working on distantly-supervised data with ambiguous or noisy labels. To
mitigate such impact, we propose uncertainty-aware bootstrap learning, which is
motivated by the intuition that the higher uncertainty of an instance, the more
likely the model confidence is inconsistent with the ground truths.
Specifically, we first explore instance-level data uncertainty to create an
initial high-confident examples. Such subset serves as filtering noisy
instances and facilitating the model to converge fast at the early stage.
During bootstrap learning, we propose self-ensembling as a regularizer to
alleviate inter-model uncertainty produced by noisy labels. We further define
probability variance of joint tagging probabilities to estimate inner-model
parametric uncertainty, which is used to select and build up new reliable
training instances for the next iteration. Experimental results on two large
datasets reveal that our approach outperforms existing strong baselines and
related methods."
Offline Vehicle Routing Problem with Online Bookings: A Novel Problem Formulation with Applications to Paratransit,0.544739,"Vehicle routing problems (VRPs) can be divided into two major categories:
offline VRPs, which consider a given set of trip requests to be served, and
online VRPs, which consider requests as they arrive in real-time. Based on
discussions with public transit agencies, we identify a real-world problem that
is not addressed by existing formulations: booking trips with flexible pickup
windows (e.g., 3 hours) in advance (e.g., the day before) and confirming tight
pickup windows (e.g., 30 minutes) at the time of booking. Such a service model
is often required in paratransit service settings, where passengers typically
book trips for the next day over the phone. To address this gap between offline
and online problems, we introduce a novel formulation, the offline vehicle
routing problem with online bookings. This problem is very challenging
computationally since it faces the complexity of considering large sets of
requests -- similar to offline VRPs -- but must abide by strict constraints on
running time -- similar to online VRPs. To solve this problem, we propose a
novel computational approach, which combines an anytime algorithm with a
learning-based policy for real-time decisions. Based on a paratransit dataset
obtained from the public transit agency of Chattanooga, TN, we demonstrate that
our novel formulation and computational approach lead to significantly better
outcomes in this setting than existing algorithms."
Fusing Local Similarities for Retrieval-based 3D Orientation Estimation of Unseen Objects,0.536357,"In this paper, we tackle the task of estimating the 3D orientation of
previously-unseen objects from monocular images. This task contrasts with the
one considered by most existing deep learning methods which typically assume
that the testing objects have been observed during training. To handle the
unseen objects, we follow a retrieval-based strategy and prevent the network
from learning object-specific features by computing multi-scale local
similarities between the query image and synthetically-generated reference
images. We then introduce an adaptive fusion module that robustly aggregates
the local similarities into a global similarity score of pairwise images.
Furthermore, we speed up the retrieval process by developing a fast retrieval
strategy. Our experiments on the LineMOD, LineMOD-Occluded, and T-LESS datasets
show that our method yields a significantly better generalization to unseen
objects than previous works. Our code and pre-trained models are available at
https://sailor-z.github.io/projects/Unseen_Object_Pose.html."
"Read, Diagnose and Chat: Towards Explainable and Interactive LLMs-Augmented Depression Detection in Social Media",0.353029,"This paper proposes a new depression detection system based on LLMs that is
both interpretable and interactive. It not only provides a diagnosis, but also
diagnostic evidence and personalized recommendations based on natural language
dialogue with the user. We address challenges such as the processing of large
amounts of text and integrate professional diagnostic criteria. Our system
outperforms traditional methods across various settings and is demonstrated
through case studies."
Non-Standard Vietnamese Word Detection and Normalization for Text-to-Speech,0.010941,"Converting written texts into their spoken forms is an essential problem in
any text-to-speech (TTS) systems. However, building an effective text
normalization solution for a real-world TTS system face two main challenges:
(1) the semantic ambiguity of non-standard words (NSWs), e.g., numbers, dates,
ranges, scores, abbreviations, and (2) transforming NSWs into pronounceable
syllables, such as URL, email address, hashtag, and contact name. In this
paper, we propose a new two-phase normalization approach to deal with these
challenges. First, a model-based tagger is designed to detect NSWs. Then,
depending on NSW types, a rule-based normalizer expands those NSWs into their
final verbal forms. We conducted three empirical experiments for NSW detection
using Conditional Random Fields (CRFs), BiLSTM-CNN-CRF, and BERT-BiGRU-CRF
models on a manually annotated dataset including 5819 sentences extracted from
Vietnamese news articles. In the second phase, we propose a forward
lexicon-based maximum matching algorithm to split down the hashtag, email, URL,
and contact name. The experimental results of the tagging phase show that the
average F1 scores of the BiLSTM-CNN-CRF and CRF models are above 90.00%,
reaching the highest F1 of 95.00% with the BERT-BiGRU-CRF model. Overall, our
approach has low sentence error rates, at 8.15% with CRF and 7.11% with
BiLSTM-CNN-CRF taggers, and only 6.67% with BERT-BiGRU-CRF tagger."
Towards Robust k-Nearest-Neighbor Machine Translation,0.713316,"k-Nearest-Neighbor Machine Translation (kNN-MT) becomes an important research
direction of NMT in recent years. Its main idea is to retrieve useful key-value
pairs from an additional datastore to modify translations without updating the
NMT model. However, the underlying retrieved noisy pairs will dramatically
deteriorate the model performance. In this paper, we conduct a preliminary
study and find that this problem results from not fully exploiting the
prediction of the NMT model. To alleviate the impact of noise, we propose a
confidence-enhanced kNN-MT model with robust training. Concretely, we introduce
the NMT confidence to refine the modeling of two important components of
kNN-MT: kNN distribution and the interpolation weight. Meanwhile we inject two
types of perturbations into the retrieved pairs for robust training.
Experimental results on four benchmark datasets demonstrate that our model not
only achieves significant improvements over current kNN-MT models, but also
exhibits better robustness. Our code is available at
https://github.com/DeepLearnXMU/Robust-knn-mt."
Multi-dimensional Signal Recovery using Low-rank Deconvolution,0.0706259,"In this work we present Low-rank Deconvolution, a powerful framework for
low-level feature-map learning for efficient signal representation with
application to signal recovery. Its formulation in multi-linear algebra
inherits properties from convolutional sparse coding and low-rank approximation
methods as in this setting signals are decomposed in a set of filters convolved
with a set of low-rank tensors. We show its advantages by learning compressed
video representations and solving image in-painting problems."
"Measuring Non-Probabilistic Uncertainty: A cognitive, logical and computational assessment of known and unknown unknowns",0.0751794,"There are two reasons why uncertainty may not be adequately described by
Probability Theory. The first one is due to unique or nearly-unique events,
that either never realized or occurred too seldom for frequencies to be
reliably measured. The second one arises when one fears that something may
happen, that one is not even able to figure out, e.g., if one asks: ""Climate
change, financial crises, pandemic, war, what next?""
  In both cases, simple one-to-one cognitive maps between available
alternatives and possible consequences eventually melt down. However, such
destructions reflect into the changing narratives of business executives,
employees and other stakeholders in specific, identifiable and differential
ways. In particular, texts such as consultants' reports or letters to
shareholders can be analysed in order to detect the impact of both sorts of
uncertainty onto the causal relations that normally guide decision-making.
  We propose structural measures of cognitive maps as a means to measure
non-probabilistic uncertainty, eventually suggesting that automated text
analysis can greatly augment the possibilities offered by these techniques.
Prospective applications may concern actors ranging from statistical institutes
to businesses as well as the general public."
Semantic-Promoted Debiasing and Background Disambiguation for Zero-Shot Instance Segmentation,0.588244,"Zero-shot instance segmentation aims to detect and precisely segment objects
of unseen categories without any training samples. Since the model is trained
on seen categories, there is a strong bias that the model tends to classify all
the objects into seen categories. Besides, there is a natural confusion between
background and novel objects that have never shown up in training. These two
challenges make novel objects hard to be raised in the final instance
segmentation results. It is desired to rescue novel objects from background and
dominated seen categories. To this end, we propose D$^2$Zero with
Semantic-Promoted Debiasing and Background Disambiguation to enhance the
performance of Zero-shot instance segmentation. Semantic-promoted debiasing
utilizes inter-class semantic relationships to involve unseen categories in
visual feature training and learns an input-conditional classifier to conduct
dynamical classification based on the input image. Background disambiguation
produces image-adaptive background representation to avoid mistaking novel
objects for background. Extensive experiments show that we significantly
outperform previous state-of-the-art methods by a large margin, e.g., 16.86%
improvement on COCO. Project page: https://henghuiding.github.io/D2Zero/"
Putting People in Their Place: Affordance-Aware Human Insertion into Scenes,0.944966,"We study the problem of inferring scene affordances by presenting a method
for realistically inserting people into scenes. Given a scene image with a
marked region and an image of a person, we insert the person into the scene
while respecting the scene affordances. Our model can infer the set of
realistic poses given the scene context, re-pose the reference person, and
harmonize the composition. We set up the task in a self-supervised fashion by
learning to re-pose humans in video clips. We train a large-scale diffusion
model on a dataset of 2.4M video clips that produces diverse plausible poses
while respecting the scene context. Given the learned human-scene composition,
our model can also hallucinate realistic people and scenes when prompted
without conditioning and also enables interactive editing. A quantitative
evaluation shows that our method synthesizes more realistic human appearance
and more natural human-scene interactions than prior work."
DiffRoll: Diffusion-based Generative Music Transcription with Unsupervised Pretraining Capability,0.762513,"In this paper we propose a novel generative approach, DiffRoll, to tackle
automatic music transcription (AMT). Instead of treating AMT as a
discriminative task in which the model is trained to convert spectrograms into
piano rolls, we think of it as a conditional generative task where we train our
model to generate realistic looking piano rolls from pure Gaussian noise
conditioned on spectrograms. This new AMT formulation enables DiffRoll to
transcribe, generate and even inpaint music. Due to the classifier-free nature,
DiffRoll is also able to be trained on unpaired datasets where only piano rolls
are available. Our experiments show that DiffRoll outperforms its
discriminative counterpart by 19 percentage points (ppt.) and our ablation
studies also indicate that it outperforms similar existing methods by 4.8 ppt.
  Source code and demonstration are available https://sony.github.io/DiffRoll/."
Fine-grained building roof instance segmentation based on domain adapted pretraining and composite dual-backbone,0.468793,"The diversity of building architecture styles of global cities situated on
various landforms, the degraded optical imagery affected by clouds and shadows,
and the significant inter-class imbalance of roof types pose challenges for
designing a robust and accurate building roof instance segmentor. To address
these issues, we propose an effective framework to fulfill semantic
interpretation of individual buildings with high-resolution optical satellite
imagery. Specifically, the leveraged domain adapted pretraining strategy and
composite dual-backbone greatly facilitates the discriminative feature
learning. Moreover, new data augmentation pipeline, stochastic weight averaging
(SWA) training and instance segmentation based model ensemble in testing are
utilized to acquire additional performance boost. Experiment results show that
our approach ranks in the first place of the 2023 IEEE GRSS Data Fusion Contest
(DFC) Track 1 test phase ($mAP_{50}$:50.6\%). Note-worthily, we have also
explored the potential of multimodal data fusion with both optical satellite
imagery and SAR data."
TwinExplainer: Explaining Predictions of an Automotive Digital Twin,0.329873,"Vehicles are complex Cyber Physical Systems (CPS) that operate in a variety
of environments, and the likelihood of failure of one or more subsystems, such
as the engine, transmission, brakes, and fuel, can result in unscheduled
downtime and incur high maintenance or repair costs. In order to prevent these
issues, it is crucial to continuously monitor the health of various subsystems
and identify abnormal sensor channel behavior. Data-driven Digital Twin (DT)
systems are capable of such a task. Current DT technologies utilize various
Deep Learning (DL) techniques that are constrained by the lack of justification
or explanation for their predictions. This inability of these opaque systems
can influence decision-making and raises user trust concerns. This paper
presents a solution to this issue, where the TwinExplainer system, with its
three-layered architectural pipeline, explains the predictions of an automotive
DT. Such a system can assist automotive stakeholders in understanding the
global scale of the sensor channels and how they contribute towards generic DT
predictions. TwinExplainer can also visualize explanations for both normal and
abnormal local predictions computed by the DT."
CL-XABSA: Contrastive Learning for Cross-lingual Aspect-based Sentiment Analysis,0.538343,"As an extensive research in the field of natural language processing (NLP),
aspect-based sentiment analysis (ABSA) is the task of predicting the sentiment
expressed in a text relative to the corresponding aspect. Unfortunately, most
languages lack sufficient annotation resources, thus more and more recent
researchers focus on cross-lingual aspect-based sentiment analysis (XABSA).
However, most recent researches only concentrate on cross-lingual data
alignment instead of model alignment. To this end, we propose a novel
framework, CL-XABSA: Contrastive Learning for Cross-lingual Aspect-Based
Sentiment Analysis. Based on contrastive learning, we close the distance
between samples with the same label in different semantic spaces, thus
achieving a convergence of semantic spaces of different languages.
Specifically, we design two contrastive strategies, token level contrastive
learning of token embeddings (TL-CTE) and sentiment level contrastive learning
of token embeddings (SL-CTE), to regularize the semantic space of source and
target language to be more uniform. Since our framework can receive datasets in
multiple languages during training, our framework can be adapted not only for
XABSA task but also for multilingual aspect-based sentiment analysis (MABSA).
To further improve the performance of our model, we perform knowledge
distillation technology leveraging data from unlabeled target language. In the
distillation XABSA task, we further explore the comparative effectiveness of
different data (source dataset, translated dataset, and code-switched dataset).
The results demonstrate that the proposed method has a certain improvement in
the three tasks of XABSA, distillation XABSA and MABSA. For reproducibility,
our code for this paper is available at https://github.com/GKLMIP/CL-XABSA."
Exploring Speaker-Related Information in Spoken Language Understanding for Better Speaker Diarization,0.452244,"Speaker diarization(SD) is a classic task in speech processing and is crucial
in multi-party scenarios such as meetings and conversations. Current mainstream
speaker diarization approaches consider acoustic information only, which result
in performance degradation when encountering adverse acoustic conditions. In
this paper, we propose methods to extract speaker-related information from
semantic content in multi-party meetings, which, as we will show, can further
benefit speaker diarization. We introduce two sub-tasks, Dialogue Detection and
Speaker-Turn Detection, in which we effectively extract speaker information
from conversational semantics. We also propose a simple yet effective algorithm
to jointly model acoustic and semantic information and obtain
speaker-identified texts. Experiments on both AISHELL-4 and AliMeeting datasets
show that our method achieves consistent improvements over acoustic-only
speaker diarization systems."
Learning Eco-Driving Strategies at Signalized Intersections,0.602787,"Signalized intersections in arterial roads result in persistent vehicle
idling and excess accelerations, contributing to fuel consumption and CO2
emissions. There has thus been a line of work studying eco-driving control
strategies to reduce fuel consumption and emission levels at intersections.
However, methods to devise effective control strategies across a variety of
traffic settings remain elusive. In this paper, we propose a reinforcement
learning (RL) approach to learn effective eco-driving control strategies. We
analyze the potential impact of a learned strategy on fuel consumption, CO2
emission, and travel time and compare with naturalistic driving and model-based
baselines. We further demonstrate the generalizability of the learned policies
under mixed traffic scenarios. Simulation results indicate that scenarios with
100% penetration of connected autonomous vehicles (CAV) may yield as high as
18% reduction in fuel consumption and 25% reduction in CO2 emission levels
while even improving travel speed by 20%. Furthermore, results indicate that
even 25% CAV penetration can bring at least 50% of the total fuel and emission
reduction benefits."
The Undesirable Dependence on Frequency of Gender Bias Metrics Based on Word Embeddings,0.5704,"Numerous works use word embedding-based metrics to quantify societal biases
and stereotypes in texts. Recent studies have found that word embeddings can
capture semantic similarity but may be affected by word frequency. In this work
we study the effect of frequency when measuring female vs. male gender bias
with word embedding-based bias quantification methods. We find that Skip-gram
with negative sampling and GloVe tend to detect male bias in high frequency
words, while GloVe tends to return female bias in low frequency words. We show
these behaviors still exist when words are randomly shuffled. This proves that
the frequency-based effect observed in unshuffled corpora stems from properties
of the metric rather than from word associations. The effect is spurious and
problematic since bias metrics should depend exclusively on word co-occurrences
and not individual word frequencies. Finally, we compare these results with the
ones obtained with an alternative metric based on Pointwise Mutual Information.
We find that this metric does not show a clear dependence on frequency, even
though it is slightly skewed towards male bias across all frequencies."
Software Vulnerability Prediction Knowledge Transferring Between Programming Languages,0.215,"Developing automated and smart software vulnerability detection models has
been receiving great attention from both research and development communities.
One of the biggest challenges in this area is the lack of code samples for all
different programming languages. In this study, we address this issue by
proposing a transfer learning technique to leverage available datasets and
generate a model to detect common vulnerabilities in different programming
languages. We use C source code samples to train a Convolutional Neural Network
(CNN) model, then, we use Java source code samples to adopt and evaluate the
learned model. We use code samples from two benchmark datasets: NIST Software
Assurance Reference Dataset (SARD) and Draper VDISC dataset. The results show
that proposed model detects vulnerabilities in both C and Java codes with
average recall of 72\%. Additionally, we employ explainable AI to investigate
how much each feature contributes to the knowledge transfer mechanisms between
C and Java in the proposed model."
SoK: Differential Privacy on Graph-Structured Data,0.584724,"In this work, we study the applications of differential privacy (DP) in the
context of graph-structured data. We discuss the formulations of DP applicable
to the publication of graphs and their associated statistics as well as machine
learning on graph-based data, including graph neural networks (GNNs). The
formulation of DP in the context of graph-structured data is difficult, as
individual data points are interconnected (often non-linearly or sparsely).
This connectivity complicates the computation of individual privacy loss in
differentially private learning. The problem is exacerbated by an absence of a
single, well-established formulation of DP in graph settings. This issue
extends to the domain of GNNs, rendering private machine learning on
graph-structured data a challenging task. A lack of prior systematisation work
motivated us to study graph-based learning from a privacy perspective. In this
work, we systematise different formulations of DP on graphs, discuss challenges
and promising applications, including the GNN domain. We compare and separate
works into graph analysis tasks and graph learning tasks with GNNs. Finally, we
conclude our work with a discussion of open questions and potential directions
for further research in this area."
Hierarchical Collaborative Hyper-parameter Tuning,0.0636376,"Hyper-parameter Tuning is among the most critical stages in building machine
learning solutions. This paper demonstrates how multi-agent systems can be
utilized to develop a distributed technique for determining near-optimal values
for any arbitrary set of hyper-parameters in a machine learning model. The
proposed method employs a distributedly formed hierarchical agent-based
architecture for the cooperative searching procedure of tuning hyper-parameter
values. The presented generic model is used to develop a guided randomized
agent-based tuning technique, and its behavior is investigated in both machine
learning and global function optimization applications. According the empirical
results, the proposed model outperformed both of its underlying randomized
tuning strategies in terms of classification error and function evaluations,
notably in higher number of dimensions."
Memory-Guided Multi-View Multi-Domain Fake News Detection,0.988183,"The wide spread of fake news is increasingly threatening both individuals and
society. Great efforts have been made for automatic fake news detection on a
single domain (e.g., politics). However, correlations exist commonly across
multiple news domains, and thus it is promising to simultaneously detect fake
news of multiple domains. Based on our analysis, we pose two challenges in
multi-domain fake news detection: 1) domain shift, caused by the discrepancy
among domains in terms of words, emotions, styles, etc. 2) domain labeling
incompleteness, stemming from the real-world categorization that only outputs
one single domain label, regardless of topic diversity of a news piece. In this
paper, we propose a Memory-guided Multi-view Multi-domain Fake News Detection
Framework (M$^3$FEND) to address these two challenges. We model news pieces
from a multi-view perspective, including semantics, emotion, and style.
Specifically, we propose a Domain Memory Bank to enrich domain information
which could discover potential domain labels based on seen news pieces and
model domain characteristics. Then, with enriched domain information as input,
a Domain Adapter could adaptively aggregate discriminative information from
multiple views for news in various domains. Extensive offline experiments on
English and Chinese datasets demonstrate the effectiveness of M$^3$FEND, and
online tests verify its superiority in practice. Our code is available at
https://github.com/ICTMCG/M3FEND."
Can Open-Domain QA Reader Utilize External Knowledge Efficiently like Humans?,0.42332,"Recent state-of-the-art open-domain QA models are typically based on a two
stage retriever-reader approach in which the retriever first finds the relevant
knowledge/passages and the reader then leverages that to predict the answer.
Prior work has shown that the performance of the reader usually tends to
improve with the increase in the number of these passages. Thus,
state-of-the-art models use a large number of passages (e.g. 100) for
inference. While the reader in this approach achieves high prediction
performance, its inference is computationally very expensive. We humans, on the
other hand, use a more efficient strategy while answering: firstly, if we can
confidently answer the question using our already acquired knowledge then we do
not even use the external knowledge, and in the case when we do require
external knowledge, we don't read the entire knowledge at once, instead, we
only read that much knowledge that is sufficient to find the answer. Motivated
by this procedure, we ask a research question ""Can the open-domain QA reader
utilize external knowledge efficiently like humans without sacrificing the
prediction performance?""
  Driven by this question, we explore an approach that utilizes both
'closed-book' (leveraging knowledge already present in the model parameters)
and 'open-book' inference (leveraging external knowledge). Furthermore, instead
of using a large fixed number of passages for open-book inference, we
dynamically read the external knowledge in multiple 'knowledge iterations'.
Through comprehensive experiments on NQ and TriviaQA datasets, we demonstrate
that this dynamic reading approach improves both the 'inference efficiency' and
the 'prediction accuracy' of the reader. Comparing with the FiD reader, this
approach matches its accuracy by utilizing just 18.32% of its reader inference
cost and also outperforms it by achieving up to 55.10% accuracy on NQ Open."
UTNLP at SemEval-2022 Task 6: A Comparative Analysis of Sarcasm Detection Using Generative-based and Mutation-based Data Augmentation,0.0532168,"Sarcasm is a term that refers to the use of words to mock, irritate, or amuse
someone. It is commonly used on social media. The metaphorical and creative
nature of sarcasm presents a significant difficulty for sentiment analysis
systems based on affective computing. The methodology and results of our team,
UTNLP, in the SemEval-2022 shared task 6 on sarcasm detection are presented in
this paper. We put different models, and data augmentation approaches to the
test and report on which one works best. The tests begin with traditional
machine learning models and progress to transformer-based and attention-based
models. We employed data augmentation based on data mutation and data
generation. Using RoBERTa and mutation-based data augmentation, our best
approach achieved an F1-sarcastic of 0.38 in the competition's evaluation
phase. After the competition, we fixed our model's flaws and achieved an
F1-sarcastic of 0.414."
CNNs and Transformers Perceive Hybrid Images Similar to Humans,0.088686,"Hybrid images is a technique to generate images with two interpretations that
change as a function of viewing distance. It has been utilized to study
multiscale processing of images by the human visual system. Using 63,000 hybrid
images across 10 fruit categories, here we show that predictions of deep
learning vision models qualitatively matches with the human perception of these
images. Our results provide yet another evidence in support of the hypothesis
that Convolutional Neural Networks (CNNs) and Transformers are good at modeling
the feedforward sweep of information in the ventral stream of visual cortex.
Code and data is available at https://github.com/aliborji/hybrid_images.git."
Class Attention Transfer Based Knowledge Distillation,0.846371,"Previous knowledge distillation methods have shown their impressive
performance on model compression tasks, however, it is hard to explain how the
knowledge they transferred helps to improve the performance of the student
network. In this work, we focus on proposing a knowledge distillation method
that has both high interpretability and competitive performance. We first
revisit the structure of mainstream CNN models and reveal that possessing the
capacity of identifying class discriminative regions of input is critical for
CNN to perform classification. Furthermore, we demonstrate that this capacity
can be obtained and enhanced by transferring class activation maps. Based on
our findings, we propose class attention transfer based knowledge distillation
(CAT-KD). Different from previous KD methods, we explore and present several
properties of the knowledge transferred by our method, which not only improve
the interpretability of CAT-KD but also contribute to a better understanding of
CNN. While having high interpretability, CAT-KD achieves state-of-the-art
performance on multiple benchmarks. Code is available at:
https://github.com/GzyAftermath/CAT-KD."
Provable Benefits of Representational Transfer in Reinforcement Learning,0.441008,"We study the problem of representational transfer in RL, where an agent first
pretrains in a number of source tasks to discover a shared representation,
which is subsequently used to learn a good policy in a \emph{target task}. We
propose a new notion of task relatedness between source and target tasks, and
develop a novel approach for representational transfer under this assumption.
Concretely, we show that given generative access to source tasks, we can
discover a representation, using which subsequent linear RL techniques quickly
converge to a near-optimal policy in the target task.
  The sample complexity is close to knowing the ground truth features in the
target task, and comparable to prior representation learning results in the
source tasks. We complement our positive results with lower bounds without
generative access, and validate our findings with empirical evaluation on rich
observation MDPs that require deep exploration. In our experiments, we observe
a speed up in learning in the target by pre-training, and also validate the
need for generative access in source tasks."
CodeExp: Explanatory Code Document Generation,0.0194986,"Developing models that can automatically generate detailed code explanation
can greatly benefit software maintenance and programming education. However,
existing code-to-text generation models often produce only high-level summaries
of code that do not capture implementation-level choices essential for these
scenarios. To fill in this gap, we propose the code explanation generation
task. We first conducted a human study to identify the criteria for
high-quality explanatory docstring for code. Based on that, we collected and
refined a large-scale code docstring corpus and formulated automatic evaluation
metrics that best match human assessments. Finally, we present a multi-stage
fine-tuning strategy and baseline models for the task. Our experiments show
that (1) our refined training dataset lets models achieve better performance in
the explanation generation tasks compared to larger unrefined data (15x
larger), and (2) fine-tuned models can generate well-structured long docstrings
comparable to human-written ones. We envision our training dataset,
human-evaluation protocol, recommended metrics, and fine-tuning strategy can
boost future code explanation research. The code and annotated data are
available at https://github.com/subercui/CodeExp."
SpeechMatrix: A Large-Scale Mined Corpus of Multilingual Speech-to-Speech Translations,0.894775,"We present SpeechMatrix, a large-scale multilingual corpus of
speech-to-speech translations mined from real speech of European Parliament
recordings. It contains speech alignments in 136 language pairs with a total of
418 thousand hours of speech. To evaluate the quality of this parallel speech,
we train bilingual speech-to-speech translation models on mined data only and
establish extensive baseline results on EuroParl-ST, VoxPopuli and FLEURS test
sets. Enabled by the multilinguality of SpeechMatrix, we also explore
multilingual speech-to-speech translation, a topic which was addressed by few
other works. We also demonstrate that model pre-training and sparse scaling
using Mixture-of-Experts bring large gains to translation performance. The
mined data and models are freely available."
Understanding the Domain Gap in LiDAR Object Detection Networks,0.049866,"In order to make autonomous driving a reality, artificial neural networks
have to work reliably in the open-world. However, the open-world is vast and
continuously changing, so it is not technically feasible to collect and
annotate training datasets which accurately represent this domain. Therefore,
there are always domain gaps between training datasets and the open-world which
must be understood. In this work, we investigate the domain gaps between
high-resolution and low-resolution LiDAR sensors in object detection networks.
Using a unique dataset, which enables us to study sensor resolution domain gaps
independent of other effects, we show two distinct domain gaps - an inference
domain gap and a training domain gap. The inference domain gap is characterised
by a strong dependence on the number of LiDAR points per object, while the
training gap shows no such dependence. These fndings show that different
approaches are required to close these inference and training domain gaps."
SSN: Stockwell Scattering Network for SAR Image Change Detection,0.554084,"Recently, synthetic aperture radar (SAR) image change detection has become an
interesting yet challenging direction due to the presence of speckle noise.
Although both traditional and modern learning-driven methods attempted to
overcome this challenge, deep convolutional neural networks (DCNNs)-based
methods are still hindered by the lack of interpretability and the requirement
of large computation power. To overcome this drawback, wavelet scattering
network (WSN) and Fourier scattering network (FSN) are proposed. Combining
respective merits of WSN and FSN, we propose Stockwell scattering network (SSN)
based on Stockwell transform which is widely applied against noisy signals and
shows advantageous characteristics in speckle reduction. The proposed SSN
provides noise-resilient feature representation and obtains state-of-art
performance in SAR image change detection as well as high computational
efficiency. Experimental results on three real SAR image datasets demonstrate
the effectiveness of the proposed method."
In-BoXBART: Get Instructions into Biomedical Multi-Task Learning,0.402515,"Single-task models have proven pivotal in solving specific tasks; however,
they have limitations in real-world applications where multi-tasking is
necessary and domain shifts are exhibited. Recently, instructional prompts have
shown significant improvement towards multi-task generalization; however, the
effect of instructional prompts and Multi-Task Learning (MTL) has not been
systematically studied in the biomedical domain. Motivated by this, this paper
explores the impact of instructional prompts for biomedical MTL. We introduce
the BoX, a collection of 32 instruction tasks for Biomedical NLP across (X)
various categories. Using this meta-dataset, we propose a unified model termed
In-BoXBART, that can jointly learn all tasks of the BoX without any
task-specific modules. To the best of our knowledge, this is the first attempt
to propose a unified model in the biomedical domain and use instructions to
achieve generalization across several biomedical tasks. Experimental results
indicate that the proposed model: 1) outperforms the single-task baseline by
~3% and multi-task (without instruction) baseline by ~18% on an average, and 2)
shows ~23% improvement compared to the single-task baseline in few-shot
learning (i.e., 32 instances per task) on an average. Our analysis indicates
that there is significant room for improvement across tasks in the BoX,
implying the scope for future research direction."
SATIN: A Multi-Task Metadataset for Classifying Satellite Imagery using Vision-Language Models,0.83607,"Interpreting remote sensing imagery enables numerous downstream applications
ranging from land-use planning to deforestation monitoring. Robustly
classifying this data is challenging due to the Earth's geographic diversity.
While many distinct satellite and aerial image classification datasets exist,
there is yet to be a benchmark curated that suitably covers this diversity. In
this work, we introduce SATellite ImageNet (SATIN), a metadataset curated from
27 existing remotely sensed datasets, and comprehensively evaluate the
zero-shot transfer classification capabilities of a broad range of
vision-language (VL) models on SATIN. We find SATIN to be a challenging
benchmark-the strongest method we evaluate achieves a classification accuracy
of 52.0%. We provide a $\href{https://satinbenchmark.github.io}{\text{public
leaderboard}}$ to guide and track the progress of VL models in this important
domain."
SSC-RS: Elevate LiDAR Semantic Scene Completion with Representation Separation and BEV Fusion,0.38652,"Semantic scene completion (SSC) jointly predicts the semantics and geometry
of the entire 3D scene, which plays an essential role in 3D scene understanding
for autonomous driving systems. SSC has achieved rapid progress with the help
of semantic context in segmentation. However, how to effectively exploit the
relationships between the semantic context in semantic segmentation and
geometric structure in scene completion remains under exploration. In this
paper, we propose to solve outdoor SSC from the perspective of representation
separation and BEV fusion. Specifically, we present the network, named SSC-RS,
which uses separate branches with deep supervision to explicitly disentangle
the learning procedure of the semantic and geometric representations. And a BEV
fusion network equipped with the proposed Adaptive Representation Fusion (ARF)
module is presented to aggregate the multi-scale features effectively and
efficiently. Due to the low computational burden and powerful representation
ability, our model has good generality while running in real-time. Extensive
experiments on SemanticKITTI demonstrate our SSC-RS achieves state-of-the-art
performance."
Cerebral Palsy Prediction with Frequency Attention Informed Graph Convolutional Networks,0.637302,"Early diagnosis and intervention are clinically considered the paramount part
of treating cerebral palsy (CP), so it is essential to design an efficient and
interpretable automatic prediction system for CP. We highlight a significant
difference between CP infants' frequency of human movement and that of the
healthy group, which improves prediction performance. However, the existing
deep learning-based methods did not use the frequency information of infants'
movement for CP prediction. This paper proposes a frequency attention informed
graph convolutional network and validates it on two consumer-grade RGB video
datasets, namely MINI-RGBD and RVI-38 datasets. Our proposed frequency
attention module aids in improving both classification performance and system
interpretability. In addition, we design a frequency-binning method that
retains the critical frequency of the human joint position data while filtering
the noise. Our prediction performance achieves state-of-the-art research on
both datasets. Our work demonstrates the effectiveness of frequency information
in supporting the prediction of CP non-intrusively and provides a way for
supporting the early diagnosis of CP in the resource-limited regions where the
clinical resources are not abundant."
A Hierarchical Encoding-Decoding Scheme for Abstractive Multi-document Summarization,0.337581,"Pre-trained language models (PLMs) have achieved outstanding achievements in
abstractive single-document summarization (SDS). However, such benefits may not
fully extend to multi-document summarization (MDS), where the handling of
cross-document information is more complex. Previous works either design new
MDS architectures or apply PLMs bluntly with concatenated source documents as a
reformulated SDS task. While the former does not utilize previous pre-training
efforts and may not generalize well across different domains, the latter may
not sufficiently attend to the intricate cross-document relationships unique to
MDS tasks. Instead, we enforce hierarchy on both the encoder and decoder to
better utilize a PLM to facilitate multi-document interactions for the MDS
task. Across 10 MDS benchmarks from various domains, our method outperforms or
is competitive with the previous best models, including those with additional
MDS pre-training or with more parameters. It outperforms its corresponding PLM
backbone by up to 3 Rouge-L and is favored by humans."
Video2StyleGAN: Disentangling Local and Global Variations in a Video,0.0895362,"Image editing using a pretrained StyleGAN generator has emerged as a powerful
paradigm for facial editing, providing disentangled controls over age,
expression, illumination, etc. However, the approach cannot be directly adopted
for video manipulations. We hypothesize that the main missing ingredient is the
lack of fine-grained and disentangled control over face location, face pose,
and local facial expressions. In this work, we demonstrate that such a
fine-grained control is indeed achievable using pretrained StyleGAN by working
across multiple (latent) spaces (namely, the positional space, the W+ space,
and the S space) and combining the optimization results across the multiple
spaces. Building on this enabling component, we introduce Video2StyleGAN that
takes a target image and driving video(s) to reenact the local and global
locations and expressions from the driving video in the identity of the target
image. We evaluate the effectiveness of our method over multiple challenging
scenarios and demonstrate clear improvements over alternative approaches."
ZeroForge: Feedforward Text-to-Shape Without 3D Supervision,0.0579269,"Current state-of-the-art methods for text-to-shape generation either require
supervised training using a labeled dataset of pre-defined 3D shapes, or
perform expensive inference-time optimization of implicit neural
representations. In this work, we present ZeroForge, an approach for zero-shot
text-to-shape generation that avoids both pitfalls. To achieve open-vocabulary
shape generation, we require careful architectural adaptation of existing
feed-forward approaches, as well as a combination of data-free CLIP-loss and
contrastive losses to avoid mode collapse. Using these techniques, we are able
to considerably expand the generative ability of existing feed-forward
text-to-shape models such as CLIP-Forge. We support our method via extensive
qualitative and quantitative evaluations"
AutoDroid: LLM-powered Task Automation in Android,0.87099,"Mobile task automation is an attractive technique that aims to enable
voice-based hands-free user interaction with smartphones. However, existing
approaches suffer from poor scalability due to the limited language
understanding ability and the non-trivial manual efforts required from
developers or end-users. The recent advance of large language models (LLMs) in
language understanding and reasoning inspires us to rethink the problem from a
model-centric perspective, where task preparation, comprehension, and execution
are handled by a unified language model. In this work, we introduce AutoDroid,
a mobile task automation system capable of handling arbitrary tasks on any
Android application without manual efforts. The key insight is to combine the
commonsense knowledge of LLMs and domain-specific knowledge of apps through
automated dynamic analysis. The main components include a functionality-aware
UI representation method that bridges the UI with the LLM, exploration-based
memory injection techniques that augment the app-specific domain knowledge of
LLM, and a multi-granularity query optimization module that reduces the cost of
model inference. We integrate AutoDroid with off-the-shelf LLMs including
online GPT-4/GPT-3.5 and on-device Vicuna, and evaluate its performance on a
new benchmark for memory-augmented Android task automation with 158 common
tasks. The results demonstrated that AutoDroid is able to precisely generate
actions with an accuracy of 90.9%, and complete tasks with a success rate of
71.3%, outperforming the GPT-4-powered baselines by 36.4% and 39.7%. The demo,
benchmark suites, and source code of AutoDroid will be released at
url{https://autodroid-sys.github.io/}."
Why Adversarial Training of ReLU Networks Is Difficult?,0.0986373,"This paper mathematically derives an analytic solution of the adversarial
perturbation on a ReLU network, and theoretically explains the difficulty of
adversarial training. Specifically, we formulate the dynamics of the
adversarial perturbation generated by the multi-step attack, which shows that
the adversarial perturbation tends to strengthen eigenvectors corresponding to
a few top-ranked eigenvalues of the Hessian matrix of the loss w.r.t. the
input. We also prove that adversarial training tends to strengthen the
influence of unconfident input samples with large gradient norms in an
exponential manner. Besides, we find that adversarial training strengthens the
influence of the Hessian matrix of the loss w.r.t. network parameters, which
makes the adversarial training more likely to oscillate along directions of a
few samples, and boosts the difficulty of adversarial training. Crucially, our
proofs provide a unified explanation for previous findings in understanding
adversarial training."
CORE: Consistent Representation Learning for Face Forgery Detection,0.694656,"Face manipulation techniques develop rapidly and arouse widespread public
concerns. Despite that vanilla convolutional neural networks achieve acceptable
performance, they suffer from the overfitting issue. To relieve this issue,
there is a trend to introduce some erasing-based augmentations. We find that
these methods indeed attempt to implicitly induce more consistent
representations for different augmentations via assigning the same label for
different augmented images. However, due to the lack of explicit
regularization, the consistency between different representations is less
satisfactory. Therefore, we constrain the consistency of different
representations explicitly and propose a simple yet effective framework,
COnsistent REpresentation Learning (CORE). Specifically, we first capture the
different representations with different augmentations, then regularize the
cosine distance of the representations to enhance the consistency. Extensive
experiments (in-dataset and cross-dataset) demonstrate that CORE performs
favorably against state-of-the-art face forgery detection methods."
Towards Open-Domain Topic Classification,0.669927,"We introduce an open-domain topic classification system that accepts
user-defined taxonomy in real time. Users will be able to classify a text
snippet with respect to any candidate labels they want, and get instant
response from our web interface. To obtain such flexibility, we build the
backend model in a zero-shot way. By training on a new dataset constructed from
Wikipedia, our label-aware text classifier can effectively utilize implicit
knowledge in the pretrained language model to handle labels it has never seen
before. We evaluate our model across four datasets from various domains with
different label sets. Experiments show that the model significantly improves
over existing zero-shot baselines in open-domain scenarios, and performs
competitively with weakly-supervised models trained on in-domain data."
AdaTest:Reinforcement Learning and Adaptive Sampling for On-chip Hardware Trojan Detection,0.69306,"This paper proposes AdaTest, a novel adaptive test pattern generation
framework for efficient and reliable Hardware Trojan (HT) detection. HT is a
backdoor attack that tampers with the design of victim integrated circuits
(ICs). AdaTest improves the existing HT detection techniques in terms of
scalability and accuracy of detecting smaller Trojans in the presence of noise
and variations. To achieve high trigger coverage, AdaTest leverages
Reinforcement Learning (RL) to produce a diverse set of test inputs.
Particularly, we progressively generate test vectors with high reward values in
an iterative manner. In each iteration, the test set is evaluated and
adaptively expanded as needed. Furthermore, AdaTest integrates adaptive
sampling to prioritize test samples that provide more information for HT
detection, thus reducing the number of samples while improving the sample
quality for faster exploration. We develop AdaTest with a Software/Hardware
co-design principle and provide an optimized on-chip architecture solution.
AdaTest's architecture minimizes the hardware overhead in two ways:(i)
Deploying circuit emulation on programmable hardware to accelerate reward
evaluation of the test input; (ii) Pipelining each computation stage in AdaTest
by automatically constructing auxiliary circuit for test input generation,
reward evaluation, and adaptive sampling. We evaluate AdaTest's performance on
various HT benchmarks and compare it with two prior works that use logic
testing for HT detection. Experimental results show that AdaTest engenders up
to two orders of test generation speedup and two orders of test set size
reduction compared to the prior works while achieving the same level or higher
Trojan detection rate."
PSENet: Progressive Self-Enhancement Network for Unsupervised Extreme-Light Image Enhancement,0.565341,"The extremes of lighting (e.g. too much or too little light) usually cause
many troubles for machine and human vision. Many recent works have mainly
focused on under-exposure cases where images are often captured in low-light
conditions (e.g. nighttime) and achieved promising results for enhancing the
quality of images. However, they are inferior to handling images under
over-exposure. To mitigate this limitation, we propose a novel unsupervised
enhancement framework which is robust against various lighting conditions while
does not require any well-exposed images to serve as the ground-truths. Our
main concept is to construct pseudo-ground-truth images synthesized from
multiple source images that simulate all potential exposure scenarios to train
the enhancement network. Our extensive experiments show that the proposed
approach consistently outperforms the current state-of-the-art unsupervised
counterparts in several public datasets in terms of both quantitative metrics
and qualitative results. Our code is available at
https://github.com/VinAIResearch/PSENet-Image-Enhancement."
Investigating the Challenges of Class Imbalance and Scale Variation in Object Detection in Aerial Images,0.0286871,"While object detection is a common problem in computer vision, it is even
more challenging when dealing with aerial satellite images. The variety in
object scales and orientations can make them difficult to identify. In
addition, there can be large amounts of densely packed small objects such as
cars. In this project, we propose a few changes to the Faster-RCNN
architecture. First, we experiment with different backbones to extract better
features. We also modify the data augmentations and generated anchor sizes for
region proposals in order to better handle small objects. Finally, we
investigate the effects of different loss functions. Our proposed design
achieves an improvement of 4.7 mAP over the baseline which used a vanilla
Faster R-CNN with a ResNet-101 FPN backbone."
Smart Multi-tenant Federated Learning,0.242747,"Federated learning (FL) is an emerging distributed machine learning method
that empowers in-situ model training on decentralized edge devices. However,
multiple simultaneous training activities could overload resource-constrained
devices. In this work, we propose a smart multi-tenant FL system, MuFL, to
effectively coordinate and execute simultaneous training activities. We first
formalize the problem of multi-tenant FL, define multi-tenant FL scenarios, and
introduce a vanilla multi-tenant FL system that trains activities sequentially
to form baselines. Then, we propose two approaches to optimize multi-tenant FL:
1) activity consolidation merges training activities into one activity with a
multi-task architecture; 2) after training it for rounds, activity splitting
divides it into groups by employing affinities among activities such that
activities within a group have better synergy. Extensive experiments
demonstrate that MuFL outperforms other methods while consuming 40% less
energy. We hope this work will inspire the community to further study and
optimize multi-tenant FL."
Human Preference Score: Better Aligning Text-to-Image Models with Human Preference,0.521627,"Recent years have witnessed a rapid growth of deep generative models, with
text-to-image models gaining significant attention from the public. However,
existing models often generate images that do not align well with human
preferences, such as awkward combinations of limbs and facial expressions. To
address this issue, we collect a dataset of human choices on generated images
from the Stable Foundation Discord channel. Our experiments demonstrate that
current evaluation metrics for generative models do not correlate well with
human choices. Thus, we train a human preference classifier with the collected
dataset and derive a Human Preference Score (HPS) based on the classifier.
Using HPS, we propose a simple yet effective method to adapt Stable Diffusion
to better align with human preferences. Our experiments show that HPS
outperforms CLIP in predicting human choices and has good generalization
capability toward images generated from other models. By tuning Stable
Diffusion with the guidance of HPS, the adapted model is able to generate
images that are more preferred by human users. The project page is available
here: https://tgxs002.github.io/align_sd_web/ ."
Structured Pruning Adapters,0.627444,"Adapters are a parameter-efficient alternative to fine-tuning, which augment
a frozen base network to learn new tasks. Yet, the inference of the adapted
model is often slower than the corresponding fine-tuned model. To improve on
this, we propose Structured Pruning Adapters (SPAs), a family of compressing,
task-switching network adapters, that accelerate and specialize networks using
tiny parameter sets and structured pruning. Specifically, we propose a
channel-based SPA and evaluate it with a suite of pruning methods on multiple
computer vision benchmarks. Compared to regular structured pruning with
fine-tuning, our channel-SPAs improve accuracy by 6.9% on average while using
half the parameters at 90% pruned weights. Alternatively, they can learn
adaptations with 17x fewer parameters at 70% pruning with 1.6% lower accuracy.
Similarly, our block-SPA requires far fewer parameters than pruning with
fine-tuning. Our experimental code and Python library of adapters are available
at github.com/lukashedegaard/structured-pruning-adapters."
Q-ViT: Fully Differentiable Quantization for Vision Transformer,0.808892,"In this paper, we propose a fully differentiable quantization method for
vision transformer (ViT) named as Q-ViT, in which both of the quantization
scales and bit-widths are learnable parameters. Specifically, based on our
observation that heads in ViT display different quantization robustness, we
leverage head-wise bit-width to squeeze the size of Q-ViT while preserving
performance. In addition, we propose a novel technique named switchable scale
to resolve the convergence problem in the joint training of quantization scales
and bit-widths. In this way, Q-ViT pushes the limits of ViT quantization to
3-bit without heavy performance drop. Moreover, we analyze the quantization
robustness of every architecture component of ViT and show that the Multi-head
Self-Attention (MSA) and the Gaussian Error Linear Units (GELU) are the key
aspects for ViT quantization. This study provides some insights for further
research about ViT quantization. Extensive experiments on different ViT models,
such as DeiT and Swin Transformer show the effectiveness of our quantization
method. In particular, our method outperforms the state-of-the-art uniform
quantization method by 1.5% on DeiT-Tiny."
A novel approach to generate datasets with XAI ground truth to evaluate image models,0.200777,"With the increased usage of artificial intelligence (AI), it is imperative to
understand how these models work internally. These needs have led to the
development of a new field called eXplainable artificial intelligence (XAI).
This field consists of on a set of techniques that allows us to theoretically
determine the cause of the AI decisions. One main issue of XAI is how to verify
the works on this field, taking into consideration the lack of ground truth
(GT). In this study, we propose a new method to generate datasets with GT. We
conducted a set of experiments that compared our GT with real model
explanations and obtained excellent results confirming that our proposed method
is correct."
To Answer or Not to Answer? Improving Machine Reading Comprehension Model with Span-based Contrastive Learning,0.716549,"Machine Reading Comprehension with Unanswerable Questions is a difficult NLP
task, challenged by the questions which can not be answered from passages. It
is observed that subtle literal changes often make an answerable question
unanswerable, however, most MRC models fail to recognize such changes. To
address this problem, in this paper, we propose a span-based method of
Contrastive Learning (spanCL) which explicitly contrast answerable questions
with their answerable and unanswerable counterparts at the answer span level.
With spanCL, MRC models are forced to perceive crucial semantic changes from
slight literal differences. Experiments on SQuAD 2.0 dataset show that spanCL
can improve baselines significantly, yielding 0.86-2.14 absolute EM
improvements. Additional experiments also show that spanCL is an effective way
to utilize generated questions."
PanoFormer: Panorama Transformer for Indoor 360 Depth Estimation,0.943347,"Existing panoramic depth estimation methods based on convolutional neural
networks (CNNs) focus on removing panoramic distortions, failing to perceive
panoramic structures efficiently due to the fixed receptive field in CNNs. This
paper proposes the panorama transformer (named PanoFormer) to estimate the
depth in panorama images, with tangent patches from spherical domain, learnable
token flows, and panorama specific metrics. In particular, we divide patches on
the spherical tangent domain into tokens to reduce the negative effect of
panoramic distortions. Since the geometric structures are essential for depth
estimation, a self-attention module is redesigned with an additional learnable
token flow. In addition, considering the characteristic of the spherical
domain, we present two panorama-specific metrics to comprehensively evaluate
the panoramic depth estimation models' performance. Extensive experiments
demonstrate that our approach significantly outperforms the state-of-the-art
(SOTA) methods. Furthermore, the proposed method can be effectively extended to
solve semantic panorama segmentation, a similar pixel2pixel task. Code will be
available."
Mixture-Net: Low-Rank Deep Image Prior Inspired by Mixture Models for Spectral Image Recovery,0.387464,"This paper proposes a non-data-driven deep neural network for spectral image
recovery problems such as denoising, single hyperspectral image
super-resolution, and compressive spectral imaging reconstruction. Unlike
previous methods, the proposed approach, dubbed Mixture-Net, implicitly learns
the prior information through the network. Mixture-Net consists of a deep
generative model whose layers are inspired by the linear and non-linear
low-rank mixture models, where the recovered image is composed of a weighted
sum between the linear and non-linear decomposition. Mixture-Net also provides
a low-rank decomposition interpreted as the spectral image abundances and
endmembers, helpful in achieving remote sensing tasks without running
additional routines. The experiments show the MixtureNet effectiveness
outperforming state-of-the-art methods in recovery quality with the advantage
of architecture interpretability."
PCL: Peer-Contrastive Learning with Diverse Augmentations for Unsupervised Sentence Embeddings,0.819687,"Learning sentence embeddings in an unsupervised manner is fundamental in
natural language processing. Recent common practice is to couple pre-trained
language models with unsupervised contrastive learning, whose success relies on
augmenting a sentence with a semantically-close positive instance to construct
contrastive pairs. Nonetheless, existing approaches usually depend on a
mono-augmenting strategy, which causes learning shortcuts towards the
augmenting biases and thus corrupts the quality of sentence embeddings. A
straightforward solution is resorting to more diverse positives from a
multi-augmenting strategy, while an open question remains about how to
unsupervisedly learn from the diverse positives but with uneven augmenting
qualities in the text field. As one answer, we propose a novel Peer-Contrastive
Learning (PCL) with diverse augmentations. PCL constructs diverse contrastive
positives and negatives at the group level for unsupervised sentence
embeddings. PCL performs peer-positive contrast as well as peer-network
cooperation, which offers an inherent anti-bias ability and an effective way to
learn from diverse augmentations. Experiments on STS benchmarks verify the
effectiveness of PCL against its competitors in unsupervised sentence
embeddings."
Bridging Physics-Informed Neural Networks with Reinforcement Learning: Hamilton-Jacobi-Bellman Proximal Policy Optimization (HJBPPO),0.592809,"This paper introduces the Hamilton-Jacobi-Bellman Proximal Policy
Optimization (HJBPPO) algorithm into reinforcement learning. The
Hamilton-Jacobi-Bellman (HJB) equation is used in control theory to evaluate
the optimality of the value function. Our work combines the HJB equation with
reinforcement learning in continuous state and action spaces to improve the
training of the value network. We treat the value network as a Physics-Informed
Neural Network (PINN) to solve for the HJB equation by computing its
derivatives with respect to its inputs exactly. The Proximal Policy
Optimization (PPO)-Clipped algorithm is improvised with this implementation as
it uses a value network to compute the objective function for its policy
network. The HJBPPO algorithm shows an improved performance compared to PPO on
the MuJoCo environments."
Toward Improving Health Literacy in Patient Education Materials with Neural Machine Translation Models,0.201583,"Health literacy is the central focus of Healthy People 2030, the fifth
iteration of the U.S. national goals and objectives. People with low health
literacy usually have trouble understanding health information, following
post-visit instructions, and using prescriptions, which results in worse health
outcomes and serious health disparities. In this study, we propose to leverage
natural language processing techniques to improve health literacy in patient
education materials by automatically translating illiterate languages in a
given sentence. We scraped patient education materials from four online health
information websites: MedlinePlus.gov, Drugs.com, Mayoclinic.org and
Reddit.com. We trained and tested the state-of-the-art neural machine
translation (NMT) models on a silver standard training dataset and a gold
standard testing dataset, respectively. The experimental results showed that
the Bidirectional Long Short-Term Memory (BiLSTM) NMT model outperformed
Bidirectional Encoder Representations from Transformers (BERT)-based NMT
models. We also verified the effectiveness of NMT models in translating health
illiterate languages by comparing the ratio of health illiterate language in
the sentence. The proposed NMT models were able to identify the correct
complicated words and simplify into layman language while at the same time the
models suffer from sentence completeness, fluency, readability, and have
difficulty in translating certain medical terms."
Specifying and Reasoning about CPS through the Lens of the NIST CPS Framework,0.151683,"This paper introduces a formal definition of a Cyber-Physical System (CPS) in
the spirit of the CPS Framework proposed by the National Institute of Standards
and Technology (NIST). It shows that using this definition, various problems
related to concerns in a CPS can be precisely formalized and implemented using
Answer Set Programming (ASP). These include problems related to the dependency
or conflicts between concerns, how to mitigate an issue, and what the most
suitable mitigation strategy for a given issue would be. It then shows how ASP
can be used to develop an implementation that addresses the aforementioned
problems. The paper concludes with a discussion of the potentials of the
proposed methodologies."
Toward the application of XAI methods in EEG-based systems,0.552001,"An interesting case of the well-known Dataset Shift Problem is the
classification of Electroencephalogram (EEG) signals in the context of
Brain-Computer Interface (BCI). The non-stationarity of EEG signals can lead to
poor generalisation performance in BCI classification systems used in different
sessions, also from the same subject. In this paper, we start from the
hypothesis that the Dataset Shift problem can be alleviated by exploiting
suitable eXplainable Artificial Intelligence (XAI) methods to locate and
transform the relevant characteristics of the input for the goal of
classification. In particular, we focus on an experimental analysis of
explanations produced by several XAI methods on an ML system trained on a
typical EEG dataset for emotion recognition. Results show that many relevant
components found by XAI methods are shared across the sessions and can be used
to build a system able to generalise better. However, relevant components of
the input signal also appear to be highly dependent on the input itself."
Extracting Cultural Commonsense Knowledge at Scale,0.985155,"Structured knowledge is important for many AI applications. Commonsense
knowledge, which is crucial for robust human-centric AI, is covered by a small
number of structured knowledge projects. However, they lack knowledge about
human traits and behaviors conditioned on socio-cultural contexts, which is
crucial for situative AI. This paper presents CANDLE, an end-to-end methodology
for extracting high-quality cultural commonsense knowledge (CCSK) at scale.
CANDLE extracts CCSK assertions from a huge web corpus and organizes them into
coherent clusters, for 3 domains of subjects (geography, religion, occupation)
and several cultural facets (food, drinks, clothing, traditions, rituals,
behaviors). CANDLE includes judicious techniques for classification-based
filtering and scoring of interestingness. Experimental evaluations show the
superiority of the CANDLE CCSK collection over prior works, and an extrinsic
use case demonstrates the benefits of CCSK for the GPT-3 language model. Code
and data can be accessed at https://candle.mpi-inf.mpg.de/."
Referential communication in heterogeneous communities of pre-trained visual deep networks,0.504407,"As large pre-trained image-processing neural networks are being embedded in
autonomous agents such as self-driving cars or robots, the question arises of
how such systems can communicate with each other about the surrounding world,
despite their different architectures and training regimes. As a first step in
this direction, we systematically explore the task of \textit{referential
communication} in a community of heterogeneous state-of-the-art pre-trained
visual networks, showing that they can develop, in a self-supervised way, a
shared protocol to refer to a target object among a set of candidates. This
shared protocol can also be used, to some extent, to communicate about
previously unseen object categories of different granularity. Moreover, a
visual network that was not initially part of an existing community can learn
the community's protocol with remarkable ease. Finally, we study, both
qualitatively and quantitatively, the properties of the emergent protocol,
providing some evidence that it is capturing high-level semantic features of
objects."
Interpreting Pretrained Language Models via Concept Bottlenecks,0.220251,"Pretrained language models (PLMs) have made significant strides in various
natural language processing tasks. However, the lack of interpretability due to
their ``black-box'' nature poses challenges for responsible implementation.
Although previous studies have attempted to improve interpretability by using,
e.g., attention weights in self-attention layers, these weights often lack
clarity, readability, and intuitiveness. In this research, we propose a novel
approach to interpreting PLMs by employing high-level, meaningful concepts that
are easily understandable for humans. For example, we learn the concept of
``Food'' and investigate how it influences the prediction of a model's
sentiment towards a restaurant review. We introduce C$^3$M, which combines
human-annotated and machine-generated concepts to extract hidden neurons
designed to encapsulate semantically meaningful and task-specific concepts.
Through empirical evaluations on real-world datasets, we manifest that our
approach offers valuable insights to interpret PLM behavior, helps diagnose
model failures, and enhances model robustness amidst noisy concept labels."
AnimeRun: 2D Animation Visual Correspondence from Open Source 3D Movies,0.483183,"Existing correspondence datasets for two-dimensional (2D) cartoon suffer from
simple frame composition and monotonic movements, making them insufficient to
simulate real animations. In this work, we present a new 2D animation visual
correspondence dataset, AnimeRun, by converting open source three-dimensional
(3D) movies to full scenes in 2D style, including simultaneous moving
background and interactions of multiple subjects. Our analyses show that the
proposed dataset not only resembles real anime more in image composition, but
also possesses richer and more complex motion patterns compared to existing
datasets. With this dataset, we establish a comprehensive benchmark by
evaluating several existing optical flow and segment matching methods, and
analyze shortcomings of these methods on animation data. Data, code and other
supplementary materials are available at
https://lisiyao21.github.io/projects/AnimeRun."
SiamMask: A Framework for Fast Online Object Tracking and Segmentation,0.952788,"In this paper we introduce SiamMask, a framework to perform both visual
object tracking and video object segmentation, in real-time, with the same
simple method. We improve the offline training procedure of popular
fully-convolutional Siamese approaches by augmenting their losses with a binary
segmentation task. Once the offline training is completed, SiamMask only
requires a single bounding box for initialization and can simultaneously carry
out visual object tracking and segmentation at high frame-rates. Moreover, we
show that it is possible to extend the framework to handle multiple object
tracking and segmentation by simply re-using the multi-task model in a cascaded
fashion. Experimental results show that our approach has high processing
efficiency, at around 55 frames per second. It yields real-time
state-of-the-art results on visual-object tracking benchmarks, while at the
same time demonstrating competitive performance at a high speed for video
object segmentation benchmarks."
Automatic Context Pattern Generation for Entity Set Expansion,0.892067,"Entity Set Expansion (ESE) is a valuable task that aims to find entities of
the target semantic class described by given seed entities. Various Natural
Language Processing (NLP) and Information Retrieval (IR) downstream
applications have benefited from ESE due to its ability to discover knowledge.
Although existing corpus-based ESE methods have achieved great progress, they
still rely on corpora with high-quality entity information annotated, because
most of them need to obtain the context patterns through the position of the
entity in a sentence. Therefore, the quality of the given corpora and their
entity annotation has become the bottleneck that limits the performance of such
methods. To overcome this dilemma and make the ESE models free from the
dependence on entity annotation, our work aims to explore a new ESE paradigm,
namely corpus-independent ESE. Specifically, we devise a context pattern
generation module that utilizes autoregressive language models (e.g., GPT-2) to
automatically generate high-quality context patterns for entities. In addition,
we propose the GAPA, a novel ESE framework that leverages the aforementioned
GenerAted PAtterns to expand target entities. Extensive experiments and
detailed analyses on three widely used datasets demonstrate the effectiveness
of our method. All the codes of our experiments are available at
https://github.com/geekjuruo/GAPA."
Solar Irradiance Anticipative Transformer,0.522922,"This paper proposes an anticipative transformer-based model for short-term
solar irradiance forecasting. Given a sequence of sky images, our proposed
vision transformer encodes features of consecutive images, feeding into a
transformer decoder to predict irradiance values associated with future unseen
sky images. We show that our model effectively learns to attend only to
relevant features in images in order to forecast irradiance. Moreover, the
proposed anticipative transformer captures long-range dependencies between sky
images to achieve a forecasting skill of 21.45 % on a 15 minute ahead
prediction for a newly introduced dataset of all-sky images when compared to a
smart persistence model."
DiffuseGAE: Controllable and High-fidelity Image Manipulation from Disentangled Representation,0.207453,"Diffusion probabilistic models (DPMs) have shown remarkable results on
various image synthesis tasks such as text-to-image generation and image
inpainting. However, compared to other generative methods like VAEs and GANs,
DPMs lack a low-dimensional, interpretable, and well-decoupled latent code.
Recently, diffusion autoencoders (Diff-AE) were proposed to explore the
potential of DPMs for representation learning via autoencoding. Diff-AE
provides an accessible latent space that exhibits remarkable interpretability,
allowing us to manipulate image attributes based on latent codes from the
space. However, previous works are not generic as they only operated on a few
limited attributes. To further explore the latent space of Diff-AE and achieve
a generic editing pipeline, we proposed a module called Group-supervised
AutoEncoder(dubbed GAE) for Diff-AE to achieve better disentanglement on the
latent code. Our proposed GAE has trained via an attribute-swap strategy to
acquire the latent codes for multi-attribute image manipulation based on
examples. We empirically demonstrate that our method enables
multiple-attributes manipulation and achieves convincing sample quality and
attribute alignments, while significantly reducing computational requirements
compared to pixel-based approaches for representational decoupling. Code will
be released soon."
BiFormer: Learning Bilateral Motion Estimation via Bilateral Transformer for 4K Video Frame Interpolation,0.591861,"A novel 4K video frame interpolator based on bilateral transformer (BiFormer)
is proposed in this paper, which performs three steps: global motion
estimation, local motion refinement, and frame synthesis. First, in global
motion estimation, we predict symmetric bilateral motion fields at a coarse
scale. To this end, we propose BiFormer, the first transformer-based bilateral
motion estimator. Second, we refine the global motion fields efficiently using
blockwise bilateral cost volumes (BBCVs). Third, we warp the input frames using
the refined motion fields and blend them to synthesize an intermediate frame.
Extensive experiments demonstrate that the proposed BiFormer algorithm achieves
excellent interpolation performance on 4K datasets. The source codes are
available at https://github.com/JunHeum/BiFormer."
Transformers are Sample-Efficient World Models,0.792866,"Deep reinforcement learning agents are notoriously sample inefficient, which
considerably limits their application to real-world problems. Recently, many
model-based methods have been designed to address this issue, with learning in
the imagination of a world model being one of the most prominent approaches.
However, while virtually unlimited interaction with a simulated environment
sounds appealing, the world model has to be accurate over extended periods of
time. Motivated by the success of Transformers in sequence modeling tasks, we
introduce IRIS, a data-efficient agent that learns in a world model composed of
a discrete autoencoder and an autoregressive Transformer. With the equivalent
of only two hours of gameplay in the Atari 100k benchmark, IRIS achieves a mean
human normalized score of 1.046, and outperforms humans on 10 out of 26 games,
setting a new state of the art for methods without lookahead search. To foster
future research on Transformers and world models for sample-efficient
reinforcement learning, we release our code and models at
https://github.com/eloialonso/iris."
Perception Prioritized Training of Diffusion Models,0.903955,"Diffusion models learn to restore noisy data, which is corrupted with
different levels of noise, by optimizing the weighted sum of the corresponding
loss terms, i.e., denoising score matching loss. In this paper, we show that
restoring data corrupted with certain noise levels offers a proper pretext task
for the model to learn rich visual concepts. We propose to prioritize such
noise levels over other levels during training, by redesigning the weighting
scheme of the objective function. We show that our simple redesign of the
weighting scheme significantly improves the performance of diffusion models
regardless of the datasets, architectures, and sampling strategies."
Traffic Accident Risk Forecasting using Contextual Vision Transformers,0.562241,"Recently, the problem of traffic accident risk forecasting has been getting
the attention of the intelligent transportation systems community due to its
significant impact on traffic clearance. This problem is commonly tackled in
the literature by using data-driven approaches that model the spatial and
temporal incident impact, since they were shown to be crucial for the traffic
accident risk forecasting problem. To achieve this, most approaches build
different architectures to capture the spatio-temporal correlations features,
making them inefficient for large traffic accident datasets. Thus, in this
work, we are proposing a novel unified framework, namely a contextual vision
transformer, that can be trained in an end-to-end approach which can
effectively reason about the spatial and temporal aspects of the problem while
providing accurate traffic accident risk predictions. We evaluate and compare
the performance of our proposed methodology against baseline approaches from
the literature across two large-scale traffic accident datasets from two
different geographical locations. The results have shown a significant
improvement with roughly 2\% in RMSE score in comparison to previous
state-of-art works (SoTA) in the literature. Moreover, our proposed approach
has outperformed the SoTA technique over the two datasets while only requiring
23x fewer computational requirements."
Domain Adaptive Video Segmentation via Temporal Pseudo Supervision,0.715771,"Video semantic segmentation has achieved great progress under the supervision
of large amounts of labelled training data. However, domain adaptive video
segmentation, which can mitigate data labelling constraints by adapting from a
labelled source domain toward an unlabelled target domain, is largely
neglected. We design temporal pseudo supervision (TPS), a simple and effective
method that explores the idea of consistency training for learning effective
representations from unlabelled target videos. Unlike traditional consistency
training that builds consistency in spatial space, we explore consistency
training in spatiotemporal space by enforcing model consistency across
augmented video frames which helps learn from more diverse target data.
Specifically, we design cross-frame pseudo labelling to provide pseudo
supervision from previous video frames while learning from the augmented
current video frames. The cross-frame pseudo labelling encourages the network
to produce high-certainty predictions, which facilitates consistency training
with cross-frame augmentation effectively. Extensive experiments over multiple
public datasets show that TPS is simpler to implement, much more stable to
train, and achieves superior video segmentation accuracy as compared with the
state-of-the-art."
FairDisCo: Fairer AI in Dermatology via Disentanglement Contrastive Learning,0.549078,"Deep learning models have achieved great success in automating skin lesion
diagnosis. However, the ethnic disparity in these models' predictions, where
lesions on darker skin types are usually underrepresented and have lower
diagnosis accuracy, receives little attention. In this paper, we propose
FairDisCo, a disentanglement deep learning framework with contrastive learning
that utilizes an additional network branch to remove sensitive attributes, i.e.
skin-type information from representations for fairness and another contrastive
branch to enhance feature extraction. We compare FairDisCo to three fairness
methods, namely, resampling, reweighting, and attribute-aware, on two newly
released skin lesion datasets with different skin types: Fitzpatrick17k and
Diverse Dermatology Images (DDI). We adapt two fairness-based metrics DPM and
EOM for our multiple classes and sensitive attributes task, highlighting the
skin-type bias in skin lesion classification. Extensive experimental evaluation
demonstrates the effectiveness of FairDisCo, with fairer and superior
performance on skin lesion classification tasks."
Motion Matters: A Novel Motion Modeling For Cross-View Gait Feature Learning,0.240797,"As a unique biometric that can be perceived at a distance, gait has broad
applications in person authentication, social security, and so on. Existing
gait recognition methods suffer from changes in viewpoint and clothing and
barely consider extracting diverse motion features, a fundamental
characteristic in gaits, from gait sequences. This paper proposes a novel
motion modeling method to extract the discriminative and robust representation.
Specifically, we first extract the motion features from the encoded motion
sequences in the shallow layer. Then we continuously enhance the motion feature
in deep layers. This motion modeling approach is independent of mainstream work
in building network architectures. As a result, one can apply this motion
modeling method to any backbone to improve gait recognition performance. In
this paper, we combine motion modeling with one commonly used backbone~(GaitGL)
as GaitGL-M to illustrate motion modeling. Extensive experimental results on
two commonly-used cross-view gait datasets demonstrate the superior performance
of GaitGL-M over existing state-of-the-art methods."
An Overview on Machine Translation Evaluation,0.403594,"Since the 1950s, machine translation (MT) has become one of the important
tasks of AI and development, and has experienced several different periods and
stages of development, including rule-based methods, statistical methods, and
recently proposed neural network-based learning methods. Accompanying these
staged leaps is the evaluation research and development of MT, especially the
important role of evaluation methods in statistical translation and neural
translation research. The evaluation task of MT is not only to evaluate the
quality of machine translation, but also to give timely feedback to machine
translation researchers on the problems existing in machine translation itself,
how to improve and how to optimise. In some practical application fields, such
as in the absence of reference translations, the quality estimation of machine
translation plays an important role as an indicator to reveal the credibility
of automatically translated target languages. This report mainly includes the
following contents: a brief history of machine translation evaluation (MTE),
the classification of research methods on MTE, and the the cutting-edge
progress, including human evaluation, automatic evaluation, and evaluation of
evaluation methods (meta-evaluation). Manual evaluation and automatic
evaluation include reference-translation based and reference-translation
independent participation; automatic evaluation methods include traditional
n-gram string matching, models applying syntax and semantics, and deep learning
models; evaluation of evaluation methods includes estimating the credibility of
human evaluations, the reliability of the automatic evaluation, the reliability
of the test set, etc. Advances in cutting-edge evaluation methods include
task-based evaluation, using pre-trained language models based on big data, and
lightweight optimisation models using distillation techniques."
PatchRot: A Self-Supervised Technique for Training Vision Transformers,0.0402278,"Vision transformers require a huge amount of labeled data to outperform
convolutional neural networks. However, labeling a huge dataset is a very
expensive process. Self-supervised learning techniques alleviate this problem
by learning features similar to supervised learning in an unsupervised way. In
this paper, we propose a self-supervised technique PatchRot that is crafted for
vision transformers. PatchRot rotates images and image patches and trains the
network to predict the rotation angles. The network learns to extract both
global and local features from an image. Our extensive experiments on different
datasets showcase PatchRot training learns rich features which outperform
supervised learning and compared baseline."
Omnigrok: Grokking Beyond Algorithmic Data,0.53064,"Grokking, the unusual phenomenon for algorithmic datasets where
generalization happens long after overfitting the training data, has remained
elusive. We aim to understand grokking by analyzing the loss landscapes of
neural networks, identifying the mismatch between training and test losses as
the cause for grokking. We refer to this as the ""LU mechanism"" because training
and test losses (against model weight norm) typically resemble ""L"" and ""U"",
respectively. This simple mechanism can nicely explain many aspects of
grokking: data size dependence, weight decay dependence, the emergence of
representations, etc. Guided by the intuitive picture, we are able to induce
grokking on tasks involving images, language and molecules. In the reverse
direction, we are able to eliminate grokking for algorithmic datasets. We
attribute the dramatic nature of grokking for algorithmic datasets to
representation learning."
FineDiving: A Fine-grained Dataset for Procedure-aware Action Quality Assessment,0.999911,"Most existing action quality assessment methods rely on the deep features of
an entire video to predict the score, which is less reliable due to the
non-transparent inference process and poor interpretability. We argue that
understanding both high-level semantics and internal temporal structures of
actions in competitive sports videos is the key to making predictions accurate
and interpretable. Towards this goal, we construct a new fine-grained dataset,
called FineDiving, developed on diverse diving events with detailed annotations
on action procedures. We also propose a procedure-aware approach for action
quality assessment, learned by a new Temporal Segmentation Attention module.
Specifically, we propose to parse pairwise query and exemplar action instances
into consecutive steps with diverse semantic and temporal correspondences. The
procedure-aware cross-attention is proposed to learn embeddings between query
and exemplar steps to discover their semantic, spatial, and temporal
correspondences, and further serve for fine-grained contrastive regression to
derive a reliable scoring mechanism. Extensive experiments demonstrate that our
approach achieves substantial improvements over state-of-the-art methods with
better interpretability. The dataset and code are available at
\url{https://github.com/xujinglin/FineDiving}."
Bilinear value networks,0.41405,"The dominant framework for off-policy multi-goal reinforcement learning
involves estimating goal conditioned Q-value function. When learning to achieve
multiple goals, data efficiency is intimately connected with the generalization
of the Q-function to new goals. The de-facto paradigm is to approximate Q(s, a,
g) using monolithic neural networks. To improve the generalization of the
Q-function, we propose a bilinear decomposition that represents the Q-value via
a low-rank approximation in the form of a dot product between two vector
fields. The first vector field, f(s, a), captures the environment's local
dynamics at the state s; whereas the second component, {\phi}(s, g), captures
the global relationship between the current state and the goal. We show that
our bilinear decomposition scheme substantially improves data efficiency, and
has superior transfer to out-of-distribution goals compared to prior methods.
Empirical evidence is provided on the simulated Fetch robot task-suite and
dexterous manipulation with a Shadow hand."
Check and Link: Pairwise Lesion Correspondence Guides Mammogram Mass Detection,0.613655,"Detecting mass in mammogram is significant due to the high occurrence and
mortality of breast cancer. In mammogram mass detection, modeling pairwise
lesion correspondence explicitly is particularly important. However, most of
the existing methods build relatively coarse correspondence and have not
utilized correspondence supervision. In this paper, we propose a new
transformer-based framework CL-Net to learn lesion detection and pairwise
correspondence in an end-to-end manner. In CL-Net, View-Interactive Lesion
Detector is proposed to achieve dynamic interaction across candidates of cross
views, while Lesion Linker employs the correspondence supervision to guide the
interaction process more accurately. The combination of these two designs
accomplishes precise understanding of pairwise lesion correspondence for
mammograms. Experiments show that CL-Net yields state-of-the-art performance on
the public DDSM dataset and our in-house dataset. Moreover, it outperforms
previous methods by a large margin in low FPI regime."
Should We Rely on Entity Mentions for Relation Extraction? Debiasing Relation Extraction with Counterfactual Analysis,0.793283,"Recent literature focuses on utilizing the entity information in the
sentence-level relation extraction (RE), but this risks leaking superficial and
spurious clues of relations. As a result, RE still suffers from unintended
entity bias, i.e., the spurious correlation between entity mentions (names) and
relations. Entity bias can mislead the RE models to extract the relations that
do not exist in the text. To combat this issue, some previous work masks the
entity mentions to prevent the RE models from overfitting entity mentions.
However, this strategy degrades the RE performance because it loses the
semantic information of entities. In this paper, we propose the CORE
(Counterfactual Analysis based Relation Extraction) debiasing method that
guides the RE models to focus on the main effects of textual context without
losing the entity information. We first construct a causal graph for RE, which
models the dependencies between variables in RE models. Then, we propose to
conduct counterfactual analysis on our causal graph to distill and mitigate the
entity bias, that captures the causal effects of specific entity mentions in
each instance. Note that our CORE method is model-agnostic to debias existing
RE systems during inference without changing their training processes.
Extensive experimental results demonstrate that our CORE yields significant
gains on both effectiveness and generalization for RE. The source code is
provided at: https://github.com/vanoracai/CoRE."
Chord-Conditioned Melody Harmonization with Controllable Harmonicity,0.383318,"Melody harmonization has long been closely associated with chorales composed
by Johann Sebastian Bach. Previous works rarely emphasised chorale generation
conditioned on chord progressions, and there has been a lack of focus on
assistive compositional tools. In this paper, we first designed a music
representation that encoded chord symbols for chord conditioning, and then
proposed DeepChoir, a melody harmonization system that can generate a four-part
chorale for a given melody conditioned on a chord progression. With
controllable harmonicity, users can control the extent of harmonicity for
generated chorales. Experimental results reveal the effectiveness of the music
representation and the controllability of DeepChoir."
GOAL: Towards Benchmarking Few-Shot Sports Game Summarization,0.361839,"Sports game summarization aims to generate sports news based on real-time
commentaries. The task has attracted wide research attention but is still
under-explored probably due to the lack of corresponding English datasets.
Therefore, in this paper, we release GOAL, the first English sports game
summarization dataset. Specifically, there are 103 commentary-news pairs in
GOAL, where the average lengths of commentaries and news are 2724.9 and 476.3
words, respectively. Moreover, to support the research in the semi-supervised
setting, GOAL additionally provides 2,160 unlabeled commentary documents. Based
on our GOAL, we build and evaluate several baselines, including extractive and
abstractive baselines. The experimental results show the challenges of this
task still remain. We hope our work could promote the research of sports game
summarization. The dataset has been released at
https://github.com/krystalan/goal."
Real Time Egocentric Segmentation for Video-self Avatar in Mixed Reality,0.6145,"In this work we present our real-time egocentric body segmentation algorithm.
Our algorithm achieves a frame rate of 66 fps for an input resolution of
640x480, thanks to our shallow network inspired in Thundernet's architecture.
Besides, we put a strong emphasis on the variability of the training data. More
concretely, we describe the creation process of our Egocentric Bodies
(EgoBodies) dataset, composed of almost 10,000 images from three datasets,
created both from synthetic methods and real capturing. We conduct experiments
to understand the contribution of the individual datasets; compare Thundernet
model trained with EgoBodies with simpler and more complex previous approaches
and discuss their corresponding performance in a real-life setup in terms of
segmentation quality and inference times. The described trained semantic
segmentation algorithm is already integrated in an end-to-end system for Mixed
Reality (MR), making it possible for users to see his/her own body while being
immersed in a MR scene."
Ensemble Modeling for Time Series Forecasting: an Adaptive Robust Optimization Approach,0.112021,"Accurate time series forecasting is critical for a wide range of problems
with temporal data. Ensemble modeling is a well-established technique for
leveraging multiple predictive models to increase accuracy and robustness, as
the performance of a single predictor can be highly variable due to shifts in
the underlying data distribution. This paper proposes a new methodology for
building robust ensembles of time series forecasting models. Our approach
utilizes Adaptive Robust Optimization (ARO) to construct a linear regression
ensemble in which the models' weights can adapt over time. We demonstrate the
effectiveness of our method through a series of synthetic experiments and
real-world applications, including air pollution management, energy consumption
forecasting, and tropical cyclone intensity forecasting. Our results show that
our adaptive ensembles outperform the best ensemble member in hindsight by
16-26% in root mean square error and 14-28% in conditional value at risk and
improve over competitive ensemble techniques."
Learning an Artificial Language for Knowledge-Sharing in Multilingual Translation,0.13657,"The cornerstone of multilingual neural translation is shared representations
across languages. Given the theoretically infinite representation power of
neural networks, semantically identical sentences are likely represented
differently. While representing sentences in the continuous latent space
ensures expressiveness, it introduces the risk of capturing of irrelevant
features which hinders the learning of a common representation. In this work,
we discretize the encoder output latent space of multilingual models by
assigning encoder states to entries in a codebook, which in effect represents
source sentences in a new artificial language. This discretization process not
only offers a new way to interpret the otherwise black-box model
representations, but, more importantly, gives potential for increasing
robustness in unseen testing conditions. We validate our approach on
large-scale experiments with realistic data volumes and domains. When tested in
zero-shot conditions, our approach is competitive with two strong alternatives
from the literature. We also use the learned artificial language to analyze
model behavior, and discover that using a similar bridge language increases
knowledge-sharing among the remaining languages."
Joint fMRI Decoding and Encoding with Latent Embedding Alignment,0.670227,"The connection between brain activity and corresponding visual stimuli is
crucial in comprehending the human brain. While deep generative models have
exhibited advancement in recovering brain recordings by generating images
conditioned on fMRI signals, accomplishing high-quality generation with
consistent semantics continues to pose challenges. Moreover, the prediction of
brain activity from visual stimuli remains a formidable undertaking. In this
paper, we introduce a unified framework that addresses both fMRI decoding and
encoding. Commencing with the establishment of two latent spaces capable of
representing and reconstructing fMRI signals and visual images, respectively,
we proceed to align the fMRI signals and visual images within the latent space,
thereby enabling a bidirectional transformation between the two domains. Our
Latent Embedding Alignment (LEA) model concurrently recovers visual stimuli
from fMRI signals and predicts brain activity from images within a unified
framework. The performance of LEA surpasses that of existing methods on
multiple benchmark fMRI decoding and encoding datasets. By integrating fMRI
decoding and encoding, LEA offers a comprehensive solution for modeling the
intricate relationship between brain activity and visual stimuli."
MASTER: Multi-task Pre-trained Bottlenecked Masked Autoencoders are Better Dense Retrievers,0.522456,"Pre-trained Transformers (\eg BERT) have been commonly used in existing dense
retrieval methods for parameter initialization, and recent studies are
exploring more effective pre-training tasks for further improving the quality
of dense vectors. Although various novel and effective tasks have been
proposed, their different input formats and learning objectives make them hard
to be integrated for jointly improving the model performance. In this work, we
aim to unify a variety of pre-training tasks into the bottlenecked masked
autoencoder manner, and integrate them into a multi-task pre-trained model,
namely MASTER. Concretely, MASTER utilizes a shared-encoder multi-decoder
architecture that can construct a representation bottleneck to compress the
abundant semantic information across tasks into dense vectors. Based on it, we
integrate three types of representative pre-training tasks: corrupted passages
recovering, related passages recovering and PLMs outputs recovering, to
characterize the inner-passage information, inter-passage relations and PLMs
knowledge. Extensive experiments have shown that our approach outperforms
competitive dense retrieval methods. Our code and data are publicly released in
\url{https://github.com/microsoft/SimXNS}."
Chain-of-Thought Prompting Elicits Reasoning in Large Language Models,1.0,"We explore how generating a chain of thought -- a series of intermediate
reasoning steps -- significantly improves the ability of large language models
to perform complex reasoning. In particular, we show how such reasoning
abilities emerge naturally in sufficiently large language models via a simple
method called chain of thought prompting, where a few chain of thought
demonstrations are provided as exemplars in prompting. Experiments on three
large language models show that chain of thought prompting improves performance
on a range of arithmetic, commonsense, and symbolic reasoning tasks. The
empirical gains can be striking. For instance, prompting a 540B-parameter
language model with just eight chain of thought exemplars achieves state of the
art accuracy on the GSM8K benchmark of math word problems, surpassing even
finetuned GPT-3 with a verifier."
Generative modeling with projected entangled-pair states,0.331622,"We argue and demonstrate that projected entangled-pair states (PEPS)
outperform matrix product states significantly for the task of generative
modeling of datasets with an intrinsic two-dimensional structure such as
images. Our approach builds on a recently introduced algorithm for sampling
PEPS, which allows for the efficient optimization and sampling of the
distributions."
Soundness of Data-Aware Processes with Arithmetic Conditions,0.335974,"Data-aware processes represent and integrate structural and behavioural
constraints in a single model, and are thus increasingly investigated in
business process management and information systems engineering. In this
spectrum, Data Petri nets (DPNs) have gained increasing popularity thanks to
their ability to balance simplicity with expressiveness. The interplay of data
and control-flow makes checking the correctness of such models, specifically
the well-known property of soundness, crucial and challenging. A major
shortcoming of previous approaches for checking soundness of DPNs is that they
consider data conditions without arithmetic, an essential feature when dealing
with real-world, concrete applications. In this paper, we attack this open
problem by providing a foundational and operational framework for assessing
soundness of DPNs enriched with arithmetic data conditions. The framework comes
with a proof-of-concept implementation that, instead of relying on ad-hoc
techniques, employs off-the-shelf established SMT technologies. The
implementation is validated on a collection of examples from the literature,
and on synthetic variants constructed from such examples."
Neural Piecewise-Constant Delay Differential Equations,0.404973,"Continuous-depth neural networks, such as the Neural Ordinary Differential
Equations (ODEs), have aroused a great deal of interest from the communities of
machine learning and data science in recent years, which bridge the connection
between deep neural networks and dynamical systems. In this article, we
introduce a new sort of continuous-depth neural network, called the Neural
Piecewise-Constant Delay Differential Equations (PCDDEs). Here, unlike the
recently proposed framework of the Neural Delay Differential Equations (DDEs),
we transform the single delay into the piecewise-constant delay(s). The Neural
PCDDEs with such a transformation, on one hand, inherit the strength of
universal approximating capability in Neural DDEs. On the other hand, the
Neural PCDDEs, leveraging the contributions of the information from the
multiple previous time steps, further promote the modeling capability without
augmenting the network dimension. With such a promotion, we show that the
Neural PCDDEs do outperform the several existing continuous-depth neural
frameworks on the one-dimensional piecewise-constant delay population dynamics
and real-world datasets, including MNIST, CIFAR10, and SVHN."
Discourse and conversation impairments in patients with dementia,0.219283,"Neurodegeneration characterizes individuals with different dementia subtypes
(e.g., individuals with Alzheimer's Disease, Primary Progressive Aphasia, and
Parkinson's Disease), leading to progressive decline in cognitive, linguistic,
and social functioning. Speech and language impairments are early symptoms in
individuals with focal forms of neurodegenerative conditions, coupled with
deficits in cognitive, social, and behavioral domains. This paper reviews the
findings on language and communication deficits and identifies the effects of
dementia on the production and perception of discourse. It discusses findings
concerning (i) language function, cognitive representation, and impairment,
(ii) communicative competence, emotions, empathy, and theory-of-mind, and (iii)
speech-in-interaction. It argues that clinical discourse analysis can provide a
comprehensive assessment of language and communication skills in individuals,
which complements the existing neurolinguistic evaluation for (differential)
diagnosis, prognosis, and treatment efficacy evaluation."
Heteroskedastic Geospatial Tracking with Distributed Camera Networks,0.250813,"Visual object tracking has seen significant progress in recent years.
However, the vast majority of this work focuses on tracking objects within the
image plane of a single camera and ignores the uncertainty associated with
predicted object locations. In this work, we focus on the geospatial object
tracking problem using data from a distributed camera network. The goal is to
predict an object's track in geospatial coordinates along with uncertainty over
the object's location while respecting communication constraints that prohibit
centralizing raw image data. We present a novel single-object geospatial
tracking data set that includes high-accuracy ground truth object locations and
video data from a network of four cameras. We present a modeling framework for
addressing this task including a novel backbone model and explore how
uncertainty calibration and fine-tuning through a differentiable tracker affect
performance."
Task Transfer and Domain Adaptation for Zero-Shot Question Answering,0.0707825,"Pretrained language models have shown success in various areas of natural
language processing, including reading comprehension tasks. However, when
applying machine learning methods to new domains, labeled data may not always
be available. To address this, we use supervised pretraining on source-domain
data to reduce sample complexity on domain-specific downstream tasks. We
evaluate zero-shot performance on domain-specific reading comprehension tasks
by combining task transfer with domain adaptation to fine-tune a pretrained
model with no labelled data from the target task. Our approach outperforms
Domain-Adaptive Pretraining on downstream domain-specific reading comprehension
tasks in 3 out of 4 domains."
Monocular Dynamic View Synthesis: A Reality Check,0.913566,"We study the recent progress on dynamic view synthesis (DVS) from monocular
video. Though existing approaches have demonstrated impressive results, we show
a discrepancy between the practical capture process and the existing
experimental protocols, which effectively leaks in multi-view signals during
training. We define effective multi-view factors (EMFs) to quantify the amount
of multi-view signal present in the input capture sequence based on the
relative camera-scene motion. We introduce two new metrics: co-visibility
masked image metrics and correspondence accuracy, which overcome the issue in
existing protocols. We also propose a new iPhone dataset that includes more
diverse real-life deformation sequences. Using our proposed experimental
protocol, we show that the state-of-the-art approaches observe a 1-2 dB drop in
masked PSNR in the absence of multi-view cues and 4-5 dB drop when modeling
complex motion. Code and data can be found at https://hangg7.com/dycheck."
Universal Perturbation Attack on Differentiable No-Reference Image- and Video-Quality Metrics,0.506226,"Universal adversarial perturbation attacks are widely used to analyze image
classifiers that employ convolutional neural networks. Nowadays, some attacks
can deceive image- and video-quality metrics. So sustainability analysis of
these metrics is important. Indeed, if an attack can confuse the metric, an
attacker can easily increase quality scores. When developers of image- and
video-algorithms can boost their scores through detached processing, algorithm
comparisons are no longer fair. Inspired by the idea of universal adversarial
perturbation for classifiers, we suggest a new method to attack differentiable
no-reference quality metrics through universal perturbation. We applied this
method to seven no-reference image- and video-quality metrics (PaQ-2-PiQ,
Linearity, VSFA, MDTVSFA, KonCept512, Nima and SPAQ). For each one, we trained
a universal perturbation that increases the respective scores. We also propose
a method for assessing metric stability and identify the metrics that are the
most vulnerable and the most resistant to our attack. The existence of
successful universal perturbations appears to diminish the metric's ability to
provide reliable scores. We therefore recommend our proposed method as an
additional verification of metric reliability to complement traditional
subjective tests and benchmarks."
A Streamlit-based Artificial Intelligence Trust Platform for Next-Generation Wireless Networks,0.527545,"With the rapid development and integration of artificial intelligence (AI)
methods in next-generation networks (NextG), AI algorithms have provided
significant advantages for NextG in terms of frequency spectrum usage,
bandwidth, latency, and security. A key feature of NextG is the integration of
AI, i.e., self-learning architecture based on self-supervised algorithms, to
improve the performance of the network. A secure AI-powered structure is also
expected to protect NextG networks against cyber-attacks. However, AI itself
may be attacked, i.e., model poisoning targeted by attackers, and it results in
cybersecurity violations. This paper proposes an AI trust platform using
Streamlit for NextG networks that allows researchers to evaluate, defend,
certify, and verify their AI models and applications against adversarial
threats of evasion, poisoning, extraction, and interference."
Deformable Voxel Grids for Shape Comparisons,0.0538978,"We present Deformable Voxel Grids (DVGs) for 3D shapes comparison and
processing. It consists of a voxel grid which is deformed to approximate the
silhouette of a shape, via energy-minimization. By interpreting the DVG as a
local coordinates system, it provides a better embedding space than a regular
voxel grid, since it is adapted to the geometry of the shape. It also allows to
deform the shape by moving the control points of the DVG, in a similar manner
to the Free Form Deformation, but with easier interpretability of the control
points positions. After proposing a computation scheme of the energies
compatible with meshes and pointclouds, we demonstrate the use of DVGs in a
variety of applications: correspondences via cubification, style transfer,
shape retrieval and PCA deformations. The first two require no learning and can
be readily run on any shapes in a matter of minutes on modest hardware. As for
the last two, they require to first optimize DVGs on a collection of shapes,
which amounts to a pre-processing step. Then, determining PCA coordinates is
straightforward and brings a few parameters to deform a shape."
Visual Place Recognition with Low-Resolution Images,0.0893831,"Images incorporate a wealth of information from a robot's surroundings. With
the widespread availability of compact cameras, visual information has become
increasingly popular for addressing the localisation problem, which is then
termed as Visual Place Recognition (VPR). While many applications use
high-resolution cameras and high-end systems to achieve optimal place-matching
performance, low-end commercial systems face limitations due to resource
constraints and relatively low-resolution and low-quality cameras. In this
paper, we analyse the effects of image resolution on the accuracy and
robustness of well-established handcrafted VPR pipelines. Handcrafted designs
have low computational demands and can adapt to flexible image resolutions,
making them a suitable approach to scale to any image source and to operate
under resource limitations. This paper aims to help academic researchers and
companies in the hardware and software industry co-design VPR solutions and
expand the use of VPR algorithms in commercial products."
EmphAssess : a Prosodic Benchmark on Assessing Emphasis Transfer in Speech-to-Speech Models,0.347567,"We introduce EmphAssess, a prosodic benchmark designed to evaluate the
capability of speech-to-speech models to encode and reproduce prosodic
emphasis. We apply this to two tasks: speech resynthesis and speech-to-speech
translation. In both cases, the benchmark evaluates the ability of the model to
encode emphasis in the speech input and accurately reproduce it in the output,
potentially across a change of speaker and language. As part of the evaluation
pipeline, we introduce EmphaClass, a new model that classifies emphasis at the
frame or word level."
Constructing Open Cloze Tests Using Generation and Discrimination Capabilities of Transformers,0.318813,"This paper presents the first multi-objective transformer model for
constructing open cloze tests that exploits generation and discrimination
capabilities to improve performance. Our model is further enhanced by tweaking
its loss function and applying a post-processing re-ranking algorithm that
improves overall test structure. Experiments using automatic and human
evaluation show that our approach can achieve up to 82% accuracy according to
experts, outperforming previous work and baselines. We also release a
collection of high-quality open cloze tests along with sample system output and
human annotations that can serve as a future benchmark."
A Psycholinguistic Analysis of BERT's Representations of Compounds,0.497774,"This work studies the semantic representations learned by BERT for compounds,
that is, expressions such as sunlight or bodyguard. We build on recent studies
that explore semantic information in Transformers at the word level and test
whether BERT aligns with human semantic intuitions when dealing with
expressions (e.g., sunlight) whose overall meaning depends -- to a various
extent -- on the semantics of the constituent words (sun, light). We leverage a
dataset that includes human judgments on two psycholinguistic measures of
compound semantic analysis: lexeme meaning dominance (LMD; quantifying the
weight of each constituent toward the compound meaning) and semantic
transparency (ST; evaluating the extent to which the compound meaning is
recoverable from the constituents' semantics). We show that BERT-based measures
moderately align with human intuitions, especially when using contextualized
representations, and that LMD is overall more predictable than ST. Contrary to
the results reported for 'standard' words, higher, more contextualized layers
are the best at representing compound meaning. These findings shed new light on
the abilities of BERT in dealing with fine-grained semantic phenomena.
Moreover, they can provide insights into how speakers represent compounds."
Multilinguals at SemEval-2022 Task 11: Transformer Based Architecture for Complex NER,0.345359,"We investigate the task of complex NER for the English language. The task is
non-trivial due to the semantic ambiguity of the textual structure and the
rarity of occurrence of such entities in the prevalent literature. Using
pre-trained language models such as BERT, we obtain a competitive performance
on this task. We qualitatively analyze the performance of multiple
architectures for this task. All our models are able to outperform the baseline
by a significant margin. Our best performing model beats the baseline F1-score
by over 9%."
"StoryER: Automatic Story Evaluation via Ranking, Rating and Reasoning",0.222113,"Existing automatic story evaluation methods place a premium on story lexical
level coherence, deviating from human preference. We go beyond this limitation
by considering a novel \textbf{Story} \textbf{E}valuation method that mimics
human preference when judging a story, namely \textbf{StoryER}, which consists
of three sub-tasks: \textbf{R}anking, \textbf{R}ating and \textbf{R}easoning.
Given either a machine-generated or a human-written story, StoryER requires the
machine to output 1) a preference score that corresponds to human preference,
2) specific ratings and their corresponding confidences and 3) comments for
various aspects (e.g., opening, character-shaping). To support these tasks, we
introduce a well-annotated dataset comprising (i) 100k ranked story pairs; and
(ii) a set of 46k ratings and comments on various aspects of the story. We
finetune Longformer-Encoder-Decoder (LED) on the collected dataset, with the
encoder responsible for preference score and aspect prediction and the decoder
for comment generation. Our comprehensive experiments result in a competitive
benchmark for each task, showing the high correlation to human preference. In
addition, we have witnessed the joint learning of the preference scores, the
aspect ratings, and the comments brings gain in each single task. Our dataset
and benchmarks are publicly available to advance the research of story
evaluation tasks.\footnote{Dataset and pre-trained model demo are available at
anonymous website \url{http://storytelling-lab.com/eval} and
\url{https://github.com/sairin1202/StoryER}}"
3D Feature Prediction for Masked-AutoEncoder-Based Point Cloud Pretraining,0.871314,"Masked autoencoders (MAE) have recently been introduced to 3D self-supervised
pretraining for point clouds due to their great success in NLP and computer
vision. Unlike MAEs used in the image domain, where the pretext task is to
restore features at the masked pixels, such as colors, the existing 3D MAE
works reconstruct the missing geometry only, i.e, the location of the masked
points. In contrast to previous studies, we advocate that point location
recovery is inessential and restoring intrinsic point features is much
superior. To this end, we propose to ignore point position reconstruction and
recover high-order features at masked points including surface normals and
surface variations, through a novel attention-based decoder which is
independent of the encoder design. We validate the effectiveness of our pretext
task and decoder design using different encoder structures for 3D training and
demonstrate the advantages of our pretrained networks on various point cloud
analysis tasks."
Prototypical Fine-tuning: Towards Robust Performance Under Varying Data Sizes,0.154759,"In this paper, we move towards combining large parametric models with
non-parametric prototypical networks. We propose prototypical fine-tuning, a
novel prototypical framework for fine-tuning pretrained language models (LM),
which automatically learns a bias to improve predictive performance for varying
data sizes, especially low-resource settings. Our prototypical fine-tuning
approach can automatically adjust the model capacity according to the number of
data points and the model's inherent attributes. Moreover, we propose four
principles for effective prototype fine-tuning towards the optimal solution.
Experimental results across various datasets show that our work achieves
significant performance improvements under various low-resource settings, as
well as comparable and usually better performances in high-resource scenarios."
An Overview of Violence Detection Techniques: Current Challenges and Future Directions,0.207463,"The Big Video Data generated in today's smart cities has raised concerns from
its purposeful usage perspective, where surveillance cameras, among many others
are the most prominent resources to contribute to the huge volumes of data,
making its automated analysis a difficult task in terms of computation and
preciseness. Violence Detection (VD), broadly plunging under Action and
Activity recognition domain, is used to analyze Big Video data for anomalous
actions incurred due to humans. The VD literature is traditionally based on
manually engineered features, though advancements to deep learning based
standalone models are developed for real-time VD analysis. This paper focuses
on overview of deep sequence learning approaches along with localization
strategies of the detected violence. This overview also dives into the initial
image processing and machine learning-based VD literature and their possible
advantages such as efficiency against the current complex models.
Furthermore,the datasets are discussed, to provide an analysis of the current
models, explaining their pros and cons with future directions in VD domain
derived from an in-depth analysis of the previous methods."
SOTIF Entropy: Online SOTIF Risk Quantification and Mitigation for Autonomous Driving,0.337696,"Autonomous driving confronts great challenges in complex traffic scenarios,
where the risk of Safety of the Intended Functionality (SOTIF) can be triggered
by the dynamic operational environment and system insufficiencies. The SOTIF
risk is reflected not only intuitively in the collision risk with objects
outside the autonomous vehicles (AVs), but also inherently in the performance
limitation risk of the implemented algorithms themselves. How to minimize the
SOTIF risk for autonomous driving is currently a critical, difficult, and
unresolved issue. Therefore, this paper proposes the ""Self-Surveillance and
Self-Adaption System"" as a systematic approach to online minimize the SOTIF
risk, which aims to provide a systematic solution for monitoring,
quantification, and mitigation of inherent and external risks. The core of this
system is the risk monitoring of the implemented artificial intelligence
algorithms within the AV. As a demonstration of the Self-Surveillance and
Self-Adaption System, the risk monitoring of the perception algorithm, i.e.,
YOLOv5 is highlighted. Moreover, the inherent perception algorithm risk and
external collision risk are jointly quantified via SOTIF entropy, which is then
propagated downstream to the decision-making module and mitigated. Finally,
several challenging scenarios are demonstrated, and the Hardware-in-the-Loop
experiments are conducted to verify the efficiency and effectiveness of the
system. The results demonstrate that the Self-Surveillance and Self-Adaption
System enables dependable online monitoring, quantification, and mitigation of
SOTIF risk in real-time critical traffic environments."
CrossFormer: Cross Spatio-Temporal Transformer for 3D Human Pose Estimation,0.572707,"3D human pose estimation can be handled by encoding the geometric
dependencies between the body parts and enforcing the kinematic constraints.
Recently, Transformer has been adopted to encode the long-range dependencies
between the joints in the spatial and temporal domains. While they had shown
excellence in long-range dependencies, studies have noted the need for
improving the locality of vision Transformers. In this direction, we propose a
novel pose estimation Transformer featuring rich representations of body joints
critical for capturing subtle changes across frames (i.e., inter-feature
representation). Specifically, through two novel interaction modules;
Cross-Joint Interaction and Cross-Frame Interaction, the model explicitly
encodes the local and global dependencies between the body joints. The proposed
architecture achieved state-of-the-art performance on two popular 3D human pose
estimation datasets, Human3.6 and MPI-INF-3DHP. In particular, our proposed
CrossFormer method boosts performance by 0.9% and 0.3%, compared to the closest
counterpart, PoseFormer, using the detected 2D poses and ground-truth settings
respectively."
Bi-level Dynamic Learning for Jointly Multi-modality Image Fusion and Beyond,0.855567,"Recently, multi-modality scene perception tasks, e.g., image fusion and scene
understanding, have attracted widespread attention for intelligent vision
systems. However, early efforts always consider boosting a single task
unilaterally and neglecting others, seldom investigating their underlying
connections for joint promotion. To overcome these limitations, we establish
the hierarchical dual tasks-driven deep model to bridge these tasks.
Concretely, we firstly construct an image fusion module to fuse complementary
characteristics and cascade dual task-related modules, including a
discriminator for visual effects and a semantic network for feature
measurement. We provide a bi-level perspective to formulate image fusion and
follow-up downstream tasks. To incorporate distinct task-related responses for
image fusion, we consider image fusion as a primary goal and dual modules as
learnable constraints. Furthermore, we develop an efficient first-order
approximation to compute corresponding gradients and present dynamic weighted
aggregation to balance the gradients for fusion learning. Extensive experiments
demonstrate the superiority of our method, which not only produces visually
pleasant fused results but also realizes significant promotion for detection
and segmentation than the state-of-the-art approaches."
Knowledge-grounded Natural Language Recommendation Explanation,0.238709,"Explanations accompanied by a recommendation can assist users in
understanding the decision made by recommendation systems, which in turn
increases a user's confidence and trust in the system. Recently, research has
focused on generating natural language explanations in a human-readable format.
Thus far, the proposed approaches leverage item reviews written by users, which
are often subjective, sparse in language, and unable to account for new items
that have not been purchased or reviewed before. Instead, we aim to generate
fact-grounded recommendation explanations that are objectively described with
item features while implicitly considering a user's preferences, based on the
user's purchase history. To achieve this, we propose a knowledge graph (KG)
approach to natural language explainable recommendation. Our approach draws on
user-item features through a novel collaborative filtering-based KG
representation to produce fact-grounded, personalized explanations, while
jointly learning user-item representations for recommendation scoring.
Experimental results show that our approach consistently outperforms previous
state-of-the-art models on natural language explainable recommendation."
Text-to-SQL Error Correction with Language Models of Code,0.632121,"Despite recent progress in text-to-SQL parsing, current semantic parsers are
still not accurate enough for practical use. In this paper, we investigate how
to build automatic text-to-SQL error correction models. Noticing that
token-level edits are out of context and sometimes ambiguous, we propose
building clause-level edit models instead. Besides, while most language models
of code are not specifically pre-trained for SQL, they know common data
structures and their operations in programming languages such as Python. Thus,
we propose a novel representation for SQL queries and their edits that adheres
more closely to the pre-training corpora of language models of code. Our error
correction model improves the exact set match accuracy of different parsers by
2.4-6.5 and obtains up to 4.3 point absolute improvement over two strong
baselines. Our code and data are available at
https://github.com/OSU-NLP-Group/Auto-SQL-Correction."
Tokenwise Contrastive Pretraining for Finer Speech-to-BERT Alignment in End-to-End Speech-to-Intent Systems,0.215277,"Recent advances in End-to-End (E2E) Spoken Language Understanding (SLU) have
been primarily due to effective pretraining of speech representations. One such
pretraining paradigm is the distillation of semantic knowledge from
state-of-the-art text-based models like BERT to speech encoder neural networks.
This work is a step towards doing the same in a much more efficient and
fine-grained manner where we align speech embeddings and BERT embeddings on a
token-by-token basis. We introduce a simple yet novel technique that uses a
cross-modal attention mechanism to extract token-level contextual embeddings
from a speech encoder such that these can be directly compared and aligned with
BERT based contextual embeddings. This alignment is performed using a novel
tokenwise contrastive loss. Fine-tuning such a pretrained model to perform
intent recognition using speech directly yields state-of-the-art performance on
two widely used SLU datasets. Our model improves further when fine-tuned with
additional regularization using SpecAugment especially when speech is noisy,
giving an absolute improvement as high as 8% over previous results."
MobileCodec: Neural Inter-frame Video Compression on Mobile Devices,0.590536,"Realizing the potential of neural video codecs on mobile devices is a big
technological challenge due to the computational complexity of deep networks
and the power-constrained mobile hardware. We demonstrate practical feasibility
by leveraging Qualcomm's technology and innovation, bridging the gap from
neural network-based codec simulations running on wall-powered workstations, to
real-time operation on a mobile device powered by Snapdragon technology. We
show the first-ever inter-frame neural video decoder running on a commercial
mobile phone, decoding high-definition videos in real-time while maintaining a
low bitrate and high visual quality."
Geometric Features Informed Multi-person Human-object Interaction Recognition in Videos,0.327975,"Human-Object Interaction (HOI) recognition in videos is important for
analyzing human activity. Most existing work focusing on visual features
usually suffer from occlusion in the real-world scenarios. Such a problem will
be further complicated when multiple people and objects are involved in HOIs.
Consider that geometric features such as human pose and object position provide
meaningful information to understand HOIs, we argue to combine the benefits of
both visual and geometric features in HOI recognition, and propose a novel
Two-level Geometric feature-informed Graph Convolutional Network (2G-GCN). The
geometric-level graph models the interdependency between geometric features of
humans and objects, while the fusion-level graph further fuses them with visual
features of humans and objects. To demonstrate the novelty and effectiveness of
our method in challenging scenarios, we propose a new multi-person HOI dataset
(MPHOI-72). Extensive experiments on MPHOI-72 (multi-person HOI), CAD-120
(single-human HOI) and Bimanual Actions (two-hand HOI) datasets demonstrate our
superior performance compared to state-of-the-arts."
Rope3D: TheRoadside Perception Dataset for Autonomous Driving and Monocular 3D Object Detection Task,0.882074,"Concurrent perception datasets for autonomous driving are mainly limited to
frontal view with sensors mounted on the vehicle. None of them is designed for
the overlooked roadside perception tasks. On the other hand, the data captured
from roadside cameras have strengths over frontal-view data, which is believed
to facilitate a safer and more intelligent autonomous driving system. To
accelerate the progress of roadside perception, we present the first
high-diversity challenging Roadside Perception 3D dataset- Rope3D from a novel
view. The dataset consists of 50k images and over 1.5M 3D objects in various
scenes, which are captured under different settings including various cameras
with ambiguous mounting positions, camera specifications, viewpoints, and
different environmental conditions. We conduct strict 2D-3D joint annotation
and comprehensive data analysis, as well as set up a new 3D roadside perception
benchmark with metrics and evaluation devkit. Furthermore, we tailor the
existing frontal-view monocular 3D object detection approaches and propose to
leverage the geometry constraint to solve the inherent ambiguities caused by
various sensors, viewpoints. Our dataset is available on
https://thudair.baai.ac.cn/rope."
Motion Sensitive Contrastive Learning for Self-supervised Video Representation,0.459931,"Contrastive learning has shown great potential in video representation
learning. However, existing approaches fail to sufficiently exploit short-term
motion dynamics, which are crucial to various down-stream video understanding
tasks. In this paper, we propose Motion Sensitive Contrastive Learning (MSCL)
that injects the motion information captured by optical flows into RGB frames
to strengthen feature learning. To achieve this, in addition to clip-level
global contrastive learning, we develop Local Motion Contrastive Learning
(LMCL) with frame-level contrastive objectives across the two modalities.
Moreover, we introduce Flow Rotation Augmentation (FRA) to generate extra
motion-shuffled negative samples and Motion Differential Sampling (MDS) to
accurately screen training samples. Extensive experiments on standard
benchmarks validate the effectiveness of the proposed method. With the
commonly-used 3D ResNet-18 as the backbone, we achieve the top-1 accuracies of
91.5\% on UCF101 and 50.3\% on Something-Something v2 for video classification,
and a 65.6\% Top-1 Recall on UCF101 for video retrieval, notably improving the
state-of-the-art."
Monocular 3D Object Reconstruction with GAN Inversion,0.219422,"Recovering a textured 3D mesh from a monocular image is highly challenging,
particularly for in-the-wild objects that lack 3D ground truths. In this work,
we present MeshInversion, a novel framework to improve the reconstruction by
exploiting the generative prior of a 3D GAN pre-trained for 3D textured mesh
synthesis. Reconstruction is achieved by searching for a latent space in the 3D
GAN that best resembles the target mesh in accordance with the single view
observation. Since the pre-trained GAN encapsulates rich 3D semantics in terms
of mesh geometry and texture, searching within the GAN manifold thus naturally
regularizes the realness and fidelity of the reconstruction. Importantly, such
regularization is directly applied in the 3D space, providing crucial guidance
of mesh parts that are unobserved in the 2D space. Experiments on standard
benchmarks show that our framework obtains faithful 3D reconstructions with
consistent geometry and texture across both observed and unobserved parts.
Moreover, it generalizes well to meshes that are less commonly seen, such as
the extended articulation of deformable objects. Code is released at
https://github.com/junzhezhang/mesh-inversion"
Analyzing social media with crowdsourcing in Crowd4SDG,0.0883571,"Social media have the potential to provide timely information about emergency
situations and sudden events. However, finding relevant information among
millions of posts being posted every day can be difficult, and developing a
data analysis project usually requires time and technical skills. This study
presents an approach that provides flexible support for analyzing social media,
particularly during emergencies. Different use cases in which social media
analysis can be adopted are introduced, and the challenges of retrieving
information from large sets of posts are discussed.
  The focus is on analyzing images and text contained in social media posts and
a set of automatic data processing tools for filtering, classification, and
geolocation of content with a human-in-the-loop approach to support the data
analyst. Such support includes both feedback and suggestions to configure
automated tools, and crowdsourcing to gather inputs from citizens. The results
are validated by discussing three case studies developed within the Crowd4SDG
H2020 European project."
SimANS: Simple Ambiguous Negatives Sampling for Dense Text Retrieval,0.673324,"Sampling proper negatives from a large document pool is vital to effectively
train a dense retrieval model. However, existing negative sampling strategies
suffer from the uninformative or false negative problem. In this work, we
empirically show that according to the measured relevance scores, the negatives
ranked around the positives are generally more informative and less likely to
be false negatives. Intuitively, these negatives are not too hard (\emph{may be
false negatives}) or too easy (\emph{uninformative}). They are the ambiguous
negatives and need more attention during training. Thus, we propose a simple
ambiguous negatives sampling method, SimANS, which incorporates a new sampling
probability distribution to sample more ambiguous negatives. Extensive
experiments on four public and one industry datasets show the effectiveness of
our approach. We made the code and models publicly available in
\url{https://github.com/microsoft/SimXNS}."
Combining Reinforcement Learning and Optimal Transport for the Traveling Salesman Problem,0.146551,"The traveling salesman problem is a fundamental combinatorial optimization
problem with strong exact algorithms. However, as problems scale up, these
exact algorithms fail to provide a solution in a reasonable time. To resolve
this, current works look at utilizing deep learning to construct reasonable
solutions. Such efforts have been very successful, but tend to be slow and
compute intensive. This paper exemplifies the integration of entropic
regularized optimal transport techniques as a layer in a deep reinforcement
learning network. We show that we can construct a model capable of learning
without supervision and inferences significantly faster than current
autoregressive approaches. We also empirically evaluate the benefits of
including optimal transport algorithms within deep learning models to enforce
assignment constraints during end-to-end training."
Semi-supervised Deep Large-baseline Homography Estimation with Progressive Equivalence Constraint,0.343644,"Homography estimation is erroneous in the case of large-baseline due to the
low image overlay and limited receptive field. To address it, we propose a
progressive estimation strategy by converting large-baseline homography into
multiple intermediate ones, cumulatively multiplying these intermediate items
can reconstruct the initial homography. Meanwhile, a semi-supervised homography
identity loss, which consists of two components: a supervised objective and an
unsupervised objective, is introduced. The first supervised loss is acting to
optimize intermediate homographies, while the second unsupervised one helps to
estimate a large-baseline homography without photometric losses. To validate
our method, we propose a large-scale dataset that covers regular and
challenging scenes. Experiments show that our method achieves state-of-the-art
performance in large-baseline scenes while keeping competitive performance in
small-baseline scenes. Code and dataset are available at
https://github.com/megvii-research/LBHomo."
Features Fusion Framework for Multimodal Irregular Time-series Events,0.292714,"Some data from multiple sources can be modeled as multimodal time-series
events which have different sampling frequencies, data compositions, temporal
relations and characteristics. Different types of events have complex nonlinear
relationships, and the time of each event is irregular. Neither the classical
Recurrent Neural Network (RNN) model nor the current state-of-the-art
Transformer model can deal with these features well. In this paper, a features
fusion framework for multimodal irregular time-series events is proposed based
on the Long Short-Term Memory networks (LSTM). Firstly, the complex features
are extracted according to the irregular patterns of different events.
Secondly, the nonlinear correlation and complex temporal dependencies
relationship between complex features are captured and fused into a tensor.
Finally, a feature gate are used to control the access frequency of different
tensors. Extensive experiments on MIMIC-III dataset demonstrate that the
proposed framework significantly outperforms to the existing methods in terms
of AUC (the area under Receiver Operating Characteristic curve) and AP (Average
Precision)."
MT4SSL: Boosting Self-Supervised Speech Representation Learning by Integrating Multiple Targets,0.791299,"In this paper, we provide a new perspective on self-supervised speech models
from how the training targets are obtained. We generalize the targets extractor
into Offline Targets Extractor (Off-TE) and Online Targets Extractor (On-TE).
Based on this, we propose a new multi-tasking learning framework for
self-supervised learning, MT4SSL, which stands for Boosting Self-Supervised
Speech Representation Learning by Integrating Multiple Targets. MT4SSL uses the
K-means algorithm as an Off-TE and a teacher network without gradients as an
On-TE, respectively. Our model outperforms previous SSL methods by nontrivial
margins on the LibriSpeech benchmark, and is comparable to or even better than
the best-performing models with fewer data. Furthermore, we find that using
both Off-TE and On-TE results in better convergence in the pre-training phase.
With both effectiveness and efficiency, we think doing multi-task learning on
self-supervised speech models from our perspective is a promising trend."
"Detection, Disambiguation, Re-ranking: Autoregressive Entity Linking as a Multi-Task Problem",0.882282,"We propose an autoregressive entity linking model, that is trained with two
auxiliary tasks, and learns to re-rank generated samples at inference time. Our
proposed novelties address two weaknesses in the literature. First, a recent
method proposes to learn mention detection and then entity candidate selection,
but relies on predefined sets of candidates. We use encoder-decoder
autoregressive entity linking in order to bypass this need, and propose to
train mention detection as an auxiliary task instead. Second, previous work
suggests that re-ranking could help correct prediction errors. We add a new,
auxiliary task, match prediction, to learn re-ranking. Without the use of a
knowledge base or candidate sets, our model sets a new state of the art in two
benchmark datasets of entity linking: COMETA in the biomedical domain, and
AIDA-CoNLL in the news domain. We show through ablation studies that each of
the two auxiliary tasks increases performance, and that re-ranking is an
important factor to the increase. Finally, our low-resource experimental
results suggest that performance on the main task benefits from the knowledge
learned by the auxiliary tasks, and not just from the additional training data."
Supervised Adversarial Contrastive Learning for Emotion Recognition in Conversations,0.996819,"Extracting generalized and robust representations is a major challenge in
emotion recognition in conversations (ERC). To address this, we propose a
supervised adversarial contrastive learning (SACL) framework for learning
class-spread structured representations in a supervised manner. SACL applies
contrast-aware adversarial training to generate worst-case samples and uses
joint class-spread contrastive learning to extract structured representations.
It can effectively utilize label-level feature consistency and retain
fine-grained intra-class features. To avoid the negative impact of adversarial
perturbations on context-dependent data, we design a contextual adversarial
training (CAT) strategy to learn more diverse features from context and enhance
the model's context robustness. Under the framework with CAT, we develop a
sequence-based SACL-LSTM to learn label-consistent and context-robust features
for ERC. Experiments on three datasets show that SACL-LSTM achieves
state-of-the-art performance on ERC. Extended experiments prove the
effectiveness of SACL and CAT."
MolScribe: Robust Molecular Structure Recognition with Image-To-Graph Generation,0.669867,"Molecular structure recognition is the task of translating a molecular image
into its graph structure. Significant variation in drawing styles and
conventions exhibited in chemical literature poses a significant challenge for
automating this task. In this paper, we propose MolScribe, a novel
image-to-graph generation model that explicitly predicts atoms and bonds, along
with their geometric layouts, to construct the molecular structure. Our model
flexibly incorporates symbolic chemistry constraints to recognize chirality and
expand abbreviated structures. We further develop data augmentation strategies
to enhance the model robustness against domain shifts. In experiments on both
synthetic and realistic molecular images, MolScribe significantly outperforms
previous models, achieving 76-93% accuracy on public benchmarks. Chemists can
also easily verify MolScribe's prediction, informed by its confidence
estimation and atom-level alignment with the input image. MolScribe is publicly
available through Python and web interfaces:
https://github.com/thomas0809/MolScribe."
Beyond Hard Labels: Investigating data label distributions,0.254992,"High-quality data is a key aspect of modern machine learning. However, labels
generated by humans suffer from issues like label noise and class ambiguities.
We raise the question of whether hard labels are sufficient to represent the
underlying ground truth distribution in the presence of these inherent
imprecision. Therefore, we compare the disparity of learning with hard and soft
labels quantitatively and qualitatively for a synthetic and a real-world
dataset. We show that the application of soft labels leads to improved
performance and yields a more regular structure of the internal feature space."
NoCoLA: The Norwegian Corpus of Linguistic Acceptability,0.480904,"While there has been a surge of large language models for Norwegian in recent
years, we lack any tool to evaluate their understanding of grammaticality. We
present two new Norwegian datasets for this task. NoCoLA_class is a supervised
binary classification task where the goal is to discriminate between acceptable
and non-acceptable sentences. On the other hand, NoCoLA_zero is a purely
diagnostic task for evaluating the grammatical judgement of a language model in
a completely zero-shot manner, i.e. without any further training. In this
paper, we describe both datasets in detail, show how to use them for different
flavors of language models, and conduct a comparative study of the existing
Norwegian language models."
Probabilities Are Not Enough: Formal Controller Synthesis for Stochastic Dynamical Models with Epistemic Uncertainty,0.983455,"Capturing uncertainty in models of complex dynamical systems is crucial to
designing safe controllers. Stochastic noise causes aleatoric uncertainty,
whereas imprecise knowledge of model parameters leads to epistemic uncertainty.
Several approaches use formal abstractions to synthesize policies that satisfy
temporal specifications related to safety and reachability. However, the
underlying models exclusively capture aleatoric but not epistemic uncertainty,
and thus require that model parameters are known precisely. Our contribution to
overcoming this restriction is a novel abstraction-based controller synthesis
method for continuous-state models with stochastic noise and uncertain
parameters. By sampling techniques and robust analysis, we capture both
aleatoric and epistemic uncertainty, with a user-specified confidence level, in
the transition probability intervals of a so-called interval Markov decision
process (iMDP). We synthesize an optimal policy on this iMDP, which translates
(with the specified confidence level) to a feedback controller for the
continuous model with the same performance guarantees. Our experimental
benchmarks confirm that accounting for epistemic uncertainty leads to
controllers that are more robust against variations in parameter values."
Depth-aware Neural Style Transfer using Instance Normalization,0.454876,"Neural Style Transfer (NST) is concerned with the artistic stylization of
visual media. It can be described as the process of transferring the style of
an artistic image onto an ordinary photograph. Recently, a number of studies
have considered the enhancement of the depth-preserving capabilities of the NST
algorithms to address the undesired effects that occur when the input content
images include numerous objects at various depths. Our approach uses a deep
residual convolutional network with instance normalization layers that utilizes
an advanced depth prediction network to integrate depth preservation as an
additional loss function to content and style. We demonstrate results that are
effective in retaining the depth and global structure of content images. Three
different evaluation processes show that our system is capable of preserving
the structure of the stylized results while exhibiting style-capture
capabilities and aesthetic qualities comparable or superior to state-of-the-art
methods. Project page:
https://ioannoue.github.io/depth-aware-nst-using-in.html."
Scalable Diffusion Models with Transformers,0.986018,"We explore a new class of diffusion models based on the transformer
architecture. We train latent diffusion models of images, replacing the
commonly-used U-Net backbone with a transformer that operates on latent
patches. We analyze the scalability of our Diffusion Transformers (DiTs)
through the lens of forward pass complexity as measured by Gflops. We find that
DiTs with higher Gflops -- through increased transformer depth/width or
increased number of input tokens -- consistently have lower FID. In addition to
possessing good scalability properties, our largest DiT-XL/2 models outperform
all prior diffusion models on the class-conditional ImageNet 512x512 and
256x256 benchmarks, achieving a state-of-the-art FID of 2.27 on the latter."
Multi-Scale Occ: 4th Place Solution for CVPR 2023 3D Occupancy Prediction Challenge,0.400175,"In this report, we present the 4th place solution for CVPR 2023 3D occupancy
prediction challenge. We propose a simple method called Multi-Scale Occ for
occupancy prediction based on lift-splat-shoot framework, which introduces
multi-scale image features for generating better multi-scale 3D voxel features
with temporal fusion of multiple past frames. Post-processing including model
ensemble, test-time augmentation, and class-wise thresh are adopted to further
boost the final performance. As shown on the leaderboard, our proposed
occupancy prediction method ranks the 4th place with 49.36 mIoU."
A Comparative Study of Graph Neural Networks for Shape Classification in Neuroimaging,0.0849553,"Graph neural networks have emerged as a promising approach for the analysis
of non-Euclidean data such as meshes. In medical imaging, mesh-like data plays
an important role for modelling anatomical structures, and shape classification
can be used in computer aided diagnosis and disease detection. However, with a
plethora of options, the best architectural choices for medical shape analysis
using GNNs remain unclear. We conduct a comparative analysis to provide
practitioners with an overview of the current state-of-the-art in geometric
deep learning for shape classification in neuroimaging. Using biological sex
classification as a proof-of-concept task, we find that using FPFH as node
features substantially improves GNN performance and generalisation to
out-of-distribution data; we compare the performance of three alternative
convolutional layers; and we reinforce the importance of data augmentation for
graph based learning. We then confirm these results hold for a clinically
relevant task, using the classification of Alzheimer's disease."
Using EBGAN for Anomaly Intrusion Detection,0.122177,"As an active network security protection scheme, intrusion detection system
(IDS) undertakes the important responsibility of detecting network attacks in
the form of malicious network traffic. Intrusion detection technology is an
important part of IDS. At present, many scholars have carried out extensive
research on intrusion detection technology. However, developing an efficient
intrusion detection method for massive network traffic data is still difficult.
Since Generative Adversarial Networks (GANs) have powerful modeling
capabilities for complex high-dimensional data, they provide new ideas for
addressing this problem. In this paper, we put forward an EBGAN-based intrusion
detection method, IDS-EBGAN, that classifies network records as normal traffic
or malicious traffic. The generator in IDS-EBGAN is responsible for converting
the original malicious network traffic in the training set into adversarial
malicious examples. This is because we want to use adversarial learning to
improve the ability of discriminator to detect malicious traffic. At the same
time, the discriminator adopts Autoencoder model. During testing, IDS-EBGAN
uses reconstruction error of discriminator to classify traffic records."
RQUGE: Reference-Free Metric for Evaluating Question Generation by Answering the Question,0.58199,"Existing metrics for evaluating the quality of automatically generated
questions such as BLEU, ROUGE, BERTScore, and BLEURT compare the reference and
predicted questions, providing a high score when there is a considerable
lexical overlap or semantic similarity between the candidate and the reference
questions. This approach has two major shortcomings. First, we need expensive
human-provided reference questions. Second, it penalises valid questions that
may not have high lexical or semantic similarity to the reference questions. In
this paper, we propose a new metric, RQUGE, based on the answerability of the
candidate question given the context. The metric consists of a
question-answering and a span scorer modules, using pre-trained models from
existing literature, thus it can be used without any further training. We
demonstrate that RQUGE has a higher correlation with human judgment without
relying on the reference question. Additionally, RQUGE is shown to be more
robust to several adversarial corruptions. Furthermore, we illustrate that we
can significantly improve the performance of QA models on out-of-domain
datasets by fine-tuning on synthetic data generated by a question generation
model and re-ranked by RQUGE."
Toward Mesh-Invariant 3D Generative Deep Learning with Geometric Measures,0.250501,"3D generative modeling is accelerating as the technology allowing the capture
of geometric data is developing. However, the acquired data is often
inconsistent, resulting in unregistered meshes or point clouds. Many generative
learning algorithms require correspondence between each point when comparing
the predicted shape and the target shape. We propose an architecture able to
cope with different parameterizations, even during the training phase. In
particular, our loss function is built upon a kernel-based metric over a
representation of meshes using geometric measures such as currents and
varifolds. The latter allows to implement an efficient dissimilarity measure
with many desirable properties such as robustness to resampling of the mesh or
point cloud. We demonstrate the efficiency and resilience of our model with a
generative learning task of human faces."
Story Visualization by Online Text Augmentation with Context Memory,0.139489,"Story visualization (SV) is a challenging text-to-image generation task for
the difficulty of not only rendering visual details from the text descriptions
but also encoding a long-term context across multiple sentences. While prior
efforts mostly focus on generating a semantically relevant image for each
sentence, encoding a context spread across the given paragraph to generate
contextually convincing images (e.g., with a correct character or with a proper
background of the scene) remains a challenge. To this end, we propose a novel
memory architecture for the Bi-directional Transformer framework with an online
text augmentation that generates multiple pseudo-descriptions as supplementary
supervision during training for better generalization to the language variation
at inference. In extensive experiments on the two popular SV benchmarks, i.e.,
the Pororo-SV and Flintstones-SV, the proposed method significantly outperforms
the state of the arts in various metrics including FID, character F1, frame
accuracy, BLEU-2/3, and R-precision with similar or less computational
complexity."
VALHALLA: Visual Hallucination for Machine Translation,0.908053,"Designing better machine translation systems by considering auxiliary inputs
such as images has attracted much attention in recent years. While existing
methods show promising performance over the conventional text-only translation
systems, they typically require paired text and image as input during
inference, which limits their applicability to real-world scenarios. In this
paper, we introduce a visual hallucination framework, called VALHALLA, which
requires only source sentences at inference time and instead uses hallucinated
visual representations for multimodal machine translation. In particular, given
a source sentence an autoregressive hallucination transformer is used to
predict a discrete visual representation from the input text, and the combined
text and hallucinated representations are utilized to obtain the target
translation. We train the hallucination transformer jointly with the
translation transformer using standard backpropagation with cross-entropy
losses while being guided by an additional loss that encourages consistency
between predictions using either ground-truth or hallucinated visual
representations. Extensive experiments on three standard translation datasets
with a diverse set of language pairs demonstrate the effectiveness of our
approach over both text-only baselines and state-of-the-art methods. Project
page: http://www.svcl.ucsd.edu/projects/valhalla."
Human-Inspired Facial Sketch Synthesis with Dynamic Adaptation,0.266833,"Facial sketch synthesis (FSS) aims to generate a vivid sketch portrait from a
given facial photo. Existing FSS methods merely rely on 2D representations of
facial semantic or appearance. However, professional human artists usually use
outlines or shadings to covey 3D geometry. Thus facial 3D geometry (e.g. depth
map) is extremely important for FSS. Besides, different artists may use diverse
drawing techniques and create multiple styles of sketches; but the style is
globally consistent in a sketch. Inspired by such observations, in this paper,
we propose a novel Human-Inspired Dynamic Adaptation (HIDA) method. Specially,
we propose to dynamically modulate neuron activations based on a joint
consideration of both facial 3D geometry and 2D appearance, as well as globally
consistent style control. Besides, we use deformable convolutions at
coarse-scales to align deep features, for generating abstract and distinct
outlines. Experiments show that HIDA can generate high-quality sketches in
multiple styles, and significantly outperforms previous methods, over a large
range of challenging faces. Besides, HIDA allows precise style control of the
synthesized sketch, and generalizes well to natural scenes and other artistic
styles. Our code and results have been released online at:
https://github.com/AiArt-HDU/HIDA."
Counting Crowds in Bad Weather,0.683705,"Crowd counting has recently attracted significant attention in the field of
computer vision due to its wide applications to image understanding. Numerous
methods have been proposed and achieved state-of-the-art performance for
real-world tasks. However, existing approaches do not perform well under
adverse weather such as haze, rain, and snow since the visual appearances of
crowds in such scenes are drastically different from those images in clear
weather of typical datasets. In this paper, we propose a method for robust
crowd counting in adverse weather scenarios. Instead of using a two-stage
approach that involves image restoration and crowd counting modules, our model
learns effective features and adaptive queries to account for large appearance
variations. With these weather queries, the proposed model can learn the
weather information according to the degradation of the input image and
optimize with the crowd counting module simultaneously. Experimental results
show that the proposed algorithm is effective in counting crowds under
different weather types on benchmark datasets. The source code and trained
models will be made available to the public."
Noisy Parallel Data Alignment,0.0580636,"An ongoing challenge in current natural language processing is how its major
advancements tend to disproportionately favor resource-rich languages, leaving
a significant number of under-resourced languages behind. Due to the lack of
resources required to train and evaluate models, most modern language
technologies are either nonexistent or unreliable to process endangered, local,
and non-standardized languages. Optical character recognition (OCR) is often
used to convert endangered language documents into machine-readable data.
However, such OCR output is typically noisy, and most word alignment models are
not built to work under such noisy conditions. In this work, we study the
existing word-level alignment models under noisy settings and aim to make them
more robust to noisy data. Our noise simulation and structural biasing method,
tested on multiple language pairs, manages to reduce the alignment error rate
on a state-of-the-art neural-based alignment model up to 59.6%."
Deep Latent-Variable Models for Text Generation,0.0977558,"Text generation aims to produce human-like natural language output for
down-stream tasks. It covers a wide range of applications like machine
translation, document summarization, dialogue generation and so on. Recently
deep neural network-based end-to-end architectures have been widely adopted.
The end-to-end approach conflates all sub-modules, which used to be designed by
complex handcrafted rules, into a holistic encode-decode architecture. Given
enough training data, it is able to achieve state-of-the-art performance yet
avoiding the need of language/domain-dependent knowledge. Nonetheless, deep
learning models are known to be extremely data-hungry, and text generated from
them usually suffer from low diversity, interpretability and controllability.
As a result, it is difficult to trust the output from them in real-life
applications. Deep latent-variable models, by specifying the probabilistic
distribution over an intermediate latent process, provide a potential way of
addressing these problems while maintaining the expressive power of deep neural
networks. This dissertation presents how deep latent-variable models can
improve over the standard encoder-decoder model for text generation."
Improving Conversational Recommendation Systems via Bias Analysis and Language-Model-Enhanced Data Augmentation,0.742214,"Conversational Recommendation System (CRS) is a rapidly growing research area
that has gained significant attention alongside advancements in language
modelling techniques. However, the current state of conversational
recommendation faces numerous challenges due to its relative novelty and
limited existing contributions. In this study, we delve into benchmark datasets
for developing CRS models and address potential biases arising from the
feedback loop inherent in multi-turn interactions, including selection bias and
multiple popularity bias variants. Drawing inspiration from the success of
generative data via using language models and data augmentation techniques, we
present two novel strategies, 'Once-Aug' and 'PopNudge', to enhance model
performance while mitigating biases. Through extensive experiments on ReDial
and TG-ReDial benchmark datasets, we show a consistent improvement of CRS
techniques with our data augmentation approaches and offer additional insights
on addressing multiple newly formulated biases."
Federated Learning with Position-Aware Neurons,0.657481,"Federated Learning (FL) fuses collaborative models from local nodes without
centralizing users' data. The permutation invariance property of neural
networks and the non-i.i.d. data across clients make the locally updated
parameters imprecisely aligned, disabling the coordinate-based parameter
averaging. Traditional neurons do not explicitly consider position information.
Hence, we propose Position-Aware Neurons (PANs) as an alternative, fusing
position-related values (i.e., position encodings) into neuron outputs. PANs
couple themselves to their positions and minimize the possibility of
dislocation, even updating on heterogeneous data. We turn on/off PANs to
disable/enable the permutation invariance property of neural networks. PANs are
tightly coupled with positions when applied to FL, making parameters across
clients pre-aligned and facilitating coordinate-based parameter averaging. PANs
are algorithm-agnostic and could universally improve existing FL algorithms.
Furthermore, ""FL with PANs"" is simple to implement and computationally
friendly."
Risk-graded Safety for Handling Medical Queries in Conversational AI,0.618521,"Conversational AI systems can engage in unsafe behaviour when handling users'
medical queries that can have severe consequences and could even lead to
deaths. Systems therefore need to be capable of both recognising the
seriousness of medical inputs and producing responses with appropriate levels
of risk. We create a corpus of human written English language medical queries
and the responses of different types of systems. We label these with both
crowdsourced and expert annotations. While individual crowdworkers may be
unreliable at grading the seriousness of the prompts, their aggregated labels
tend to agree with professional opinion to a greater extent on identifying the
medical queries and recognising the risk types posed by the responses. Results
of classification experiments suggest that, while these tasks can be automated,
caution should be exercised, as errors can potentially be very serious."
FOLIO: Natural Language Reasoning with First-Order Logic,0.510599,"We present FOLIO, a human-annotated, open-domain, and logically complex and
diverse dataset for reasoning in natural language (NL), equipped with first
order logic (FOL) annotations. FOLIO consists of 1,435 examples (unique
conclusions), each paired with one of 487 sets of premises which serve as rules
to be used to deductively reason for the validity of each conclusion. The
logical correctness of premises and conclusions is ensured by their parallel
FOL annotations, which are automatically verified by our FOL inference engine.
In addition to the main NL reasoning task, NL-FOL pairs in FOLIO automatically
constitute a new NL-FOL translation dataset using FOL as the logical form. Our
experiments on FOLIO systematically evaluate the FOL reasoning ability of
supervised fine-tuning on medium-sized language models (BERT, RoBERTa) and
few-shot prompting on large language models (GPT-NeoX, OPT, GPT-3, Codex). For
NL-FOL translation, we experiment with GPT-3 and Codex. Our results show that
one of the most capable Large Language Model (LLM) publicly available, GPT-3
davinci, achieves only slightly better than random results with few-shot
prompting on a subset of FOLIO, and the model is especially bad at predicting
the correct truth values for False and Unknown conclusions. Our dataset and
code are available at https://github.com/Yale-LILY/FOLIO."
MR Image Denoising and Super-Resolution Using Regularized Reverse Diffusion,0.867339,"Patient scans from MRI often suffer from noise, which hampers the diagnostic
capability of such images. As a method to mitigate such artifact, denoising is
largely studied both within the medical imaging community and beyond the
community as a general subject. However, recent deep neural network-based
approaches mostly rely on the minimum mean squared error (MMSE) estimates,
which tend to produce a blurred output. Moreover, such models suffer when
deployed in real-world sitautions: out-of-distribution data, and complex noise
distributions that deviate from the usual parametric noise models. In this
work, we propose a new denoising method based on score-based reverse diffusion
sampling, which overcomes all the aforementioned drawbacks. Our network,
trained only with coronal knee scans, excels even on out-of-distribution in
vivo liver MRI data, contaminated with complex mixture of noise. Even more, we
propose a method to enhance the resolution of the denoised image with the same
network. With extensive experiments, we show that our method establishes
state-of-the-art performance, while having desirable properties which prior
MMSE denoisers did not have: flexibly choosing the extent of denoising, and
quantifying uncertainty."
SkeleVision: Towards Adversarial Resiliency of Person Tracking with Multi-Task Learning,0.0550003,"Person tracking using computer vision techniques has wide ranging
applications such as autonomous driving, home security and sports analytics.
However, the growing threat of adversarial attacks raises serious concerns
regarding the security and reliability of such techniques. In this work, we
study the impact of multi-task learning (MTL) on the adversarial robustness of
the widely used SiamRPN tracker, in the context of person tracking.
Specifically, we investigate the effect of jointly learning with semantically
analogous tasks of person tracking and human keypoint detection. We conduct
extensive experiments with more powerful adversarial attacks that can be
physically realizable, demonstrating the practical value of our approach. Our
empirical study with simulated as well as real-world datasets reveals that
training with MTL consistently makes it harder to attack the SiamRPN tracker,
compared to typically training only on the single task of person tracking."
PoxVerifi: An Information Verification System to Combat Monkeypox Misinformation,0.590795,"Following recent outbreaks, monkeypox-related misinformation continues to
rapidly spread online. This negatively impacts response strategies and
disproportionately harms LGBTQ+ communities in the short-term, and ultimately
undermines the overall effectiveness of public health responses. In an attempt
to combat monkeypox-related misinformation, we present PoxVerifi, an
open-source, extensible tool that provides a comprehensive approach to
assessing the accuracy of monkeypox related claims. Leveraging information from
existing fact checking sources and published World Health Organization (WHO)
information, we created an open-sourced corpus of 225 rated monkeypox claims.
Additionally, we trained an open-sourced BERT-based machine learning model for
specifically classifying monkeypox information, which achieved 96%
cross-validation accuracy. PoxVerifi is a Google Chrome browser extension
designed to empower users to navigate through monkeypox-related misinformation.
Specifically, PoxVerifi provides users with a comprehensive toolkit to assess
the veracity of headlines on any webpage across the Internet without having to
visit an external site. Users can view an automated accuracy review from our
trained machine learning model, a user-generated accuracy review based on
community-member votes, and have the ability to see similar, vetted, claims.
Besides PoxVerifi's comprehensive approach to claim-testing, our platform
provides an efficient and accessible method to crowdsource accuracy ratings on
monkeypox related-claims, which can be aggregated to create new labeled
misinformation datasets."
Differentiable Zooming for Multiple Instance Learning on Whole-Slide Images,0.914264,"Multiple Instance Learning (MIL) methods have become increasingly popular for
classifying giga-pixel sized Whole-Slide Images (WSIs) in digital pathology.
Most MIL methods operate at a single WSI magnification, by processing all the
tissue patches. Such a formulation induces high computational requirements, and
constrains the contextualization of the WSI-level representation to a single
scale. A few MIL methods extend to multiple scales, but are computationally
more demanding. In this paper, inspired by the pathological diagnostic process,
we propose ZoomMIL, a method that learns to perform multi-level zooming in an
end-to-end manner. ZoomMIL builds WSI representations by aggregating
tissue-context information from multiple magnifications. The proposed method
outperforms the state-of-the-art MIL methods in WSI classification on two large
datasets, while significantly reducing the computational demands with regard to
Floating-Point Operations (FLOPs) and processing time by up to 40x."
Reinforcement Learning of Multi-Domain Dialog Policies Via Action Embeddings,0.485925,"Learning task-oriented dialog policies via reinforcement learning typically
requires large amounts of interaction with users, which in practice renders
such methods unusable for real-world applications. In order to reduce the data
requirements, we propose to leverage data from across different dialog domains,
thereby reducing the amount of data required from each given domain. In
particular, we propose to learn domain-agnostic action embeddings, which
capture general-purpose structure that informs the system how to act given the
current dialog context, and are then specialized to a specific domain. We show
how this approach is capable of learning with significantly less interaction
with users, with a reduction of 35% in the number of dialogs required to learn,
and to a higher level of proficiency than training separate policies for each
domain on a set of simulated domains."
A distribution-dependent Mumford-Shah model for unsupervised hyperspectral image segmentation,0.0937102,"Hyperspectral images provide a rich representation of the underlying spectrum
for each pixel, allowing for a pixel-wise classification/segmentation into
different classes. As the acquisition of labeled training data is very
time-consuming, unsupervised methods become crucial in hyperspectral image
analysis. The spectral variability and noise in hyperspectral data make this
task very challenging and define special requirements for such methods.
  Here, we present a novel unsupervised hyperspectral segmentation framework.
It starts with a denoising and dimensionality reduction step by the
well-established Minimum Noise Fraction (MNF) transform. Then, the Mumford-Shah
(MS) segmentation functional is applied to segment the data. We equipped the MS
functional with a novel robust distribution-dependent indicator function
designed to handle the characteristic challenges of hyperspectral data. To
optimize our objective function with respect to the parameters for which no
closed form solution is available, we propose an efficient fixed point
iteration scheme. Numerical experiments on four public benchmark datasets show
that our method produces competitive results, which outperform three
state-of-the-art methods substantially on three of these datasets."
RC-MVSNet: Unsupervised Multi-View Stereo with Neural Rendering,0.500266,"Finding accurate correspondences among different views is the Achilles' heel
of unsupervised Multi-View Stereo (MVS). Existing methods are built upon the
assumption that corresponding pixels share similar photometric features.
However, multi-view images in real scenarios observe non-Lambertian surfaces
and experience occlusions. In this work, we propose a novel approach with
neural rendering (RC-MVSNet) to solve such ambiguity issues of correspondences
among views. Specifically, we impose a depth rendering consistency loss to
constrain the geometry features close to the object surface to alleviate
occlusions. Concurrently, we introduce a reference view synthesis loss to
generate consistent supervision, even for non-Lambertian surfaces. Extensive
experiments on DTU and Tanks\&Temples benchmarks demonstrate that our RC-MVSNet
approach achieves state-of-the-art performance over unsupervised MVS frameworks
and competitive performance to many supervised methods.The code is released at
https://github.com/Boese0601/RC-MVSNet"
Word-level Persian Lipreading Dataset,0.246093,"Lip-reading has made impressive progress in recent years, driven by advances
in deep learning. Nonetheless, the prerequisite such advances is a suitable
dataset. This paper provides a new in-the-wild dataset for Persian word-level
lipreading containing 244,000 videos from approximately 1,800 speakers. We
evaluated the state-of-the-art method in this field and used a novel approach
for word-level lip-reading. In this method, we used the AV-HuBERT model for
feature extraction and obtained significantly better performance on our
dataset."
SAGE: SLAM with Appearance and Geometry Prior for Endoscopy,0.824327,"In endoscopy, many applications (e.g., surgical navigation) would benefit
from a real-time method that can simultaneously track the endoscope and
reconstruct the dense 3D geometry of the observed anatomy from a monocular
endoscopic video. To this end, we develop a Simultaneous Localization and
Mapping system by combining the learning-based appearance and optimizable
geometry priors and factor graph optimization. The appearance and geometry
priors are explicitly learned in an end-to-end differentiable training pipeline
to master the task of pair-wise image alignment, one of the core components of
the SLAM system. In our experiments, the proposed SLAM system is shown to
robustly handle the challenges of texture scarceness and illumination variation
that are commonly seen in endoscopy. The system generalizes well to unseen
endoscopes and subjects and performs favorably compared with a state-of-the-art
feature-based SLAM system. The code repository is available at
https://github.com/lppllppl920/SAGE-SLAM.git."
SPECTRE: Spectral Conditioning Helps to Overcome the Expressivity Limits of One-shot Graph Generators,0.601672,"We approach the graph generation problem from a spectral perspective by first
generating the dominant parts of the graph Laplacian spectrum and then building
a graph matching these eigenvalues and eigenvectors. Spectral conditioning
allows for direct modeling of the global and local graph structure and helps to
overcome the expressivity and mode collapse issues of one-shot graph
generators. Our novel GAN, called SPECTRE, enables the one-shot generation of
much larger graphs than previously possible with one-shot models. SPECTRE
outperforms state-of-the-art deep autoregressive generators in terms of
modeling fidelity, while also avoiding expensive sequential generation and
dependence on node ordering. A case in point, in sizable synthetic and
real-world graphs SPECTRE achieves a 4-to-170 fold improvement over the best
competitor that does not overfit and is 23-to-30 times faster than
autoregressive generators."
Investigating Data Variance in Evaluations of Automatic Machine Translation Metrics,0.171987,"Current practices in metric evaluation focus on one single dataset, e.g.,
Newstest dataset in each year's WMT Metrics Shared Task. However, in this
paper, we qualitatively and quantitatively show that the performances of
metrics are sensitive to data. The ranking of metrics varies when the
evaluation is conducted on different datasets. Then this paper further
investigates two potential hypotheses, i.e., insignificant data points and the
deviation of Independent and Identically Distributed (i.i.d) assumption, which
may take responsibility for the issue of data variance. In conclusion, our
findings suggest that when evaluating automatic translation metrics,
researchers should take data variance into account and be cautious to claim the
result on a single dataset, because it may leads to inconsistent results with
most of other datasets."
Curriculum-Driven Edubot: A Framework for Developing Language Learning Chatbots Through Synthesizing Conversational Data,0.424263,"Chatbots have become popular in educational settings, revolutionizing how
students interact with material and how teachers teach. We present
Curriculum-Driven EduBot, a framework for developing a chatbot that combines
the interactive features of chatbots with the systematic material of English
textbooks to assist students in enhancing their conversational skills. We begin
by extracting pertinent topics from textbooks and then using large language
models to generate dialogues related to these topics. We then fine-tune an
open-source LLM using our generated conversational data to create our
curriculum-driven chatbot. User studies demonstrate that our chatbot
outperforms ChatGPT in leading curriculum-based dialogues and adapting its
dialogue to match the user's English proficiency level. By combining
traditional textbook methodologies with conversational AI, our approach offers
learners an interactive tool that aligns with their curriculum and provides
user-tailored conversation practice. This facilitates meaningful student-bot
dialogues and enriches the overall learning experience within the curriculum's
pedagogical framework."
CORE: A Retrieve-then-Edit Framework for Counterfactual Data Generation,0.40863,"Counterfactual data augmentation (CDA) -- i.e., adding minimally perturbed
inputs during training -- helps reduce model reliance on spurious correlations
and improves generalization to out-of-distribution (OOD) data. Prior work on
generating counterfactuals only considered restricted classes of perturbations,
limiting their effectiveness. We present COunterfactual Generation via
Retrieval and Editing (CORE), a retrieval-augmented generation framework for
creating diverse counterfactual perturbations for CDA. For each training
example, CORE first performs a dense retrieval over a task-related unlabeled
text corpus using a learned bi-encoder and extracts relevant counterfactual
excerpts. CORE then incorporates these into prompts to a large language model
with few-shot learning capabilities, for counterfactual editing. Conditioning
language model edits on naturally occurring data results in diverse
perturbations. Experiments on natural language inference and sentiment analysis
benchmarks show that CORE counterfactuals are more effective at improving
generalization to OOD data compared to other DA approaches. We also show that
the CORE retrieval framework can be used to encourage diversity in manually
authored perturbations"
Prompt Vision Transformer for Domain Generalization,0.445588,"Though vision transformers (ViTs) have exhibited impressive ability for
representation learning, we empirically find that they cannot generalize well
to unseen domains with previous domain generalization algorithms. In this
paper, we propose a novel approach DoPrompt based on prompt learning to embed
the knowledge of source domains in domain prompts for target domain prediction.
Specifically, domain prompts are prepended before ViT input tokens from the
corresponding source domain. Each domain prompt learns domain-specific
knowledge efficiently since it is optimized only for one domain. Meanwhile, we
train a prompt adapter to produce a suitable prompt for each input image based
on the learned source domain prompts. At test time, the adapted prompt
generated by the prompt adapter can exploit the similarity between the feature
of the out-of-domain image and source domains to properly integrate the source
domain knowledge. Extensive experiments are conducted on four benchmark
datasets. Our approach achieves 1.4% improvements in the averaged accuracy,
which is 3.5 times the improvement of the state-of-the-art algorithm with a ViT
backbone."
Open-Vocabulary Universal Image Segmentation with MaskCLIP,0.419424,"In this paper, we tackle an emerging computer vision task, open-vocabulary
universal image segmentation, that aims to perform semantic/instance/panoptic
segmentation (background semantic labeling + foreground instance segmentation)
for arbitrary categories of text-based descriptions in inference time. We first
build a baseline method by directly adopting pre-trained CLIP models without
finetuning or distillation. We then develop MaskCLIP, a Transformer-based
approach with a MaskCLIP Visual Encoder, which is an encoder-only module that
seamlessly integrates mask tokens with a pre-trained ViT CLIP model for
semantic/instance segmentation and class prediction. MaskCLIP learns to
efficiently and effectively utilize pre-trained partial/dense CLIP features
within the MaskCLIP Visual Encoder that avoids the time-consuming
student-teacher training process. MaskCLIP outperforms previous methods for
semantic/instance/panoptic segmentation on ADE20K and PASCAL datasets. We show
qualitative illustrations for MaskCLIP with online custom categories. Project
website: https://maskclip.github.io."
Mere Contrastive Learning for Cross-Domain Sentiment Analysis,0.262643,"Cross-domain sentiment analysis aims to predict the sentiment of texts in the
target domain using the model trained on the source domain to cope with the
scarcity of labeled data. Previous studies are mostly cross-entropy-based
methods for the task, which suffer from instability and poor generalization. In
this paper, we explore contrastive learning on the cross-domain sentiment
analysis task. We propose a modified contrastive objective with in-batch
negative samples so that the sentence representations from the same class will
be pushed close while those from the different classes become further apart in
the latent space. Experiments on two widely used datasets show that our model
can achieve state-of-the-art performance in both cross-domain and multi-domain
sentiment analysis tasks. Meanwhile, visualizations demonstrate the
effectiveness of transferring knowledge learned in the source domain to the
target domain and the adversarial test verifies the robustness of our model."
Empirical Evaluation of Physical Adversarial Patch Attacks Against Overhead Object Detection Models,0.134309,"Adversarial patches are images designed to fool otherwise well-performing
neural network-based computer vision models. Although these attacks were
initially conceived of and studied digitally, in that the raw pixel values of
the image were perturbed, recent work has demonstrated that these attacks can
successfully transfer to the physical world. This can be accomplished by
printing out the patch and adding it into scenes of newly captured images or
video footage. In this work we further test the efficacy of adversarial patch
attacks in the physical world under more challenging conditions. We consider
object detection models trained on overhead imagery acquired through aerial or
satellite cameras, and we test physical adversarial patches inserted into
scenes of a desert environment. Our main finding is that it is far more
difficult to successfully implement the adversarial patch attacks under these
conditions than in the previously considered conditions. This has important
implications for AI safety as the real-world threat posed by adversarial
examples may be overstated."
Combining Humor and Sarcasm for Improving Political Parody Detection,0.469148,"Parody is a figurative device used for mimicking entities for comedic or
critical purposes. Parody is intentionally humorous and often involves sarcasm.
This paper explores jointly modelling these figurative tropes with the goal of
improving performance of political parody detection in tweets. To this end, we
present a multi-encoder model that combines three parallel encoders to enrich
parody-specific representations with humor and sarcasm information. Experiments
on a publicly available data set of political parody tweets demonstrate that
our approach outperforms previous state-of-the-art methods."
Evaluating Mixed-initiative Conversational Search Systems via User Simulation,0.723938,"Clarifying the underlying user information need by asking clarifying
questions is an important feature of modern conversational search system.
However, evaluation of such systems through answering prompted clarifying
questions requires significant human effort, which can be time-consuming and
expensive. In this paper, we propose a conversational User Simulator, called
USi, for automatic evaluation of such conversational search systems. Given a
description of an information need, USi is capable of automatically answering
clarifying questions about the topic throughout the search session. Through a
set of experiments, including automated natural language generation metrics and
crowdsourcing studies, we show that responses generated by USi are both inline
with the underlying information need and comparable to human-generated answers.
Moreover, we make the first steps towards multi-turn interactions, where
conversational search systems asks multiple questions to the (simulated) user
with a goal of clarifying the user need. To this end, we expand on currently
available datasets for studying clarifying questions, i.e., Qulac and ClariQ,
by performing a crowdsourcing-based multi-turn data acquisition. We show that
our generative, GPT2-based model, is capable of providing accurate and natural
answers to unseen clarifying questions in the single-turn setting and discuss
capabilities of our model in the multi-turn setting. We provide the code, data,
and the pre-trained model to be used for further research on the topic."
Diffusion Probabilistic Modeling for Video Generation,0.999953,"Denoising diffusion probabilistic models are a promising new class of
generative models that mark a milestone in high-quality image generation. This
paper showcases their ability to sequentially generate video, surpassing prior
methods in perceptual and probabilistic forecasting metrics. We propose an
autoregressive, end-to-end optimized video diffusion model inspired by recent
advances in neural video compression. The model successively generates future
frames by correcting a deterministic next-frame prediction using a stochastic
residual generated by an inverse diffusion process. We compare this approach
against five baselines on four datasets involving natural and simulation-based
videos. We find significant improvements in terms of perceptual quality for all
datasets. Furthermore, by introducing a scalable version of the Continuous
Ranked Probability Score (CRPS) applicable to video, we show that our model
also outperforms existing approaches in their probabilistic frame forecasting
ability."
Filtered-CoPhy: Unsupervised Learning of Counterfactual Physics in Pixel Space,0.378745,"Learning causal relationships in high-dimensional data (images, videos) is a
hard task, as they are often defined on low dimensional manifolds and must be
extracted from complex signals dominated by appearance, lighting, textures and
also spurious correlations in the data. We present a method for learning
counterfactual reasoning of physical processes in pixel space, which requires
the prediction of the impact of interventions on initial conditions. Going
beyond the identification of structural relationships, we deal with the
challenging problem of forecasting raw video over long horizons. Our method
does not require the knowledge or supervision of any ground truth positions or
other object or scene properties. Our model learns and acts on a suitable
hybrid latent representation based on a combination of dense features, sets of
2D keypoints and an additional latent vector per keypoint. We show that this
better captures the dynamics of physical processes than purely dense or sparse
representations. We introduce a new challenging and carefully designed
counterfactual benchmark for predictions in pixel space and outperform strong
baselines in physics-inspired ML and video prediction."
EC-KitY: Evolutionary Computation Tool Kit in Python with Seamless Machine Learning Integration,0.553022,"EC-KitY is a comprehensive Python library for doing evolutionary computation
(EC), licensed under the BSD 3-Clause License, and compatible with
scikit-learn. Designed with modern software engineering and machine learning
integration in mind, EC-KitY can support all popular EC paradigms, including
genetic algorithms, genetic programming, coevolution, evolutionary
multi-objective optimization, and more. This paper provides an overview of the
package, including the ease of setting up an EC experiment, the architecture,
the main features, and a comparison with other libraries."
Tracr: Compiled Transformers as a Laboratory for Interpretability,0.746284,"We show how to ""compile"" human-readable programs into standard decoder-only
transformer models. Our compiler, Tracr, generates models with known structure.
This structure can be used to design experiments. For example, we use it to
study ""superposition"" in transformers that execute multi-step algorithms.
Additionally, the known structure of Tracr-compiled models can serve as
ground-truth for evaluating interpretability methods. Commonly, because the
""programs"" learned by transformers are unknown it is unclear whether an
interpretation succeeded. We demonstrate our approach by implementing and
examining programs including computing token frequencies, sorting, and
parenthesis checking. We provide an open-source implementation of Tracr at
https://github.com/google-deepmind/tracr."
Semeval-2022 Task 1: CODWOE -- Comparing Dictionaries and Word Embeddings,0.908236,"Word embeddings have advanced the state of the art in NLP across numerous
tasks. Understanding the contents of dense neural representations is of utmost
interest to the computational semantics community. We propose to focus on
relating these opaque word vectors with human-readable definitions, as found in
dictionaries. This problem naturally divides into two subtasks: converting
definitions into embeddings, and converting embeddings into definitions. This
task was conducted in a multilingual setting, using comparable sets of
embeddings trained homogeneously."
Certified Adversarial Robustness via Anisotropic Randomized Smoothing,0.327036,"Randomized smoothing has achieved great success for certified robustness
against adversarial perturbations. Given any arbitrary classifier, randomized
smoothing can guarantee the classifier's prediction over the perturbed input
with provable robustness bound by injecting noise into the classifier. However,
all of the existing methods rely on fixed i.i.d. probability distribution to
generate noise for all dimensions of the data (e.g., all the pixels in an
image), which ignores the heterogeneity of inputs and data dimensions. Thus,
existing randomized smoothing methods cannot provide optimal protection for all
the inputs. To address this limitation, we propose a novel anisotropic
randomized smoothing method which ensures provable robustness guarantee based
on pixel-wise noise distributions. Also, we design a novel CNN-based noise
generator to efficiently fine-tune the pixel-wise noise distributions for all
the pixels in each input. Experimental results demonstrate that our method
significantly outperforms the state-of-the-art randomized smoothing methods."
Incorporating Dynamic Semantics into Pre-Trained Language Model for Aspect-based Sentiment Analysis,0.95448,"Aspect-based sentiment analysis (ABSA) predicts sentiment polarity towards a
specific aspect in the given sentence. While pre-trained language models such
as BERT have achieved great success, incorporating dynamic semantic changes
into ABSA remains challenging. To this end, in this paper, we propose to
address this problem by Dynamic Re-weighting BERT (DR-BERT), a novel method
designed to learn dynamic aspect-oriented semantics for ABSA. Specifically, we
first take the Stack-BERT layers as a primary encoder to grasp the overall
semantic of the sentence and then fine-tune it by incorporating a lightweight
Dynamic Re-weighting Adapter (DRA). Note that the DRA can pay close attention
to a small region of the sentences at each step and re-weigh the vitally
important words for better aspect-aware sentiment understanding. Finally,
experimental results on three benchmark datasets demonstrate the effectiveness
and the rationality of our proposed model and provide good interpretable
insights for future semantic modeling."
A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI),0.808963,"Within the field of Requirements Engineering (RE), the increasing
significance of Explainable Artificial Intelligence (XAI) in aligning
AI-supported systems with user needs, societal expectations, and regulatory
standards has garnered recognition. In general, explainability has emerged as
an important non-functional requirement that impacts system quality. However,
the supposed trade-off between explainability and performance challenges the
presumed positive influence of explainability. If meeting the requirement of
explainability entails a reduction in system performance, then careful
consideration must be given to which of these quality aspects takes precedence
and how to compromise between them. In this paper, we critically examine the
alleged trade-off. We argue that it is best approached in a nuanced way that
incorporates resource availability, domain characteristics, and considerations
of risk. By providing a foundation for future research and best practices, this
work aims to advance the field of RE for AI."
Rather a Nurse than a Physician -- Contrastive Explanations under Investigation,0.740519,"Contrastive explanations, where one decision is explained in contrast to
another, are supposed to be closer to how humans explain a decision than
non-contrastive explanations, where the decision is not necessarily referenced
to an alternative. This claim has never been empirically validated. We analyze
four English text-classification datasets (SST2, DynaSent, BIOS and
DBpedia-Animals). We fine-tune and extract explanations from three different
models (RoBERTa, GTP-2, and T5), each in three different sizes and apply three
post-hoc explainability methods (LRP, GradientxInput, GradNorm). We furthermore
collect and release human rationale annotations for a subset of 100 samples
from the BIOS dataset for contrastive and non-contrastive settings. A
cross-comparison between model-based rationales and human annotations, both in
contrastive and non-contrastive settings, yields a high agreement between the
two settings for models as well as for humans. Moreover, model-based
explanations computed in both settings align equally well with human
rationales. Thus, we empirically find that humans do not necessarily explain in
a contrastive manner.9 pages, long paper at ACL 2022 proceedings."
Efficient Machine Translation Domain Adaptation,0.832935,"Machine translation models struggle when translating out-of-domain text,
which makes domain adaptation a topic of critical importance. However, most
domain adaptation methods focus on fine-tuning or training the entire or part
of the model on every new domain, which can be costly. On the other hand,
semi-parametric models have been shown to successfully perform domain
adaptation by retrieving examples from an in-domain datastore (Khandelwal et
al., 2021). A drawback of these retrieval-augmented models, however, is that
they tend to be substantially slower. In this paper, we explore several
approaches to speed up nearest neighbor machine translation. We adapt the
methods recently proposed by He et al. (2021) for language modeling, and
introduce a simple but effective caching strategy that avoids performing
retrieval when similar contexts have been seen before. Translation quality and
runtimes for several domains show the effectiveness of the proposed solutions."
Head Rotation in Denoising Diffusion Models,0.0761638,"Denoising Diffusion Models (DDM) are emerging as the cutting-edge technology
in the realm of deep generative modeling, challenging the dominance of
Generative Adversarial Networks. However, effectively exploring the latent
space's semantics and identifying compelling trajectories for manipulating and
editing important attributes of the generated samples remains challenging,
primarily due to the high-dimensional nature of the latent space. In this
study, we specifically concentrate on face rotation, which is known to be one
of the most intricate editing operations. By leveraging a recent embedding
technique for Denoising Diffusion Implicit Models (DDIM), we achieve, in many
cases, noteworthy manipulations encompassing a wide rotation angle of $\pm
30^o$, preserving the distinct characteristics of the individual. Our
methodology exploits the computation of trajectories approximating clouds of
latent representations of dataset samples with different yaw rotations through
linear regression. Specific trajectories are obtained by restricting the
analysis to subsets of data sharing significant attributes with the source
image. One of these attributes is the light provenance: a byproduct of our
research is a labeling of CelebA, categorizing images into three major groups
based on the illumination direction: left, center, and right."
Using contextual sentence analysis models to recognize ESG concepts,0.646293,"This paper summarizes the joint participation of the Trading Central Labs and
the L3i laboratory of the University of La Rochelle on both sub-tasks of the
Shared Task FinSim-4 evaluation campaign. The first sub-task aims to enrich the
'Fortia ESG taxonomy' with new lexicon entries while the second one aims to
classify sentences to either 'sustainable' or 'unsustainable' with respect to
ESG (Environment, Social and Governance) related factors. For the first
sub-task, we proposed a model based on pre-trained Sentence-BERT models to
project sentences and concepts in a common space in order to better represent
ESG concepts. The official task results show that our system yields a
significant performance improvement compared to the baseline and outperforms
all other submissions on the first sub-task. For the second sub-task, we
combine the RoBERTa model with a feed-forward multi-layer perceptron in order
to extract the context of sentences and classify them. Our model achieved high
accuracy scores (over 92%) and was ranked among the top 5 systems."
ShapePU: A New PU Learning Framework Regularized by Global Consistency for Scribble Supervised Cardiac Segmentation,0.31418,"Cardiac segmentation is an essential step for the diagnosis of cardiovascular
diseases. However, pixel-wise dense labeling is both costly and time-consuming.
Scribble, as a form of sparse annotation, is more accessible than full
annotations. However, it's particularly challenging to train a segmentation
network with weak supervision from scribbles. To tackle this problem, we
propose a new scribble-guided method for cardiac segmentation, based on the
Positive-Unlabeled (PU) learning framework and global consistency
regularization, and termed as ShapePU. To leverage unlabeled pixels via PU
learning, we first present an Expectation-Maximization (EM) algorithm to
estimate the proportion of each class in the unlabeled pixels. Given the
estimated ratios, we then introduce the marginal probability maximization to
identify the classes of unlabeled pixels. To exploit shape knowledge, we apply
cutout operations to training images, and penalize the inconsistent
segmentation results. Evaluated on two open datasets, i.e, ACDC and MSCMRseg,
our scribble-supervised ShapePU surpassed the fully supervised approach
respectively by 1.4% and 9.8% in average Dice, and outperformed the
state-of-the-art weakly supervised and PU learning methods by large margins.
Our code is available at https://github.com/BWGZK/ShapePU."
Improving Passage Retrieval with Zero-Shot Question Generation,0.958994,"We propose a simple and effective re-ranking method for improving passage
retrieval in open question answering. The re-ranker re-scores retrieved
passages with a zero-shot question generation model, which uses a pre-trained
language model to compute the probability of the input question conditioned on
a retrieved passage. This approach can be applied on top of any retrieval
method (e.g. neural or keyword-based), does not require any domain- or
task-specific training (and therefore is expected to generalize better to data
distribution shifts), and provides rich cross-attention between query and
passage (i.e. it must explain every token in the question). When evaluated on a
number of open-domain retrieval datasets, our re-ranker improves strong
unsupervised retrieval models by 6%-18% absolute and strong supervised models
by up to 12% in terms of top-20 passage retrieval accuracy. We also obtain new
state-of-the-art results on full open-domain question answering by simply
adding the new re-ranker to existing models with no further changes."
MMTAfrica: Multilingual Machine Translation for African Languages,0.639247,"In this paper, we focus on the task of multilingual machine translation for
African languages and describe our contribution in the 2021 WMT Shared Task:
Large-Scale Multilingual Machine Translation. We introduce MMTAfrica, the first
many-to-many multilingual translation system for six African languages: Fon
(fon), Igbo (ibo), Kinyarwanda (kin), Swahili/Kiswahili (swa), Xhosa (xho), and
Yoruba (yor) and two non-African languages: English (eng) and French (fra). For
multilingual translation concerning African languages, we introduce a novel
backtranslation and reconstruction objective, BT\&REC, inspired by the random
online back translation and T5 modeling framework respectively, to effectively
leverage monolingual data. Additionally, we report improvements from MMTAfrica
over the FLORES 101 benchmarks (spBLEU gains ranging from $+0.58$ in Swahili to
French to $+19.46$ in French to Xhosa). We release our dataset and code source
at https://github.com/edaiofficial/mmtafrica."
Synthetic Disinformation Attacks on Automated Fact Verification Systems,0.908585,"Automated fact-checking is a needed technology to curtail the spread of
online misinformation. One current framework for such solutions proposes to
verify claims by retrieving supporting or refuting evidence from related
textual sources. However, the realistic use cases for fact-checkers will
require verifying claims against evidence sources that could be affected by the
same misinformation. Furthermore, the development of modern NLP tools that can
produce coherent, fabricated content would allow malicious actors to
systematically generate adversarial disinformation for fact-checkers.
  In this work, we explore the sensitivity of automated fact-checkers to
synthetic adversarial evidence in two simulated settings: AdversarialAddition,
where we fabricate documents and add them to the evidence repository available
to the fact-checking system, and AdversarialModification, where existing
evidence source documents in the repository are automatically altered. Our
study across multiple models on three benchmarks demonstrates that these
systems suffer significant performance drops against these attacks. Finally, we
discuss the growing threat of modern NLG systems as generators of
disinformation in the context of the challenges they pose to automated
fact-checkers."
Quantifying syntax similarity with a polynomial representation of dependency trees,0.533744,"We introduce a graph polynomial that distinguishes tree structures to
represent dependency grammar and a measure based on the polynomial
representation to quantify syntax similarity. The polynomial encodes accurate
and comprehensive information about the dependency structure and dependency
relations of words in a sentence. We apply the polynomial-based methods to
analyze sentences in the Parallel Universal Dependencies treebanks.
Specifically, we compare the syntax of sentences and their translations in
different languages, and we perform a syntactic typology study of available
languages in the Parallel Universal Dependencies treebanks. We also demonstrate
and discuss the potential of the methods in measuring syntax diversity of
corpora."
"Development of the ChatGPT, Generative Artificial Intelligence and Natural Large Language Models for Accountable Reporting and Use (CANGARU) Guidelines",0.19182,"The swift progress and ubiquitous adoption of Generative AI (GAI), Generative
Pre-trained Transformers (GPTs), and large language models (LLMs) like ChatGPT,
have spurred queries about their ethical application, use, and disclosure in
scholarly research and scientific productions. A few publishers and journals
have recently created their own sets of rules; however, the absence of a
unified approach may lead to a 'Babel Tower Effect,' potentially resulting in
confusion rather than desired standardization. In response to this, we present
the ChatGPT, Generative Artificial Intelligence, and Natural Large Language
Models for Accountable Reporting and Use Guidelines (CANGARU) initiative, with
the aim of fostering a cross-disciplinary global inclusive consensus on the
ethical use, disclosure, and proper reporting of GAI/GPT/LLM technologies in
academia. The present protocol consists of four distinct parts: a) an ongoing
systematic review of GAI/GPT/LLM applications to understand the linked ideas,
findings, and reporting standards in scholarly research, and to formulate
guidelines for its use and disclosure, b) a bibliometric analysis of existing
author guidelines in journals that mention GAI/GPT/LLM, with the goal of
evaluating existing guidelines, analyzing the disparity in their
recommendations, and identifying common rules that can be brought into the
Delphi consensus process, c) a Delphi survey to establish agreement on the
items for the guidelines, ensuring principled GAI/GPT/LLM use, disclosure, and
reporting in academia, and d) the subsequent development and dissemination of
the finalized guidelines and their supplementary explanation and elaboration
documents."
Evolutionary Game-Theoretical Analysis for General Multiplayer Asymmetric Games,0.590861,"Evolutionary game theory has been a successful tool to combine classical game
theory with learning-dynamical descriptions in multiagent systems. Provided
some symmetric structures of interacting players, many studies have been
focused on using a simplified heuristic payoff table as input to analyse the
dynamics of interactions. Nevertheless, even for the state-of-the-art method,
there are two limits. First, there is inaccuracy when analysing the simplified
payoff table. Second, no existing work is able to deal with 2-population
multiplayer asymmetric games. In this paper, we fill the gap between heuristic
payoff table and dynamic analysis without any inaccuracy. In addition, we
propose a general framework for $m$ versus $n$ 2-population multiplayer
asymmetric games. Then, we compare our method with the state-of-the-art in some
classic games. Finally, to illustrate our method, we perform empirical
game-theoretical analysis on Wolfpack as well as StarCraft II, both of which
involve complex multiagent interactions."
UniFusion: Unified Multi-view Fusion Transformer for Spatial-Temporal Representation in Bird's-Eye-View,0.395634,"Bird's eye view (BEV) representation is a new perception formulation for
autonomous driving, which is based on spatial fusion. Further, temporal fusion
is also introduced in BEV representation and gains great success. In this work,
we propose a new method that unifies both spatial and temporal fusion and
merges them into a unified mathematical formulation. The unified fusion could
not only provide a new perspective on BEV fusion but also brings new
capabilities. With the proposed unified spatial-temporal fusion, our method
could support long-range fusion, which is hard to achieve in conventional BEV
methods. Moreover, the BEV fusion in our work is temporal-adaptive and the
weights of temporal fusion are learnable. In contrast, conventional methods
mainly use fixed and equal weights for temporal fusion. Besides, the proposed
unified fusion could avoid information lost in conventional BEV fusion methods
and make full use of features. Extensive experiments and ablation studies on
the NuScenes dataset show the effectiveness of the proposed method and our
method gains the state-of-the-art performance in the map segmentation task."
Unbiased Multi-Modality Guidance for Image Inpainting,0.481432,"Image inpainting is an ill-posed problem to recover missing or damaged image
content based on incomplete images with masks. Previous works usually predict
the auxiliary structures (e.g., edges, segmentation and contours) to help fill
visually realistic patches in a multi-stage fashion. However, imprecise
auxiliary priors may yield biased inpainted results. Besides, it is
time-consuming for some methods to be implemented by multiple stages of complex
neural networks. To solve this issue, we develop an end-to-end multi-modality
guided transformer network, including one inpainting branch and two auxiliary
branches for semantic segmentation and edge textures. Within each transformer
block, the proposed multi-scale spatial-aware attention module can learn the
multi-modal structural features efficiently via auxiliary denormalization.
Different from previous methods relying on direct guidance from biased priors,
our method enriches semantically consistent context in an image based on
discriminative interplay information from multiple modalities. Comprehensive
experiments on several challenging image inpainting datasets show that our
method achieves state-of-the-art performance to deal with various
regular/irregular masks efficiently."
What's the Meaning of Superhuman Performance in Today's NLU?,0.344702,"In the last five years, there has been a significant focus in Natural
Language Processing (NLP) on developing larger Pretrained Language Models
(PLMs) and introducing benchmarks such as SuperGLUE and SQuAD to measure their
abilities in language understanding, reasoning, and reading comprehension.
These PLMs have achieved impressive results on these benchmarks, even
surpassing human performance in some cases. This has led to claims of
superhuman capabilities and the provocative idea that certain tasks have been
solved. In this position paper, we take a critical look at these claims and ask
whether PLMs truly have superhuman abilities and what the current benchmarks
are really evaluating. We show that these benchmarks have serious limitations
affecting the comparison between humans and PLMs and provide recommendations
for fairer and more transparent benchmarks."
Combining Commonsense Reasoning and Knowledge Acquisition to Guide Deep Learning in Robotics,0.0709716,"Algorithms based on deep network models are being used for many pattern
recognition and decision-making tasks in robotics and AI. Training these models
requires a large labeled dataset and considerable computational resources,
which are not readily available in many domains. Also, it is difficult to
explore the internal representations and reasoning mechanisms of these models.
As a step towards addressing the underlying knowledge representation,
reasoning, and learning challenges, the architecture described in this paper
draws inspiration from research in cognitive systems. As a motivating example,
we consider an assistive robot trying to reduce clutter in any given scene by
reasoning about the occlusion of objects and stability of object configurations
in an image of the scene. In this context, our architecture incrementally
learns and revises a grounding of the spatial relations between objects and
uses this grounding to extract spatial information from input images.
Non-monotonic logical reasoning with this information and incomplete
commonsense domain knowledge is used to make decisions about stability and
occlusion. For images that cannot be processed by such reasoning, regions
relevant to the tasks at hand are automatically identified and used to train
deep network models to make the desired decisions. Image regions used to train
the deep networks are also used to incrementally acquire previously unknown
state constraints that are merged with the existing knowledge for subsequent
reasoning. Experimental evaluation performed using simulated and real-world
images indicates that in comparison with baselines based just on deep networks,
our architecture improves reliability of decision making and reduces the effort
involved in training data-driven deep network models."
Self-Influence Guided Data Reweighting for Language Model Pre-training,0.358725,"Language Models (LMs) pre-trained with self-supervision on large text corpora
have become the default starting point for developing models for various NLP
tasks. Once the pre-training corpus has been assembled, all data samples in the
corpus are treated with equal importance during LM pre-training. However, due
to varying levels of relevance and quality of data, equal importance to all the
data samples may not be the optimal choice. While data reweighting has been
explored in the context of task-specific supervised learning and LM
fine-tuning, model-driven reweighting for pre-training data has not been
explored. We fill this important gap and propose PRESENCE, a method for jointly
reweighting samples by leveraging self-influence (SI) scores as an indicator of
sample importance and pre-training. PRESENCE promotes novelty and stability for
model pre-training. Through extensive analysis spanning multiple model sizes,
datasets, and tasks, we present PRESENCE as an important first step in the
research direction of sample reweighting for pre-training language models."
Few-Shot Fine-Grained Entity Typing with Automatic Label Interpretation and Instance Generation,0.655283,"We study the problem of few-shot Fine-grained Entity Typing (FET), where only
a few annotated entity mentions with contexts are given for each entity type.
Recently, prompt-based tuning has demonstrated superior performance to standard
fine-tuning in few-shot scenarios by formulating the entity type classification
task as a ''fill-in-the-blank'' problem. This allows effective utilization of
the strong language modeling capability of Pre-trained Language Models (PLMs).
Despite the success of current prompt-based tuning approaches, two major
challenges remain: (1) the verbalizer in prompts is either manually designed or
constructed from external knowledge bases, without considering the target
corpus and label hierarchy information, and (2) current approaches mainly
utilize the representation power of PLMs, but have not explored their
generation power acquired through extensive general-domain pre-training. In
this work, we propose a novel framework for few-shot FET consisting of two
modules: (1) an entity type label interpretation module automatically learns to
relate type labels to the vocabulary by jointly leveraging few-shot instances
and the label hierarchy, and (2) a type-based contextualized instance generator
produces new instances based on given instances to enlarge the training set for
better generalization. On three benchmark datasets, our model outperforms
existing methods by significant margins. Code can be found at
https://github.com/teapot123/Fine-Grained-Entity-Typing."
HybridPoint: Point Cloud Registration Based on Hybrid Point Sampling and Matching,0.0877374,"Patch-to-point matching has become a robust way of point cloud registration.
However, previous patch-matching methods employ superpoints with poor
localization precision as nodes, which may lead to ambiguous patch partitions.
In this paper, we propose a HybridPoint-based network to find more robust and
accurate correspondences. Firstly, we propose to use salient points with
prominent local features as nodes to increase patch repeatability, and
introduce some uniformly distributed points to complete the point cloud, thus
constituting hybrid points. Hybrid points not only have better localization
precision but also give a complete picture of the whole point cloud.
Furthermore, based on the characteristic of hybrid points, we propose a
dual-classes patch matching module, which leverages the matching results of
salient points and filters the matching noise of non-salient points.
Experiments show that our model achieves state-of-the-art performance on
3DMatch, 3DLoMatch, and KITTI odometry, especially with 93.0% Registration
Recall on the 3DMatch dataset. Our code and models are available at
https://github.com/liyih/HybridPoint."
Look where you look! Saliency-guided Q-networks for generalization in visual Reinforcement Learning,0.567643,"Deep reinforcement learning policies, despite their outstanding efficiency in
simulated visual control tasks, have shown disappointing ability to generalize
across disturbances in the input training images. Changes in image statistics
or distracting background elements are pitfalls that prevent generalization and
real-world applicability of such control policies. We elaborate on the
intuition that a good visual policy should be able to identify which pixels are
important for its decision, and preserve this identification of important
sources of information across images. This implies that training of a policy
with small generalization gap should focus on such important pixels and ignore
the others. This leads to the introduction of saliency-guided Q-networks
(SGQN), a generic method for visual reinforcement learning, that is compatible
with any value function learning method. SGQN vastly improves the
generalization capability of Soft Actor-Critic agents and outperforms existing
stateof-the-art methods on the Deepmind Control Generalization benchmark,
setting a new reference in terms of training efficiency, generalization gap,
and policy interpretability."
Ontologically Faithful Generation of Non-Player Character Dialogues,0.441543,"We introduce a language generation task grounded in a popular video game
environment. KNUDGE (KNowledge Constrained User-NPC Dialogue GEneration)
requires models to produce trees of dialogue between video game characters that
accurately reflect quest and entity specifications stated in natural language.
KNUDGE is constructed from side quest dialogues drawn directly from game data
of Obsidian Entertainment's The Outer Worlds, leading to real-world
complexities in generation: (1) dialogues are branching trees as opposed to
linear chains of utterances; (2) utterances must remain faithful to the game
lore -- character personas, backstories, and entity relationships; and (3) a
dialogue must accurately reveal new quest details to the human player. We
report results for a set of neural generation models using supervised and
in-context learning techniques; we find competent performance but room for
future work addressing the challenges of creating realistic, game-quality
dialogues."
Feature Engineering and Classification Models for Partial Discharge in Power Transformers,0.230516,"To ensure reliability, power transformers are monitored for partial discharge
(PD) events, which are symptoms of transformer failure. Since failures can have
catastrophic cascading consequences, it is critical to preempt them as early as
possible. Our goal is to classify PDs as corona, floating, particle, or void,
to gain an understanding of the failure location. Using phase resolved PD
signal data, we create a small set of features, which can be used to classify
PDs with high accuracy. This set of features consists of the total magnitude,
the maximum magnitude, and the length of the longest empty band. These features
represent the entire signal and not just a single phase, so the feature set has
a fixed size and is easily comprehensible. With both Random Forest and SVM
classification methods, we attain a 99% classification accuracy, which is
significantly higher than classification using phase based feature sets such as
phase magnitude. Furthermore, we develop a stacking ensemble to combine several
classification models, resulting in a superior model that outperforms existing
methods in both accuracy and variance."
On Pathologies in KL-Regularized Reinforcement Learning from Expert Demonstrations,0.940226,"KL-regularized reinforcement learning from expert demonstrations has proved
successful in improving the sample efficiency of deep reinforcement learning
algorithms, allowing them to be applied to challenging physical real-world
tasks. However, we show that KL-regularized reinforcement learning with
behavioral reference policies derived from expert demonstrations can suffer
from pathological training dynamics that can lead to slow, unstable, and
suboptimal online learning. We show empirically that the pathology occurs for
commonly chosen behavioral policy classes and demonstrate its impact on sample
efficiency and online policy performance. Finally, we show that the pathology
can be remedied by non-parametric behavioral reference policies and that this
allows KL-regularized reinforcement learning to significantly outperform
state-of-the-art approaches on a variety of challenging locomotion and
dexterous hand manipulation tasks."
Joint Skeletal and Semantic Embedding Loss for Micro-gesture Classification,0.649246,"In this paper, we briefly introduce the solution of our team HFUT-VUT for the
Micros-gesture Classification in the MiGA challenge at IJCAI 2023. The
micro-gesture classification task aims at recognizing the action category of a
given video based on the skeleton data. For this task, we propose a
3D-CNNs-based micro-gesture recognition network, which incorporates a skeletal
and semantic embedding loss to improve action classification performance.
Finally, we rank 1st in the Micro-gesture Classification Challenge, surpassing
the second-place team in terms of Top-1 accuracy by 1.10%."
MMoT: Mixture-of-Modality-Tokens Transformer for Composed Multimodal Conditional Image Synthesis,0.0796629,"Existing multimodal conditional image synthesis (MCIS) methods generate
images conditioned on any combinations of various modalities that require all
of them must be exactly conformed, hindering the synthesis controllability and
leaving the potential of cross-modality under-exploited. To this end, we
propose to generate images conditioned on the compositions of multimodal
control signals, where modalities are imperfectly complementary, i.e., composed
multimodal conditional image synthesis (CMCIS). Specifically, we observe two
challenging issues of the proposed CMCIS task, i.e., the modality coordination
problem and the modality imbalance problem. To tackle these issues, we
introduce a Mixture-of-Modality-Tokens Transformer (MMoT) that adaptively fuses
fine-grained multimodal control signals, a multimodal balanced training loss to
stabilize the optimization of each modality, and a multimodal sampling guidance
to balance the strength of each modality control signal. Comprehensive
experimental results demonstrate that MMoT achieves superior performance on
both unimodal conditional image synthesis (UCIS) and MCIS tasks with
high-quality and faithful image synthesis on complex multimodal conditions. The
project website is available at https://jabir-zheng.github.io/MMoT."
Cross-Cultural Transfer Learning for Chinese Offensive Language Detection,0.4725,"Detecting offensive language is a challenging task. Generalizing across
different cultures and languages becomes even more challenging: besides
lexical, syntactic and semantic differences, pragmatic aspects such as cultural
norms and sensitivities, which are particularly relevant in this context, vary
greatly. In this paper, we target Chinese offensive language detection and aim
to investigate the impact of transfer learning using offensive language
detection data from different cultural backgrounds, specifically Korean and
English. We find that culture-specific biases in what is considered offensive
negatively impact the transferability of language models (LMs) and that LMs
trained on diverse cultural data are sensitive to different features in Chinese
offensive language detection. In a few-shot learning scenario, however, our
study shows promising prospects for non-English offensive language detection
with limited resources. Our findings highlight the importance of cross-cultural
transfer learning in improving offensive language detection and promoting
inclusive digital spaces."
Facial Expression Recognition based on Multi-head Cross Attention Network,0.837349,"Facial expression in-the-wild is essential for various interactive computing
domains. In this paper, we proposed an extended version of DAN model to address
the VA estimation and facial expression challenges introduced in ABAW 2022. Our
method produced preliminary results of 0.44 of mean CCC value for the VA
estimation task, and 0.33 of the average F1 score for the expression
classification task."
HYPRO: A Hybridly Normalized Probabilistic Model for Long-Horizon Prediction of Event Sequences,0.559377,"In this paper, we tackle the important yet under-investigated problem of
making long-horizon prediction of event sequences. Existing state-of-the-art
models do not perform well at this task due to their autoregressive structure.
We propose HYPRO, a hybridly normalized probabilistic model that naturally fits
this task: its first part is an autoregressive base model that learns to
propose predictions; its second part is an energy function that learns to
reweight the proposals such that more realistic predictions end up with higher
probabilities. We also propose efficient training and inference algorithms for
this model. Experiments on multiple real-world datasets demonstrate that our
proposed HYPRO model can significantly outperform previous models at making
long-horizon predictions of future events. We also conduct a range of ablation
studies to investigate the effectiveness of each component of our proposed
methods."
NOPE: Novel Object Pose Estimation from a Single Image,0.633687,"The practicality of 3D object pose estimation remains limited for many
applications due to the need for prior knowledge of a 3D model and a training
period for new objects. To address this limitation, we propose an approach that
takes a single image of a new object as input and predicts the relative pose of
this object in new images without prior knowledge of the object's 3D model and
without requiring training time for new objects and categories. We achieve this
by training a model to directly predict discriminative embeddings for
viewpoints surrounding the object. This prediction is done using a simple U-Net
architecture with attention and conditioned on the desired pose, which yields
extremely fast inference. We compare our approach to state-of-the-art methods
and show it outperforms them both in terms of accuracy and robustness. Our
source code is publicly available at https://github.com/nv-nguyen/nope"
RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning,0.999839,"Prompting has shown impressive success in enabling large pretrained language
models (LMs) to perform diverse NLP tasks, especially when only few downstream
data are available. Automatically finding the optimal prompt for each task,
however, is challenging. Most existing work resorts to tuning soft prompt
(e.g., embeddings) which falls short of interpretability, reusability across
LMs, and applicability when gradients are not accessible. Discrete prompt, on
the other hand, is difficult to optimize, and is often created by ""enumeration
(e.g., paraphrasing)-then-selection"" heuristics that do not explore the prompt
space systematically. This paper proposes RLPrompt, an efficient discrete
prompt optimization approach with reinforcement learning (RL). RLPrompt
formulates a parameter-efficient policy network that generates the desired
discrete prompt after training with reward. To overcome the complexity and
stochasticity of reward signals by the large LM environment, we incorporate
effective reward stabilization that substantially enhances the training
efficiency. RLPrompt is flexibly applicable to different types of LMs, such as
masked (e.g., BERT) and left-to-right models (e.g., GPTs), for both
classification and generation tasks. Experiments on few-shot classification and
unsupervised text style transfer show superior performance over a wide range of
existing finetuning or prompting methods. Interestingly, the resulting
optimized prompts are often ungrammatical gibberish text; and surprisingly,
those gibberish prompts are transferrable between different LMs to retain
significant performance, indicating LM prompting may not follow human language
patterns."
A Framework for Automated Measurement of Responsible AI Harms in Generative AI Applications,0.523567,"We present a framework for the automated measurement of responsible AI (RAI)
metrics for large language models (LLMs) and associated products and services.
Our framework for automatically measuring harms from LLMs builds on existing
technical and sociotechnical expertise and leverages the capabilities of
state-of-the-art LLMs, such as GPT-4. We use this framework to run through
several case studies investigating how different LLMs may violate a range of
RAI-related principles. The framework may be employed alongside domain-specific
sociotechnical expertise to create measurements for new harm areas in the
future. By implementing this framework, we aim to enable more advanced harm
measurement efforts and further the responsible use of LLMs."
A Blackbox Approach to Best of Both Worlds in Bandits and Beyond,0.631179,"Best-of-both-worlds algorithms for online learning which achieve near-optimal
regret in both the adversarial and the stochastic regimes have received growing
attention recently. Existing techniques often require careful adaptation to
every new problem setup, including specialised potentials and careful tuning of
algorithm parameters. Yet, in domains such as linear bandits, it is still
unknown if there exists an algorithm that can simultaneously obtain
$O(\log(T))$ regret in the stochastic regime and $\tilde{O}(\sqrt{T})$ regret
in the adversarial regime. In this work, we resolve this question positively
and present a general reduction from best of both worlds to a wide family of
follow-the-regularized-leader (FTRL) and online-mirror-descent (OMD)
algorithms. We showcase the capability of this reduction by transforming
existing algorithms that are only known to achieve worst-case guarantees into
new algorithms with best-of-both-worlds guarantees in contextual bandits, graph
bandits and tabular Markov decision processes."
Bounding Evidence and Estimating Log-Likelihood in VAE,0.211783,"Many crucial problems in deep learning and statistics are caused by a
variational gap, i.e., a difference between evidence and evidence lower bound
(ELBO). As a consequence, in the classical VAE model, we obtain only the lower
bound on the log-likelihood since ELBO is used as a cost function, and
therefore we cannot compare log-likelihood between models. In this paper, we
present a general and effective upper bound of the variational gap, which
allows us to efficiently estimate the true evidence. We provide an extensive
theoretical study of the proposed approach. Moreover, we show that by applying
our estimation, we can easily obtain lower and upper bounds for the
log-likelihood of VAE models."
Invertible Tabular GANs: Killing Two Birds with OneStone for Tabular Data Synthesis,0.47562,"Tabular data synthesis has received wide attention in the literature. This is
because available data is often limited, incomplete, or cannot be obtained
easily, and data privacy is becoming increasingly important. In this work, we
present a generalized GAN framework for tabular synthesis, which combines the
adversarial training of GANs and the negative log-density regularization of
invertible neural networks. The proposed framework can be used for two
distinctive objectives. First, we can further improve the synthesis quality, by
decreasing the negative log-density of real records in the process of
adversarial training. On the other hand, by increasing the negative log-density
of real records, realistic fake records can be synthesized in a way that they
are not too much close to real records and reduce the chance of potential
information leakage. We conduct experiments with real-world datasets for
classification, regression, and privacy attacks. In general, the proposed
method demonstrates the best synthesis quality (in terms of task-oriented
evaluation metrics, e.g., F1) when decreasing the negative log-density during
the adversarial training. If increasing the negative log-density, our
experimental results show that the distance between real and fake records
increases, enhancing robustness against privacy attacks."
Solutions to preference manipulation in recommender systems require knowledge of meta-preferences,0.160338,"Iterative machine learning algorithms used to power recommender systems often
change people's preferences by trying to learn them. Further a recommender can
better predict what a user will do by making its users more predictable. Some
preference changes on the part of the user are self-induced and desired whether
the recommender caused them or not. This paper proposes that solutions to
preference manipulation in recommender systems must take into account certain
meta-preferences (preferences over another preference) in order to respect the
autonomy of the user and not be manipulative."
"Representing motion as a sequence of latent primitives, a flexible approach for human motion modelling",0.0331084,"We propose a new representation of human body motion which encodes a full
motion in a sequence of latent motion primitives. Recently, task generic motion
priors have been introduced and propose a coherent representation of human
motion based on a single latent code, with encouraging results for many tasks.
Extending these methods to longer motion with various duration and framerate is
all but straightforward as one latent code proves inefficient to encode longer
term variability. Our hypothesis is that long motions are better represented as
a succession of actions than in a single block. By leveraging a
sequence-to-sequence architecture, we propose a model that simultaneously
learns a temporal segmentation of motion and a prior on the motion segments. To
provide flexibility with temporal resolution and motion duration, our
representation is continuous in time and can be queried for any timestamp. We
show experimentally that our method leads to a significant improvement over
state-of-the-art motion priors on a spatio-temporal completion task on sparse
pointclouds. Code will be made available upon publication."
Revisiting PatchMatch Multi-View Stereo for Urban 3D Reconstruction,0.203965,"In this paper, a complete pipeline for image-based 3D reconstruction of urban
scenarios is proposed, based on PatchMatch Multi-View Stereo (MVS). Input
images are firstly fed into an off-the-shelf visual SLAM system to extract
camera poses and sparse keypoints, which are used to initialize PatchMatch
optimization. Then, pixelwise depths and normals are iteratively computed in a
multi-scale framework with a novel depth-normal consistency loss term and a
global refinement algorithm to balance the inherently local nature of
PatchMatch. Finally, a large-scale point cloud is generated by back-projecting
multi-view consistent estimates in 3D. The proposed approach is carefully
evaluated against both classical MVS algorithms and monocular depth networks on
the KITTI dataset, showing state of the art performances."
A Semantic Web Technology Index,0.906989,"Semantic Web (SW) technology has been widely applied to many domains such as
medicine, health care, finance, geology. At present, researchers mainly rely on
their experience and preferences to develop and evaluate the work of SW
technology. Although the general architecture (e.g., Tim Berners-Lee's Semantic
Web Layer Cake) of SW technology was proposed many years ago and has been
well-known, it still lacks a concrete guideline for standardizing the
development of SW technology. In this paper, we propose an SW technology index
to standardize the development for ensuring that the work of SW technology is
designed well and to quantitatively evaluate the quality of the work in SW
technology. This index consists of 10 criteria that quantify the quality as a
score of 0 ~ 10. We address each criterion in detail for a clear explanation
from three aspects: 1) what is the criterion? 2) why do we consider this
criterion and 3) how do the current studies meet this criterion? Finally, we
present the validation of this index by providing some examples of how to apply
the index to the validation cases. We conclude that the index is a useful
standard to guide and evaluate the work in SW technology."
On the Planning Abilities of Large Language Models : A Critical Investigation,0.984913,"Intrigued by the claims of emergent reasoning capabilities in LLMs trained on
general web corpora, in this paper, we set out to investigate their planning
capabilities. We aim to evaluate (1) the effectiveness of LLMs in generating
plans autonomously in commonsense planning tasks and (2) the potential of LLMs
in LLM-Modulo settings where they act as a source of heuristic guidance for
external planners and verifiers. We conduct a systematic study by generating a
suite of instances on domains similar to the ones employed in the International
Planning Competition and evaluate LLMs in two distinct modes: autonomous and
heuristic. Our findings reveal that LLMs' ability to generate executable plans
autonomously is rather limited, with the best model (GPT-4) having an average
success rate of ~12% across the domains. However, the results in the LLM-Modulo
setting show more promise. In the LLM-Modulo setting, we demonstrate that
LLM-generated plans can improve the search process for underlying sound
planners and additionally show that external verifiers can help provide
feedback on the generated plans and back-prompt the LLM for better plan
generation."
Slice Transformer and Self-supervised Learning for 6DoF Localization in 3D Point Cloud Maps,0.0582988,"Precise localization is critical for autonomous vehicles. We present a
self-supervised learning method that employs Transformers for the first time
for the task of outdoor localization using LiDAR data. We propose a pre-text
task that reorganizes the slices of a $360^\circ$ LiDAR scan to leverage its
axial properties. Our model, called Slice Transformer, employs multi-head
attention while systematically processing the slices. To the best of our
knowledge, this is the first instance of leveraging multi-head attention for
outdoor point clouds. We additionally introduce the Perth-WA dataset, which
provides a large-scale LiDAR map of Perth city in Western Australia, covering
$\sim$4km$^2$ area. Localization annotations are provided for Perth-WA. The
proposed localization method is thoroughly evaluated on Perth-WA and
Appollo-SouthBay datasets. We also establish the efficacy of our
self-supervised learning approach for the common downstream task of object
classification using ModelNet40 and ScanNN datasets. The code and Perth-WA data
will be publicly released."
Shape-Guided Diffusion with Inside-Outside Attention,0.765696,"We introduce precise object silhouette as a new form of user control in
text-to-image diffusion models, which we dub Shape-Guided Diffusion. Our
training-free method uses an Inside-Outside Attention mechanism during the
inversion and generation process to apply a shape constraint to the cross- and
self-attention maps. Our mechanism designates which spatial region is the
object (inside) vs. background (outside) then associates edits to the correct
region. We demonstrate the efficacy of our method on the shape-guided editing
task, where the model must replace an object according to a text prompt and
object mask. We curate a new ShapePrompts benchmark derived from MS-COCO and
achieve SOTA results in shape faithfulness without a degradation in text
alignment or image realism according to both automatic metrics and annotator
ratings. Our data and code will be made available at
https://shape-guided-diffusion.github.io."
UUKG: Unified Urban Knowledge Graph Dataset for Urban Spatiotemporal Prediction,0.625422,"Accurate Urban SpatioTemporal Prediction (USTP) is of great importance to the
development and operation of the smart city. As an emerging building block,
multi-sourced urban data are usually integrated as urban knowledge graphs
(UrbanKGs) to provide critical knowledge for urban spatiotemporal prediction
models. However, existing UrbanKGs are often tailored for specific downstream
prediction tasks and are not publicly available, which limits the potential
advancement. This paper presents UUKG, the unified urban knowledge graph
dataset for knowledge-enhanced urban spatiotemporal predictions. Specifically,
we first construct UrbanKGs consisting of millions of triplets for two
metropolises by connecting heterogeneous urban entities such as administrative
boroughs, POIs, and road segments. Moreover, we conduct qualitative and
quantitative analysis on constructed UrbanKGs and uncover diverse high-order
structural patterns, such as hierarchies and cycles, that can be leveraged to
benefit downstream USTP tasks. To validate and facilitate the use of UrbanKGs,
we implement and evaluate 15 KG embedding methods on the KG completion task and
integrate the learned KG embeddings into 9 spatiotemporal models for five
different USTP tasks. The extensive experimental results not only provide
benchmarks of knowledge-enhanced USTP models under different task settings but
also highlight the potential of state-of-the-art high-order structure-aware
UrbanKG embedding methods. We hope the proposed UUKG fosters research on urban
knowledge graphs and broad smart city applications. The dataset and source code
are available at https://github.com/usail-hkust/UUKG/."
Phantom Sponges: Exploiting Non-Maximum Suppression to Attack Deep Object Detectors,0.594228,"Adversarial attacks against deep learning-based object detectors have been
studied extensively in the past few years. Most of the attacks proposed have
targeted the model's integrity (i.e., caused the model to make incorrect
predictions), while adversarial attacks targeting the model's availability, a
critical aspect in safety-critical domains such as autonomous driving, have not
yet been explored by the machine learning research community. In this paper, we
propose a novel attack that negatively affects the decision latency of an
end-to-end object detection pipeline. We craft a universal adversarial
perturbation (UAP) that targets a widely used technique integrated in many
object detector pipelines -- non-maximum suppression (NMS). Our experiments
demonstrate the proposed UAP's ability to increase the processing time of
individual frames by adding ""phantom"" objects that overload the NMS algorithm
while preserving the detection of the original objects which allows the attack
to go undetected for a longer period of time."
Languages You Know Influence Those You Learn: Impact of Language Characteristics on Multi-Lingual Text-to-Text Transfer,0.210085,"Multi-lingual language models (LM), such as mBERT, XLM-R, mT5, mBART, have
been remarkably successful in enabling natural language tasks in low-resource
languages through cross-lingual transfer from high-resource ones. In this work,
we try to better understand how such models, specifically mT5, transfer *any*
linguistic and semantic knowledge across languages, even though no explicit
cross-lingual signals are provided during pre-training. Rather, only
unannotated texts from each language are presented to the model separately and
independently of one another, and the model appears to implicitly learn
cross-lingual connections. This raises several questions that motivate our
study, such as: Are the cross-lingual connections between every language pair
equally strong? What properties of source and target language impact the
strength of cross-lingual transfer? Can we quantify the impact of those
properties on the cross-lingual transfer?
  In our investigation, we analyze a pre-trained mT5 to discover the attributes
of cross-lingual connections learned by the model. Through a statistical
interpretation framework over 90 language pairs across three tasks, we show
that transfer performance can be modeled by a few linguistic and data-derived
features. These observations enable us to interpret cross-lingual understanding
of the mT5 model. Through these observations, one can favorably choose the best
source language for a task, and can anticipate its training data demands. A key
finding of this work is that similarity of syntax, morphology and phonology are
good predictors of cross-lingual transfer, significantly more than just the
lexical similarity of languages. For a given language, we are able to predict
zero-shot performance, that increases on a logarithmic scale with the number of
few-shot target language data points."
Learning a General Clause-to-Clause Relationships for Enhancing Emotion-Cause Pair Extraction,0.761617,"Emotion-cause pair extraction (ECPE) is an emerging task aiming to extract
potential pairs of emotions and corresponding causes from documents. Previous
approaches have focused on modeling the pair-to-pair relationship and achieved
promising results. However, the clause-to-clause relationship, which
fundamentally symbolizes the underlying structure of a document, has still been
in its research infancy. In this paper, we define a novel clause-to-clause
relationship. To learn it applicably, we propose a general clause-level
encoding model named EA-GAT comprising E-GAT and Activation Sort. E-GAT is
designed to aggregate information from different types of clauses; Activation
Sort leverages the individual emotion/cause prediction and the sort-based
mapping to propel the clause to a more favorable representation. Since EA-GAT
is a clause-level encoding model, it can be broadly integrated with any
previous approach. Experimental results show that our approach has a
significant advantage over all current approaches on the Chinese and English
benchmark corpus, with an average of $2.1\%$ and $1.03\%$."
DexTransfer: Real World Multi-fingered Dexterous Grasping with Minimal Human Demonstrations,0.626191,"Teaching a multi-fingered dexterous robot to grasp objects in the real world
has been a challenging problem due to its high dimensional state and action
space. We propose a robot-learning system that can take a small number of human
demonstrations and learn to grasp unseen object poses given partially occluded
observations. Our system leverages a small motion capture dataset and generates
a large dataset with diverse and successful trajectories for a multi-fingered
robot gripper. By adding domain randomization, we show that our dataset
provides robust grasping trajectories that can be transferred to a policy
learner. We train a dexterous grasping policy that takes the point clouds of
the object as input and predicts continuous actions to grasp objects from
different initial robot states. We evaluate the effectiveness of our system on
a 22-DoF floating Allegro Hand in simulation and a 23-DoF Allegro robot hand
with a KUKA arm in real world. The policy learned from our dataset can
generalize well on unseen object poses in both simulation and the real world"
Evaluation of Human-Understandability of Global Model Explanations using Decision Tree,0.139015,"In explainable artificial intelligence (XAI) research, the predominant focus
has been on interpreting models for experts and practitioners. Model agnostic
and local explanation approaches are deemed interpretable and sufficient in
many applications. However, in domains like healthcare, where end users are
patients without AI or domain expertise, there is an urgent need for model
explanations that are more comprehensible and instil trust in the model's
operations. We hypothesise that generating model explanations that are
narrative, patient-specific and global(holistic of the model) would enable
better understandability and enable decision-making. We test this using a
decision tree model to generate both local and global explanations for patients
identified as having a high risk of coronary heart disease. These explanations
are presented to non-expert users. We find a strong individual preference for a
specific type of explanation. The majority of participants prefer global
explanations, while a smaller group prefers local explanations. A task based
evaluation of mental models of these participants provide valuable feedback to
enhance narrative global explanations. This, in turn, guides the design of
health informatics systems that are both trustworthy and actionable."
VISION DIFFMASK: Faithful Interpretation of Vision Transformers with Differentiable Patch Masking,0.0771237,"The lack of interpretability of the Vision Transformer may hinder its use in
critical real-world applications despite its effectiveness. To overcome this
issue, we propose a post-hoc interpretability method called VISION DIFFMASK,
which uses the activations of the model's hidden layers to predict the relevant
parts of the input that contribute to its final predictions. Our approach uses
a gating mechanism to identify the minimal subset of the original input that
preserves the predicted distribution over classes. We demonstrate the
faithfulness of our method, by introducing a faithfulness task, and comparing
it to other state-of-the-art attribution methods on CIFAR-10 and ImageNet-1K,
achieving compelling results. To aid reproducibility and further extension of
our work, we open source our implementation:
https://github.com/AngelosNal/Vision-DiffMask"
VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking,0.999998,"3D object detectors usually rely on hand-crafted proxies, e.g., anchors or
centers, and translate well-studied 2D frameworks to 3D. Thus, sparse voxel
features need to be densified and processed by dense prediction heads, which
inevitably costs extra computation. In this paper, we instead propose VoxelNext
for fully sparse 3D object detection. Our core insight is to predict objects
directly based on sparse voxel features, without relying on hand-crafted
proxies. Our strong sparse convolutional network VoxelNeXt detects and tracks
3D objects through voxel features entirely. It is an elegant and efficient
framework, with no need for sparse-to-dense conversion or NMS post-processing.
Our method achieves a better speed-accuracy trade-off than other mainframe
detectors on the nuScenes dataset. For the first time, we show that a fully
sparse voxel-based representation works decently for LIDAR 3D object detection
and tracking. Extensive experiments on nuScenes, Waymo, and Argoverse2
benchmarks validate the effectiveness of our approach. Without bells and
whistles, our model outperforms all existing LIDAR methods on the nuScenes
tracking test benchmark."
GitNet: Geometric Prior-based Transformation for Birds-Eye-View Segmentation,0.565371,"Birds-eye-view (BEV) semantic segmentation is critical for autonomous driving
for its powerful spatial representation ability. It is challenging to estimate
the BEV semantic maps from monocular images due to the spatial gap, since it is
implicitly required to realize both the perspective-to-BEV transformation and
segmentation. We present a novel two-stage Geometry Prior-based Transformation
framework named GitNet, consisting of (i) the geometry-guided pre-alignment and
(ii) ray-based transformer. In the first stage, we decouple the BEV
segmentation into the perspective image segmentation and geometric prior-based
mapping, with explicit supervision by projecting the BEV semantic labels onto
the image plane to learn visibility-aware features and learnable geometry to
translate into BEV space. Second, the pre-aligned coarse BEV features are
further deformed by ray-based transformers to take visibility knowledge into
account. GitNet achieves the leading performance on the challenging nuScenes
and Argoverse Datasets."
Assessing the potential of AI-assisted pragmatic annotation: The case of apologies,0.882681,"Certain forms of linguistic annotation, like part of speech and semantic
tagging, can be automated with high accuracy. However, manual annotation is
still necessary for complex pragmatic and discursive features that lack a
direct mapping to lexical forms. This manual process is time-consuming and
error-prone, limiting the scalability of function-to-form approaches in corpus
linguistics. To address this, our study explores automating pragma-discursive
corpus annotation using large language models (LLMs). We compare ChatGPT, the
Bing chatbot, and a human coder in annotating apology components in English
based on the local grammar framework. We find that the Bing chatbot
outperformed ChatGPT, with accuracy approaching that of a human coder. These
results suggest that AI can be successfully deployed to aid pragma-discursive
corpus annotation, making the process more efficient and scalable. Keywords:
linguistic annotation, function-to-form approaches, large language models,
local grammar analysis, Bing chatbot, ChatGPT"
Slim-neck by GSConv: A better design paradigm of detector architectures for autonomous vehicles,0.859222,"Object detection is a significant downstream task in computer vision. For the
on-board edge computing platforms, a giant model is difficult to achieve the
real-time detection requirement. And, a lightweight model built from a large
number of the depth-wise separable convolution layers cannot achieve the
sufficient accuracy. We introduce a new lightweight convolution technique,
GSConv, to lighten the model but maintain the accuracy. The GSConv accomplishes
an excellent trade-off between the model's accuracy and speed. And, we provide
a design paradigm, slim-neck, to achieve a higher computational
cost-effectiveness of the detectors. The effectiveness of our approach was
robustly demonstrated in over twenty sets comparative experiments. In
particular, the detectors of ameliorated by our approach obtains
state-of-the-art results (e.g. 70.9% mAP0.5 for the SODA10M at a speed of ~
100FPS on a Tesla T4 GPU) compared with the originals. Code is available at
https://github.com/alanli1997/slim-neck-by-gsconv"
Unsupervised Segmentation in Real-World Images via Spelke Object Inference,0.774114,"Self-supervised, category-agnostic segmentation of real-world images is a
challenging open problem in computer vision. Here, we show how to learn static
grouping priors from motion self-supervision by building on the cognitive
science concept of a Spelke Object: a set of physical stuff that moves
together. We introduce the Excitatory-Inhibitory Segment Extraction Network
(EISEN), which learns to extract pairwise affinity graphs for static scenes
from motion-based training signals. EISEN then produces segments from
affinities using a novel graph propagation and competition network. During
training, objects that undergo correlated motion (such as robot arms and the
objects they move) are decoupled by a bootstrapping process: EISEN explains
away the motion of objects it has already learned to segment. We show that
EISEN achieves a substantial improvement in the state of the art for
self-supervised image segmentation on challenging synthetic and real-world
robotics datasets."
Help me write a poem: Instruction Tuning as a Vehicle for Collaborative Poetry Writing,0.999898,"Recent work in training large language models (LLMs) to follow natural
language instructions has opened up exciting opportunities for natural language
interface design. Building on the prior success of LLMs in the realm of
computer-assisted creativity, we aim to study if LLMs can improve the quality
of user-generated content through collaboration. We present CoPoet, a
collaborative poetry writing system. In contrast to auto-completing a user's
text, CoPoet is controlled by user instructions that specify the attributes of
the desired text, such as Write a sentence about `love' or Write a sentence
ending in `fly'. The core component of our system is a language model
fine-tuned on a diverse collection of instructions for poetry writing. Our
model is not only competitive with publicly available LLMs trained on
instructions (InstructGPT), but is also capable of satisfying unseen
compositional instructions. A study with 15 qualified crowdworkers shows that
users successfully write poems with CoPoet on diverse topics ranging from
Monarchy to Climate change. Further, the collaboratively written poems are
preferred by third-party evaluators over those written without the system."
MobileVidFactory: Automatic Diffusion-Based Social Media Video Generation for Mobile Devices from Text,0.865314,"Videos for mobile devices become the most popular access to share and acquire
information recently. For the convenience of users' creation, in this paper, we
present a system, namely MobileVidFactory, to automatically generate vertical
mobile videos where users only need to give simple texts mainly. Our system
consists of two parts: basic and customized generation. In the basic
generation, we take advantage of the pretrained image diffusion model, and
adapt it to a high-quality open-domain vertical video generator for mobile
devices. As for the audio, by retrieving from our big database, our system
matches a suitable background sound for the video. Additionally to produce
customized content, our system allows users to add specified screen texts to
the video for enriching visual expression, and specify texts for automatic
reading with optional voices as they like."
Font Representation Learning via Paired-glyph Matching,0.0480929,"Fonts can convey profound meanings of words in various forms of glyphs.
Without typography knowledge, manually selecting an appropriate font or
designing a new font is a tedious and painful task. To allow users to explore
vast font styles and create new font styles, font retrieval and font style
transfer methods have been proposed. These tasks increase the need for learning
high-quality font representations. Therefore, we propose a novel font
representation learning scheme to embed font styles into the latent space. For
the discriminative representation of a font from others, we propose a
paired-glyph matching-based font representation learning model that attracts
the representations of glyphs in the same font to one another, but pushes away
those of other fonts. Through evaluations on font retrieval with query glyphs
on new fonts, we show our font representation learning scheme achieves better
generalization performance than the existing font representation learning
techniques. Finally on the downstream font style transfer and generation tasks,
we confirm the benefits of transfer learning with the proposed method. The
source code is available at https://github.com/junhocho/paired-glyph-matching."
Empowering Cross-lingual Behavioral Testing of NLP Models with Typological Features,0.704495,"A challenge towards developing NLP systems for the world's languages is
understanding how they generalize to typological differences relevant for
real-world applications. To this end, we propose M2C, a morphologically-aware
framework for behavioral testing of NLP models. We use M2C to generate tests
that probe models' behavior in light of specific linguistic features in 12
typologically diverse languages. We evaluate state-of-the-art language models
on the generated tests. While models excel at most tests in English, we
highlight generalization failures to specific typological characteristics such
as temporal expressions in Swahili and compounding possessives in Finish. Our
findings motivate the development of models that address these blind spots."
The Myth of Culturally Agnostic AI Models,0.166613,"The paper discusses the potential of large vision-language models as objects
of interest for empirical cultural studies. Focusing on the comparative
analysis of outputs from two popular text-to-image synthesis models, DALL-E 2
and Stable Diffusion, the paper tries to tackle the pros and cons of striving
towards culturally agnostic vs. culturally specific AI models. The paper
discusses several examples of memorization and bias in generated outputs which
showcase the trade-off between risk mitigation and cultural specificity, as
well as the overall impossibility of developing culturally agnostic models."
"To Build Our Future, We Must Know Our Past: Contextualizing Paradigm Shifts in Natural Language Processing",0.036312,"NLP is in a period of disruptive change that is impacting our methodologies,
funding sources, and public perception. In this work, we seek to understand how
to shape our future by better understanding our past. We study factors that
shape NLP as a field, including culture, incentives, and infrastructure by
conducting long-form interviews with 26 NLP researchers of varying seniority,
research area, institution, and social identity. Our interviewees identify
cyclical patterns in the field, as well as new shifts without historical
parallel, including changes in benchmark culture and software infrastructure.
We complement this discussion with quantitative analysis of citation,
authorship, and language use in the ACL Anthology over time. We conclude by
discussing shared visions, concerns, and hopes for the future of NLP. We hope
that this study of our field's past and present can prompt informed discussion
of our community's implicit norms and more deliberate action to consciously
shape the future."
A Multi-Document Coverage Reward for RELAXed Multi-Document Summarization,0.575949,"Multi-document summarization (MDS) has made significant progress in recent
years, in part facilitated by the availability of new, dedicated datasets and
capacious language models. However, a standing limitation of these models is
that they are trained against limited references and with plain
maximum-likelihood objectives. As for many other generative tasks,
reinforcement learning (RL) offers the potential to improve the training of MDS
models; yet, it requires a carefully-designed reward that can ensure
appropriate leverage of both the reference summaries and the input documents.
For this reason, in this paper we propose fine-tuning an MDS baseline with a
reward that balances a reference-based metric such as ROUGE with coverage of
the input documents. To implement the approach, we utilize RELAX (Grathwohl et
al., 2018), a contemporary gradient estimator which is both low-variance and
unbiased, and we fine-tune the baseline in a few-shot style for both stability
and computational efficiency. Experimental results over the Multi-News and WCEP
MDS datasets show significant improvements of up to +0.95 pp average ROUGE
score and +3.17 pp METEOR score over the baseline, and competitive results with
the literature. In addition, they show that the coverage of the input documents
is increased, and evenly across all documents."
Distilling Style from Image Pairs for Global Forward and Inverse Tone Mapping,0.214744,"Many image enhancement or editing operations, such as forward and inverse
tone mapping or color grading, do not have a unique solution, but instead a
range of solutions, each representing a different style. Despite this, existing
learning-based methods attempt to learn a unique mapping, disregarding this
style. In this work, we show that information about the style can be distilled
from collections of image pairs and encoded into a 2- or 3-dimensional vector.
This gives us not only an efficient representation but also an interpretable
latent space for editing the image style. We represent the global color mapping
between a pair of images as a custom normalizing flow, conditioned on a
polynomial basis of the pixel color. We show that such a network is more
effective than PCA or VAE at encoding image style in low-dimensional space and
lets us obtain an accuracy close to 40 dB, which is about 7-10 dB improvement
over the state-of-the-art methods."
Diverse Weight Averaging for Out-of-Distribution Generalization,0.989455,"Standard neural networks struggle to generalize under distribution shifts in
computer vision. Fortunately, combining multiple networks can consistently
improve out-of-distribution generalization. In particular, weight averaging
(WA) strategies were shown to perform best on the competitive DomainBed
benchmark; they directly average the weights of multiple networks despite their
nonlinearities. In this paper, we propose Diverse Weight Averaging (DiWA), a
new WA strategy whose main motivation is to increase the functional diversity
across averaged models. To this end, DiWA averages weights obtained from
several independent training runs: indeed, models obtained from different runs
are more diverse than those collected along a single run thanks to differences
in hyperparameters and training procedures. We motivate the need for diversity
by a new bias-variance-covariance-locality decomposition of the expected error,
exploiting similarities between WA and standard functional ensembling.
Moreover, this decomposition highlights that WA succeeds when the variance term
dominates, which we show occurs when the marginal distribution changes at test
time. Experimentally, DiWA consistently improves the state of the art on
DomainBed without inference overhead."
Honesty Is the Best Policy: Defining and Mitigating AI Deception,0.659979,"Deceptive agents are a challenge for the safety, trustworthiness, and
cooperation of AI systems. We focus on the problem that agents might deceive in
order to achieve their goals (for instance, in our experiments with language
models, the goal of being evaluated as truthful). There are a number of
existing definitions of deception in the literature on game theory and symbolic
AI, but there is no overarching theory of deception for learning agents in
games. We introduce a formal definition of deception in structural causal
games, grounded in the philosophy literature, and applicable to real-world
machine learning systems. Several examples and results illustrate that our
formal definition aligns with the philosophical and commonsense meaning of
deception. Our main technical result is to provide graphical criteria for
deception. We show, experimentally, that these results can be used to mitigate
deception in reinforcement learning agents and language models."
RAVEN: In-Context Learning with Retrieval-Augmented Encoder-Decoder Language Models,0.432753,"In this paper, we investigate the in-context learning ability of
retrieval-augmented encoder-decoder language models. We first conduct a
comprehensive analysis of existing models and identify their limitations in
in-context learning, primarily due to a mismatch between pretraining and
inference, as well as a restricted context length. To address these issues, we
propose RAVEN, a model that combines retrieval-augmented masked language
modeling and prefix language modeling. We further introduce Fusion-in-Context
Learning to enhance the few-shot performance by enabling the model to leverage
more in-context examples without requiring additional training. Through
extensive experiments, we demonstrate that our simple yet effective design
significantly improves performance, achieving results comparable to the most
advanced language models in certain scenarios, despite having substantially
fewer parameters. Our work underscores the potential of retrieval-augmented
encoder-decoder language models for in-context learning and encourages further
research in this direction."
Enhance Topics Analysis based on Keywords Properties,0.0365669,"Topic Modelling is one of the most prevalent text analysis technique used to
explore and retrieve collection of documents. The evaluation of the topic model
algorithms is still a very challenging tasks due to the absence of
gold-standard list of topics to compare against for every corpus. In this work,
we present a specificity score based on keywords properties that is able to
select the most informative topics. This approach helps the user to focus on
the most informative topics. In the experiments, we show that we are able to
compress the state-of-the-art topic modelling results of different factors with
an information loss that is much lower than the solution based on the recent
coherence score presented in literature."
Auto-labelling of Bug Report using Natural Language Processing,0.694511,"The exercise of detecting similar bug reports in bug tracking systems is
known as duplicate bug report detection. Having prior knowledge of a bug
report's existence reduces efforts put into debugging problems and identifying
the root cause. Rule and Query-based solutions recommend a long list of
potential similar bug reports with no clear ranking. In addition, triage
engineers are less motivated to spend time going through an extensive list.
Consequently, this deters the use of duplicate bug report retrieval solutions.
In this paper, we have proposed a solution using a combination of NLP
techniques. Our approach considers unstructured and structured attributes of a
bug report like summary, description and severity, impacted products,
platforms, categories, etc. It uses a custom data transformer, a deep neural
network, and a non-generalizing machine learning method to retrieve existing
identical bug reports. We have performed numerous experiments with significant
data sources containing thousands of bug reports and showcased that the
proposed solution achieves a high retrieval accuracy of 70% for recall@5."
Exploring Large-scale Unlabeled Faces to Enhance Facial Expression Recognition,0.770541,"Facial Expression Recognition (FER) is an important task in computer vision
and has wide applications in human-computer interaction, intelligent security,
emotion analysis, and other fields. However, the limited size of FER datasets
limits the generalization ability of expression recognition models, resulting
in ineffective model performance. To address this problem, we propose a
semi-supervised learning framework that utilizes unlabeled face data to train
expression recognition models effectively. Our method uses a dynamic threshold
module (\textbf{DTM}) that can adaptively adjust the confidence threshold to
fully utilize the face recognition (FR) data to generate pseudo-labels, thus
improving the model's ability to model facial expressions. In the ABAW5 EXPR
task, our method achieved excellent results on the official validation set."
Interactive Image Segmentation with Cross-Modality Vision Transformers,0.389677,"Interactive image segmentation aims to segment the target from the background
with the manual guidance, which takes as input multimodal data such as images,
clicks, scribbles, and bounding boxes. Recently, vision transformers have
achieved a great success in several downstream visual tasks, and a few efforts
have been made to bring this powerful architecture to interactive segmentation
task. However, the previous works neglect the relations between two modalities
and directly mock the way of processing purely visual information with
self-attentions. In this paper, we propose a simple yet effective network for
click-based interactive segmentation with cross-modality vision transformers.
Cross-modality transformers exploits mutual information to better guide the
learning process. The experiments on several benchmarks show that the proposed
method achieves superior performance in comparison to the previous
state-of-the-art models. The stability of our method in term of avoiding
failure cases shows its potential to be a practical annotation tool. The code
and pretrained models will be released under
https://github.com/lik1996/iCMFormer."
Weakly Supervised 3D Point Cloud Segmentation via Multi-Prototype Learning,0.519184,"Addressing the annotation challenge in 3D Point Cloud segmentation has
inspired research into weakly supervised learning. Existing approaches mainly
focus on exploiting manifold and pseudo-labeling to make use of large unlabeled
data points. A fundamental challenge here lies in the large intra-class
variations of local geometric structure, resulting in subclasses within a
semantic class. In this work, we leverage this intuition and opt for
maintaining an individual classifier for each subclass. Technically, we design
a multi-prototype classifier, each prototype serves as the classifier weights
for one subclass. To enable effective updating of multi-prototype classifier
weights, we propose two constraints respectively for updating the prototypes
w.r.t. all point features and for encouraging the learning of diverse
prototypes. Experiments on weakly supervised 3D point cloud segmentation tasks
validate the efficacy of proposed method in particular at low-label regime. Our
hypothesis is also verified given the consistent discovery of semantic
subclasses at no cost of additional annotations."
Handwritten Arabic Character Recognition for Children Writ-ing Using Convolutional Neural Network and Stroke Identification,0.891498,"Automatic Arabic handwritten recognition is one of the recently studied
problems in the field of Machine Learning. Unlike Latin languages, Arabic is a
Semitic language that forms a harder challenge, especially with variability of
patterns caused by factors such as writer age. Most of the studies focused on
adults, with only one recent study on children. Moreover, much of the recent
Machine Learning methods focused on using Convolutional Neural Networks, a
powerful class of neural networks that can extract complex features from
images. In this paper we propose a convolutional neural network (CNN) model
that recognizes children handwriting with an accuracy of 91% on the Hijja
dataset, a recent dataset built by collecting images of the Arabic characters
written by children, and 97% on Arabic Handwritten Character Dataset. The
results showed a good improvement over the proposed model from the Hijja
dataset authors, yet it reveals a bigger challenge to solve for children Arabic
handwritten character recognition. Moreover, we proposed a new approach using
multi models instead of single model based on the number of strokes in a
character, and merged Hijja with AHCD which reached an averaged prediction
accuracy of 96%."
Robust Double-Encoder Network for RGB-D Panoptic Segmentation,0.66072,"Perception is crucial for robots that act in real-world environments, as
autonomous systems need to see and understand the world around them to act
properly. Panoptic segmentation provides an interpretation of the scene by
computing a pixelwise semantic label together with instance IDs. In this paper,
we address panoptic segmentation using RGB-D data of indoor scenes. We propose
a novel encoder-decoder neural network that processes RGB and depth separately
through two encoders. The features of the individual encoders are progressively
merged at different resolutions, such that the RGB features are enhanced using
complementary depth information. We propose a novel merging approach called
ResidualExcite, which reweighs each entry of the feature map according to its
importance. With our double-encoder architecture, we are robust to missing
cues. In particular, the same model can train and infer on RGB-D, RGB-only, and
depth-only input data, without the need to train specialized models. We
evaluate our method on publicly available datasets and show that our approach
achieves superior results compared to other common approaches for panoptic
segmentation."
Video ControlNet: Towards Temporally Consistent Synthetic-to-Real Video Translation Using Conditional Image Diffusion Models,0.55578,"In this study, we present an efficient and effective approach for achieving
temporally consistent synthetic-to-real video translation in videos of varying
lengths. Our method leverages off-the-shelf conditional image diffusion models,
allowing us to perform multiple synthetic-to-real image generations in
parallel. By utilizing the available optical flow information from the
synthetic videos, our approach seamlessly enforces temporal consistency among
corresponding pixels across frames. This is achieved through joint noise
optimization, effectively minimizing spatial and temporal discrepancies. To the
best of our knowledge, our proposed method is the first to accomplish diverse
and temporally consistent synthetic-to-real video translation using conditional
image diffusion models. Furthermore, our approach does not require any training
or fine-tuning of the diffusion models. Extensive experiments conducted on
various benchmarks for synthetic-to-real video translation demonstrate the
effectiveness of our approach, both quantitatively and qualitatively. Finally,
we show that our method outperforms other baseline methods in terms of both
temporal consistency and visual quality."
MMMNA-Net for Overall Survival Time Prediction of Brain Tumor Patients,0.236337,"Overall survival (OS) time is one of the most important evaluation indices
for gliomas situations. Multimodal Magnetic Resonance Imaging (MRI) scans play
an important role in the study of glioma prognosis OS time. Several deep
learning-based methods are proposed for the OS time prediction on multi-modal
MRI problems. However, these methods usually fuse multi-modal information at
the beginning or at the end of the deep learning networks and lack the fusion
of features from different scales. In addition, the fusion at the end of
networks always adapts global with global (eg. fully connected after
concatenation of global average pooling output) or local with local (eg.
bilinear pooling), which loses the information of local with global. In this
paper, we propose a novel method for multi-modal OS time prediction of brain
tumor patients, which contains an improved nonlocal features fusion module
introduced on different scales. Our method obtains a relative 8.76% improvement
over the current state-of-art method (0.6989 vs. 0.6426 on accuracy). Extensive
testing demonstrates that our method could adapt to situations with missing
modalities. The code is available at
https://github.com/TangWen920812/mmmna-net."
Modeling Intensification for Sign Language Generation: A Computational Approach,0.12671,"End-to-end sign language generation models do not accurately represent the
prosody in sign language. A lack of temporal and spatial variations leads to
poor-quality generated presentations that confuse human interpreters. In this
paper, we aim to improve the prosody in generated sign languages by modeling
intensification in a data-driven manner. We present different strategies
grounded in linguistics of sign language that inform how intensity modifiers
can be represented in gloss annotations. To employ our strategies, we first
annotate a subset of the benchmark PHOENIX-14T, a German Sign Language dataset,
with different levels of intensification. We then use a supervised intensity
tagger to extend the annotated dataset and obtain labels for the remaining
portion of it. This enhanced dataset is then used to train state-of-the-art
transformer models for sign language generation. We find that our efforts in
intensification modeling yield better results when evaluated with automatic
metrics. Human evaluation also indicates a higher preference of the videos
generated using our model."
Attention-Based Lip Audio-Visual Synthesis for Talking Face Generation in the Wild,0.540495,"Talking face generation with great practical significance has attracted more
attention in recent audio-visual studies. How to achieve accurate lip
synchronization is a long-standing challenge to be further investigated.
Motivated by xxx, in this paper, an AttnWav2Lip model is proposed by
incorporating spatial attention module and channel attention module into
lip-syncing strategy. Rather than focusing on the unimportant regions of the
face image, the proposed AttnWav2Lip model is able to pay more attention on the
lip region reconstruction. To our limited knowledge, this is the first attempt
to introduce attention mechanism to the scheme of talking face generation. An
extensive experiments have been conducted to evaluate the effectiveness of the
proposed model. Compared to the baseline measured by LSE-D and LSE-C metrics, a
superior performance has been demonstrated on the benchmark lip synthesis
datasets, including LRW, LRS2 and LRS3."
Dynamic Residual Classifier for Class Incremental Learning,0.704187,"The rehearsal strategy is widely used to alleviate the catastrophic
forgetting problem in class incremental learning (CIL) by preserving limited
exemplars from previous tasks. With imbalanced sample numbers between old and
new classes, the classifier learning can be biased. Existing CIL methods
exploit the long-tailed (LT) recognition techniques, e.g., the adjusted losses
and the data re-sampling methods, to handle the data imbalance issue within
each increment task. In this work, the dynamic nature of data imbalance in CIL
is shown and a novel Dynamic Residual Classifier (DRC) is proposed to handle
this challenging scenario. Specifically, DRC is built upon a recent advance
residual classifier with the branch layer merging to handle the model-growing
problem. Moreover, DRC is compatible with different CIL pipelines and
substantially improves them. Combining DRC with the model adaptation and fusion
(MAF) pipeline, this method achieves state-of-the-art results on both the
conventional CIL and the LT-CIL benchmarks. Extensive experiments are also
conducted for a detailed analysis. The code is publicly available."
Real-time Recognition of Yoga Poses using computer Vision for Smart Health Care,0.631845,"Nowadays, yoga has become a part of life for many people. Exercises and
sports technological assistance is implemented in yoga pose identification. In
this work, a self-assistance based yoga posture identification technique is
developed, which helps users to perform Yoga with the correction feature in
Real-time. The work also presents Yoga-hand mudra (hand gestures)
identification. The YOGI dataset has been developed which include 10 Yoga
postures with around 400-900 images of each pose and also contain 5 mudras for
identification of mudras postures. It contains around 500 images of each mudra.
The feature has been extracted by making a skeleton on the body for yoga poses
and hand for mudra poses. Two different algorithms have been used for creating
a skeleton one for yoga poses and the second for hand mudras. Angles of the
joints have been extracted as a features for different machine learning and
deep learning models. among all the models XGBoost with RandomSearch CV is most
accurate and gives 99.2\% accuracy. The complete design framework is described
in the present paper."
Multi-class Categorization of Reasons behind Mental Disturbance in Long Texts,0.364936,"Motivated with recent advances in inferring users' mental state in social
media posts, we identify and formulate the problem of finding causal indicators
behind mental illness in self-reported text. In the past, we witness the
presence of rule-based studies for causal explanation analysis on curated
Facebook data. The investigation on transformer-based model for multi-class
causal categorization in Reddit posts point to a problem of using long-text
which contains as many as 4000 words. Developing end-to-end transformer-based
models subject to the limitation of maximum-length in a given instance. To
handle this problem, we use Longformer and deploy its encoding on
transformer-based classifier. The experimental results show that Longformer
achieves new state-of-the-art results on M-CAMS, a publicly available dataset
with 62\% F1-score. Cause-specific analysis and ablation study prove the
effectiveness of Longformer. We believe our work facilitates causal analysis of
depression and suicide risk on social media data, and shows potential for
application on other mental health conditions."
"CGiS-Net: Aggregating Colour, Geometry and Implicit Semantic Features for Indoor Place Recognition",0.550614,"We describe a novel approach to indoor place recognition from RGB point
clouds based on aggregating low-level colour and geometry features with
high-level implicit semantic features. It uses a 2-stage deep learning
framework, in which the first stage is trained for the auxiliary task of
semantic segmentation and the second stage uses features from layers in the
first stage to generate discriminate descriptors for place recognition. The
auxiliary task encourages the features to be semantically meaningful, hence
aggregating the geometry and colour in the RGB point cloud data with implicit
semantic information. We use an indoor place recognition dataset derived from
the ScanNet dataset for training and evaluation, with a test set comprising
3,608 point clouds generated from 100 different rooms. Comparison with a
traditional feature-based method and four state-of-the-art deep learning
methods demonstrate that our approach significantly outperforms all five
methods, achieving, for example, a top-3 average recall rate of 75% compared
with 41% for the closest rival method. Our code is available at:
https://github.com/YuhangMing/Semantic-Indoor-Place-Recognition"
Hi4D: 4D Instance Segmentation of Close Human Interaction,0.893827,"We propose Hi4D, a method and dataset for the automatic analysis of
physically close human-human interaction under prolonged contact. Robustly
disentangling several in-contact subjects is a challenging task due to
occlusions and complex shapes. Hence, existing multi-view systems typically
fuse 3D surfaces of close subjects into a single, connected mesh. To address
this issue we leverage i) individually fitted neural implicit avatars; ii) an
alternating optimization scheme that refines pose and surface through periods
of close proximity; and iii) thus segment the fused raw scans into individual
instances. From these instances we compile Hi4D dataset of 4D textured scans of
20 subject pairs, 100 sequences, and a total of more than 11K frames. Hi4D
contains rich interaction-centric annotations in 2D and 3D alongside accurately
registered parametric body models. We define varied human pose and shape
estimation tasks on this dataset and provide results from state-of-the-art
methods on these benchmarks."
Dataset Condensation with Latent Space Knowledge Factorization and Sharing,0.299334,"In this paper, we introduce a novel approach for systematically solving
dataset condensation problem in an efficient manner by exploiting the
regularity in a given dataset. Instead of condensing the dataset directly in
the original input space, we assume a generative process of the dataset with a
set of learnable codes defined in a compact latent space followed by a set of
tiny decoders which maps them differently to the original input space. By
combining different codes and decoders interchangeably, we can dramatically
increase the number of synthetic examples with essentially the same parameter
count, because the latent space is much lower dimensional and since we can
assume as many decoders as necessary to capture different styles represented in
the dataset with negligible cost. Such knowledge factorization allows efficient
sharing of information between synthetic examples in a systematic way,
providing far better trade-off between compression ratio and quality of the
generated examples. We experimentally show that our method achieves new
state-of-the-art records by significant margins on various benchmark datasets
such as SVHN, CIFAR10, CIFAR100, and TinyImageNet."
Bubble identification from images with machine learning methods,0.424227,"An automated and reliable processing of bubbly flow images is highly needed
to analyse large data sets of comprehensive experimental series. A particular
difficulty arises due to overlapping bubble projections in recorded images,
which highly complicates the identification of individual bubbles. Recent
approaches focus on the use of deep learning algorithms for this task and have
already proven the high potential of such techniques. The main difficulties are
the capability to handle different image conditions, higher gas volume
fractions and a proper reconstruction of the hidden segment of a partly
occluded bubble. In the present work, we try to tackle these points by testing
three different methods based on Convolutional Neural Networks (CNNs) for the
two former and two individual approaches that can be used subsequently to
address the latter. To validate our methodology, we created test data sets with
synthetic images that further demonstrate the capabilities as well as
limitations of our combined approach. The generated data, code and trained
models are made accessible to facilitate the use as well as further
developments in the research field of bubble recognition in experimental
images."
HYRR: Hybrid Infused Reranking for Passage Retrieval,0.168563,"We present Hybrid Infused Reranking for Passages Retrieval (HYRR), a
framework for training rerankers based on a hybrid of BM25 and neural retrieval
models. Retrievers based on hybrid models have been shown to outperform both
BM25 and neural models alone. Our approach exploits this improved performance
when training a reranker, leading to a robust reranking model. The reranker, a
cross-attention neural model, is shown to be robust to different first-stage
retrieval systems, achieving better performance than rerankers simply trained
upon the first-stage retrievers in the multi-stage systems. We present
evaluations on a supervised passage retrieval task using MS MARCO and zero-shot
retrieval tasks using BEIR. The empirical results show strong performance on
both evaluations."
RQAT-INR: Improved Implicit Neural Image Compression,0.620297,"Deep variational autoencoders for image and video compression have gained
significant attraction in the recent years, due to their potential to offer
competitive or better compression rates compared to the decades long
traditional codecs such as AVC, HEVC or VVC. However, because of complexity and
energy consumption, these approaches are still far away from practical usage in
industry. More recently, implicit neural representation (INR) based codecs have
emerged, and have lower complexity and energy usage to classical approaches at
decoding. However, their performances are not in par at the moment with
state-of-the-art methods. In this research, we first show that INR based image
codec has a lower complexity than VAE based approaches, then we propose several
improvements for INR-based image codec and outperformed baseline model by a
large margin."
Graecia capta ferum victorem cepit. Detecting Latin Allusions to Ancient Greek Literature,0.261533,"Intertextual allusions hold a pivotal role in Classical Philology, with Latin
authors frequently referencing Ancient Greek texts. Until now, the automatic
identification of these intertextual references has been constrained to
monolingual approaches, seeking parallels solely within Latin or Greek texts.
In this study, we introduce SPhilBERTa, a trilingual Sentence-RoBERTa model
tailored for Classical Philology, which excels at cross-lingual semantic
comprehension and identification of identical sentences across Ancient Greek,
Latin, and English. We generate new training data by automatically translating
English texts into Ancient Greek. Further, we present a case study,
demonstrating SPhilBERTa's capability to facilitate automated detection of
intertextual parallels. Our models and resources are available at
https://github.com/Heidelberg-NLP/ancient-language-models."
Do Differences in Values Influence Disagreements in Online Discussions?,0.896703,"Disagreements are common in online discussions. Disagreement may foster
collaboration and improve the quality of a discussion under some conditions.
Although there exist methods for recognizing disagreement, a deeper
understanding of factors that influence disagreement is lacking in the
literature. We investigate a hypothesis that differences in personal values are
indicative of disagreement in online discussions. We show how state-of-the-art
models can be used for estimating values in online discussions and how the
estimated values can be aggregated into value profiles. We evaluate the
estimated value profiles based on human-annotated agreement labels. We find
that the dissimilarity of value profiles correlates with disagreement in
specific cases. We also find that including value information in agreement
prediction improves performance."
Interpretable Molecular Graph Generation via Monotonic Constraints,0.626729,"Designing molecules with specific properties is a long-lasting research
problem and is central to advancing crucial domains such as drug discovery and
material science. Recent advances in deep graph generative models treat
molecule design as graph generation problems which provide new opportunities
toward the breakthrough of this long-lasting problem. Existing models, however,
have many shortcomings, including poor interpretability and controllability
toward desired molecular properties. This paper focuses on new methodologies
for molecule generation with interpretable and controllable deep generative
models, by proposing new monotonically-regularized graph variational
autoencoders. The proposed models learn to represent the molecules with latent
variables and then learn the correspondence between them and molecule
properties parameterized by polynomial functions. To further improve the
intepretability and controllability of molecule generation towards desired
properties, we derive new objectives which further enforce monotonicity of the
relation between some latent variables and target molecule properties such as
toxicity and clogP. Extensive experimental evaluation demonstrates the
superiority of the proposed framework on accuracy, novelty, disentanglement,
and control towards desired molecular properties. The code is open-source at
https://anonymous.4open.science/r/MDVAE-FD2C."
Automated multilingual detection of Pro-Kremlin propaganda in newspapers and Telegram posts,0.536058,"The full-scale conflict between the Russian Federation and Ukraine generated
an unprecedented amount of news articles and social media data reflecting
opposing ideologies and narratives. These polarized campaigns have led to
mutual accusations of misinformation and fake news, shaping an atmosphere of
confusion and mistrust for readers worldwide. This study analyses how the media
affected and mirrored public opinion during the first month of the war using
news articles and Telegram news channels in Ukrainian, Russian, Romanian and
English. We propose and compare two methods of multilingual automated
pro-Kremlin propaganda identification, based on Transformers and linguistic
features. We analyse the advantages and disadvantages of both methods, their
adaptability to new genres and languages, and ethical considerations of their
usage for content moderation. With this work, we aim to lay the foundation for
further development of moderation tools tailored to the current conflict."
CLIP-Sculptor: Zero-Shot Generation of High-Fidelity and Diverse Shapes from Natural Language,0.458668,"Recent works have demonstrated that natural language can be used to generate
and edit 3D shapes. However, these methods generate shapes with limited
fidelity and diversity. We introduce CLIP-Sculptor, a method to address these
constraints by producing high-fidelity and diverse 3D shapes without the need
for (text, shape) pairs during training. CLIP-Sculptor achieves this in a
multi-resolution approach that first generates in a low-dimensional latent
space and then upscales to a higher resolution for improved shape fidelity. For
improved shape diversity, we use a discrete latent space which is modeled using
a transformer conditioned on CLIP's image-text embedding space. We also present
a novel variant of classifier-free guidance, which improves the
accuracy-diversity trade-off. Finally, we perform extensive experiments
demonstrating that CLIP-Sculptor outperforms state-of-the-art baselines. The
code is available at https://ivl.cs.brown.edu/#/projects/clip-sculptor."
Search for universal minimum drag resistance underwater vehicle hull using CFD,0.711708,"In Autonomous Underwater Vehicles (AUVs) design, hull resistance is an
important factor in determining the power requirements and range of vehicle and
consequently affect battery size, weight, and volume requirement of the design.
In this paper, we leverage on AI-based optimization algorithm along with
Computational Fluid Dynamics (CFD) simulation to study the optimal hull design
that minimizing the resistance. By running the CFD-based optimization at
different operating velocities and turbulence intensity, we want to
study/search the possibility of a universal design that will provide least
resistance/near-optimal design across all operating conditions (operating
velocity) and environmental conditions (turbulence intensity). Early result
demonstrated that the optimal design found at low velocity and low turbulence
condition performs very poor at high velocity and high turbulence conditions.
However, a design that is optimal at high velocity and high turbulence
conditions performs near-optimal across many considered velocity and turbulence
conditions."
A Socially Assistive Robot using Automated Planning in a Paediatric Clinical Setting,0.245642,"We present an ongoing project that aims to develop a social robot to help
children cope with painful and distressing medical procedures in a clinical
setting. Our approach uses automated planning as a core component for action
selection in order to generate plans that include physical, sensory, and social
actions for the robot to use when interacting with humans. A key capability of
our system is that the robot's behaviour adapts based on the affective state of
the child patient. The robot must operate in a challenging physical and social
environment where appropriate and safe interaction with children,
parents/caregivers, and healthcare professionals is crucial. In this paper, we
present our system, examine some of the key challenges of the scenario, and
describe how they are addressed by our system."
All You May Need for VQA are Image Captions,0.69657,"Visual Question Answering (VQA) has benefited from increasingly sophisticated
models, but has not enjoyed the same level of engagement in terms of data
creation. In this paper, we propose a method that automatically derives VQA
examples at volume, by leveraging the abundance of existing image-caption
annotations combined with neural models for textual question generation. We
show that the resulting data is of high-quality. VQA models trained on our data
improve state-of-the-art zero-shot accuracy by double digits and achieve a
level of robustness that lacks in the same model trained on human-annotated VQA
data."
NICO++: Towards Better Benchmarking for Domain Generalization,0.941617,"Despite the remarkable performance that modern deep neural networks have
achieved on independent and identically distributed (I.I.D.) data, they can
crash under distribution shifts. Most current evaluation methods for domain
generalization (DG) adopt the leave-one-out strategy as a compromise on the
limited number of domains. We propose a large-scale benchmark with extensive
labeled domains named NICO++ along with more rational evaluation methods for
comprehensively evaluating DG algorithms. To evaluate DG datasets, we propose
two metrics to quantify covariate shift and concept shift, respectively. Two
novel generalization bounds from the perspective of data construction are
proposed to prove that limited concept shift and significant covariate shift
favor the evaluation capability for generalization. Through extensive
experiments, NICO++ shows its superior evaluation capability compared with
current DG datasets and its contribution in alleviating unfairness caused by
the leak of oracle knowledge in model selection."
Improving Complex Knowledge Base Question Answering via Question-to-Action and Question-to-Question Alignment,0.0857353,"Complex knowledge base question answering can be achieved by converting
questions into sequences of predefined actions. However, there is a significant
semantic and structural gap between natural language and action sequences,
which makes this conversion difficult. In this paper, we introduce an
alignment-enhanced complex question answering framework, called ALCQA, which
mitigates this gap through question-to-action alignment and
question-to-question alignment. We train a question rewriting model to align
the question and each action, and utilize a pretrained language model to
implicitly align the question and KG artifacts. Moreover, considering that
similar questions correspond to similar action sequences, we retrieve top-k
similar question-answer pairs at the inference stage through
question-to-question alignment and propose a novel reward-guided action
sequence selection strategy to select from candidate action sequences. We
conduct experiments on CQA and WQSP datasets, and the results show that our
approach outperforms state-of-the-art methods and obtains a 9.88\% improvements
in the F1 metric on CQA dataset. Our source code is available at
https://github.com/TTTTTTTTy/ALCQA."
Learning Appearance-motion Normality for Video Anomaly Detection,0.849839,"Video anomaly detection is a challenging task in the computer vision
community. Most single task-based methods do not consider the independence of
unique spatial and temporal patterns, while two-stream structures lack the
exploration of the correlations. In this paper, we propose spatial-temporal
memories augmented two-stream auto-encoder framework, which learns the
appearance normality and motion normality independently and explores the
correlations via adversarial learning. Specifically, we first design two proxy
tasks to train the two-stream structure to extract appearance and motion
features in isolation. Then, the prototypical features are recorded in the
corresponding spatial and temporal memory pools. Finally, the encoding-decoding
network performs adversarial learning with the discriminator to explore the
correlations between spatial and temporal patterns. Experimental results show
that our framework outperforms the state-of-the-art methods, achieving AUCs of
98.1% and 89.8% on UCSD Ped2 and CUHK Avenue datasets."
Hierarchical Phrase-based Sequence-to-Sequence Learning,0.675982,"We describe a neural transducer that maintains the flexibility of standard
sequence-to-sequence (seq2seq) models while incorporating hierarchical phrases
as a source of inductive bias during training and as explicit constraints
during inference. Our approach trains two models: a discriminative parser based
on a bracketing transduction grammar whose derivation tree hierarchically
aligns source and target phrases, and a neural seq2seq model that learns to
translate the aligned phrases one-by-one. We use the same seq2seq model to
translate at all phrase scales, which results in two inference modes: one mode
in which the parser is discarded and only the seq2seq component is used at the
sequence-level, and another in which the parser is combined with the seq2seq
model. Decoding in the latter mode is done with the cube-pruned CKY algorithm,
which is more involved but can make use of new translation rules during
inference. We formalize our model as a source-conditioned synchronous grammar
and develop an efficient variational inference algorithm for training. When
applied on top of both randomly initialized and pretrained seq2seq models, we
find that both inference modes performs well compared to baselines on small
scale machine translation benchmarks."
Test Time Adaptation for Blind Image Quality Assessment,0.86683,"While the design of blind image quality assessment (IQA) algorithms has
improved significantly, the distribution shift between the training and testing
scenarios often leads to a poor performance of these methods at inference time.
This motivates the study of test time adaptation (TTA) techniques to improve
their performance at inference time. Existing auxiliary tasks and loss
functions used for TTA may not be relevant for quality-aware adaptation of the
pre-trained model. In this work, we introduce two novel quality-relevant
auxiliary tasks at the batch and sample levels to enable TTA for blind IQA. In
particular, we introduce a group contrastive loss at the batch level and a
relative rank loss at the sample level to make the model quality aware and
adapt to the target data. Our experiments reveal that even using a small batch
of images from the test distribution helps achieve significant improvement in
performance by updating the batch normalization statistics of the source model."
Memory-Driven Text-to-Image Generation,0.906372,"We introduce a memory-driven semi-parametric approach to text-to-image
generation, which is based on both parametric and non-parametric techniques.
The non-parametric component is a memory bank of image features constructed
from a training set of images. The parametric component is a generative
adversarial network. Given a new text description at inference time, the memory
bank is used to selectively retrieve image features that are provided as basic
information of target images, which enables the generator to produce realistic
synthetic results. We also incorporate the content information into the
discriminator, together with semantic features, allowing the discriminator to
make a more reliable prediction. Experimental results demonstrate that the
proposed memory-driven semi-parametric approach produces more realistic images
than purely parametric approaches, in terms of both visual fidelity and
text-image semantic consistency."
Improving Object-centric Learning with Query Optimization,0.574453,"The ability to decompose complex natural scenes into meaningful
object-centric abstractions lies at the core of human perception and reasoning.
In the recent culmination of unsupervised object-centric learning, the
Slot-Attention module has played an important role with its simple yet
effective design and fostered many powerful variants. These methods, however,
have been exceedingly difficult to train without supervision and are ambiguous
in the notion of object, especially for complex natural scenes. In this paper,
we propose to address these issues by investigating the potential of learnable
queries as initializations for Slot-Attention learning, uniting it with efforts
from existing attempts on improving Slot-Attention learning with bi-level
optimization. With simple code adjustments on Slot-Attention, our model,
Bi-level Optimized Query Slot Attention, achieves state-of-the-art results on 3
challenging synthetic and 7 complex real-world datasets in unsupervised image
segmentation and reconstruction, outperforming previous baselines by a large
margin. We provide thorough ablative studies to validate the necessity and
effectiveness of our design. Additionally, our model exhibits great potential
for concept binding and zero-shot learning. Our work is made publicly available
at https://bo-qsa.github.io"
Watts: Infrastructure for Open-Ended Learning,0.0450352,"This paper proposes a framework called Watts for implementing, comparing, and
recombining open-ended learning (OEL) algorithms. Motivated by modularity and
algorithmic flexibility, Watts atomizes the components of OEL systems to
promote the study of and direct comparisons between approaches. Examining
implementations of three OEL algorithms, the paper introduces the modules of
the framework. The hope is for Watts to enable benchmarking and to explore new
types of OEL algorithms. The repo is available at
\url{https://github.com/aadharna/watts}"
Momentum-Based Policy Gradient with Second-Order Information,0.461418,"Variance-reduced gradient estimators for policy gradient methods have been
one of the main focus of research in the reinforcement learning in recent years
as they allow acceleration of the estimation process. We propose a
variance-reduced policy-gradient method, called SHARP, which incorporates
second-order information into stochastic gradient descent (SGD) using momentum
with a time-varying learning rate. SHARP algorithm is parameter-free, achieving
$\epsilon$-approximate first-order stationary point with $O(\epsilon^{-3})$
number of trajectories, while using a batch size of $O(1)$ at each iteration.
Unlike most previous work, our proposed algorithm does not require importance
sampling which can compromise the advantage of variance reduction process.
Moreover, the variance of estimation error decays with the fast rate of
$O(1/t^{2/3})$ where $t$ is the number of iterations. Our extensive
experimental evaluations show the effectiveness of the proposed algorithm on
various control tasks and its advantage over the state of the art in practice."
Under-Approximating Expected Total Rewards in POMDPs,0.524159,"We consider the problem: is the optimal expected total reward to reach a goal
state in a partially observable Markov decision process (POMDP) below a given
threshold? We tackle this -- generally undecidable -- problem by computing
under-approximations on these total expected rewards. This is done by
abstracting finite unfoldings of the infinite belief MDP of the POMDP. The key
issue is to find a suitable under-approximation of the value function. We
provide two techniques: a simple (cut-off) technique that uses a good policy on
the POMDP, and a more advanced technique (belief clipping) that uses minimal
shifts of probabilities between beliefs. We use mixed-integer linear
programming (MILP) to find such minimal probability shifts and experimentally
show that our techniques scale quite well while providing tight lower bounds on
the expected total reward."
InstantBooth: Personalized Text-to-Image Generation without Test-Time Finetuning,0.979533,"Recent advances in personalized image generation allow a pre-trained
text-to-image model to learn a new concept from a set of images. However,
existing personalization approaches usually require heavy test-time finetuning
for each concept, which is time-consuming and difficult to scale. We propose
InstantBooth, a novel approach built upon pre-trained text-to-image models that
enables instant text-guided image personalization without any test-time
finetuning. We achieve this with several major components. First, we learn the
general concept of the input images by converting them to a textual token with
a learnable image encoder. Second, to keep the fine details of the identity, we
learn rich visual feature representation by introducing a few adapter layers to
the pre-trained model. We train our components only on text-image pairs without
using paired images of the same concept. Compared to test-time finetuning-based
methods like DreamBooth and Textual-Inversion, our model can generate
competitive results on unseen concepts concerning language-image alignment,
image fidelity, and identity preservation while being 100 times faster."
BLASER: A Text-Free Speech-to-Speech Translation Evaluation Metric,0.770012,"End-to-End speech-to-speech translation (S2ST) is generally evaluated with
text-based metrics. This means that generated speech has to be automatically
transcribed, making the evaluation dependent on the availability and quality of
automatic speech recognition (ASR) systems. In this paper, we propose a
text-free evaluation metric for end-to-end S2ST, named BLASER, to avoid the
dependency on ASR systems. BLASER leverages a multilingual multimodal encoder
to directly encode the speech segments for source input, translation output and
reference into a shared embedding space and computes a score of the translation
quality that can be used as a proxy to human evaluation. To evaluate our
approach, we construct training and evaluation sets from more than 40k human
annotations covering seven language directions. The best results of BLASER are
achieved by training with supervision from human rating scores. We show that
when evaluated at the sentence level, BLASER correlates significantly better
with human judgment compared to ASR-dependent metrics including ASR-SENTBLEU in
all translation directions and ASR-COMET in five of them. Our analysis shows
combining speech and text as inputs to BLASER does not increase the correlation
with human scores, but best correlations are achieved when using speech, which
motivates the goal of our research. Moreover, we show that using ASR for
references is detrimental for text-based metrics."
Blur Interpolation Transformer for Real-World Motion from Blur,0.789912,"This paper studies the challenging problem of recovering motion from blur,
also known as joint deblurring and interpolation or blur temporal
super-resolution. The challenges are twofold: 1) the current methods still
leave considerable room for improvement in terms of visual quality even on the
synthetic dataset, and 2) poor generalization to real-world data. To this end,
we propose a blur interpolation transformer (BiT) to effectively unravel the
underlying temporal correlation encoded in blur. Based on multi-scale residual
Swin transformer blocks, we introduce dual-end temporal supervision and
temporally symmetric ensembling strategies to generate effective features for
time-varying motion rendering. In addition, we design a hybrid camera system to
collect the first real-world dataset of one-to-many blur-sharp video pairs.
Experimental results show that BiT has a significant gain over the
state-of-the-art methods on the public dataset Adobe240. Besides, the proposed
real-world dataset effectively helps the model generalize well to real blurry
scenarios. Code and data are available at https://github.com/zzh-tech/BiT."
A-OKVQA: A Benchmark for Visual Question Answering using World Knowledge,0.999817,"The Visual Question Answering (VQA) task aspires to provide a meaningful
testbed for the development of AI models that can jointly reason over visual
and natural language inputs. Despite a proliferation of VQA datasets, this goal
is hindered by a set of common limitations. These include a reliance on
relatively simplistic questions that are repetitive in both concepts and
linguistic structure, little world knowledge needed outside of the paired
image, and limited reasoning required to arrive at the correct answer. We
introduce A-OKVQA, a crowdsourced dataset composed of a diverse set of about
25K questions requiring a broad base of commonsense and world knowledge to
answer. In contrast to the existing knowledge-based VQA datasets, the questions
generally cannot be answered by simply querying a knowledge base, and instead
require some form of commonsense reasoning about the scene depicted in the
image. We demonstrate the potential of this new dataset through a detailed
analysis of its contents and baseline performance measurements over a variety
of state-of-the-art vision-language models. Project page:
http://a-okvqa.allenai.org/"
JamPatoisNLI: A Jamaican Patois Natural Language Inference Dataset,0.568936,"JamPatoisNLI provides the first dataset for natural language inference in a
creole language, Jamaican Patois. Many of the most-spoken low-resource
languages are creoles. These languages commonly have a lexicon derived from a
major world language and a distinctive grammar reflecting the languages of the
original speakers and the process of language birth by creolization. This gives
them a distinctive place in exploring the effectiveness of transfer from large
monolingual or multilingual pretrained models. While our work, along with
previous work, shows that transfer from these models to low-resource languages
that are unrelated to languages in their training set is not very effective, we
would expect stronger results from transfer to creoles. Indeed, our experiments
show considerably better results from few-shot learning of JamPatoisNLI than
for such unrelated languages, and help us begin to understand how the unique
relationship between creoles and their high-resource base languages affect
cross-lingual transfer. JamPatoisNLI, which consists of naturally-occurring
premises and expert-written hypotheses, is a step towards steering research
into a traditionally underserved language and a useful benchmark for
understanding cross-lingual NLP."
SPIN: An Empirical Evaluation on Sharing Parameters of Isotropic Networks,0.0666767,"Recent isotropic networks, such as ConvMixer and vision transformers, have
found significant success across visual recognition tasks, matching or
outperforming non-isotropic convolutional neural networks (CNNs). Isotropic
architectures are particularly well-suited to cross-layer weight sharing, an
effective neural network compression technique. In this paper, we perform an
empirical evaluation on methods for sharing parameters in isotropic networks
(SPIN). We present a framework to formalize major weight sharing design
decisions and perform a comprehensive empirical evaluation of this design
space. Guided by our experimental results, we propose a weight sharing strategy
to generate a family of models with better overall efficiency, in terms of
FLOPs and parameters versus accuracy, compared to traditional scaling methods
alone, for example compressing ConvMixer by 1.9x while improving accuracy on
ImageNet. Finally, we perform a qualitative study to further understand the
behavior of weight sharing in isotropic architectures. The code is available at
https://github.com/apple/ml-spin."
Effective Image Tampering Localization with Multi-Scale ConvNeXt Feature Fusion,0.431287,"With the widespread use of powerful image editing tools, image tampering
becomes easy and realistic. Existing image forensic methods still face
challenges of low generalization performance and robustness. In this letter, we
propose an effective image tampering localization scheme based on ConvNeXt
network and multi-scale feature fusion. Stacked ConvNeXt blocks are used as an
encoder to capture hierarchical multi-scale features, which are then fused in
decoder for locating tampered pixels accurately. Combined loss and effective
data augmentation are adopted to further improve the model performance.
Extensive experimental results show that localization performance of our
proposed scheme outperforms other state-of-the-art ones. The source code will
be available at https://github.com/ZhuHC98/ITL-SSN."
Semi-supervised Hand Appearance Recovery via Structure Disentanglement and Dual Adversarial Discrimination,0.621822,"Enormous hand images with reliable annotations are collected through
marker-based MoCap. Unfortunately, degradations caused by markers limit their
application in hand appearance reconstruction. A clear appearance recovery
insight is an image-to-image translation trained with unpaired data. However,
most frameworks fail because there exists structure inconsistency from a
degraded hand to a bare one. The core of our approach is to first disentangle
the bare hand structure from those degraded images and then wrap the appearance
to this structure with a dual adversarial discrimination (DAD) scheme. Both
modules take full advantage of the semi-supervised learning paradigm: The
structure disentanglement benefits from the modeling ability of ViT, and the
translator is enhanced by the dual discrimination on both translation processes
and translation results. Comprehensive evaluations have been conducted to prove
that our framework can robustly recover photo-realistic hand appearance from
diverse marker-contained and even object-occluded datasets. It provides a novel
avenue to acquire bare hand appearance data for other downstream learning
problems.The codes will be publicly available at https://www.yangangwang.com"
Better Diffusion Models Further Improve Adversarial Training,0.999596,"It has been recognized that the data generated by the denoising diffusion
probabilistic model (DDPM) improves adversarial training. After two years of
rapid development in diffusion models, a question naturally arises: can better
diffusion models further improve adversarial training? This paper gives an
affirmative answer by employing the most recent diffusion model which has
higher efficiency ($\sim 20$ sampling steps) and image quality (lower FID
score) compared with DDPM. Our adversarially trained models achieve
state-of-the-art performance on RobustBench using only generated data (no
external datasets). Under the $\ell_\infty$-norm threat model with
$\epsilon=8/255$, our models achieve $70.69\%$ and $42.67\%$ robust accuracy on
CIFAR-10 and CIFAR-100, respectively, i.e. improving upon previous
state-of-the-art models by $+4.58\%$ and $+8.03\%$. Under the $\ell_2$-norm
threat model with $\epsilon=128/255$, our models achieve $84.86\%$ on CIFAR-10
($+4.44\%$). These results also beat previous works that use external data. We
also provide compelling results on the SVHN and TinyImageNet datasets. Our code
is available at https://github.com/wzekai99/DM-Improves-AT."
Efficient Black-Box Adversarial Attacks on Neural Text Detectors,0.220714,"Neural text detectors are models trained to detect whether a given text was
generated by a language model or written by a human. In this paper, we
investigate three simple and resource-efficient strategies (parameter tweaking,
prompt engineering, and character-level mutations) to alter texts generated by
GPT-3.5 that are unsuspicious or unnoticeable for humans but cause
misclassification by neural text detectors. The results show that especially
parameter tweaking and character-level mutations are effective strategies."
PERGAMO: Personalized 3D Garments from Monocular Video,0.756493,"Clothing plays a fundamental role in digital humans. Current approaches to
animate 3D garments are mostly based on realistic physics simulation, however,
they typically suffer from two main issues: high computational run-time cost,
which hinders their development; and simulation-to-real gap, which impedes the
synthesis of specific real-world cloth samples. To circumvent both issues we
propose PERGAMO, a data-driven approach to learn a deformable model for 3D
garments from monocular images. To this end, we first introduce a novel method
to reconstruct the 3D geometry of garments from a single image, and use it to
build a dataset of clothing from monocular videos. We use these 3D
reconstructions to train a regression model that accurately predicts how the
garment deforms as a function of the underlying body pose. We show that our
method is capable of producing garment animations that match the real-world
behaviour, and generalizes to unseen body motions extracted from motion capture
dataset."
Scaling-up Generalized Planning as Heuristic Search with Landmarks,0.288773,"Landmarks are one of the most effective search heuristics for classical
planning, but largely ignored in generalized planning. Generalized planning
(GP) is usually addressed as a combinatorial search in a given space of
algorithmic solutions, where candidate solutions are evaluated w.r.t.~the
instances they solve. This type of solution evaluation ignores any sub-goal
information that is not explicit in the representation of the planning
instances, causing plateaus in the space of candidate generalized plans.
Furthermore, node expansion in GP is a run-time bottleneck since it requires
evaluating every child node over the entire batch of classical planning
instances in a GP problem. In this paper we define a landmark counting
heuristic for GP (that considers sub-goal information that is not explicitly
represented in the planning instances), and a novel heuristic search algorithm
for GP (that we call PGP) and that progressively processes subsets of the
planning instances of a GP problem. Our two orthogonal contributions are
analyzed in an ablation study, showing that both improve the state-of-the-art
in GP as heuristic search, and that both benefit from each other when used in
combination."
BSRT: Improving Burst Super-Resolution with Swin Transformer and Flow-Guided Deformable Alignment,0.731738,"This work addresses the Burst Super-Resolution (BurstSR) task using a new
architecture, which requires restoring a high-quality image from a sequence of
noisy, misaligned, and low-resolution RAW bursts. To overcome the challenges in
BurstSR, we propose a Burst Super-Resolution Transformer (BSRT), which can
significantly improve the capability of extracting inter-frame information and
reconstruction. To achieve this goal, we propose a Pyramid Flow-Guided
Deformable Convolution Network (Pyramid FG-DCN) and incorporate Swin
Transformer Blocks and Groups as our main backbone. More specifically, we
combine optical flows and deformable convolutions, hence our BSRT can handle
misalignment and aggregate the potential texture information in multi-frames
more efficiently. In addition, our Transformer-based structure can capture
long-range dependency to further improve the performance. The evaluation on
both synthetic and real-world tracks demonstrates that our approach achieves a
new state-of-the-art in BurstSR task. Further, our BSRT wins the championship
in the NTIRE2022 Burst Super-Resolution Challenge."
Z-Code++: A Pre-trained Language Model Optimized for Abstractive Summarization,0.875828,"This paper presents Z-Code++, a new pre-trained language model optimized for
abstractive text summarization. The model extends the state of the art
encoder-decoder model using three techniques. First, we use a two-phase
pre-training process to improve model's performance on low-resource
summarization tasks. The model is first pre-trained using text corpora for
language understanding, and then is continually pre-trained on summarization
corpora for grounded text generation. Second, we replace self-attention layers
in the encoder with disentangled attention layers, where each word is
represented using two vectors that encode its content and position,
respectively. Third, we use fusion-in-encoder, a simple yet effective method of
encoding long sequences in a hierarchical manner. Z-Code++ creates new state of
the art on 9 out of 13 text summarization tasks across 5 languages. Our model
is parameter-efficient in that it outperforms the 600x larger PaLM-540B on
XSum, and the finetuned 200x larger GPT3-175B on SAMSum. In zero-shot and
few-shot settings, our model substantially outperforms the competing models."
Mark My Words: Dangers of Watermarked Images in ImageNet,0.0686769,"The utilization of pre-trained networks, especially those trained on
ImageNet, has become a common practice in Computer Vision. However, prior
research has indicated that a significant number of images in the ImageNet
dataset contain watermarks, making pre-trained networks susceptible to learning
artifacts such as watermark patterns within their latent spaces. In this paper,
we aim to assess the extent to which popular pre-trained architectures display
such behavior and to determine which classes are most affected. Additionally,
we examine the impact of watermarks on the extracted features. Contrary to the
popular belief that the Chinese logographic watermarks impact the ""carton""
class only, our analysis reveals that a variety of ImageNet classes, such as
""monitor"", ""broom"", ""apron"" and ""safe"" rely on spurious correlations. Finally,
we propose a simple approach to mitigate this issue in fine-tuned networks by
ignoring the encodings from the feature-extractor layer of ImageNet pre-trained
networks that are most susceptible to watermark imprints."
"Can Foundation Models Watch, Talk and Guide You Step by Step to Make a Cake?",0.163669,"Despite tremendous advances in AI, it remains a significant challenge to
develop interactive task guidance systems that can offer situated, personalized
guidance and assist humans in various tasks. These systems need to have a
sophisticated understanding of the user as well as the environment, and make
timely accurate decisions on when and what to say. To address this issue, we
created a new multimodal benchmark dataset, Watch, Talk and Guide (WTaG) based
on natural interaction between a human user and a human instructor. We further
proposed two tasks: User and Environment Understanding, and Instructor Decision
Making. We leveraged several foundation models to study to what extent these
models can be quickly adapted to perceptually enabled task guidance. Our
quantitative, qualitative, and human evaluation results show that these models
can demonstrate fair performances in some cases with no task-specific training,
but a fast and reliable adaptation remains a significant challenge. Our
benchmark and baselines will provide a stepping stone for future work on
situated task guidance."
Sentiment Perception Adversarial Attacks on Neural Machine Translation Systems,0.14858,"With the advent of deep learning methods, Neural Machine Translation (NMT)
systems have become increasingly powerful. However, deep learning based systems
are susceptible to adversarial attacks, where imperceptible changes to the
input can cause undesirable changes at the output of the system. To date there
has been little work investigating adversarial attacks on sequence-to-sequence
systems, such as NMT models. Previous work in NMT has examined attacks with the
aim of introducing target phrases in the output sequence. In this work,
adversarial attacks for NMT systems are explored from an output perception
perspective. Thus the aim of an attack is to change the perception of the
output sequence, without altering the perception of the input sequence. For
example, an adversary may distort the sentiment of translated reviews to have
an exaggerated positive sentiment. In practice it is challenging to run
extensive human perception experiments, so a proxy deep-learning classifier
applied to the NMT output is used to measure perception changes. Experiments
demonstrate that the sentiment perception of NMT systems' output sequences can
be changed significantly with small imperceptible changes to input sequences."
A Simple and Powerful Global Optimization for Unsupervised Video Object Segmentation,0.760263,"We propose a simple, yet powerful approach for unsupervised object
segmentation in videos. We introduce an objective function whose minimum
represents the mask of the main salient object over the input sequence. It only
relies on independent image features and optical flows, which can be obtained
using off-the-shelf self-supervised methods. It scales with the length of the
sequence with no need for superpixels or sparsification, and it generalizes to
different datasets without any specific training. This objective function can
actually be derived from a form of spectral clustering applied to the entire
video. Our method achieves on-par performance with the state of the art on
standard benchmarks (DAVIS2016, SegTrack-v2, FBMS59), while being conceptually
and practically much simpler. Code is available at
https://ponimatkin.github.io/ssl-vos."
Offline Reinforcement Learning with Differential Privacy,0.571326,"The offline reinforcement learning (RL) problem is often motivated by the
need to learn data-driven decision policies in financial, legal and healthcare
applications. However, the learned policy could retain sensitive information of
individuals in the training data (e.g., treatment and outcome of patients),
thus susceptible to various privacy risks. We design offline RL algorithms with
differential privacy guarantees which provably prevent such risks. These
algorithms also enjoy strong instance-dependent learning bounds under both
tabular and linear Markov decision process (MDP) settings. Our theory and
simulation suggest that the privacy guarantee comes at (almost) no drop in
utility comparing to the non-private counterpart for a medium-size dataset."
CommunityLM: Probing Partisan Worldviews from Language Models,0.321067,"As political attitudes have diverged ideologically in the United States,
political speech has diverged lingusitically. The ever-widening polarization
between the US political parties is accelerated by an erosion of mutual
understanding between them. We aim to make these communities more
comprehensible to each other with a framework that probes community-specific
responses to the same survey questions using community language models
CommunityLM. In our framework we identify committed partisan members for each
community on Twitter and fine-tune LMs on the tweets authored by them. We then
assess the worldviews of the two groups using prompt-based probing of their
corresponding LMs, with prompts that elicit opinions about public figures and
groups surveyed by the American National Election Studies (ANES) 2020
Exploratory Testing Survey. We compare the responses generated by the LMs to
the ANES survey results, and find a level of alignment that greatly exceeds
several baseline methods. Our work aims to show that we can use community LMs
to query the worldview of any group of people given a sufficiently large sample
of their social media discussions or media diet."
Zero-Shot Scene Graph Generation via Triplet Calibration and Reduction,0.0780837,"Scene Graph Generation (SGG) plays a pivotal role in downstream
vision-language tasks. Existing SGG methods typically suffer from poor
compositional generalizations on unseen triplets. They are generally trained on
incompletely annotated scene graphs that contain dominant triplets and tend to
bias toward these seen triplets during inference. To address this issue, we
propose a Triplet Calibration and Reduction (T-CAR) framework in this paper. In
our framework, a triplet calibration loss is first presented to regularize the
representations of diverse triplets and to simultaneously excavate the unseen
triplets in incompletely annotated training scene graphs. Moreover, the unseen
space of scene graphs is usually several times larger than the seen space since
it contains a huge number of unrealistic compositions. Thus, we propose an
unseen space reduction loss to shift the attention of excavation to reasonable
unseen compositions to facilitate the model training. Finally, we propose a
contextual encoder to improve the compositional generalizations of unseen
triplets by explicitly modeling the relative spatial relations between subjects
and objects. Extensive experiments show that our approach achieves consistent
improvements for zero-shot SGG over state-of-the-art methods. The code is
available at https://github.com/jkli1998/T-CAR."
Parametric Information Maximization for Generalized Category Discovery,0.416616,"We introduce a Parametric Information Maximization (PIM) model for the
Generalized Category Discovery (GCD) problem. Specifically, we propose a
bi-level optimization formulation, which explores a parameterized family of
objective functions, each evaluating a weighted mutual information between the
features and the latent labels, subject to supervision constraints from the
labeled samples. Our formulation mitigates the class-balance bias encoded in
standard information maximization approaches, thereby handling effectively both
short-tailed and long-tailed data sets. We report extensive experiments and
comparisons demonstrating that our PIM model consistently sets new
state-of-the-art performances in GCD across six different datasets, more so
when dealing with challenging fine-grained problems."
RepMix: Representation Mixing for Robust Attribution of Synthesized Images,0.779171,"Rapid advances in Generative Adversarial Networks (GANs) raise new challenges
for image attribution; detecting whether an image is synthetic and, if so,
determining which GAN architecture created it. Uniquely, we present a solution
to this task capable of 1) matching images invariant to their semantic content;
2) robust to benign transformations (changes in quality, resolution, shape,
etc.) commonly encountered as images are re-shared online. In order to
formalize our research, a challenging benchmark, Attribution88, is collected
for robust and practical image attribution. We then propose RepMix, our GAN
fingerprinting technique based on representation mixing and a novel loss. We
validate its capability of tracing the provenance of GAN-generated images
invariant to the semantic content of the image and also robust to
perturbations. We show our approach improves significantly from existing GAN
fingerprinting works on both semantic generalization and robustness. Data and
code are available at https://github.com/TuBui/image_attribution."
Digital Twin Applications in Urban Logistics: An Overview,0.650761,"Urban traffic attributed to commercial and industrial transportation is
observed to largely affect living standards in cities due to external effects
pertaining to pollution and congestion. In order to counter this, smart cities
deploy technological tools to achieve sustainability. Such tools include
Digital Twins (DT)s which are virtual replicas of real-life physical systems.
Research suggests that DTs can be very beneficial in how they control a
physical system by constantly optimizing its performance. The concept has been
extensively studied in other technology-driven industries like manufacturing.
However, little work has been done with regards to their application in urban
logistics. In this paper, we seek to provide a framework by which DTs could be
easily adapted to urban logistics networks. To do this, we provide a
characterization of key factors in urban logistics for dynamic decision-making.
We also survey previous research on DT applications in urban logistics as we
found that a holistic overview is lacking. Using this knowledge in combination
with the characterization, we produce a conceptual model that describes the
ontology, learning capabilities and optimization prowess of an urban logistics
digital twin through its quantitative models. We finish off with a discussion
on potential research benefits and limitations based on previous research and
our practical experience."
Graph Neural Networks: a bibliometrics overview,0.31101,"Recently, graph neural networks have become a hot topic in machine learning
community. This paper presents a Scopus based bibliometric overview of the GNNs
research since 2004, when GNN papers were first published. The study aims to
evaluate GNN research trend, both quantitatively and qualitatively. We provide
the trend of research, distribution of subjects, active and influential authors
and institutions, sources of publications, most cited documents, and hot
topics. Our investigations reveal that the most frequent subject categories in
this field are computer science, engineering, telecommunications, linguistics,
operations research and management science, information science and library
science, business and economics, automation and control systems, robotics, and
social sciences. In addition, the most active source of GNN publications is
Lecture Notes in Computer Science. The most prolific or impactful institutions
are found in the United States, China, and Canada. We also provide must read
papers and future directions. Finally, the application of graph convolutional
networks and attention mechanism are now among hot topics of GNN research."
An Efficient Approximate Method for Online Convolutional Dictionary Learning,0.0655538,"Most existing convolutional dictionary learning (CDL) algorithms are based on
batch learning, where the dictionary filters and the convolutional sparse
representations are optimized in an alternating manner using a training
dataset. When large training datasets are used, batch CDL algorithms become
prohibitively memory-intensive. An online-learning technique is used to reduce
the memory requirements of CDL by optimizing the dictionary incrementally after
finding the sparse representations of each training sample. Nevertheless,
learning large dictionaries using the existing online CDL (OCDL) algorithms
remains highly computationally expensive. In this paper, we present a novel
approximate OCDL method that incorporates sparse decomposition of the training
samples. The resulting optimization problems are addressed using the
alternating direction method of multipliers. Extensive experimental evaluations
using several image datasets show that the proposed method substantially
reduces computational costs while preserving the effectiveness of the
state-of-the-art OCDL algorithms."
LEXTREME: A Multi-Lingual and Multi-Task Benchmark for the Legal Domain,0.599472,"Lately, propelled by the phenomenal advances around the transformer
architecture, the legal NLP field has enjoyed spectacular growth. To measure
progress, well curated and challenging benchmarks are crucial. However, most
benchmarks are English only and in legal NLP specifically there is no
multilingual benchmark available yet. Additionally, many benchmarks are
saturated, with the best models clearly outperforming the best humans and
achieving near perfect scores. We survey the legal NLP literature and select 11
datasets covering 24 languages, creating LEXTREME. To provide a fair
comparison, we propose two aggregate scores, one based on the datasets and one
on the languages. The best baseline (XLM-R large) achieves both a dataset
aggregate score a language aggregate score of 61.3. This indicates that
LEXTREME is still very challenging and leaves ample room for improvement. To
make it easy for researchers and practitioners to use, we release LEXTREME on
huggingface together with all the code required to evaluate models and a public
Weights and Biases project with all the runs."
An Understanding-Oriented Robust Machine Reading Comprehension Model,0.371395,"Although existing machine reading comprehension models are making rapid
progress on many datasets, they are far from robust. In this paper, we propose
an understanding-oriented machine reading comprehension model to address three
kinds of robustness issues, which are over sensitivity, over stability and
generalization. Specifically, we first use a natural language inference module
to help the model understand the accurate semantic meanings of input questions
so as to address the issues of over sensitivity and over stability. Then in the
machine reading comprehension module, we propose a memory-guided multi-head
attention method that can further well understand the semantic meanings of
input questions and passages. Third, we propose a multilanguage learning
mechanism to address the issue of generalization. Finally, these modules are
integrated with a multi-task learning based method. We evaluate our model on
three benchmark datasets that are designed to measure models robustness,
including DuReader (robust) and two SQuAD-related datasets. Extensive
experiments show that our model can well address the mentioned three kinds of
robustness issues. And it achieves much better results than the compared
state-of-the-art models on all these datasets under different evaluation
metrics, even under some extreme and unfair evaluations. The source code of our
work is available at: https://github.com/neukg/RobustMRC."
An Efficient Self-Supervised Cross-View Training For Sentence Embedding,0.122416,"Self-supervised sentence representation learning is the task of constructing
an embedding space for sentences without relying on human annotation efforts.
One straightforward approach is to finetune a pretrained language model (PLM)
with a representation learning method such as contrastive learning. While this
approach achieves impressive performance on larger PLMs, the performance
rapidly degrades as the number of parameters decreases. In this paper, we
propose a framework called Self-supervised Cross-View Training (SCT) to narrow
the performance gap between large and small PLMs. To evaluate the effectiveness
of SCT, we compare it to 5 baseline and state-of-the-art competitors on seven
Semantic Textual Similarity (STS) benchmarks using 5 PLMs with the number of
parameters ranging from 4M to 340M. The experimental results show that STC
outperforms the competitors for PLMs with less than 100M parameters in 18 of 21
cases."
Jambu: A historical linguistic database for South Asian languages,0.409659,"We introduce Jambu, a cognate database of South Asian languages which unifies
dozens of previous sources in a structured and accessible format. The database
includes 287k lemmata from 602 lects, grouped together in 23k sets of cognates.
We outline the data wrangling necessary to compile the dataset and train neural
models for reflex prediction on the Indo-Aryan subset of the data. We hope that
Jambu is an invaluable resource for all historical linguists and Indologists,
and look towards further improvement and expansion of the database."
Privacy-Preserving Text Classification on BERT Embeddings with Homomorphic Encryption,0.670069,"Embeddings, which compress information in raw text into semantics-preserving
low-dimensional vectors, have been widely adopted for their efficacy. However,
recent research has shown that embeddings can potentially leak private
information about sensitive attributes of the text, and in some cases, can be
inverted to recover the original input text. To address these growing privacy
challenges, we propose a privatization mechanism for embeddings based on
homomorphic encryption, to prevent potential leakage of any piece of
information in the process of text classification. In particular, our method
performs text classification on the encryption of embeddings from
state-of-the-art models like BERT, supported by an efficient GPU implementation
of CKKS encryption scheme. We show that our method offers encrypted protection
of BERT embeddings, while largely preserving their utility on downstream text
classification tasks."
Putting AI Ethics into Practice: The Hourglass Model of Organizational AI Governance,0.543743,"The organizational use of artificial intelligence (AI) has rapidly spread
across various sectors. Alongside the awareness of the benefits brought by AI,
there is a growing consensus on the necessity of tackling the risks and
potential harms, such as bias and discrimination, brought about by advanced AI
technologies. A multitude of AI ethics principles have been proposed to tackle
these risks, but the outlines of organizational processes and practices for
ensuring socially responsible AI development are in a nascent state. To address
the paucity of comprehensive governance models, we present an AI governance
framework, the hourglass model of organizational AI governance, which targets
organizations that develop and use AI systems. The framework is designed to
help organizations deploying AI systems translate ethical AI principles into
practice and align their AI systems and processes with the forthcoming European
AI Act. The hourglass framework includes governance requirements at the
environmental, organizational, and AI system levels. At the AI system level, we
connect governance requirements to AI system life cycles to ensure governance
throughout the system's life span. The governance model highlights the systemic
nature of AI governance and opens new research avenues into its practical
implementation, the mechanisms that connect different AI governance layers, and
the dynamics between the AI governance actors. The model also offers a starting
point for organizational decision-makers to consider the governance components
needed to ensure social acceptability, mitigate risks, and realize the
potential of AI."
Mask-FPAN: Semi-Supervised Face Parsing in the Wild With De-Occlusion and UV GAN,0.565079,"Fine-grained semantic segmentation of a person's face and head, including
facial parts and head components, has progressed a great deal in recent years.
However, it remains a challenging task, whereby considering ambiguous
occlusions and large pose variations are particularly difficult. To overcome
these difficulties, we propose a novel framework termed Mask-FPAN. It uses a
de-occlusion module that learns to parse occluded faces in a semi-supervised
way. In particular, face landmark localization, face occlusionstimations, and
detected head poses are taken into account. A 3D morphable face model combined
with the UV GAN improves the robustness of 2D face parsing. In addition, we
introduce two new datasets named FaceOccMask-HQ and CelebAMaskOcc-HQ for face
paring work. The proposed Mask-FPAN framework addresses the face parsing
problem in the wild and shows significant performance improvements with MIOU
from 0.7353 to 0.9013 compared to the state-of-the-art on challenging face
datasets."
An Empirical Analysis of Recurrent Learning Algorithms In Neural Lossy Image Compression Systems,0.264827,"Recent advances in deep learning have resulted in image compression
algorithms that outperform JPEG and JPEG 2000 on the standard Kodak benchmark.
However, they are slow to train (due to backprop-through-time) and, to the best
of our knowledge, have not been systematically evaluated on a large variety of
datasets. In this paper, we perform the first large-scale comparison of recent
state-of-the-art hybrid neural compression algorithms, while exploring the
effects of alternative training strategies (when applicable). The hybrid
recurrent neural decoder is a former state-of-the-art model (recently overtaken
by a Google model) that can be trained using backprop-through-time (BPTT) or
with alternative algorithms like sparse attentive backtracking (SAB), unbiased
online recurrent optimization (UORO), and real-time recurrent learning (RTRL).
We compare these training alternatives along with the Google models (GOOG and
E2E) on 6 benchmark datasets. Surprisingly, we found that the model trained
with SAB performs better (outperforming even BPTT), resulting in faster
convergence and a better peak signal-to-noise ratio."
Object Discovery from Motion-Guided Tokens,0.212293,"Object discovery -- separating objects from the background without manual
labels -- is a fundamental open challenge in computer vision. Previous methods
struggle to go beyond clustering of low-level cues, whether handcrafted (e.g.,
color, texture) or learned (e.g., from auto-encoders). In this work, we augment
the auto-encoder representation learning framework with two key components:
motion-guidance and mid-level feature tokenization. Although both have been
separately investigated, we introduce a new transformer decoder showing that
their benefits can compound thanks to motion-guided vector quantization. We
show that our architecture effectively leverages the synergy between motion and
tokenization, improving upon the state of the art on both synthetic and real
datasets. Our approach enables the emergence of interpretable object-specific
mid-level features, demonstrating the benefits of motion-guidance (no labeling)
and quantization (interpretability, memory efficiency)."
A9-Dataset: Multi-Sensor Infrastructure-Based Dataset for Mobility Research,0.839921,"Data-intensive machine learning based techniques increasingly play a
prominent role in the development of future mobility solutions - from driver
assistance and automation functions in vehicles, to real-time traffic
management systems realized through dedicated infrastructure. The availability
of high quality real-world data is often an important prerequisite for the
development and reliable deployment of such systems in large scale. Towards
this endeavour, we present the A9-Dataset based on roadside sensor
infrastructure from the 3 km long Providentia++ test field near Munich in
Germany. The dataset includes anonymized and precision-timestamped multi-modal
sensor and object data in high resolution, covering a variety of traffic
situations. As part of the first set of data, which we describe in this paper,
we provide camera and LiDAR frames from two overhead gantry bridges on the A9
autobahn with the corresponding objects labeled with 3D bounding boxes. The
first set includes in total more than 1000 sensor frames and 14000 traffic
objects. The dataset is available for download at https://a9-dataset.com."
Prediction of Football Player Value using Bayesian Ensemble Approach,0.0600162,"The transfer fees of sports players have become astronomical. This is because
bringing players of great future value to the club is essential for their
survival. We present a case study on the key factors affecting the world's top
soccer players' transfer fees based on the FIFA data analysis. To predict each
player's market value, we propose an improved LightGBM model by optimizing its
hyperparameter using a Tree-structured Parzen Estimator (TPE) algorithm. We
identify prominent features by the SHapley Additive exPlanations (SHAP)
algorithm. The proposed method has been compared against the baseline
regression models (e.g., linear regression, lasso, elastic net, kernel ridge
regression) and gradient boosting model without hyperparameter optimization.
The optimized LightGBM model showed an excellent accuracy of approximately 3.8,
1.4, and 1.8 times on average compared to the regression baseline models, GBDT,
and LightGBM model in terms of RMSE. Our model offers interpretability in
deciding what attributes football clubs should consider in recruiting players
in the future."
Learning Cautiously in Federated Learning with Noisy and Heterogeneous Clients,0.174379,"Federated learning (FL) is a distributed framework for collaboratively
training with privacy guarantees. In real-world scenarios, clients may have
Non-IID data (local class imbalance) with poor annotation quality (label
noise). The co-existence of label noise and class imbalance in FL's small local
datasets renders conventional FL methods and noisy-label learning methods both
ineffective. To address the challenges, we propose FedCNI without using an
additional clean proxy dataset. It includes a noise-resilient local solver and
a robust global aggregator. For the local solver, we design a more robust
prototypical noise detector to distinguish noisy samples. Further to reduce the
negative impact brought by the noisy samples, we devise a curriculum pseudo
labeling method and a denoise Mixup training strategy. For the global
aggregator, we propose a switching re-weighted aggregation method tailored to
different learning periods. Extensive experiments demonstrate our method can
substantially outperform state-of-the-art solutions in mix-heterogeneous FL
environments."
Improved Universal Sentence Embeddings with Prompt-based Contrastive Learning and Energy-based Learning,0.64335,"Contrastive learning has been demonstrated to be effective in enhancing
pre-trained language models (PLMs) to derive superior universal sentence
embeddings. However, existing contrastive methods still have two limitations.
Firstly, previous works may acquire poor performance under domain shift
settings, thus hindering the application of sentence representations in
practice. We attribute this low performance to the over-parameterization of
PLMs with millions of parameters. To alleviate it, we propose PromCSE
(Prompt-based Contrastive Learning for Sentence Embeddings), which only trains
small-scale \emph{Soft Prompt} (i.e., a set of trainable vectors) while keeping
PLMs fixed. Secondly, the commonly used NT-Xent loss function of contrastive
learning does not fully exploit hard negatives in supervised learning settings.
To this end, we propose to integrate an Energy-based Hinge loss to enhance the
pairwise discriminative power, inspired by the connection between the NT-Xent
loss and the Energy-based Learning paradigm. Empirical results on seven
standard semantic textual similarity (STS) tasks and a domain-shifted STS task
both show the effectiveness of our method compared with the current
state-of-the-art sentence embedding models. Our code is publicly avaliable at
https://github.com/YJiangcm/PromCSE"
Measuring axiomatic soundness of counterfactual image models,0.907701,"We present a general framework for evaluating image counterfactuals. The
power and flexibility of deep generative models make them valuable tools for
learning mechanisms in structural causal models. However, their flexibility
makes counterfactual identifiability impossible in the general case. Motivated
by these issues, we revisit Pearl's axiomatic definition of counterfactuals to
determine the necessary constraints of any counterfactual inference model:
composition, reversibility, and effectiveness. We frame counterfactuals as
functions of an input variable, its parents, and counterfactual parents and use
the axiomatic constraints to restrict the set of functions that could represent
the counterfactual, thus deriving distance metrics between the approximate and
ideal functions. We demonstrate how these metrics can be used to compare and
choose between different approximate counterfactual inference models and to
provide insight into a model's shortcomings and trade-offs."
Semi-supervised New Event Type Induction and Description via Contrastive Loss-Enforced Batch Attention,0.575568,"Most event extraction methods have traditionally relied on an annotated set
of event types. However, creating event ontologies and annotating supervised
training data are expensive and time-consuming. Previous work has proposed
semi-supervised approaches which leverage seen (annotated) types to learn how
to automatically discover new event types. State-of-the-art methods, both
semi-supervised or fully unsupervised, use a form of reconstruction loss on
specific tokens in a context. In contrast, we present a novel approach to
semi-supervised new event type induction using a masked contrastive loss, which
learns similarities between event mentions by enforcing an attention mechanism
over the data minibatch. We further disentangle the discovered clusters by
approximating the underlying manifolds in the data, which allows us to increase
normalized mutual information and Fowlkes-Mallows scores by over 20% absolute.
Building on these clustering results, we extend our approach to two new tasks:
predicting the type name of the discovered clusters and linking them to
FrameNet frames."
Detecting Label Errors by using Pre-Trained Language Models,0.409172,"We show that large pre-trained language models are inherently highly capable
of identifying label errors in natural language datasets: simply examining
out-of-sample data points in descending order of fine-tuned task loss
significantly outperforms more complex error-detection mechanisms proposed in
previous work.
  To this end, we contribute a novel method for introducing realistic,
human-originated label noise into existing crowdsourced datasets such as SNLI
and TweetNLP. We show that this noise has similar properties to real,
hand-verified label errors, and is harder to detect than existing synthetic
noise, creating challenges for model robustness. We argue that human-originated
noise is a better standard for evaluation than synthetic noise.
  Finally, we use crowdsourced verification to evaluate the detection of real
errors on IMDB, Amazon Reviews, and Recon, and confirm that pre-trained models
perform at a 9-36% higher absolute Area Under the Precision-Recall Curve than
existing models."
Optimizing text representations to capture (dis)similarity between political parties,0.134655,"Even though fine-tuned neural language models have been pivotal in enabling
""deep"" automatic text analysis, optimizing text representations for specific
applications remains a crucial bottleneck. In this study, we look at this
problem in the context of a task from computational social science, namely
modeling pairwise similarities between political parties. Our research question
is what level of structural information is necessary to create robust text
representation, contrasting a strongly informed approach (which uses both claim
span and claim category annotations) with approaches that forgo one or both
types of annotation with document structure-based heuristics. Evaluating our
models on the manifestos of German parties for the 2021 federal election. We
find that heuristics that maximize within-party over between-party similarity
along with a normalization step lead to reliable party similarity prediction,
without the need for manual annotation."
Similarity search on neighbor's graphs with automatic Pareto optimal performance and minimum expected quality setups based on hyperparameter optimization,0.312711,"This manuscript introduces an autotuned algorithm for searching nearest
neighbors based on neighbor graphs and optimization metaheuristics to produce
Pareto-optimal searches for quality and search speed automatically; the same
strategy is also used to produce indexes that achieve a minimum quality. Our
approach is described and benchmarked with other state-of-the-art similarity
search methods, showing convenience and competitiveness."
Bio-inspired Min-Nets Improve the Performance and Robustness of Deep Networks,0.387023,"Min-Nets are inspired by end-stopped cortical cells with units that output
the minimum of two learned filters. We insert such Min-units into
state-of-the-art deep networks, such as the popular ResNet and DenseNet, and
show that the resulting Min-Nets perform better on the Cifar-10 benchmark.
Moreover, we show that Min-Nets are more robust against JPEG compression
artifacts. We argue that the minimum operation is the simplest way of
implementing an AND operation on pairs of filters and that such AND operations
introduce a bias that is appropriate given the statistics of natural images."
Improving the Adversarial Robustness of NLP Models by Information Bottleneck,0.679301,"Existing studies have demonstrated that adversarial examples can be directly
attributed to the presence of non-robust features, which are highly predictive,
but can be easily manipulated by adversaries to fool NLP models. In this study,
we explore the feasibility of capturing task-specific robust features, while
eliminating the non-robust ones by using the information bottleneck theory.
Through extensive experiments, we show that the models trained with our
information bottleneck-based method are able to achieve a significant
improvement in robust accuracy, exceeding performances of all the previously
reported defense methods while suffering almost no performance drop in clean
accuracy on SST-2, AGNEWS and IMDB datasets."
Bridging the KB-Text Gap: Leveraging Structured Knowledge-aware Pre-training for KBQA,0.807384,"Knowledge Base Question Answering (KBQA) aims to answer natural language
questions with factual information such as entities and relations in KBs.
However, traditional Pre-trained Language Models (PLMs) are directly
pre-trained on large-scale natural language corpus, which poses challenges for
them in understanding and representing complex subgraphs in structured KBs. To
bridge the gap between texts and structured KBs, we propose a Structured
Knowledge-aware Pre-training method (SKP). In the pre-training stage, we
introduce two novel structured knowledge-aware tasks, guiding the model to
effectively learn the implicit relationship and better representations of
complex subgraphs. In downstream KBQA task, we further design an efficient
linearization strategy and an interval attention mechanism, which assist the
model to better encode complex subgraphs and shield the interference of
irrelevant subgraphs during reasoning respectively. Detailed experiments and
analyses on WebQSP verify the effectiveness of SKP, especially the significant
improvement in subgraph retrieval (+4.08% H@10)."
MapPrior: Bird's-Eye View Map Layout Estimation with Generative Models,0.386338,"Despite tremendous advancements in bird's-eye view (BEV) perception, existing
models fall short in generating realistic and coherent semantic map layouts,
and they fail to account for uncertainties arising from partial sensor
information (such as occlusion or limited coverage). In this work, we introduce
MapPrior, a novel BEV perception framework that combines a traditional
discriminative BEV perception model with a learned generative model for
semantic map layouts. Our MapPrior delivers predictions with better accuracy,
realism, and uncertainty awareness. We evaluate our model on the large-scale
nuScenes benchmark. At the time of submission, MapPrior outperforms the
strongest competing method, with significantly improved MMD and ECE scores in
camera- and LiDAR-based BEV perception."
Explainable Multi-Agent Reinforcement Learning for Temporal Queries,0.577713,"As multi-agent reinforcement learning (MARL) systems are increasingly
deployed throughout society, it is imperative yet challenging for users to
understand the emergent behaviors of MARL agents in complex environments. This
work presents an approach for generating policy-level contrastive explanations
for MARL to answer a temporal user query, which specifies a sequence of tasks
completed by agents with possible cooperation. The proposed approach encodes
the temporal query as a PCTL logic formula and checks if the query is feasible
under a given MARL policy via probabilistic model checking. Such explanations
can help reconcile discrepancies between the actual and anticipated multi-agent
behaviors. The proposed approach also generates correct and complete
explanations to pinpoint reasons that make a user query infeasible. We have
successfully applied the proposed approach to four benchmark MARL domains (up
to 9 agents in one domain). Moreover, the results of a user study show that the
generated explanations significantly improve user performance and satisfaction."
"Don't Generate, Discriminate: A Proposal for Grounding Language Models to Real-World Environments",0.503758,"A key missing capacity of current language models (LMs) is grounding to
real-world environments. Most existing work for grounded language understanding
uses LMs to directly generate plans that can be executed in the environment to
achieve the desired effects. It thereby casts the burden of ensuring
grammaticality, faithfulness, and controllability all on the LMs. We propose
Pangu, a generic framework for grounded language understanding that capitalizes
on the discriminative ability of LMs instead of their generative ability. Pangu
consists of a symbolic agent and a neural LM working in a concerted fashion:
The agent explores the environment to incrementally construct valid plans, and
the LM evaluates the plausibility of the candidate plans to guide the search
process. A case study on the challenging problem of knowledge base question
answering (KBQA), which features a massive environment, demonstrates the
remarkable effectiveness and flexibility of Pangu: A BERT-base LM is sufficient
for setting a new record on standard KBQA datasets, and larger LMs further
bring substantial gains. Pangu also enables, for the first time, effective
few-shot in-context learning for KBQA with large LMs such as Codex."
Long-tailed Food Classification,0.835899,"Food classification serves as the basic step of image-based dietary
assessment to predict the types of foods in each input image. However, food
image predictions in a real world scenario are usually long-tail distributed
among different food classes, which cause heavy class-imbalance problems and a
restricted performance. In addition, none of the existing long-tailed
classification methods focus on food data, which can be more challenging due to
the lower inter-class and higher intra-class similarity among foods. In this
work, we first introduce two new benchmark datasets for long-tailed food
classification including Food101-LT and VFN-LT where the number of samples in
VFN-LT exhibits the real world long-tailed food distribution. Then we propose a
novel 2-Phase framework to address the problem of class-imbalance by (1)
undersampling the head classes to remove redundant samples along with
maintaining the learned information through knowledge distillation, and (2)
oversampling the tail classes by performing visual-aware data augmentation. We
show the effectiveness of our method by comparing with existing
state-of-the-art long-tailed classification methods and show improved
performance on both Food101-LT and VFN-LT benchmarks. The results demonstrate
the potential to apply our method to related real life applications."
Zero-shot Cross-lingual Transfer of Prompt-based Tuning with a Unified Multilingual Prompt,0.448658,"Prompt-based tuning has been proven effective for pretrained language models
(PLMs). While most of the existing work focuses on the monolingual prompts, we
study the multilingual prompts for multilingual PLMs, especially in the
zero-shot cross-lingual setting. To alleviate the effort of designing different
prompts for multiple languages, we propose a novel model that uses a unified
prompt for all languages, called UniPrompt. Different from the discrete prompts
and soft prompts, the unified prompt is model-based and language-agnostic.
Specifically, the unified prompt is initialized by a multilingual PLM to
produce language-independent representation, after which is fused with the text
input. During inference, the prompts can be pre-computed so that no extra
computation cost is needed. To collocate with the unified prompt, we propose a
new initialization method for the target label word to further improve the
model's transferability across languages. Extensive experiments show that our
proposed methods can significantly outperform the strong baselines across
different languages. We release data and code to facilitate future research."
Continual Road-Scene Semantic Segmentation via Feature-Aligned Symmetric Multi-Modal Network,0.566107,"State-of-the-art multimodal semantic segmentation strategies combining LiDAR
and color data are usually designed on top of asymmetric information-sharing
schemes and assume that both modalities are always available. This strong
assumption may not hold in real-world scenarios, where sensors are prone to
failure or can face adverse conditions that make the acquired information
unreliable. This problem is exacerbated when continual learning scenarios are
considered since they have stringent data reliability constraints. In this
work, we re-frame the task of multimodal semantic segmentation by enforcing a
tightly coupled feature representation and a symmetric information-sharing
scheme, which allows our approach to work even when one of the input modalities
is missing. We also introduce an ad-hoc class-incremental continual learning
scheme, proving our approach's effectiveness and reliability even in
safety-critical settings, such as autonomous driving. We evaluate our approach
on the SemanticKITTI dataset, achieving impressive performances."
Reconstructing Groups of People with Hypergraph Relational Reasoning,0.574279,"Due to the mutual occlusion, severe scale variation, and complex spatial
distribution, the current multi-person mesh recovery methods cannot produce
accurate absolute body poses and shapes in large-scale crowded scenes. To
address the obstacles, we fully exploit crowd features for reconstructing
groups of people from a monocular image. A novel hypergraph relational
reasoning network is proposed to formulate the complex and high-order relation
correlations among individuals and groups in the crowd. We first extract
compact human features and location information from the original
high-resolution image. By conducting the relational reasoning on the extracted
individual features, the underlying crowd collectiveness and interaction
relationship can provide additional group information for the reconstruction.
Finally, the updated individual features and the localization information are
used to regress human meshes in camera coordinates. To facilitate the network
training, we further build pseudo ground-truth on two crowd datasets, which may
also promote future research on pose estimation and human behavior
understanding in crowded scenes. The experimental results show that our
approach outperforms other baseline methods both in crowded and common
scenarios. The code and datasets are publicly available at
https://github.com/boycehbz/GroupRec."
Large Language Models on the Chessboard: A Study on ChatGPT's Formal Language Comprehension and Complex Reasoning Skills,0.361165,"While large language models have made strides in natural language processing,
their proficiency in complex reasoning tasks requiring formal language
comprehension, such as chess, remains less investigated. This paper probes the
performance of ChatGPT, a sophisticated language model by OpenAI in tackling
such complex reasoning tasks, using chess as a case study. Through robust
metrics examining both the legality and quality of moves, we assess ChatGPT's
understanding of the chessboard, adherence to chess rules, and strategic
decision-making abilities. Our evaluation identifies limitations within
ChatGPT's attention mechanism that affect its formal language comprehension and
uncovers the model's underdeveloped self-regulation abilities. Our study also
reveals ChatGPT's propensity for a coherent strategy in its gameplay and a
noticeable uptick in decision-making assertiveness when the model is presented
with a greater volume of natural language or possesses a more lucid
understanding of the state of the chessboard. These findings contribute to the
growing exploration of language models' abilities beyond natural language
processing, providing valuable information for future research towards models
demonstrating human-like cognitive abilities."
Prompt Engineering a Prompt Engineer,0.637058,"Prompt engineering is a challenging yet crucial task for optimizing the
performance of large language models on customized tasks. It requires complex
reasoning to examine the model's errors, hypothesize what is missing or
misleading in the current prompt, and communicate the task with clarity. While
recent works indicate that large language models can be meta-prompted to
perform automatic prompt engineering, we argue that their potential is limited
due to insufficient guidance for complex reasoning in the meta-prompt. We fill
this gap by infusing into the meta-prompt three key components: detailed
descriptions, context specification, and a step-by-step reasoning template. The
resulting method, named PE2, showcases remarkable versatility across diverse
language tasks. It finds prompts that outperform ""let's think step by step"" by
6.3% on MultiArith and 3.1% on GSM8K, and outperforms competitive baselines on
counterfactual tasks by 6.9%. Further, we show that PE2 can make targeted
prompt edits, rectify erroneous prompts, and induce multi-step plans for
complex tasks."
Learning Uncertainty with Artificial Neural Networks for Improved Predictive Process Monitoring,0.513304,"The inability of artificial neural networks to assess the uncertainty of
their predictions is an impediment to their widespread use. We distinguish two
types of learnable uncertainty: model uncertainty due to a lack of training
data and noise-induced observational uncertainty. Bayesian neural networks use
solid mathematical foundations to learn the model uncertainties of their
predictions. The observational uncertainty can be calculated by adding one
layer to these networks and augmenting their loss functions. Our contribution
is to apply these uncertainty concepts to predictive process monitoring tasks
to train uncertainty-based models to predict the remaining time and outcomes.
Our experiments show that uncertainty estimates allow more and less accurate
predictions to be differentiated and confidence intervals to be constructed in
both regression and classification tasks. These conclusions remain true even in
early stages of running processes. Moreover, the deployed techniques are fast
and produce more accurate predictions. The learned uncertainty could increase
users' confidence in their process prediction systems, promote better
cooperation between humans and these systems, and enable earlier
implementations with smaller datasets."
AVeriTeC: A Dataset for Real-world Claim Verification with Evidence from the Web,0.81599,"Existing datasets for automated fact-checking have substantial limitations,
such as relying on artificial claims, lacking annotations for evidence and
intermediate reasoning, or including evidence published after the claim. In
this paper we introduce AVeriTeC, a new dataset of 4,568 real-world claims
covering fact-checks by 50 different organizations. Each claim is annotated
with question-answer pairs supported by evidence available online, as well as
textual justifications explaining how the evidence combines to produce a
verdict. Through a multi-round annotation process, we avoid common pitfalls
including context dependence, evidence insufficiency, and temporal leakage, and
reach a substantial inter-annotator agreement of $\kappa=0.619$ on verdicts. We
develop a baseline as well as an evaluation scheme for verifying claims through
several question-answering steps against the open web."
Sentiment analysis with adaptive multi-head attention in Transformer,0.584371,"We propose a novel framework based on the attention mechanism to identify the
sentiment of a movie review document. Previous efforts on deep neural networks
with attention mechanisms focus on encoder and decoder with fixed numbers of
multi-head attention. Therefore, we need a mechanism to stop the attention
process automatically if no more useful information can be read from the
memory.In this paper, we propose an adaptive multi-head attention architecture
(AdaptAttn) which varies the number of attention heads based on length of
sentences. AdaptAttn has a data preprocessing step where each document is
classified into any one of the three bins small, medium or large based on
length of the sentence. The document classified as small goes through two heads
in each layer, the medium group passes four heads and the large group is
processed by eight heads. We examine the merit of our model on the Stanford
large movie review dataset. The experimental results show that the F1 score
from our model is on par with the baseline model."
Stitch it in Time: GAN-Based Facial Editing of Real Videos,0.998332,"The ability of Generative Adversarial Networks to encode rich semantics
within their latent space has been widely adopted for facial image editing.
However, replicating their success with videos has proven challenging. Sets of
high-quality facial videos are lacking, and working with videos introduces a
fundamental barrier to overcome - temporal coherency. We propose that this
barrier is largely artificial. The source video is already temporally coherent,
and deviations from this state arise in part due to careless treatment of
individual components in the editing pipeline. We leverage the natural
alignment of StyleGAN and the tendency of neural networks to learn low
frequency functions, and demonstrate that they provide a strongly consistent
prior. We draw on these insights and propose a framework for semantic editing
of faces in videos, demonstrating significant improvements over the current
state-of-the-art. Our method produces meaningful face manipulations, maintains
a higher degree of temporal consistency, and can be applied to challenging,
high quality, talking head videos which current methods struggle with."
Evaluation Metrics in the Era of GPT-4: Reliably Evaluating Large Language Models on Sequence to Sequence Tasks,0.556798,"Large Language Models (LLMs) evaluation is a patchy and inconsistent
landscape, and it is becoming clear that the quality of automatic evaluation
metrics is not keeping up with the pace of development of generative models. We
aim to improve the understanding of current models' performance by providing a
preliminary and hybrid evaluation on a range of open and closed-source
generative LLMs on three NLP benchmarks: text summarisation, text
simplification and grammatical error correction (GEC), using both automatic and
human evaluation. We also explore the potential of the recently released GPT-4
to act as an evaluator. We find that ChatGPT consistently outperforms many
other popular models according to human reviewers on the majority of metrics,
while scoring much more poorly when using classic automatic evaluation metrics.
We also find that human reviewers rate the gold reference as much worse than
the best models' outputs, indicating the poor quality of many popular
benchmarks. Finally, we find that GPT-4 is capable of ranking models' outputs
in a way which aligns reasonably closely to human judgement despite
task-specific variations, with a lower alignment in the GEC task."
Spatio-Visual Fusion-Based Person Re-Identification for Overhead Fisheye Images,0.2013,"Person re-identification (PRID) has been thoroughly researched in typical
surveillance scenarios where various scenes are monitored by side-mounted,
rectilinear-lens cameras. To date, few methods have been proposed for fisheye
cameras mounted overhead and their performance is lacking. In order to close
this performance gap, we propose a multi-feature framework for fisheye PRID
where we combine deep-learning, color-based and location-based features by
means of novel feature fusion. We evaluate the performance of our framework for
various feature combinations on FRIDA, a public fisheye PRID dataset. The
results demonstrate that our multi-feature approach outperforms recent
appearance-based deep-learning methods by almost 18% points and location-based
methods by almost 3% points in matching accuracy. We also demonstrate the
potential application of the proposed PRID framework to people counting in
large, crowded indoor spaces."
Deep neural networks for fine-grained surveillance of overdose mortality,0.42305,"Surveillance of drug overdose deaths relies on death certificates for
identification of the substances that caused death. Drugs and drug classes can
be identified through the International Classification of Diseases, 10th
Revision (ICD-10) codes present on death certificates. However, ICD-10 codes do
not always provide high levels of specificity in drug identification. To
achieve more fine-grained identification of substances on a death certificate,
the free-text cause of death section, completed by the medical certifier, must
be analyzed. Current methods for analyzing free-text death certificates rely
solely on look-up tables for identifying specific substances, which must be
frequently updated and maintained. To improve identification of drugs on death
certificates, a deep learning named-entity recognition model was developed,
which achieved an F1-score of 99.13%. This model can identify new drug
misspellings and novel substances that are not present on current surveillance
look-up tables, enhancing the surveillance of drug overdose deaths."
Enhancing Low Resource NER Using Assisting Language And Transfer Learning,0.507972,"Named Entity Recognition (NER) is a fundamental task in NLP that is used to
locate the key information in text and is primarily applied in conversational
and search systems. In commercial applications, NER or comparable slot-filling
methods have been widely deployed for popular languages. NER is used in
applications such as human resources, customer service, search engines, content
classification, and academia. In this paper, we draw focus on identifying name
entities for low-resource Indian languages that are closely related, like Hindi
and Marathi. We use various adaptations of BERT such as baseBERT, AlBERT, and
RoBERTa to train a supervised NER model. We also compare multilingual models
with monolingual models and establish a baseline. In this work, we show the
assisting capabilities of the Hindi and Marathi languages for the NER task. We
show that models trained using multiple languages perform better than a single
language. However, we also observe that blind mixing of all datasets doesn't
necessarily provide improvements and data selection methods may be required."
Separating Rule Discovery and Global Solution Composition in a Learning Classifier System,0.132671,"While utilization of digital agents to support crucial decision making is
increasing, trust in suggestions made by these agents is hard to achieve.
However, it is essential to profit from their application, resulting in a need
for explanations for both the decision making process and the model. For many
systems, such as common black-box models, achieving at least some
explainability requires complex post-processing, while other systems profit
from being, to a reasonable extent, inherently interpretable. We propose a
rule-based learning system specifically conceptualised and, thus, especially
suited for these scenarios. Its models are inherently transparent and easily
interpretable by design. One key innovation of our system is that the rules'
conditions and which rules compose a problem's solution are evolved separately.
We utilise independent rule fitnesses which allows users to specifically tailor
their model structure to fit the given requirements for explainability."
Hierarchical Vision Transformers for Cardiac Ejection Fraction Estimation,0.833826,"The left ventricular of ejection fraction is one of the most important metric
of cardiac function. It is used by cardiologist to identify patients who are
eligible for lifeprolonging therapies. However, the assessment of ejection
fraction suffers from inter-observer variability. To overcome this challenge,
we propose a deep learning approach, based on hierarchical vision Transformers,
to estimate the ejection fraction from echocardiogram videos. The proposed
method can estimate ejection fraction without the need for left ventrice
segmentation first, make it more efficient than other methods. We evaluated our
method on EchoNet-Dynamic dataset resulting 5.59, 7.59 and 0.59 for MAE, RMSE
and R2 respectivelly. This results are better compared to the state-of-the-art
method, Ultrasound Video Transformer (UVT). The source code is available on
https://github.com/lhfazry/UltraSwin."
Chain of Thought Prompting Elicits Knowledge Augmentation,0.754477,"The knowledge-augmented deep learning paradigm refers to a paradigm in which
domain knowledge is identified and integrated into deep models. Conventional
methods typically employ task-specific approaches to gather external knowledge
from various sources. In contrast, large language models are extensively
pre-trained and can serve as a comprehensive source of external knowledge. In
this paper, we propose CoT-KA, a Chain-of-Thought-based method that augments
knowledge for deep learning. CoT-KA avoids the need for additional knowledge
retrieval or knowledge reasoning models, as required in conventional
augmentation methods. Our results demonstrate that CoT-KA outperforms both pure
CoT-based methods and the non-augmented method across the majority of eleven
publicly available benchmarks for various reasoning tasks."
BotsTalk: Machine-sourced Framework for Automatic Curation of Large-scale Multi-skill Dialogue Datasets,0.845744,"To build open-domain chatbots that are able to use diverse communicative
skills, we propose a novel framework BotsTalk, where multiple agents grounded
to the specific target skills participate in a conversation to automatically
annotate multi-skill dialogues. We further present Blended Skill BotsTalk
(BSBT), a large-scale multi-skill dialogue dataset comprising 300K
conversations. Through extensive experiments, we demonstrate that our dataset
can be effective for multi-skill dialogue systems which require an
understanding of skill blending as well as skill grounding. Our code and data
are available at https://github.com/convei-lab/BotsTalk."
On the Importance of Noise Scheduling for Diffusion Models,0.69145,"We empirically study the effect of noise scheduling strategies for denoising
diffusion generative models. There are three findings: (1) the noise scheduling
is crucial for the performance, and the optimal one depends on the task (e.g.,
image sizes), (2) when increasing the image size, the optimal noise scheduling
shifts towards a noisier one (due to increased redundancy in pixels), and (3)
simply scaling the input data by a factor of $b$ while keeping the noise
schedule function fixed (equivalent to shifting the logSNR by $\log b$) is a
good strategy across image sizes. This simple recipe, when combined with
recently proposed Recurrent Interface Network (RIN), yields state-of-the-art
pixel-based diffusion models for high-resolution images on ImageNet, enabling
single-stage, end-to-end generation of diverse and high-fidelity images at
1024$\times$1024 resolution (without upsampling/cascades)."
SeedFormer: Patch Seeds based Point Cloud Completion with Upsample Transformer,0.894548,"Point cloud completion has become increasingly popular among generation tasks
of 3D point clouds, as it is a challenging yet indispensable problem to recover
the complete shape of a 3D object from its partial observation. In this paper,
we propose a novel SeedFormer to improve the ability of detail preservation and
recovery in point cloud completion. Unlike previous methods based on a global
feature vector, we introduce a new shape representation, namely Patch Seeds,
which not only captures general structures from partial inputs but also
preserves regional information of local patterns. Then, by integrating seed
features into the generation process, we can recover faithful details for
complete point clouds in a coarse-to-fine manner. Moreover, we devise an
Upsample Transformer by extending the transformer structure into basic
operations of point generators, which effectively incorporates spatial and
semantic relationships between neighboring points. Qualitative and quantitative
evaluations demonstrate that our method outperforms state-of-the-art completion
networks on several benchmark datasets. Our code is available at
https://github.com/hrzhou2/seedformer."
Membership Inference Attacks and Generalization: A Causal Perspective,0.442162,"Membership inference (MI) attacks highlight a privacy weakness in present
stochastic training methods for neural networks. It is not well understood,
however, why they arise. Are they a natural consequence of imperfect
generalization only? Which underlying causes should we address during training
to mitigate these attacks? Towards answering such questions, we propose the
first approach to explain MI attacks and their connection to generalization
based on principled causal reasoning. We offer causal graphs that
quantitatively explain the observed MI attack performance achieved for $6$
attack variants. We refute several prior non-quantitative hypotheses that
over-simplify or over-estimate the influence of underlying causes, thereby
failing to capture the complex interplay between several factors. Our causal
models also show a new connection between generalization and MI attacks via
their shared causal factors. Our causal models have high predictive power
($0.90$), i.e., their analytical predictions match with observations in unseen
experiments often, which makes analysis via them a pragmatic alternative."
Annotating Ambiguous Images: General Annotation Strategy for High-Quality Data with Real-World Biomedical Validation,0.045325,"In the field of image classification, existing methods often struggle with
biased or ambiguous data, a prevalent issue in real-world scenarios. Current
strategies, including semi-supervised learning and class blending, offer
partial solutions but lack a definitive resolution. Addressing this gap, our
paper introduces a novel strategy for generating high-quality labels in
challenging datasets. Central to our approach is a clearly designed flowchart,
based on a broad literature review, which enables the creation of reliable
labels. We validate our methodology through a rigorous real-world test case in
the biomedical field, specifically in deducing height reduction from vertebral
imaging. Our empirical study, leveraging over 250,000 annotations, demonstrates
the effectiveness of our strategies decisions compared to their alternatives."
Lifelong Bandit Optimization: No Prior and No Regret,0.488216,"Machine learning algorithms are often repeatedly applied to problems with
similar structure over and over again. We focus on solving a sequence of bandit
optimization tasks and develop LIBO, an algorithm which adapts to the
environment by learning from past experience and becomes more sample-efficient
in the process. We assume a kernelized structure where the kernel is unknown
but shared across all tasks. LIBO sequentially meta-learns a kernel that
approximates the true kernel and solves the incoming tasks with the latest
kernel estimate. Our algorithm can be paired with any kernelized or linear
bandit algorithm and guarantees oracle optimal performance, meaning that as
more tasks are solved, the regret of LIBO on each task converges to the regret
of the bandit algorithm with oracle knowledge of the true kernel. Naturally, if
paired with a sublinear bandit algorithm, LIBO yields a sublinear lifelong
regret. We also show that direct access to the data from each task is not
necessary for attaining sublinear regret. We propose F-LIBO, which solves the
lifelong problem in a federated manner."
"Continual Learning, Fast and Slow",0.568865,"According to the Complementary Learning Systems (CLS)
theory~\cite{mcclelland1995there} in neuroscience, humans do effective
\emph{continual learning} through two complementary systems: a fast learning
system centered on the hippocampus for rapid learning of the specifics,
individual experiences; and a slow learning system located in the neocortex for
the gradual acquisition of structured knowledge about the environment.
Motivated by this theory, we propose \emph{DualNets} (for Dual Networks), a
general continual learning framework comprising a fast learning system for
supervised learning of pattern-separated representation from specific tasks and
a slow learning system for representation learning of task-agnostic general
representation via Self-Supervised Learning (SSL). DualNets can seamlessly
incorporate both representation types into a holistic framework to facilitate
better continual learning in deep neural networks. Via extensive experiments,
we demonstrate the promising results of DualNets on a wide range of continual
learning protocols, ranging from the standard offline, task-aware setting to
the challenging online, task-free scenario. Notably, on the
CTrL~\cite{veniat2020efficient} benchmark that has unrelated tasks with vastly
different visual images, DualNets can achieve competitive performance with
existing state-of-the-art dynamic architecture
strategies~\cite{ostapenko2021continual}. Furthermore, we conduct comprehensive
ablation studies to validate DualNets efficacy, robustness, and scalability.
Code will be made available at \url{https://github.com/phquang/DualNet}."
Neural network fragile watermarking with no model performance degradation,0.652493,"Deep neural networks are vulnerable to malicious fine-tuning attacks such as
data poisoning and backdoor attacks. Therefore, in recent research, it is
proposed how to detect malicious fine-tuning of neural network models. However,
it usually negatively affects the performance of the protected model. Thus, we
propose a novel neural network fragile watermarking with no model performance
degradation. In the process of watermarking, we train a generative model with
the specific loss function and secret key to generate triggers that are
sensitive to the fine-tuning of the target classifier. In the process of
verifying, we adopt the watermarked classifier to get labels of each fragile
trigger. Then, malicious fine-tuning can be detected by comparing secret keys
and labels. Experiments on classic datasets and classifiers show that the
proposed method can effectively detect model malicious fine-tuning with no
model performance degradation."
Neuro-symbolic Explainable Artificial Intelligence Twin for Zero-touch IoE in Wireless Network,0.745045,"Explainable artificial intelligence (XAI) twin systems will be a fundamental
enabler of zero-touch network and service management (ZSM) for sixth-generation
(6G) wireless networks. A reliable XAI twin system for ZSM requires two
composites: an extreme analytical ability for discretizing the physical
behavior of the Internet of Everything (IoE) and rigorous methods for
characterizing the reasoning of such behavior. In this paper, a novel
neuro-symbolic explainable artificial intelligence twin framework is proposed
to enable trustworthy ZSM for a wireless IoE. The physical space of the XAI
twin executes a neural-network-driven multivariate regression to capture the
time-dependent wireless IoE environment while determining unconscious decisions
of IoE service aggregation. Subsequently, the virtual space of the XAI twin
constructs a directed acyclic graph (DAG)-based Bayesian network that can infer
a symbolic reasoning score over unconscious decisions through a first-order
probabilistic language model. Furthermore, a Bayesian multi-arm bandits-based
learning problem is proposed for reducing the gap between the expected
explained score and the current obtained score of the proposed neuro-symbolic
XAI twin. To address the challenges of extensible, modular, and stateless
management functions in ZSM, the proposed neuro-symbolic XAI twin framework
consists of two learning systems: 1) an implicit learner that acts as an
unconscious learner in physical space, and 2) an explicit leaner that can
exploit symbolic reasoning based on implicit learner decisions and prior
evidence. Experimental results show that the proposed neuro-symbolic XAI twin
can achieve around 96.26% accuracy while guaranteeing from 18% to 44% more
trust score in terms of reasoning and closed-loop automation."
FVQA 2.0: Introducing Adversarial Samples into Fact-based Visual Question Answering,0.106454,"The widely used Fact-based Visual Question Answering (FVQA) dataset contains
visually-grounded questions that require information retrieval using common
sense knowledge graphs to answer. It has been observed that the original
dataset is highly imbalanced and concentrated on a small portion of its
associated knowledge graph. We introduce FVQA 2.0 which contains adversarial
variants of test questions to address this imbalance. We show that systems
trained with the original FVQA train sets can be vulnerable to adversarial
samples and we demonstrate an augmentation scheme to reduce this vulnerability
without human annotations."
Zero-Shot Co-salient Object Detection Framework,0.777138,"Co-salient Object Detection (CoSOD) endeavors to replicate the human visual
system's capacity to recognize common and salient objects within a collection
of images. Despite recent advancements in deep learning models, these models
still rely on training with well-annotated CoSOD datasets. The exploration of
training-free zero-shot CoSOD frameworks has been limited. In this paper,
taking inspiration from the zero-shot transfer capabilities of foundational
computer vision models, we introduce the first zero-shot CoSOD framework that
harnesses these models without any training process. To achieve this, we
introduce two novel components in our proposed framework: the group prompt
generation (GPG) module and the co-saliency map generation (CMP) module. We
evaluate the framework's performance on widely-used datasets and observe
impressive results. Our approach surpasses existing unsupervised methods and
even outperforms fully supervised methods developed before 2020, while
remaining competitive with some fully supervised methods developed before 2022."
"Env-Aware Anomaly Detection: Ignore Style Changes, Stay True to Content!",0.559414,"We introduce a formalization and benchmark for the unsupervised anomaly
detection task in the distribution-shift scenario. Our work builds upon the
iWildCam dataset, and, to the best of our knowledge, we are the first to
propose such an approach for visual data. We empirically validate that
environment-aware methods perform better in such cases when compared with the
basic Empirical Risk Minimization (ERM). We next propose an extension for
generating positive samples for contrastive methods that considers the
environment labels when training, improving the ERM baseline score by 8.7%."
Domain-Agnostic Tuning-Encoder for Fast Personalization of Text-To-Image Models,0.503423,"Text-to-image (T2I) personalization allows users to guide the creative image
generation process by combining their own visual concepts in natural language
prompts. Recently, encoder-based techniques have emerged as a new effective
approach for T2I personalization, reducing the need for multiple images and
long training times. However, most existing encoders are limited to a
single-class domain, which hinders their ability to handle diverse concepts. In
this work, we propose a domain-agnostic method that does not require any
specialized dataset or prior information about the personalized concepts. We
introduce a novel contrastive-based regularization technique to maintain high
fidelity to the target concept characteristics while keeping the predicted
embeddings close to editable regions of the latent space, by pushing the
predicted tokens toward their nearest existing CLIP tokens. Our experimental
results demonstrate the effectiveness of our approach and show how the learned
tokens are more semantic than tokens predicted by unregularized models. This
leads to a better representation that achieves state-of-the-art performance
while being more flexible than previous methods."
Same Author or Just Same Topic? Towards Content-Independent Style Representations,0.323622,"Linguistic style is an integral component of language. Recent advances in the
development of style representations have increasingly used training objectives
from authorship verification (AV): Do two texts have the same author? The
assumption underlying the AV training task (same author approximates same
writing style) enables self-supervised and, thus, extensive training. However,
a good performance on the AV task does not ensure good ""general-purpose"" style
representations. For example, as the same author might typically write about
certain topics, representations trained on AV might also encode content
information instead of style alone. We introduce a variation of the AV training
task that controls for content using conversation or domain labels. We evaluate
whether known style dimensions are represented and preferred over content
information through an original variation to the recently proposed STEL
framework. We find that representations trained by controlling for conversation
are better than representations trained with domain or no content control at
representing style independent from content."
ArcAid: Analysis of Archaeological Artifacts using Drawings,0.30814,"Archaeology is an intriguing domain for computer vision. It suffers not only
from shortage in (labeled) data, but also from highly-challenging data, which
is often extremely abraded and damaged. This paper proposes a novel
semi-supervised model for classification and retrieval of images of
archaeological artifacts. This model utilizes unique data that exists in the
domain -- manual drawings made by special artists. These are used during
training to implicitly transfer the domain knowledge from the drawings to their
corresponding images, improving their classification results. We show that
while learning how to classify, our model also learns how to generate drawings
of the artifacts, an important documentation task, which is currently performed
manually. Last but not least, we collected a new dataset of stamp-seals of the
Southern Levant. Our code and dataset are publicly available."
Bidirectional Feature Globalization for Few-shot Semantic Segmentation of 3D Point Cloud Scenes,0.672609,"Few-shot segmentation of point cloud remains a challenging task, as there is
no effective way to convert local point cloud information to global
representation, which hinders the generalization ability of point features. In
this study, we propose a bidirectional feature globalization (BFG) approach,
which leverages the similarity measurement between point features and prototype
vectors to embed global perception to local point features in a bidirectional
fashion. With point-to-prototype globalization (Po2PrG), BFG aggregates local
point features to prototypes according to similarity weights from dense point
features to sparse prototypes. With prototype-to-point globalization (Pr2PoG),
the global perception is embedded to local point features based on similarity
weights from sparse prototypes to dense point features. The sparse prototypes
of each class embedded with global perception are summarized to a single
prototype for few-shot 3D segmentation based on the metric learning framework.
Extensive experiments on S3DIS and ScanNet demonstrate that BFG significantly
outperforms the state-of-the-art methods."
Vision Transformer with Attention Map Hallucination and FFN Compaction,0.138989,"Vision Transformer(ViT) is now dominating many vision tasks. The drawback of
quadratic complexity of its token-wise multi-head self-attention (MHSA), is
extensively addressed via either token sparsification or dimension reduction
(in spatial or channel). However, the therein redundancy of MHSA is usually
overlooked and so is the feed-forward network (FFN). To this end, we propose
attention map hallucination and FFN compaction to fill in the blank.
Specifically, we observe similar attention maps exist in vanilla ViT and
propose to hallucinate half of the attention maps from the rest with much
cheaper operations, which is called hallucinated-MHSA (hMHSA). As for FFN, we
factorize its hidden-to-output projection matrix and leverage the
re-parameterization technique to strengthen its capability, making it
compact-FFN (cFFN). With our proposed modules, a 10$\%$-20$\%$ reduction of
floating point operations (FLOPs) and parameters (Params) is achieved for
various ViT-based backbones, including straight (DeiT), hybrid (NextViT) and
hierarchical (PVT) structures, meanwhile, the performances are quite
competitive."
The moral authority of ChatGPT,0.909972,"ChatGPT is not only fun to chat with, but it also searches information,
answers questions, and gives advice. With consistent moral advice, it might
improve the moral judgment and decisions of users, who often hold contradictory
moral beliefs. Unfortunately, ChatGPT turns out highly inconsistent as a moral
advisor. Nonetheless, it influences users' moral judgment, we find in an
experiment, even if they know they are advised by a chatting bot, and they
underestimate how much they are influenced. Thus, ChatGPT threatens to corrupt
rather than improves users' judgment. These findings raise the question of how
to ensure the responsible use of ChatGPT and similar AI. Transparency is often
touted but seems ineffective. We propose training to improve digital literacy."
Beyond English-Centric Bitexts for Better Multilingual Language Representation Learning,0.691008,"In this paper, we elaborate upon recipes for building multilingual
representation models that are not only competitive with existing
state-of-the-art models but are also more parameter efficient, thereby
promoting better adoption in resource-constrained scenarios and practical
applications. We show that going beyond English-centric bitexts, coupled with a
novel sampling strategy aimed at reducing under-utilization of training data,
substantially boosts performance across model sizes for both Electra and MLM
pre-training objectives. We introduce XY-LENT: X-Y bitext enhanced Language
ENcodings using Transformers which not only achieves state-of-the-art
performance over 5 cross-lingual tasks within all model size bands, is also
competitive across bands. Our XY-LENT XL variant outperforms XLM-RXXL and
exhibits competitive performance with mT5 XXL while being 5x and 6x smaller
respectively. We then show that our proposed method helps ameliorate the curse
of multilinguality, with the XY-LENT XL achieving 99.3% GLUE performance and
98.5% SQuAD 2.0 performance compared to a SoTA English only model in the same
size band. We then analyze our models performance on extremely low resource
languages and posit that scaling alone may not be sufficient for improving the
performance in this scenario"
$k$NN-Adapter: Efficient Domain Adaptation for Black-Box Language Models,0.529348,"Fine-tuning a language model on a new domain is standard practice for domain
adaptation. However, it can be infeasible when it comes to modern large-scale
language models such as GPT-3, which can only be accessed through APIs, making
it difficult to access the internal parameters of the model. In this paper, we
propose $k$NN-Adapter, a method to effectively adapt these black-box large
language models (LLMs) to a new domain. The $k$NN-Adapter builds on top of the
retrieval-augmented language model, and adaptively learns to interpolate the
output of the language model with retrieval results from a datastore consisting
of the target domain data. Our experiments on four different domains
demonstrate that $k$NN-Adapter significantly improves perplexity, and works
particularly well in settings with limited access to LLMs. Additionally, we
show that $k$NN-Adapter is more effective than fine-tuning when the amount of
training data is limited. We also release a dataset to encourage further study."
Knowledge Injected Prompt Based Fine-tuning for Multi-label Few-shot ICD Coding,0.889946,"Automatic International Classification of Diseases (ICD) coding aims to
assign multiple ICD codes to a medical note with average length of 3,000+
tokens. This task is challenging due to a high-dimensional space of multi-label
assignment (tens of thousands of ICD codes) and the long-tail challenge: only a
few codes (common diseases) are frequently assigned while most codes (rare
diseases) are infrequently assigned. This study addresses the long-tail
challenge by adapting a prompt-based fine-tuning technique with label
semantics, which has been shown to be effective under few-shot setting. To
further enhance the performance in medical domain, we propose a
knowledge-enhanced longformer by injecting three domain-specific knowledge:
hierarchy, synonym, and abbreviation with additional pretraining using
contrastive learning. Experiments on MIMIC-III-full, a benchmark dataset of
code assignment, show that our proposed method outperforms previous
state-of-the-art method in 14.5% in marco F1 (from 10.3 to 11.8, P<0.001). To
further test our model on few-shot setting, we created a new rare diseases
coding dataset, MIMIC-III-rare50, on which our model improves marco F1 from
17.1 to 30.4 and micro F1 from 17.2 to 32.6 compared to previous method."
Few-shot Unified Question Answering: Tuning Models or Prompts?,0.0453345,"Question-answering (QA) tasks often investigate specific question types,
knowledge domains, or reasoning skills, leading to specialized models catering
to specific categories of QA tasks. While recent research has explored the idea
of unified QA models, such models are usually explored for high-resource
scenarios and require re-training to extend their capabilities. To overcome
these drawbacks, the paper explores the potential of two paradigms of tuning,
model, and prompts, for unified QA under a low-resource setting. The paper
provides an exhaustive analysis of their applicability using 16 QA datasets,
revealing that prompt tuning can perform as well as model tuning in a few-shot
setting with a good initialization. The study also shows that parameter-sharing
results in superior few-shot performance, simple knowledge transfer techniques
for prompt initialization can be effective, and prompt tuning achieves a
significant performance boost from pre-training in a low-resource regime. The
research offers insights into the advantages and limitations of prompt tuning
for unified QA in a few-shot setting, contributing to the development of
effective and efficient systems in low-resource scenarios."
Emergent Communication through Metropolis-Hastings Naming Game with Deep Generative Models,0.880075,"Constructive studies on symbol emergence systems seek to investigate
computational models that can better explain human language evolution, the
creation of symbol systems, and the construction of internal representations.
This study provides a new model for emergent communication, which is based on a
probabilistic generative model (PGM) instead of a discriminative model based on
deep reinforcement learning. We define the Metropolis-Hastings (MH) naming game
by generalizing previously proposed models. It is not a referential game with
explicit feedback, as assumed by many emergent communication studies. Instead,
it is a game based on joint attention without explicit feedback.
Mathematically, the MH naming game is proved to be a type of MH algorithm for
an integrative PGM that combines two agents that play the naming game. From
this viewpoint, symbol emergence is regarded as decentralized Bayesian
inference, and semiotic communication is regarded as inter-personal cross-modal
inference. This notion leads to the collective predictive coding hypothesis}
regarding language evolution and, in general, the emergence of symbols. We also
propose the inter-Gaussian mixture model (GMM)+ variational autoencoder (VAE),
a deep generative model for emergent communication based on the MH naming game.
The model has been validated on MNIST and Fruits 360 datasets. Experimental
findings demonstrate that categories are formed from real images observed by
agents, and signs are correctly shared across agents by successfully utilizing
both of the observations of agents via the MH naming game. Furthermore,
scholars verified that visual images were recalled from signs uttered by
agents. Notably, emergent communication without supervision and reward feedback
improved the performance of the unsupervised representation learning of agents."
Measuring Progress in Fine-grained Vision-and-Language Understanding,0.686153,"While pretraining on large-scale image-text data from the Web has facilitated
rapid progress on many vision-and-language (V&L) tasks, recent work has
demonstrated that pretrained models lack ""fine-grained"" understanding, such as
the ability to recognise relationships, verbs, and numbers in images. This has
resulted in an increased interest in the community to either develop new
benchmarks or models for such capabilities. To better understand and quantify
progress in this direction, we investigate four competitive V&L models on four
fine-grained benchmarks. Through our analysis, we find that X-VLM (Zeng et al.,
2022) consistently outperforms other baselines, and that modelling innovations
can impact performance more than scaling Web data, which even degrades
performance sometimes. Through a deeper investigation of X-VLM, we highlight
the importance of both novel losses and rich data sources for learning
fine-grained skills. Finally, we inspect training dynamics, and discover that
for some tasks, performance peaks early in training or significantly
fluctuates, never converging."
Training Vision Transformers with Only 2040 Images,0.326,"Vision Transformers (ViTs) is emerging as an alternative to convolutional
neural networks (CNNs) for visual recognition. They achieve competitive results
with CNNs but the lack of the typical convolutional inductive bias makes them
more data-hungry than common CNNs. They are often pretrained on JFT-300M or at
least ImageNet and few works study training ViTs with limited data. In this
paper, we investigate how to train ViTs with limited data (e.g., 2040 images).
We give theoretical analyses that our method (based on parametric instance
discrimination) is superior to other methods in that it can capture both
feature alignment and instance similarities. We achieve state-of-the-art
results when training from scratch on 7 small datasets under various ViT
backbones. We also investigate the transferring ability of small datasets and
find that representations learned from small datasets can even improve
large-scale ImageNet training."
L3Cube-MahaHate: A Tweet-based Marathi Hate Speech Detection Dataset and BERT models,0.919792,"Social media platforms are used by a large number of people prominently to
express their thoughts and opinions. However, these platforms have contributed
to a substantial amount of hateful and abusive content as well. Therefore, it
is important to curb the spread of hate speech on these platforms. In India,
Marathi is one of the most popular languages used by a wide audience. In this
work, we present L3Cube-MahaHate, the first major Hate Speech Dataset in
Marathi. The dataset is curated from Twitter, annotated manually. Our dataset
consists of over 25000 distinct tweets labeled into four major classes i.e
hate, offensive, profane, and not. We present the approaches used for
collecting and annotating the data and the challenges faced during the process.
Finally, we present baseline classification results using deep learning models
based on CNN, LSTM, and Transformers. We explore mono-lingual and multi-lingual
variants of BERT like MahaBERT, IndicBERT, mBERT, and xlm-RoBERTa and show that
mono-lingual models perform better than their multi-lingual counterparts. The
MahaBERT model provides the best results on L3Cube-MahaHate Corpus. The data
and models are available at https://github.com/l3cube-pune/MarathiNLP ."
"Establishing Meta-Decision-Making for AI: An Ontology of Relevance, Representation and Reasoning",0.432761,"We propose an ontology of building decision-making systems, with the aim of
establishing Meta-Decision-Making for Artificial Intelligence (AI), improving
autonomy, and creating a framework to build metrics and benchmarks upon. To
this end, we propose the three parts of Relevance, Representation, and
Reasoning, and discuss their value in ensuring safety and mitigating risk in
the context of third wave cognitive systems. Our nomenclature reflects the
literature on decision-making, and our ontology allows researchers that adopt
it to frame their work in relation to one or more of these parts."
Toward Student-Oriented Teacher Network Training For Knowledge Distillation,0.204831,"How to conduct teacher training for knowledge distillation is still an open
problem. It has been widely observed that a best-performing teacher does not
necessarily yield the best-performing student, suggesting a fundamental
discrepancy between the current teacher training practice and the ideal teacher
training strategy. To fill this gap, we explore the feasibility of training a
teacher that is oriented toward student performance with empirical risk
minimization (ERM). Our analyses are inspired by the recent findings that the
effectiveness of knowledge distillation hinges on the teacher's capability to
approximate the true label distribution of training inputs. We theoretically
establish that the ERM minimizer can approximate the true label distribution of
training data as long as the feature extractor of the learner network is
Lipschitz continuous and is robust to feature transformations. In light of our
theory, we propose a teacher training method SoTeacher which incorporates
Lipschitz regularization and consistency regularization into ERM. Experiments
on benchmark datasets using various knowledge distillation algorithms and
teacher-student pairs confirm that SoTeacher can improve student accuracy
consistently."
Improving Robustness of Convolutional Neural Networks Using Element-Wise Activation Scaling,0.42834,"Recent works reveal that re-calibrating the intermediate activation of
adversarial examples can improve the adversarial robustness of a CNN model. The
state of the arts [Baiet al., 2021] and [Yanet al., 2021] explores this feature
at the channel level, i.e. the activation of a channel is uniformly scaled by a
factor. In this paper, we investigate the intermediate activation manipulation
at a more fine-grained level. Instead of uniformly scaling the activation, we
individually adjust each element within an activation and thus propose
Element-Wise Activation Scaling, dubbed EWAS, to improve CNNs' adversarial
robustness. Experimental results on ResNet-18 and WideResNet with CIFAR10 and
SVHN show that EWAS significantly improves the robustness accuracy. Especially
for ResNet18 on CIFAR10, EWAS increases the adversarial accuracy by 37.65% to
82.35% against C&W attack. EWAS is simple yet very effective in terms of
improving robustness. The codes are anonymously available at
https://anonymous.4open.science/r/EWAS-DD64."
Fine-tuned Sentiment Analysis of COVID-19 Vaccine-Related Social Media Data: Comparative Study,0.61043,"This study investigated and compared public sentiment related to COVID-19
vaccines expressed on two popular social media platforms, Reddit and Twitter,
harvested from January 1, 2020, to March 1, 2022. To accomplish this task, we
created a fine-tuned DistilRoBERTa model to predict sentiments of approximately
9.5 million Tweets and 70 thousand Reddit comments. To fine-tune our model, our
team manually labeled the sentiment of 3600 Tweets and then augmented our
dataset by the method of back-translation. Text sentiment for each social media
platform was then classified with our fine-tuned model using Python and the
Huggingface sentiment analysis pipeline. Our results determined that the
average sentiment expressed on Twitter was more negative (52% positive) than
positive and the sentiment expressed on Reddit was more positive than negative
(53% positive). Though average sentiment was found to vary between these social
media platforms, both displayed similar behavior related to sentiment shared at
key vaccine-related developments during the pandemic. Considering this similar
trend in shared sentiment demonstrated across social media platforms, Twitter
and Reddit continue to be valuable data sources that public health officials
can utilize to strengthen vaccine confidence and combat misinformation. As the
spread of misinformation poses a range of psychological and psychosocial risks
(anxiety, fear, etc.), there is an urgency in understanding the public
perspective and attitude toward shared falsities. Comprehensive educational
delivery systems tailored to the population's expressed sentiments that
facilitate digital literacy, health information-seeking behavior, and precision
health promotion could aid in clarifying such misinformation."
Contracting Skeletal Kinematics for Human-Related Video Anomaly Detection,0.0850383,"Detecting the anomaly of human behavior is paramount to timely recognizing
endangering situations, such as street fights or elderly falls. However,
anomaly detection is complex since anomalous events are rare and because it is
an open set recognition task, i.e., what is anomalous at inference has not been
observed at training. We propose COSKAD, a novel model that encodes skeletal
human motion by a graph convolutional network and learns to COntract SKeletal
kinematic embeddings onto a latent hypersphere of minimum volume for Video
Anomaly Detection. We propose three latent spaces: the commonly-adopted
Euclidean and the novel spherical and hyperbolic. All variants outperform the
state-of-the-art on the most recent UBnormal dataset, for which we contribute a
human-related version with annotated skeletons. COSKAD sets a new
state-of-the-art on the human-related versions of ShanghaiTech Campus and CUHK
Avenue, with performance comparable to video-based methods. Source code and
dataset will be released upon acceptance."
MEAD: A Multi-Armed Approach for Evaluation of Adversarial Examples Detectors,0.192685,"Detection of adversarial examples has been a hot topic in the last years due
to its importance for safely deploying machine learning algorithms in critical
applications. However, the detection methods are generally validated by
assuming a single implicitly known attack strategy, which does not necessarily
account for real-life threats. Indeed, this can lead to an overoptimistic
assessment of the detectors' performance and may induce some bias in the
comparison between competing detection schemes. We propose a novel multi-armed
framework, called MEAD, for evaluating detectors based on several attack
strategies to overcome this limitation. Among them, we make use of three new
objectives to generate attacks. The proposed performance metric is based on the
worst-case scenario: detection is successful if and only if all different
attacks are correctly recognized. Empirically, we show the effectiveness of our
approach. Moreover, the poor performance obtained for state-of-the-art
detectors opens a new exciting line of research."
Improving Grammar-based Sequence-to-Sequence Modeling with Decomposition and Constraints,0.0612848,"Neural QCFG is a grammar-based sequence-tosequence (seq2seq) model with
strong inductive biases on hierarchical structures. It excels in
interpretability and generalization but suffers from expensive inference. In
this paper, we study two low-rank variants of Neural QCFG for faster inference
with different trade-offs between efficiency and expressiveness. Furthermore,
utilizing the symbolic interface provided by the grammar, we introduce two soft
constraints over tree hierarchy and source coverage. We experiment with various
datasets and find that our models outperform vanilla Neural QCFG in most
settings."
A Real World Dataset for Multi-view 3D Reconstruction,0.319556,"We present a dataset of 998 3D models of everyday tabletop objects along with
their 847,000 real world RGB and depth images. Accurate annotations of camera
poses and object poses for each image are performed in a semi-automated fashion
to facilitate the use of the dataset for myriad 3D applications like shape
reconstruction, object pose estimation, shape retrieval etc. We primarily focus
on learned multi-view 3D reconstruction due to the lack of appropriate real
world benchmark for the task and demonstrate that our dataset can fill that
gap. The entire annotated dataset along with the source code for the annotation
tools and evaluation baselines is available at
http://www.ocrtoc.org/3d-reconstruction.html."
"Measure More, Question More: Experimental Studies on Transformer-based Language Models and Complement Coercion",0.115617,"Transformer-based language models have shown strong performance on an array
of natural language understanding tasks. However, the question of how these
models react to implicit meaning has been largely unexplored. We investigate
this using the complement coercion phenomenon, which involves sentences like
""The student finished the book about sailing"" where the action ""reading"" is
implicit. We compare LMs' surprisal estimates at various critical sentence
regions in sentences with and without implicit meaning. Effects associated with
recovering implicit meaning were found at a critical region other than where
sentences minimally differ. We then use follow-up experiments to factor out
potential confounds, revealing different perspectives that offer a richer and
more accurate picture."
TEN: Twin Embedding Networks for the Jigsaw Puzzle Problem with Eroded Boundaries,0.0722556,"This paper introduces the novel CNN-based encoder Twin Embedding Network
(TEN), for the jigsaw puzzle problem (JPP), which represents a puzzle piece
with respect to its boundary in a latent embedding space. Combining this latent
representation with a simple distance measure, we demonstrate improved accuracy
levels of our newly proposed pairwise compatibility measure (CM), compared to
that of various classical methods, for degraded puzzles with eroded tile
boundaries. We focus on this problem instance for our case study, as it serves
as an appropriate testbed for real-world scenarios. Specifically, we
demonstrated an improvement of up to 8.5% and 16.8% in reconstruction accuracy,
for so-called Type-1 and Type-2 problem variants, respectively. Furthermore, we
also demonstrated that TEN is faster by a few orders of magnitude, on average,
than a typical deep neural network (NN) model, i.e., it is as fast as the
classical methods. In this regard, the paper makes a significant first attempt
at bridging the gap between the relatively low accuracy (of classical methods
and the intensive computational complexity (of NN models), for practical,
real-world puzzle-like problems."
Dynamic Benchmarking of Masked Language Models on Temporal Concept Drift with Multiple Views,0.208886,"Temporal concept drift refers to the problem of data changing over time. In
NLP, that would entail that language (e.g. new expressions, meaning shifts) and
factual knowledge (e.g. new concepts, updated facts) evolve over time. Focusing
on the latter, we benchmark $11$ pretrained masked language models (MLMs) on a
series of tests designed to evaluate the effect of temporal concept drift, as
it is crucial that widely used language models remain up-to-date with the
ever-evolving factual updates of the real world. Specifically, we provide a
holistic framework that (1) dynamically creates temporal test sets of any time
granularity (e.g. month, quarter, year) of factual data from Wikidata, (2)
constructs fine-grained splits of tests (e.g. updated, new, unchanged facts) to
ensure comprehensive analysis, and (3) evaluates MLMs in three distinct ways
(single-token probing, multi-token generation, MLM scoring). In contrast to
prior work, our framework aims to unveil how robust an MLM is over time and
thus to provide a signal in case it has become outdated, by leveraging multiple
views of evaluation."
Recognizing and Extracting Cybersecurtity-relevant Entities from Text,0.251691,"Cyber Threat Intelligence (CTI) is information describing threat vectors,
vulnerabilities, and attacks and is often used as training data for AI-based
cyber defense systems such as Cybersecurity Knowledge Graphs (CKG). There is a
strong need to develop community-accessible datasets to train existing AI-based
cybersecurity pipelines to efficiently and accurately extract meaningful
insights from CTI. We have created an initial unstructured CTI corpus from a
variety of open sources that we are using to train and test cybersecurity
entity models using the spaCy framework and exploring self-learning methods to
automatically recognize cybersecurity entities. We also describe methods to
apply cybersecurity domain entity linking with existing world knowledge from
Wikidata. Our future work will survey and test spaCy NLP tools and create
methods for continuous integration of new information extracted from text."
FlowCam: Training Generalizable 3D Radiance Fields without Camera Poses via Pixel-Aligned Scene Flow,0.648888,"Reconstruction of 3D neural fields from posed images has emerged as a
promising method for self-supervised representation learning. The key challenge
preventing the deployment of these 3D scene learners on large-scale video data
is their dependence on precise camera poses from structure-from-motion, which
is prohibitively expensive to run at scale. We propose a method that jointly
reconstructs camera poses and 3D neural scene representations online and in a
single forward pass. We estimate poses by first lifting frame-to-frame optical
flow to 3D scene flow via differentiable rendering, preserving locality and
shift-equivariance of the image processing backbone. SE(3) camera pose
estimation is then performed via a weighted least-squares fit to the scene flow
field. This formulation enables us to jointly supervise pose estimation and a
generalizable neural scene representation via re-rendering the input video, and
thus, train end-to-end and fully self-supervised on real-world video datasets.
We demonstrate that our method performs robustly on diverse, real-world video,
notably on sequences traditionally challenging to optimization-based pose
estimation techniques."
MMES: Mixture Model based Evolution Strategy for Large-Scale Optimization,0.371766,"This work provides an efficient sampling method for the covariance matrix
adaptation evolution strategy (CMA-ES) in large-scale settings. In contract to
the Gaussian sampling in CMA-ES, the proposed method generates mutation vectors
from a mixture model, which facilitates exploiting the rich variable
correlations of the problem landscape within a limited time budget. We analyze
the probability distribution of this mixture model and show that it
approximates the Gaussian distribution of CMA-ES with a controllable accuracy.
We use this sampling method, coupled with a novel method for mutation strength
adaptation, to formulate the mixture model based evolution strategy (MMES) -- a
CMA-ES variant for large-scale optimization. The numerical simulations show
that, while significantly reducing the time complexity of CMA-ES, MMES
preserves the rotational invariance, is scalable to high dimensional problems,
and is competitive against the state-of-the-arts in performing global
optimization."
SpeechTokenizer: Unified Speech Tokenizer for Speech Large Language Models,0.913992,"Current speech large language models build upon discrete speech
representations, which can be categorized into semantic tokens and acoustic
tokens. However, existing speech tokens are not specifically designed for
speech language modeling. To assess the suitability of speech tokens for
building speech language models, we established the first benchmark,
SLMTokBench. Our results indicate that neither semantic nor acoustic tokens are
ideal for this purpose. Therefore, we propose SpeechTokenizer, a unified speech
tokenizer for speech large language models. SpeechTokenizer adopts the
Encoder-Decoder architecture with residual vector quantization (RVQ). Unifying
semantic and acoustic tokens, SpeechTokenizer disentangles different aspects of
speech information hierarchically across different RVQ layers. Furthermore, We
construct a Unified Speech Language Model (USLM) leveraging SpeechTokenizer.
Experiments show that SpeechTokenizer performs comparably to EnCodec in speech
reconstruction and demonstrates strong performance on the SLMTokBench
benchmark. Also, USLM outperforms VALL-E in zero-shot Text-to-Speech tasks.
Code and models are available at
https://github.com/ZhangXInFD/SpeechTokenizer/."
Exploring Wasserstein Distance across Concept Embeddings for Ontology Matching,0.122438,"Measuring the distance between ontological elements is fundamental for
ontology matching. String-based distance metrics are notorious for shallow
syntactic matching. In this exploratory study, we investigate Wasserstein
distance targeting continuous space that can incorporate various types of
information. We use a pre-trained word embeddings system to embed ontology
element labels. We examine the effectiveness of Wasserstein distance for
measuring similarity between ontologies, and discovering and refining matchings
between individual elements. Our experiments with the OAEI conference track and
MSE benchmarks achieved competitive results compared to the leading systems."
SYNAuG: Exploiting Synthetic Data for Data Imbalance Problems,0.0618953,"Data imbalance in training data often leads to biased predictions from
trained models, which in turn causes ethical and social issues. A
straightforward solution is to carefully curate training data, but given the
enormous scale of modern neural networks, this is prohibitively labor-intensive
and thus impractical. Inspired by recent developments in generative models,
this paper explores the potential of synthetic data to address the data
imbalance problem. To be specific, our method, dubbed SYNAuG, leverages
synthetic data to equalize the unbalanced distribution of training data. Our
experiments demonstrate that, although a domain gap between real and synthetic
data exists, training with SYNAuG followed by fine-tuning with a few real
samples allows to achieve impressive performance on diverse tasks with
different data imbalance issues, surpassing existing task-specific methods for
the same purpose."
Gait Recognition in Large-scale Free Environment via Single LiDAR,0.737184,"Human gait recognition is crucial in multimedia, enabling identification
through walking patterns without direct interaction, enhancing the integration
across various media forms in real-world applications like smart homes,
healthcare and non-intrusive security. LiDAR's ability to capture depth makes
it pivotal for robotic perception and holds promise for real-world gait
recognition. In this paper, based on a single LiDAR, we present the
Hierarchical Multi-representation Feature Interaction Network (HMRNet) for
robust gait recognition. Prevailing LiDAR-based gait datasets primarily derive
from controlled settings with predefined trajectory, remaining a gap with
real-world scenarios. To facilitate LiDAR-based gait recognition research, we
introduce FreeGait, a comprehensive gait dataset from large-scale,
unconstrained settings, enriched with multi-modal and varied 2D/3D data.
Notably, our approach achieves state-of-the-art performance on prior dataset
(SUSTech1K) and on FreeGait. Code and dataset will be released upon publication
of this paper."
Transkimmer: Transformer Learns to Layer-wise Skim,0.259538,"Transformer architecture has become the de-facto model for many machine
learning tasks from natural language processing and computer vision. As such,
improving its computational efficiency becomes paramount. One of the major
computational inefficiency of Transformer-based models is that they spend the
identical amount of computation throughout all layers. Prior works have
proposed to augment the Transformer model with the capability of skimming
tokens to improve its computational efficiency. However, they suffer from not
having effectual and end-to-end optimization of the discrete skimming
predictor. To address the above limitations, we propose the Transkimmer
architecture, which learns to identify hidden state tokens that are not
required by each layer. The skimmed tokens are then forwarded directly to the
final output, thus reducing the computation of the successive layers. The key
idea in Transkimmer is to add a parameterized predictor before each layer that
learns to make the skimming decision. We also propose to adopt
reparameterization trick and add skim loss for the end-to-end training of
Transkimmer. Transkimmer achieves 10.97x average speedup on GLUE benchmark
compared with vanilla BERT-base baseline with less than 1% accuracy
degradation."
A Walk in the Park: Learning to Walk in 20 Minutes With Model-Free Reinforcement Learning,0.784893,"Deep reinforcement learning is a promising approach to learning policies in
uncontrolled environments that do not require domain knowledge. Unfortunately,
due to sample inefficiency, deep RL applications have primarily focused on
simulated environments. In this work, we demonstrate that the recent
advancements in machine learning algorithms and libraries combined with a
carefully tuned robot controller lead to learning quadruped locomotion in only
20 minutes in the real world. We evaluate our approach on several indoor and
outdoor terrains which are known to be challenging for classical model-based
controllers. We observe the robot to be able to learn walking gait consistently
on all of these terrains. Finally, we evaluate our design decisions in a
simulated environment."
Linear Convergence of Natural Policy Gradient Methods with Log-Linear Policies,0.812857,"We consider infinite-horizon discounted Markov decision processes and study
the convergence rates of the natural policy gradient (NPG) and the Q-NPG
methods with the log-linear policy class. Using the compatible function
approximation framework, both methods with log-linear policies can be written
as inexact versions of the policy mirror descent (PMD) method. We show that
both methods attain linear convergence rates and
$\tilde{\mathcal{O}}(1/\epsilon^2)$ sample complexities using a simple,
non-adaptive geometrically increasing step size, without resorting to entropy
or other strongly convex regularization. Lastly, as a byproduct, we obtain
sublinear convergence rates for both methods with arbitrary constant step size."
RELIC: Retrieving Evidence for Literary Claims,0.768384,"Humanities scholars commonly provide evidence for claims that they make about
a work of literature (e.g., a novel) in the form of quotations from the work.
We collect a large-scale dataset (RELiC) of 78K literary quotations and
surrounding critical analysis and use it to formulate the novel task of
literary evidence retrieval, in which models are given an excerpt of literary
analysis surrounding a masked quotation and asked to retrieve the quoted
passage from the set of all passages in the work. Solving this retrieval task
requires a deep understanding of complex literary and linguistic phenomena,
which proves challenging to methods that overwhelmingly rely on lexical and
semantic similarity matching. We implement a RoBERTa-based dense passage
retriever for this task that outperforms existing pretrained information
retrieval baselines; however, experiments and analysis by human domain experts
indicate that there is substantial room for improvement over our dense
retriever."
Multilingual Contextual Adapters To Improve Custom Word Recognition In Low-resource Languages,0.534582,"Connectionist Temporal Classification (CTC) models are popular for their
balance between speed and performance for Automatic Speech Recognition (ASR).
However, these CTC models still struggle in other areas, such as
personalization towards custom words. A recent approach explores Contextual
Adapters, wherein an attention-based biasing model for CTC is used to improve
the recognition of custom entities. While this approach works well with enough
data, we showcase that it isn't an effective strategy for low-resource
languages. In this work, we propose a supervision loss for smoother training of
the Contextual Adapters. Further, we explore a multilingual strategy to improve
performance with limited training data. Our method achieves 48% F1 improvement
in retrieving unseen custom entities for a low-resource language.
Interestingly, as a by-product of training the Contextual Adapters, we see a
5-11% Word Error Rate (WER) reduction in the performance of the base CTC model
as well."
Swin MAE: Masked Autoencoders for Small Datasets,0.6089,"The development of deep learning models in medical image analysis is majorly
limited by the lack of large-sized and well-annotated datasets. Unsupervised
learning does not require labels and is more suitable for solving medical image
analysis problems. However, most of the current unsupervised learning methods
need to be applied to large datasets. To make unsupervised learning applicable
to small datasets, we proposed Swin MAE, which is a masked autoencoder with
Swin Transformer as its backbone. Even on a dataset of only a few thousand
medical images and without using any pre-trained models, Swin MAE is still able
to learn useful semantic features purely from images. It can equal or even
slightly outperform the supervised model obtained by Swin Transformer trained
on ImageNet in terms of the transfer learning results of downstream tasks. The
code is publicly available at https://github.com/Zian-Xu/Swin-MAE."
Source Code Summarization with Structural Relative Position Guided Transformer,0.337199,"Source code summarization aims at generating concise and clear natural
language descriptions for programming languages. Well-written code summaries
are beneficial for programmers to participate in the software development and
maintenance process. To learn the semantic representations of source code,
recent efforts focus on incorporating the syntax structure of code into neural
networks such as Transformer. Such Transformer-based approaches can better
capture the long-range dependencies than other neural networks including
Recurrent Neural Networks (RNNs), however, most of them do not consider the
structural relative correlations between tokens, e.g., relative positions in
Abstract Syntax Trees (ASTs), which is beneficial for code semantics learning.
To model the structural dependency, we propose a Structural Relative Position
guided Transformer, named SCRIPT. SCRIPT first obtains the structural relative
positions between tokens via parsing the ASTs of source code, and then passes
them into two types of Transformer encoders. One Transformer directly adjusts
the input according to the structural relative distance; and the other
Transformer encodes the structural relative positions during computing the
self-attention scores. Finally, we stack these two types of Transformer
encoders to learn representations of source code. Experimental results show
that the proposed SCRIPT outperforms the state-of-the-art methods by at least
1.6%, 1.4% and 2.8% with respect to BLEU, ROUGE-L and METEOR on benchmark
datasets, respectively. We further show that how the proposed SCRIPT captures
the structural relative dependencies."
Multi Modal Facial Expression Recognition with Transformer-Based Fusion Networks and Dynamic Sampling,0.770541,"Facial expression recognition is an essential task for various applications,
including emotion detection, mental health analysis, and human-machine
interactions. In this paper, we propose a multi-modal facial expression
recognition method that exploits audio information along with facial images to
provide a crucial clue to differentiate some ambiguous facial expressions.
Specifically, we introduce a Modal Fusion Module (MFM) to fuse audio-visual
information, where image and audio features are extracted from Swin
Transformer. Additionally, we tackle the imbalance problem in the dataset by
employing dynamic data resampling. Our model has been evaluated in the
Affective Behavior in-the-wild (ABAW) challenge of CVPR 2023."
Deep Reinforcement Learning Based Semi-Autonomous Control for Robotic Surgery,0.279523,"In recent decades, the tremendous benefits surgical robots have brought to
surgeons and patients have been witnessed. With the dexterous operation and the
great precision, surgical robots can offer patients less recovery time and less
hospital stay. However, the controls for current surgical robots in practical
usage are fully carried out by surgeons via teleoperation. During the surgery
process, there exists a lot of repetitive but simple manipulation, which can
cause unnecessary fatigue to the surgeons. In this paper, we proposed a deep
reinforcement learning-based semi-autonomous control framework for robotic
surgery. The user study showed that the framework can reduce the completion
time by 19.1% and the travel length by 58.7%."
AdaLoGN: Adaptive Logic Graph Network for Reasoning-Based Machine Reading Comprehension,0.653461,"Recent machine reading comprehension datasets such as ReClor and LogiQA
require performing logical reasoning over text. Conventional neural models are
insufficient for logical reasoning, while symbolic reasoners cannot directly
apply to text. To meet the challenge, we present a neural-symbolic approach
which, to predict an answer, passes messages over a graph representing logical
relations between text units. It incorporates an adaptive logic graph network
(AdaLoGN) which adaptively infers logical relations to extend the graph and,
essentially, realizes mutual and iterative reinforcement between neural and
symbolic reasoning. We also implement a novel subgraph-to-node message passing
mechanism to enhance context-option interaction for answering multiple-choice
questions. Our approach shows promising results on ReClor and LogiQA."
Differentiable Inference of Temporal Logic Formulas,0.610211,"We demonstrate the first Recurrent Neural Network architecture for learning
Signal Temporal Logic formulas, and present the first systematic comparison of
formula inference methods. Legacy systems embed much expert knowledge which is
not explicitly formalized. There is great interest in learning formal
specifications that characterize the ideal behavior of such systems -- that is,
formulas in temporal logic that are satisfied by the system's output signals.
Such specifications can be used to better understand the system's behavior and
improve design of its next iteration. Previous inference methods either assumed
certain formula templates, or did a heuristic enumeration of all possible
templates. This work proposes a neural network architecture that infers the
formula structure via gradient descent, eliminating the need for imposing any
specific templates. It combines learning of formula structure and parameters in
one optimization. Through systematic comparison, we demonstrate that this
method achieves similar or better mis-classification rates (MCR) than
enumerative and lattice methods. We also observe that different formulas can
achieve similar MCR, empirically demonstrating the under-determinism of the
problem of temporal logic inference."
GloCAL: Glocalized Curriculum-Aided Learning of Multiple Tasks with Application to Robotic Grasping,0.0804053,"The domain of robotics is challenging to apply deep reinforcement learning
due to the need for large amounts of data and for ensuring safety during
learning. Curriculum learning has shown good performance in terms of sample-
efficient deep learning. In this paper, we propose an algorithm (named GloCAL)
that creates a curriculum for an agent to learn multiple discrete tasks, based
on clustering tasks according to their evaluation scores. From the
highest-performing cluster, a global task representative of the cluster is
identified for learning a global policy that transfers to subsequently formed
new clusters, while the remaining tasks in the cluster are learned as local
policies. The efficacy and efficiency of our GloCAL algorithm are compared with
other approaches in the domain of grasp learning for 49 objects with varied
object complexity and grasp difficulty from the EGAD! dataset. The results show
that GloCAL is able to learn to grasp 100% of the objects, whereas other
approaches achieve at most 86% despite being given 1.5 times longer training
time."
Unsupervised Slot Schema Induction for Task-oriented Dialog,0.811124,"Carefully-designed schemas describing how to collect and annotate dialog
corpora are a prerequisite towards building task-oriented dialog systems. In
practical applications, manually designing schemas can be error-prone,
laborious, iterative, and slow, especially when the schema is complicated. To
alleviate this expensive and time consuming process, we propose an unsupervised
approach for slot schema induction from unlabeled dialog corpora. Leveraging
in-domain language models and unsupervised parsing structures, our data-driven
approach extracts candidate slots without constraints, followed by
coarse-to-fine clustering to induce slot types. We compare our method against
several strong supervised baselines, and show significant performance
improvement in slot schema induction on MultiWoz and SGD datasets. We also
demonstrate the effectiveness of induced schemas on downstream applications
including dialog state tracking and response generation."
Meta-Causal Feature Learning for Out-of-Distribution Generalization,0.871295,"Causal inference has become a powerful tool to handle the out-of-distribution
(OOD) generalization problem, which aims to extract the invariant features.
However, conventional methods apply causal learners from multiple data splits,
which may incur biased representation learning from imbalanced data
distributions and difficulty in invariant feature learning from heterogeneous
sources. To address these issues, this paper presents a balanced meta-causal
learner (BMCL), which includes a balanced task generation module (BTG) and a
meta-causal feature learning module (MCFL). Specifically, the BTG module learns
to generate balanced subsets by a self-learned partitioning algorithm with
constraints on the proportions of sample classes and contexts. The MCFL module
trains a meta-learner adapted to different distributions. Experiments conducted
on NICO++ dataset verified that BMCL effectively identifies the class-invariant
visual regions for classification and may serve as a general framework to
improve the performance of the state-of-the-art methods."
In-Contextual Gender Bias Suppression for Large Language Models,0.388836,"Despite their impressive performance in a wide range of NLP tasks, Large
Language Models (LLMs) have been reported to encode worrying-levels of gender
biases. Prior work has proposed debiasing methods that require human labelled
examples, data augmentation and fine-tuning of LLMs, which are computationally
costly. Moreover, one might not even have access to the model parameters for
performing debiasing such as in the case of closed LLMs such as GPT-4. To
address this challenge, we propose bias suppression that prevents biased
generations of LLMs by simply providing textual preambles constructed from
manually designed templates and real-world statistics, without accessing to
model parameters. We show that, using CrowsPairs dataset, our textual preambles
covering counterfactual statements can suppress gender biases in English LLMs
such as LLaMA2. Moreover, we find that gender-neutral descriptions of
gender-biased objects can also suppress their gender biases. Moreover, we show
that bias suppression has acceptable adverse effect on downstream task
performance with HellaSwag and COPA."
Emotion-Aware Prosodic Phrasing for Expressive Text-to-Speech,0.290818,"Prosodic phrasing is crucial to the naturalness and intelligibility of
end-to-end Text-to-Speech (TTS). There exist both linguistic and emotional
prosody in natural speech. As the study of prosodic phrasing has been
linguistically motivated, prosodic phrasing for expressive emotion rendering
has not been well studied. In this paper, we propose an emotion-aware prosodic
phrasing model, termed \textit{EmoPP}, to mine the emotional cues of utterance
accurately and predict appropriate phrase breaks. We first conduct objective
observations on the ESD dataset to validate the strong correlation between
emotion and prosodic phrasing. Then the objective and subjective evaluations
show that the EmoPP outperforms all baselines and achieves remarkable
performance in terms of emotion expressiveness. The audio samples and the code
are available at \url{https://github.com/AI-S2-Lab/EmoPP}."
Improved Diffusion-based Image Colorization via Piggybacked Models,0.591464,"Image colorization has been attracting the research interests of the
community for decades. However, existing methods still struggle to provide
satisfactory colorized results given grayscale images due to a lack of
human-like global understanding of colors. Recently, large-scale Text-to-Image
(T2I) models have been exploited to transfer the semantic information from the
text prompts to the image domain, where text provides a global control for
semantic objects in the image. In this work, we introduce a colorization model
piggybacking on the existing powerful T2I diffusion model. Our key idea is to
exploit the color prior knowledge in the pre-trained T2I diffusion model for
realistic and diverse colorization. A diffusion guider is designed to
incorporate the pre-trained weights of the latent diffusion model to output a
latent color prior that conforms to the visual semantics of the grayscale
input. A lightness-aware VQVAE will then generate the colorized result with
pixel-perfect alignment to the given grayscale image. Our model can also
achieve conditional colorization with additional inputs (e.g. user hints and
texts). Extensive experiments show that our method achieves state-of-the-art
performance in terms of perceptual quality."
DAMO-NLP at SemEval-2022 Task 11: A Knowledge-based System for Multilingual Named Entity Recognition,0.995366,"The MultiCoNER shared task aims at detecting semantically ambiguous and
complex named entities in short and low-context settings for multiple
languages. The lack of contexts makes the recognition of ambiguous named
entities challenging. To alleviate this issue, our team DAMO-NLP proposes a
knowledge-based system, where we build a multilingual knowledge base based on
Wikipedia to provide related context information to the named entity
recognition (NER) model. Given an input sentence, our system effectively
retrieves related contexts from the knowledge base. The original input
sentences are then augmented with such context information, allowing
significantly better contextualized token representations to be captured. Our
system wins 10 out of 13 tracks in the MultiCoNER shared task."
DiffusionAD: Norm-guided One-step Denoising Diffusion for Anomaly Detection,0.0776775,"Anomaly detection has garnered extensive applications in real industrial
manufacturing due to its remarkable effectiveness and efficiency. However,
previous generative-based models have been limited by suboptimal reconstruction
quality, hampering their overall performance. A fundamental enhancement lies in
our reformulation of the reconstruction process using a diffusion model into a
noise-to-norm paradigm. Here, anomalous regions are perturbed with Gaussian
noise and reconstructed as normal, overcoming the limitations of previous
models by facilitating anomaly-free restoration. Additionally, we propose a
rapid one-step denoising paradigm, significantly faster than the traditional
iterative denoising in diffusion models. Furthermore, the introduction of the
norm-guided paradigm elevates the accuracy and fidelity of reconstructions. The
segmentation sub-network predicts pixel-level anomaly scores using the input
image and its anomaly-free restoration. Comprehensive evaluations on four
standard and challenging benchmarks reveal that DiffusionAD outperforms current
state-of-the-art approaches, demonstrating the effectiveness and broad
applicability of the proposed pipeline."
QC-StyleGAN -- Quality Controllable Image Generation and Manipulation,0.0334092,"The introduction of high-quality image generation models, particularly the
StyleGAN family, provides a powerful tool to synthesize and manipulate images.
However, existing models are built upon high-quality (HQ) data as desired
outputs, making them unfit for in-the-wild low-quality (LQ) images, which are
common inputs for manipulation. In this work, we bridge this gap by proposing a
novel GAN structure that allows for generating images with controllable
quality. The network can synthesize various image degradation and restore the
sharp image via a quality control code. Our proposed QC-StyleGAN can directly
edit LQ images without altering their quality by applying GAN inversion and
manipulation techniques. It also provides for free an image restoration
solution that can handle various degradations, including noise, blur,
compression artifacts, and their mixtures. Finally, we demonstrate numerous
other applications such as image degradation synthesis, transfer, and
interpolation. The code is available at
https://github.com/VinAIResearch/QC-StyleGAN."
Search and Score-based Waterfall Auction Optimization,0.131756,"Online advertising is a major source of income for many online companies. One
common approach is to sell online advertisements via waterfall auctions,
through which a publisher makes sequential price offers to ad networks. The
publisher controls the order and prices of the waterfall in an attempt to
maximize his revenue. In this work, we propose a methodology to learn a
waterfall strategy from historical data by wisely searching in the space of
possible waterfalls and selecting the one leading to the highest revenues. The
contribution of this work is twofold; First, we propose a novel method to
estimate the valuation distribution of each user, with respect to each ad
network. Second, we utilize the valuation matrix to score our candidate
waterfalls as part of a procedure that iteratively searches in local
neighborhoods. Our framework guarantees that the waterfall revenue improves
between iterations ultimately converging into a local optimum. Real-world
demonstrations are provided to show that the proposed method improves the total
revenue of real-world waterfalls, as compared to manual expert optimization.
Finally, the code and the data are available here."
xCloth: Extracting Template-free Textured 3D Clothes from a Monocular Image,0.415682,"Existing approaches for 3D garment reconstruction either assume a predefined
template for the garment geometry (restricting them to fixed clothing styles)
or yield vertex colored meshes (lacking high-frequency textural details). Our
novel framework co-learns geometric and semantic information of garment surface
from the input monocular image for template-free textured 3D garment
digitization. More specifically, we propose to extend PeeledHuman
representation to predict the pixel-aligned, layered depth and semantic maps to
extract 3D garments. The layered representation is further exploited to UV
parametrize the arbitrary surface of the extracted garment without any human
intervention to form a UV atlas. The texture is then imparted on the UV atlas
in a hybrid fashion by first projecting pixels from the input image to UV space
for the visible region, followed by inpainting the occluded regions. Thus, we
are able to digitize arbitrarily loose clothing styles while retaining
high-frequency textural details from a monocular image. We achieve
high-fidelity 3D garment reconstruction results on three publicly available
datasets and generalization on internet images."
"Stochastic LLMs do not Understand Language: Towards Symbolic, Explainable and Ontologically Based LLMs",0.0473578,"In our opinion the exuberance surrounding the relative success of data-driven
large language models (LLMs) is slightly misguided and for several reasons (i)
LLMs cannot be relied upon for factual information since for LLMs all ingested
text (factual or non-factual) was created equal; (ii) due to their subsymbolic
na-ture, whatever 'knowledge' these models acquire about language will always
be buried in billions of microfeatures (weights), none of which is meaningful
on its own; and (iii) LLMs will often fail to make the correct inferences in
several linguistic contexts (e.g., nominal compounds, copredication, quantifier
scope ambi-guities, intensional contexts. Since we believe the relative success
of data-driven large language models (LLMs) is not a reflection on the symbolic
vs. subsymbol-ic debate but a reflection on applying the successful strategy of
a bottom-up reverse engineering of language at scale, we suggest in this paper
applying the effective bottom-up strategy in a symbolic setting resulting in
symbolic, explainable, and ontologically grounded language models."
A Global Model Approach to Robust Few-Shot SAR Automatic Target Recognition,0.875866,"In real-world scenarios, it may not always be possible to collect hundreds of
labeled samples per class for training deep learning-based SAR Automatic Target
Recognition (ATR) models. This work specifically tackles the few-shot SAR ATR
problem, where only a handful of labeled samples may be available to support
the task of interest. Our approach is composed of two stages. In the first, a
global representation model is trained via self-supervised learning on a large
pool of diverse and unlabeled SAR data. In the second stage, the global model
is used as a fixed feature extractor and a classifier is trained to partition
the feature space given the few-shot support samples, while simultaneously
being calibrated to detect anomalous inputs. Unlike competing approaches which
require a pristine labeled dataset for pretraining via meta-learning, our
approach learns highly transferable features from unlabeled data that have
little-to-no relation to the downstream task. We evaluate our method in
standard and extended MSTAR operating conditions and find it to achieve high
accuracy and robust out-of-distribution detection in many different few-shot
settings. Our results are particularly significant because they show the merit
of a global model approach to SAR ATR, which makes minimal assumptions, and
provides many axes for extendability."
Geometry Interaction Knowledge Graph Embeddings,0.957237,"Knowledge graph (KG) embeddings have shown great power in learning
representations of entities and relations for link prediction tasks. Previous
work usually embeds KGs into a single geometric space such as Euclidean space
(zero curved), hyperbolic space (negatively curved) or hyperspherical space
(positively curved) to maintain their specific geometric structures (e.g.,
chain, hierarchy and ring structures). However, the topological structure of
KGs appears to be complicated, since it may contain multiple types of geometric
structures simultaneously. Therefore, embedding KGs in a single space, no
matter the Euclidean space, hyperbolic space or hyperspheric space, cannot
capture the complex structures of KGs accurately. To overcome this challenge,
we propose Geometry Interaction knowledge graph Embeddings (GIE), which learns
spatial structures interactively between the Euclidean, hyperbolic and
hyperspherical spaces. Theoretically, our proposed GIE can capture a richer set
of relational information, model key inference patterns, and enable expressive
semantic matching across entities. Experimental results on three
well-established knowledge graph completion benchmarks show that our GIE
achieves the state-of-the-art performance with fewer parameters."
PointCLM: A Contrastive Learning-based Framework for Multi-instance Point Cloud Registration,0.245876,"Multi-instance point cloud registration is the problem of estimating multiple
poses of source point cloud instances within a target point cloud. Solving this
problem is challenging since inlier correspondences of one instance constitute
outliers of all the other instances. Existing methods often rely on
time-consuming hypothesis sampling or features leveraging spatial consistency,
resulting in limited performance. In this paper, we propose PointCLM, a
contrastive learning-based framework for mutli-instance point cloud
registration. We first utilize contrastive learning to learn well-distributed
deep representations for the input putative correspondences. Then based on
these representations, we propose a outlier pruning strategy and a clustering
strategy to efficiently remove outliers and assign the remaining
correspondences to correct instances. Our method outperforms the
state-of-the-art methods on both synthetic and real datasets by a large margin."
Exploring Visual Prompts for Adapting Large-Scale Models,0.827194,"We investigate the efficacy of visual prompting to adapt large-scale models
in vision. Following the recent approach from prompt tuning and adversarial
reprogramming, we learn a single image perturbation such that a frozen model
prompted with this perturbation performs a new task. Through comprehensive
experiments, we demonstrate that visual prompting is particularly effective for
CLIP and robust to distribution shift, achieving performance competitive with
standard linear probes. We further analyze properties of the downstream
dataset, prompt design, and output transformation in regard to adaptation
performance. The surprising effectiveness of visual prompting provides a new
perspective on adapting pre-trained models in vision. Code is available at
http://hjbahng.github.io/visual_prompting ."
Near-Optimal Deployment Efficiency in Reward-Free Reinforcement Learning with Linear Function Approximation,0.250876,"We study the problem of deployment efficient reinforcement learning (RL) with
linear function approximation under the \emph{reward-free} exploration setting.
This is a well-motivated problem because deploying new policies is costly in
real-life RL applications. Under the linear MDP setting with feature dimension
$d$ and planning horizon $H$, we propose a new algorithm that collects at most
$\widetilde{O}(\frac{d^2H^5}{\epsilon^2})$ trajectories within $H$ deployments
to identify $\epsilon$-optimal policy for any (possibly data-dependent) choice
of reward functions. To the best of our knowledge, our approach is the first to
achieve optimal deployment complexity and optimal $d$ dependence in sample
complexity at the same time, even if the reward is known ahead of time. Our
novel techniques include an exploration-preserving policy discretization and a
generalized G-optimal experiment design, which could be of independent
interest. Lastly, we analyze the related problem of regret minimization in
low-adaptive RL and provide information-theoretic lower bounds for switching
cost and batch complexity."
Planning with Dynamically Estimated Action Costs,0.0680787,"Information about action costs is critical for real-world AI planning
applications. Rather than rely solely on declarative action models, recent
approaches also use black-box external action cost estimators, often learned
from data, that are applied during the planning phase. These, however, can be
computationally expensive, and produce uncertain values. In this paper we
suggest a generalization of deterministic planning with action costs that
allows selecting between multiple estimators for action cost, to balance
computation time against bounded estimation uncertainty. This enables a much
richer -- and correspondingly more realistic -- problem representation.
Importantly, it allows planners to bound plan accuracy, thereby increasing
reliability, while reducing unnecessary computational burden, which is critical
for scaling to large problems. We introduce a search algorithm, generalizing
$A^*$, that solves such planning problems, and additional algorithmic
extensions. In addition to theoretical guarantees, extensive experiments show
considerable savings in runtime compared to alternatives."
Epsilon-Identifiability of Causal Quantities,0.230531,"Identifying the effects of causes and causes of effects is vital in virtually
every scientific field. Often, however, the needed probabilities may not be
fully identifiable from the data sources available. This paper shows how
partial identifiability is still possible for several probabilities of
causation. We term this epsilon-identifiability and demonstrate its usefulness
in cases where the behavior of certain subpopulations can be restricted to
within some narrow bounds. In particular, we show how unidentifiable causal
effects and counterfactual probabilities can be narrowly bounded when such
allowances are made. Often those allowances are easily measured and reasonably
assumed. Finally, epsilon-identifiability is applied to the unit selection
problem."
Alignahead: Online Cross-Layer Knowledge Extraction on Graph Neural Networks,0.175662,"Existing knowledge distillation methods on graph neural networks (GNNs) are
almost offline, where the student model extracts knowledge from a powerful
teacher model to improve its performance. However, a pre-trained teacher model
is not always accessible due to training cost, privacy, etc. In this paper, we
propose a novel online knowledge distillation framework to resolve this
problem. Specifically, each student GNN model learns the extracted local
structure from another simultaneously trained counterpart in an alternating
training procedure. We further develop a cross-layer distillation strategy by
aligning ahead one student layer with the layer in different depth of another
student model, which theoretically makes the structure information spread over
all layers. Experimental results on five datasets including PPI,
Coauthor-CS/Physics and Amazon-Computer/Photo demonstrate that the student
performance is consistently boosted in our collaborative training framework
without the supervision of a pre-trained teacher model. In addition, we also
find that our alignahead technique can accelerate the model convergence speed
and its effectiveness can be generally improved by increasing the student
numbers in training. Code is available:
https://github.com/GuoJY-eatsTG/Alignahead"
Dual-Stream Transformer for Generic Event Boundary Captioning,0.157169,"This paper describes our champion solution for the CVPR2022 Generic Event
Boundary Captioning (GEBC) competition. GEBC requires the captioning model to
have a comprehension of instantaneous status changes around the given video
boundary, which makes it much more challenging than conventional video
captioning task. In this paper, a Dual-Stream Transformer with improvements on
both video content encoding and captions generation is proposed: (1) We utilize
three pre-trained models to extract the video features from different
granularities. Moreover, we exploit the types of boundary as hints to help the
model generate captions. (2) We particularly design an model, termed as
Dual-Stream Transformer, to learn discriminative representations for boundary
captioning. (3) Towards generating content-relevant and human-like captions, we
improve the description quality by designing a word-level ensemble strategy.
The promising results on the GEBC test split demonstrate the efficacy of our
proposed model."
On the focusing of thermal images,0.426022,"In this paper we present a new thermographic image database suitable for the
analysis of automatic focus measures. This database consists of 8 different
sets of scenes, where each scene contains one image for 96 different focus
positions. Using this database we evaluate the usefulness of six focus measures
with the goal to determine the optimal focus position. Experimental results
reveal that an accurate automatic detection of optimal focus position is
possible, even with a low computational burden. We also present an acquisition
tool able to help the acquisition of thermal images. To the best of our
knowledge, this is the first study about automatic focus of thermal images."
The Secret of Metaphor on Expressing Stronger Emotion,0.864665,"Metaphors are proven to have stronger emotional impact than literal
expressions. Although this conclusion is shown to be promising in benefiting
various NLP applications, the reasons behind this phenomenon are not well
studied. This paper conducts the first study in exploring how metaphors convey
stronger emotion than their literal counterparts. We find that metaphors are
generally more specific than literal expressions. The more specific property of
metaphor can be one of the reasons for metaphors' superiority in emotion
expression. When we compare metaphors with literal expressions with the same
specificity level, the gap of emotion expressing ability between both reduces
significantly. In addition, we observe specificity is crucial in literal
language as well, as literal language can express stronger emotion by making it
more specific."
Efficient Generator of Mathematical Expressions for Symbolic Regression,0.123915,"We propose an approach to symbolic regression based on a novel variational
autoencoder for generating hierarchical structures, HVAE. It combines simple
atomic units with shared weights to recursively encode and decode the
individual nodes in the hierarchy. Encoding is performed bottom-up and decoding
top-down. We empirically show that HVAE can be trained efficiently with small
corpora of mathematical expressions and can accurately encode expressions into
a smooth low-dimensional latent space. The latter can be efficiently explored
with various optimization methods to address the task of symbolic regression.
Indeed, random search through the latent space of HVAE performs better than
random search through expressions generated by manually crafted probabilistic
grammars for mathematical expressions. Finally, EDHiE system for symbolic
regression, which applies an evolutionary algorithm to the latent space of
HVAE, reconstructs equations from a standard symbolic regression benchmark
better than a state-of-the-art system based on a similar combination of deep
learning and evolutionary algorithms.\v{z}"
BBTv2: Towards a Gradient-Free Future with Large Language Models,0.872972,"Most downstream adaptation methods tune all or part of the parameters of
pre-trained models (PTMs) through gradient descent, where the tuning cost
increases linearly with the growth of the model size. By contrast,
gradient-free methods only require the forward computation of the PTM to tune
the prompt, retaining the benefits of efficient tuning and deployment. Though,
past work on gradient-free tuning often introduces gradient descent to seek a
good initialization of prompt and lacks versatility across tasks and PTMs. In
this paper, we present BBTv2, an improved version of Black-Box Tuning, to drive
PTMs for few-shot learning. We prepend continuous prompts to every layer of the
PTM and propose a divide-and-conquer gradient-free algorithm to optimize the
prompts at different layers alternately. Extensive experiments across various
tasks and PTMs show that BBTv2 can achieve comparable performance to full model
tuning and state-of-the-art parameter-efficient methods (e.g., Adapter, LoRA,
BitFit, etc.) under few-shot settings while maintaining much fewer tunable
parameters."
Multi-Task Cross-Modality Attention-Fusion for 2D Object Detection,0.113584,"Accurate and robust object detection is critical for autonomous driving.
Image-based detectors face difficulties caused by low visibility in adverse
weather conditions. Thus, radar-camera fusion is of particular interest but
presents challenges in optimally fusing heterogeneous data sources. To approach
this issue, we propose two new radar preprocessing techniques to better align
radar and camera data. In addition, we introduce a Multi-Task Cross-Modality
Attention-Fusion Network (MCAF-Net) for object detection, which includes two
new fusion blocks. These allow for exploiting information from the feature maps
more comprehensively. The proposed algorithm jointly detects objects and
segments free space, which guides the model to focus on the more relevant part
of the scene, namely, the occupied space. Our approach outperforms current
state-of-the-art radar-camera fusion-based object detectors in the nuScenes
dataset and achieves more robust results in adverse weather conditions and
nighttime scenarios."
A Unified View of Masked Image Modeling,0.728224,"Masked image modeling has demonstrated great potential to eliminate the
label-hungry problem of training large-scale vision Transformers, achieving
impressive performance on various downstream tasks. In this work, we propose a
unified view of masked image modeling after revisiting existing methods. Under
the unified view, we introduce a simple yet effective method, termed as
MaskDistill, which reconstructs normalized semantic features from teacher
models at the masked positions, conditioning on corrupted input images.
Experimental results on image classification and semantic segmentation show
that MaskDistill achieves comparable or superior performance than
state-of-the-art methods. When using the huge vision Transformer and
pretraining 300 epochs, MaskDistill obtains 88.3% fine-tuning top-1 accuracy on
ImageNet-1k (224 size) and 58.8% semantic segmentation mIoU metric on ADE20k
(512 size). The code and pretrained models will be available at
https://aka.ms/unimim."
Is it all a cluster game? -- Exploring Out-of-Distribution Detection based on Clustering in the Embedding Space,0.229091,"It is essential for safety-critical applications of deep neural networks to
determine when new inputs are significantly different from the training
distribution. In this paper, we explore this out-of-distribution (OOD)
detection problem for image classification using clusters of semantically
similar embeddings of the training data and exploit the differences in distance
relationships to these clusters between in- and out-of-distribution data. We
study the structure and separation of clusters in the embedding space and find
that supervised contrastive learning leads to well-separated clusters while its
self-supervised counterpart fails to do so. In our extensive analysis of
different training methods, clustering strategies, distance metrics, and
thresholding approaches, we observe that there is no clear winner. The optimal
approach depends on the model architecture and selected datasets for in- and
out-of-distribution. While we could reproduce the outstanding results for
contrastive training on CIFAR-10 as in-distribution data, we find standard
cross-entropy paired with cosine similarity outperforms all contrastive
training methods when training on CIFAR-100 instead. Cross-entropy provides
competitive results as compared to expensive contrastive training methods."
Tele-Knowledge Pre-training for Fault Analysis,0.543068,"In this work, we share our experience on tele-knowledge pre-training for
fault analysis, a crucial task in telecommunication applications that requires
a wide range of knowledge normally found in both machine log data and product
documents. To organize this knowledge from experts uniformly, we propose to
create a Tele-KG (tele-knowledge graph). Using this valuable data, we further
propose a tele-domain language pre-training model TeleBERT and its
knowledge-enhanced version, a tele-knowledge re-training model KTeleBERT. which
includes effective prompt hints, adaptive numerical data encoding, and two
knowledge injection paradigms. Concretely, our proposal includes two stages:
first, pre-training TeleBERT on 20 million tele-related corpora, and then
re-training it on 1 million causal and machine-related corpora to obtain
KTeleBERT. Our evaluation on multiple tasks related to fault analysis in
tele-applications, including root-cause analysis, event association prediction,
and fault chain tracing, shows that pre-training a language model with
tele-domain data is beneficial for downstream tasks. Moreover, the KTeleBERT
re-training further improves the performance of task models, highlighting the
effectiveness of incorporating diverse tele-knowledge into the model."
Improving Speech Recognition for Indic Languages using Language Model,0.0512443,"We study the effect of applying a language model (LM) on the output of
Automatic Speech Recognition (ASR) systems for Indic languages. We fine-tune
wav2vec $2.0$ models for $18$ Indic languages and adjust the results with
language models trained on text derived from a variety of sources. Our findings
demonstrate that the average Character Error Rate (CER) decreases by over $28$
\% and the average Word Error Rate (WER) decreases by about $36$ \% after
decoding with LM. We show that a large LM may not provide a substantial
improvement as compared to a diverse one. We also demonstrate that high quality
transcriptions can be obtained on domain-specific data without retraining the
ASR model and show results on biomedical domain."
System 2 Attention (is something you might need too),0.710487,"Soft attention in Transformer-based Large Language Models (LLMs) is
susceptible to incorporating irrelevant information from the context into its
latent representations, which adversely affects next token generations. To help
rectify these issues, we introduce System 2 Attention (S2A), which leverages
the ability of LLMs to reason in natural language and follow instructions in
order to decide what to attend to. S2A regenerates the input context to only
include the relevant portions, before attending to the regenerated context to
elicit the final response. In experiments, S2A outperforms standard
attention-based LLMs on three tasks containing opinion or irrelevant
information, QA, math word problems and longform generation, where S2A
increases factuality and objectivity, and decreases sycophancy."
Recursive Joint Attention for Audio-Visual Fusion in Regression based Emotion Recognition,0.39664,"In video-based emotion recognition (ER), it is important to effectively
leverage the complementary relationship among audio (A) and visual (V)
modalities, while retaining the intra-modal characteristics of individual
modalities. In this paper, a recursive joint attention model is proposed along
with long short-term memory (LSTM) modules for the fusion of vocal and facial
expressions in regression-based ER. Specifically, we investigated the
possibility of exploiting the complementary nature of A and V modalities using
a joint cross-attention model in a recursive fashion with LSTMs to capture the
intra-modal temporal dependencies within the same modalities as well as among
the A-V feature representations. By integrating LSTMs with recursive joint
cross-attention, our model can efficiently leverage both intra- and inter-modal
relationships for the fusion of A and V modalities. The results of extensive
experiments performed on the challenging Affwild2 and Fatigue (private)
datasets indicate that the proposed A-V fusion model can significantly
outperform state-of-art-methods."
ParaLS: Lexical Substitution via Pretrained Paraphraser,0.564799,"Lexical substitution (LS) aims at finding appropriate substitutes for a
target word in a sentence. Recently, LS methods based on pretrained language
models have made remarkable progress, generating potential substitutes for a
target word through analysis of its contextual surroundings. However, these
methods tend to overlook the preservation of the sentence's meaning when
generating the substitutes. This study explores how to generate the substitute
candidates from a paraphraser, as the generated paraphrases from a paraphraser
contain variations in word choice and preserve the sentence's meaning. Since we
cannot directly generate the substitutes via commonly used decoding strategies,
we propose two simple decoding strategies that focus on the variations of the
target word during decoding. Experimental results show that our methods
outperform state-of-the-art LS methods based on pre-trained language models on
three benchmarks."
DPPD: Deformable Polar Polygon Object Detection,0.039385,"Regular object detection methods output rectangle bounding boxes, which are
unable to accurately describe the actual object shapes. Instance segmentation
methods output pixel-level labels, which are computationally expensive for
real-time applications. Therefore, a polygon representation is needed to
achieve precise shape alignment, while retaining low computation cost. We
develop a novel Deformable Polar Polygon Object Detection method (DPPD) to
detect objects in polygon shapes. In particular, our network predicts, for each
object, a sparse set of flexible vertices to construct the polygon, where each
vertex is represented by a pair of angle and distance in the Polar coordinate
system. To enable training, both ground truth and predicted polygons are
densely resampled to have the same number of vertices with equal-spaced
raypoints. The resampling operation is fully differentable, allowing gradient
back-propagation. Sparse polygon predicton ensures high-speed runtime inference
while dense resampling allows the network to learn object shapes with high
precision. The polygon detection head is established on top of an anchor-free
and NMS-free network architecture. DPPD has been demonstrated successfully in
various object detection tasks for autonomous driving such as traffic-sign,
crosswalk, vehicle and pedestrian objects."
The Hardness of Reasoning about Probabilities and Causality,0.77687,"We study formal languages which are capable of fully expressing quantitative
probabilistic reasoning and do-calculus reasoning for causal effects, from a
computational complexity perspective. We focus on satisfiability problems whose
instance formulas allow expressing many tasks in probabilistic and causal
inference. The main contribution of this work is establishing the exact
computational complexity of these satisfiability problems. We introduce a new
natural complexity class, named succ$\exists$R, which can be viewed as a
succinct variant of the well-studied class $\exists$R, and show that the
problems we consider are complete for succ$\exists$R. Our results imply even
stronger algorithmic limitations than were proven by Fagin, Halpern, and
Megiddo (1990) and Moss\'{e}, Ibeling, and Icard (2022) for some variants of
the standard languages used commonly in probabilistic and causal inference."
FastGeodis: Fast Generalised Geodesic Distance Transform,0.718154,"The FastGeodis package provides an efficient implementation for computing
Geodesic and Euclidean distance transforms (or a mixture of both), targeting
efficient utilisation of CPU and GPU hardware. In particular, it implements the
paralellisable raster scan method from Criminisi et al. (2009), where elements
in a row (2D) or plane (3D) can be computed with parallel threads. This package
is able to handle 2D as well as 3D data, where it achieves up to a 20x speedup
on a CPU and up to a 74x speedup on a GPU as compared to an existing
open-source library (Wang, 2020) that uses a non-parallelisable single-thread
CPU implementation. The performance speedups reported here were evaluated using
3D volume data on an Nvidia GeForce Titan X (12 GB) with a 6-Core Intel Xeon
E5-1650 CPU. Further in-depth comparison of performance improvements are
discussed in the FastGeodis documentation: https://fastgeodis.readthedocs.io"
Improving Sentiment Analysis By Emotion Lexicon Approach on Vietnamese Texts,0.304787,"The sentiment analysis task has various applications in practice. In the
sentiment analysis task, words and phrases that represent positive and negative
emotions are important. Finding out the words that represent the emotion from
the text can improve the performance of the classification models for the
sentiment analysis task. In this paper, we propose a methodology that combines
the emotion lexicon with the classification model to enhance the accuracy of
the models. Our experimental results show that the emotion lexicon combined
with the classification model improves the performance of models."
Enhanced Bi-directional Motion Estimation for Video Frame Interpolation,0.83706,"We present a novel simple yet effective algorithm for motion-based video
frame interpolation. Existing motion-based interpolation methods typically rely
on a pre-trained optical flow model or a U-Net based pyramid network for motion
estimation, which either suffer from large model size or limited capacity in
handling complex and large motion cases. In this work, by carefully integrating
intermediateoriented forward-warping, lightweight feature encoder, and
correlation volume into a pyramid recurrent framework, we derive a compact
model to simultaneously estimate the bidirectional motion between input frames.
It is 15 times smaller in size than PWC-Net, yet enables more reliable and
flexible handling of challenging motion cases. Based on estimated
bi-directional motion, we forward-warp input frames and their context features
to intermediate frame, and employ a synthesis network to estimate the
intermediate frame from warped representations. Our method achieves excellent
performance on a broad range of video frame interpolation benchmarks. Code and
trained models are available at \url{https://github.com/srcn-ivl/EBME}."
Removing RLHF Protections in GPT-4 via Fine-Tuning,0.837009,"As large language models (LLMs) have increased in their capabilities, so does
their potential for dual use. To reduce harmful outputs, produces and vendors
of LLMs have used reinforcement learning with human feedback (RLHF). In tandem,
LLM vendors have been increasingly enabling fine-tuning of their most powerful
models. However, concurrent work has shown that fine-tuning can remove RLHF
protections. We may expect that the most powerful models currently available
(GPT-4) are less susceptible to fine-tuning attacks. In this work, we show the
contrary: fine-tuning allows attackers to remove RLHF protections with as few
as 340 examples and a 95% success rate. These training examples can be
automatically generated with weaker models. We further show that removing RLHF
protections does not decrease usefulness on non-censored outputs, providing
evidence that our fine-tuning strategy does not decrease usefulness despite
using weaker models to generate training data. Our results show the need for
further research on protections on LLMs."
AraLegal-BERT: A pretrained language model for Arabic Legal text,0.754525,"The effectiveness of the BERT model on multiple linguistic tasks has been
well documented. On the other hand, its potentials for narrow and specific
domains such as Legal, have not been fully explored. In this paper, we examine
how BERT can be used in the Arabic legal domain and try customizing this
language model for several downstream tasks using several different
domain-relevant training and testing datasets to train BERT from scratch. We
introduce the AraLegal-BERT, a bidirectional encoder Transformer-based model
that have been thoroughly tested and carefully optimized with the goal to
amplify the impact of NLP-driven solution concerning jurisprudence, legal
documents, and legal practice. We fine-tuned AraLegal-BERT and evaluated it
against three BERT variations for Arabic language in three natural languages
understanding (NLU) tasks. The results show that the base version of
AraLegal-BERT achieve better accuracy than the general and original BERT over
the Legal text."
Using Natural Language and Program Abstractions to Instill Human Inductive Biases in Machines,0.615549,"Strong inductive biases give humans the ability to quickly learn to perform a
variety of tasks. Although meta-learning is a method to endow neural networks
with useful inductive biases, agents trained by meta-learning may sometimes
acquire very different strategies from humans. We show that co-training these
agents on predicting representations from natural language task descriptions
and programs induced to generate such tasks guides them toward more human-like
inductive biases. Human-generated language descriptions and program induction
models that add new learned primitives both contain abstract concepts that can
compress description length. Co-training on these representations result in
more human-like behavior in downstream meta-reinforcement learning agents than
less abstract controls (synthetic language descriptions, program induction
without learned primitives), suggesting that the abstraction supported by these
representations is key."
Unbiased organism-agnostic and highly sensitive signal peptide predictor with deep protein language model,0.572113,"Signal peptide (SP) is a short peptide located in the N-terminus of proteins.
It is essential to target and transfer transmembrane and secreted proteins to
correct positions. Compared with traditional experimental methods to identify
signal peptides, computational methods are faster and more efficient, which are
more practical for analyzing thousands or even millions of protein sequences,
especially for metagenomic data. Here we present Unbiased Organism-agnostic
Signal Peptide Network (USPNet), a signal peptide classification and cleavage
site prediction deep learning method that takes advantage of protein language
models. We propose to apply label distribution-aware margin loss to handle data
imbalance problems and use evolutionary information of protein to enrich
representation and overcome species information dependence."
Multi-Scale Attention-based Multiple Instance Learning for Classification of Multi-Gigapixel Histology Images,0.33779,"Histology images with multi-gigapixel of resolution yield rich information
for cancer diagnosis and prognosis. Most of the time, only slide-level label is
available because pixel-wise annotation is labour intensive task. In this
paper, we propose a deep learning pipeline for classification in histology
images. Using multiple instance learning, we attempt to predict the latent
membrane protein 1 (LMP1) status of nasopharyngeal carcinoma (NPC) based on
haematoxylin and eosin-stain (H&E) histology images. We utilised attention
mechanism with residual connection for our aggregation layers. In our 3-fold
cross-validation experiment, we achieved average accuracy, AUC and F1-score
0.936, 0.995 and 0.862, respectively. This method also allows us to examine the
model interpretability by visualising attention scores. To the best of our
knowledge, this is the first attempt to predict LMP1 status on NPC using deep
learning."
FL Games: A federated learning framework for distribution shifts,0.358566,"Federated learning aims to train predictive models for data that is
distributed across clients, under the orchestration of a server. However,
participating clients typically each hold data from a different distribution,
whereby predictive models with strong in-distribution generalization can fail
catastrophically on unseen domains. In this work, we argue that in order to
generalize better across non-i.i.d. clients, it is imperative to only learn
correlations that are stable and invariant across domains. We propose FL Games,
a game-theoretic framework for federated learning for learning causal features
that are invariant across clients. While training to achieve the Nash
equilibrium, the traditional best response strategy suffers from high-frequency
oscillations. We demonstrate that FL Games effectively resolves this challenge
and exhibits smooth performance curves. Further, FL Games scales well in the
number of clients, requires significantly fewer communication rounds, and is
agnostic to device heterogeneity. Through empirical evaluation, we demonstrate
that FL Games achieves high out-of-distribution performance on various
benchmarks."
CoT-MAE v2: Contextual Masked Auto-Encoder with Multi-view Modeling for Passage Retrieval,0.194958,"Growing techniques have been emerging to improve the performance of passage
retrieval. As an effective representation bottleneck pretraining technique, the
contextual masked auto-encoder utilizes contextual embedding to assist in the
reconstruction of passages. However, it only uses a single auto-encoding
pre-task for dense representation pre-training. This study brings multi-view
modeling to the contextual masked auto-encoder. Firstly, multi-view
representation utilizes both dense and sparse vectors as multi-view
representations, aiming to capture sentence semantics from different aspects.
Moreover, multiview decoding paradigm utilizes both autoencoding and
auto-regressive decoders in representation bottleneck pre-training, aiming to
provide both reconstructive and generative signals for better contextual
representation pretraining. We refer to this multi-view pretraining method as
CoT-MAE v2. Through extensive experiments, we show that CoT-MAE v2 is effective
and robust on large-scale passage retrieval benchmarks and out-of-domain
zero-shot benchmarks."
Metaphorical Language Change Is Self-Organized Criticality,0.0840667,"One way to resolve the actuation problem of metaphorical language change is
to provide a statistical profile of metaphorical constructions and generative
rules with antecedent conditions. Based on arguments from the view of language
as complex systems and the dynamic view of metaphor, this paper argues that
metaphorical language change qualifies as a self-organized criticality state
and the linguistic expressions of a metaphor can be profiled as a fractal with
spatio-temporal correlations. Synchronously, these metaphorical expressions
self-organize into a self-similar, scale-invariant fractal that follows a
power-law distribution; temporally, long range inter-dependence constrains the
self-organization process by the way of transformation rules that are intrinsic
of a language system. This argument is verified in the paper with statistical
analyses of twelve randomly selected Chinese verb metaphors in a large-scale
diachronic corpus."
Argumentation Element Annotation Modeling using XLNet,0.773344,"This study demonstrates the effectiveness of XLNet, a transformer-based
language model, for annotating argumentative elements in persuasive essays.
XLNet's architecture incorporates a recurrent mechanism that allows it to model
long-term dependencies in lengthy texts. Fine-tuned XLNet models were applied
to three datasets annotated with different schemes - a proprietary dataset
using the Annotations for Revisions and Reflections on Writing (ARROW) scheme,
the PERSUADE corpus, and the Argument Annotated Essays (AAE) dataset. The XLNet
models achieved strong performance across all datasets, even surpassing human
agreement levels in some cases. This shows XLNet capably handles diverse
annotation schemes and lengthy essays. Comparisons between the model outputs on
different datasets also revealed insights into the relationships between the
annotation tags. Overall, XLNet's strong performance on modeling argumentative
structures across diverse datasets highlights its suitability for providing
automated feedback on essay organization."
Knowledge Is Flat: A Seq2Seq Generative Framework for Various Knowledge Graph Completion,0.834493,"Knowledge Graph Completion (KGC) has been recently extended to multiple
knowledge graph (KG) structures, initiating new research directions, e.g.
static KGC, temporal KGC and few-shot KGC. Previous works often design KGC
models closely coupled with specific graph structures, which inevitably results
in two drawbacks: 1) structure-specific KGC models are mutually incompatible;
2) existing KGC methods are not adaptable to emerging KGs. In this paper, we
propose KG-S2S, a Seq2Seq generative framework that could tackle different
verbalizable graph structures by unifying the representation of KG facts into
""flat"" text, regardless of their original form. To remedy the KG structure
information loss from the ""flat"" text, we further improve the input
representations of entities and relations, and the inference algorithm in
KG-S2S. Experiments on five benchmarks show that KG-S2S outperforms many
competitive baselines, setting new state-of-the-art performance. Finally, we
analyze KG-S2S's ability on the different relations and the Non-entity
Generations."
NMTSloth: Understanding and Testing Efficiency Degradation of Neural Machine Translation Systems,0.956164,"Neural Machine Translation (NMT) systems have received much recent attention
due to their human-level accuracy. While existing works mostly focus on either
improving accuracy or testing accuracy robustness, the computation efficiency
of NMT systems, which is of paramount importance due to often vast translation
demands and real-time requirements, has surprisingly received little attention.
In this paper, we make the first attempt to understand and test potential
computation efficiency robustness in state-of-the-art NMT systems. By analyzing
the working mechanism and implementation of 1455 public-accessible NMT systems,
we observe a fundamental property in NMT systems that could be manipulated in
an adversarial manner to reduce computation efficiency significantly. Our key
motivation is to generate test inputs that could sufficiently delay the
generation of EOS such that NMT systems would have to go through enough
iterations to satisfy the pre-configured threshold. We present NMTSloth, which
develops a gradient-guided technique that searches for a minimal and
unnoticeable perturbation at character-level, token-level, and structure-level,
which sufficiently delays the appearance of EOS and forces these inputs to
reach the naturally-unreachable threshold. To demonstrate the effectiveness of
NMTSloth, we conduct a systematic evaluation on three public-available NMT
systems: Google T5, AllenAI WMT14, and Helsinki-NLP translators. Experimental
results show that NMTSloth can increase NMT systems' response latency and
energy consumption by 85% to 3153% and 86% to 3052%, respectively, by
perturbing just one character or token in the input sentence. Our case study
shows that inputs generated by NMTSloth significantly affect the battery power
in real-world mobile devices (i.e., drain more than 30 times battery power than
normal inputs)."
A Multibranch Convolutional Neural Network for Hyperspectral Unmixing,0.632268,"Hyperspectral unmixing remains one of the most challenging tasks in the
analysis of such data. Deep learning has been blooming in the field and proved
to outperform other classic unmixing techniques, and can be effectively
deployed onboard Earth observation satellites equipped with hyperspectral
imagers. In this letter, we follow this research pathway and propose a
multi-branch convolutional neural network that benefits from fusing spectral,
spatial, and spectral-spatial features in the unmixing process. The results of
our experiments, backed up with the ablation study, revealed that our
techniques outperform others from the literature and lead to higher-quality
fractional abundance estimation. Also, we investigated the influence of
reducing the training sets on the capabilities of all algorithms and their
robustness against noise, as capturing large and representative ground-truth
sets is time-consuming and costly in practice, especially in emerging Earth
observation scenarios."
Prior-Guided One-shot Neural Architecture Search,0.765376,"Neural architecture search methods seek optimal candidates with efficient
weight-sharing supernet training. However, recent studies indicate poor ranking
consistency about the performance between stand-alone architectures and
shared-weight networks. In this paper, we present Prior-Guided One-shot NAS
(PGONAS) to strengthen the ranking correlation of supernets. Specifically, we
first explore the effect of activation functions and propose a balanced
sampling strategy based on the Sandwich Rule to alleviate weight coupling in
the supernet. Then, FLOPs and Zen-Score are adopted to guide the training of
supernet with ranking correlation loss. Our PGONAS ranks 3rd place in the
supernet Track Track of CVPR2022 Second lightweight NAS challenge. Code is
available in
https://github.com/pprp/CVPR2022-NAS?competition-Track1-3th-solution."
Visual Answer Localization with Cross-modal Mutual Knowledge Transfer,0.0586337,"The goal of visual answering localization (VAL) in the video is to obtain a
relevant and concise time clip from a video as the answer to the given natural
language question. Early methods are based on the interaction modelling between
video and text to predict the visual answer by the visual predictor. Later,
using the textual predictor with subtitles for the VAL proves to be more
precise. However, these existing methods still have cross-modal knowledge
deviations from visual frames or textual subtitles. In this paper, we propose a
cross-modal mutual knowledge transfer span localization (MutualSL) method to
reduce the knowledge deviation. MutualSL has both visual predictor and textual
predictor, where we expect the prediction results of these both to be
consistent, so as to promote semantic knowledge understanding between
cross-modalities. On this basis, we design a one-way dynamic loss function to
dynamically adjust the proportion of knowledge transfer. We have conducted
extensive experiments on three public datasets for evaluation. The experimental
results show that our method outperforms other competitive state-of-the-art
(SOTA) methods, demonstrating its effectiveness."
AI-Augmented Business Process Management Systems: A Research Manifesto,0.992051,"AI-Augmented Business Process Management Systems (ABPMSs) are an emerging
class of process-aware information systems, empowered by trustworthy AI
technology. An ABPMS enhances the execution of business processes with the aim
of making these processes more adaptable, proactive, explainable, and
context-sensitive. This manifesto presents a vision for ABPMSs and discusses
research challenges that need to be surmounted to realize this vision. To this
end, we define the concept of ABPMS, we outline the lifecycle of processes
within an ABPMS, we discuss core characteristics of an ABPMS, and we derive a
set of challenges to realize systems with these characteristics."
BlobGAN: Spatially Disentangled Scene Representations,0.800611,"We propose an unsupervised, mid-level representation for a generative model
of scenes. The representation is mid-level in that it is neither per-pixel nor
per-image; rather, scenes are modeled as a collection of spatial, depth-ordered
""blobs"" of features. Blobs are differentiably placed onto a feature grid that
is decoded into an image by a generative adversarial network. Due to the
spatial uniformity of blobs and the locality inherent to convolution, our
network learns to associate different blobs with different entities in a scene
and to arrange these blobs to capture scene layout. We demonstrate this
emergent behavior by showing that, despite training without any supervision,
our method enables applications such as easy manipulation of objects within a
scene (e.g., moving, removing, and restyling furniture), creation of feasible
scenes given constraints (e.g., plausible rooms with drawers at a particular
location), and parsing of real-world images into constituent parts. On a
challenging multi-category dataset of indoor scenes, BlobGAN outperforms
StyleGAN2 in image quality as measured by FID. See our project page for video
results and interactive demo: https://www.dave.ml/blobgan"
Flow-Guided Transformer for Video Inpainting,0.617272,"We propose a flow-guided transformer, which innovatively leverage the motion
discrepancy exposed by optical flows to instruct the attention retrieval in
transformer for high fidelity video inpainting. More specially, we design a
novel flow completion network to complete the corrupted flows by exploiting the
relevant flow features in a local temporal window. With the completed flows, we
propagate the content across video frames, and adopt the flow-guided
transformer to synthesize the rest corrupted regions. We decouple transformers
along temporal and spatial dimension, so that we can easily integrate the
locally relevant completed flows to instruct spatial attention only.
Furthermore, we design a flow-reweight module to precisely control the impact
of completed flows on each spatial transformer. For the sake of efficiency, we
introduce window partition strategy to both spatial and temporal transformers.
Especially in spatial transformer, we design a dual perspective spatial MHSA,
which integrates the global tokens to the window-based attention. Extensive
experiments demonstrate the effectiveness of the proposed method qualitatively
and quantitatively. Codes are available at https://github.com/hitachinsk/FGT."
Infusing Lattice Symmetry Priors in Attention Mechanisms for Sample-Efficient Abstract Geometric Reasoning,0.0417885,"The Abstraction and Reasoning Corpus (ARC) (Chollet, 2019) and its most
recent language-complete instantiation (LARC) has been postulated as an
important step towards general AI. Yet, even state-of-the-art machine learning
models struggle to achieve meaningful performance on these problems, falling
behind non-learning based approaches. We argue that solving these tasks
requires extreme generalization that can only be achieved by proper accounting
for core knowledge priors. As a step towards this goal, we focus on geometry
priors and introduce LatFormer, a model that incorporates lattice symmetry
priors in attention masks. We show that, for any transformation of the
hypercubic lattice, there exists a binary attention mask that implements that
group action. Hence, our study motivates a modification to the standard
attention mechanism, where attention weights are scaled using soft masks
generated by a convolutional network. Experiments on synthetic geometric
reasoning show that LatFormer requires 2 orders of magnitude fewer data than
standard attention and transformers. Moreover, our results on ARC and LARC
tasks that incorporate geometric priors provide preliminary evidence that these
complex datasets do not lie out of the reach of deep learning models."
Improving Language Models via Plug-and-Play Retrieval Feedback,0.725941,"Large language models (LLMs) exhibit remarkable performance across various
NLP tasks. However, they often generate incorrect or hallucinated information,
which hinders their practical applicability in real-world scenarios. Human
feedback has been shown to effectively enhance the factuality and quality of
generated content, addressing some of these limitations. However, this approach
is resource-intensive, involving manual input and supervision, which can be
time-consuming and expensive. Moreover, it cannot be provided during inference,
further limiting its practical utility in dynamic and interactive applications.
In this paper, we introduce ReFeed, a novel pipeline designed to enhance LLMs
by providing automatic retrieval feedback in a plug-and-play framework without
the need for expensive fine-tuning. ReFeed first generates initial outputs,
then utilizes a retrieval model to acquire relevant information from large
document collections, and finally incorporates the retrieved information into
the in-context demonstration for output refinement, thereby addressing the
limitations of LLMs in a more efficient and cost-effective manner. Experiments
on four knowledge-intensive benchmark datasets demonstrate our proposed ReFeed
could improve over +6.0% under zero-shot setting and +2.5% under few-shot
setting, compared to baselines without using retrieval feedback."
IDIAPers @ Causal News Corpus 2022: Extracting Cause-Effect-Signal Triplets via Pre-trained Autoregressive Language Model,0.304214,"In this paper, we describe our shared task submissions for Subtask 2 in
CASE-2022, Event Causality Identification with Casual News Corpus. The
challenge focused on the automatic detection of all cause-effect-signal spans
present in the sentence from news-media. We detect cause-effect-signal spans in
a sentence using T5 -- a pre-trained autoregressive language model. We
iteratively identify all cause-effect-signal span triplets, always conditioning
the prediction of the next triplet on the previously predicted ones. To predict
the triplet itself, we consider different causal relationships such as
cause$\rightarrow$effect$\rightarrow$signal. Each triplet component is
generated via a language model conditioned on the sentence, the previous parts
of the current triplet, and previously predicted triplets. Despite training on
an extremely small dataset of 160 samples, our approach achieved competitive
performance, being placed second in the competition. Furthermore, we show that
assuming either cause$\rightarrow$effect or effect$\rightarrow$cause order
achieves similar results."
Behind the Scenes: Density Fields for Single View Reconstruction,0.79327,"Inferring a meaningful geometric scene representation from a single image is
a fundamental problem in computer vision. Approaches based on traditional depth
map prediction can only reason about areas that are visible in the image.
Currently, neural radiance fields (NeRFs) can capture true 3D including color,
but are too complex to be generated from a single image. As an alternative, we
propose to predict implicit density fields. A density field maps every location
in the frustum of the input image to volumetric density. By directly sampling
color from the available views instead of storing color in the density field,
our scene representation becomes significantly less complex compared to NeRFs,
and a neural network can predict it in a single forward pass. The prediction
network is trained through self-supervision from only video data. Our
formulation allows volume rendering to perform both depth prediction and novel
view synthesis. Through experiments, we show that our method is able to predict
meaningful geometry for regions that are occluded in the input image.
Additionally, we demonstrate the potential of our approach on three datasets
for depth prediction and novel-view synthesis."
PRiSM: Enhancing Low-Resource Document-Level Relation Extraction with Relation-Aware Score Calibration,0.400094,"Document-level relation extraction (DocRE) aims to extract relations of all
entity pairs in a document. A key challenge in DocRE is the cost of annotating
such data which requires intensive human effort. Thus, we investigate the case
of DocRE in a low-resource setting, and we find that existing models trained on
low data overestimate the NA (""no relation"") label, causing limited
performance. In this work, we approach the problem from a calibration
perspective and propose PRiSM, which learns to adapt logits based on relation
semantic information. We evaluate our method on three DocRE datasets and
demonstrate that integrating existing models with PRiSM improves performance by
as much as 26.38 F1 score, while the calibration error drops as much as 36
times when trained with about 3% of data. The code is publicly available at
https://github.com/brightjade/PRiSM."
RobustLoc: Robust Camera Pose Regression in Challenging Driving Environments,0.775592,"Camera relocalization has various applications in autonomous driving.
Previous camera pose regression models consider only ideal scenarios where
there is little environmental perturbation. To deal with challenging driving
environments that may have changing seasons, weather, illumination, and the
presence of unstable objects, we propose RobustLoc, which derives its
robustness against perturbations from neural differential equations. Our model
uses a convolutional neural network to extract feature maps from multi-view
images, a robust neural differential equation diffusion block module to diffuse
information interactively, and a branched pose decoder with multi-layer
training to estimate the vehicle poses. Experiments demonstrate that RobustLoc
surpasses current state-of-the-art camera pose regression models and achieves
robust performance in various environments. Our code is released at:
https://github.com/sijieaaa/RobustLoc"
Two-Step Question Retrieval for Open-Domain QA,0.111721,"The retriever-reader pipeline has shown promising performance in open-domain
QA but suffers from a very slow inference speed. Recently proposed question
retrieval models tackle this problem by indexing question-answer pairs and
searching for similar questions. These models have shown a significant increase
in inference speed, but at the cost of lower QA performance compared to the
retriever-reader models. This paper proposes a two-step question retrieval
model, SQuID (Sequential Question-Indexed Dense retrieval) and distant
supervision for training. SQuID uses two bi-encoders for question retrieval.
The first-step retriever selects top-k similar questions, and the second-step
retriever finds the most similar question from the top-k questions. We evaluate
the performance and the computational efficiency of SQuID. The results show
that SQuID significantly increases the performance of existing question
retrieval models with a negligible loss on inference speed."
Anti-Asian Hate Speech Detection via Data Augmented Semantic Relation Inference,0.563221,"With the spreading of hate speech on social media in recent years, automatic
detection of hate speech is becoming a crucial task and has attracted attention
from various communities. This task aims to recognize online posts (e.g.,
tweets) that contain hateful information. The peculiarities of languages in
social media, such as short and poorly written content, lead to the difficulty
of learning semantics and capturing discriminative features of hate speech.
Previous studies have utilized additional useful resources, such as sentiment
hashtags, to improve the performance of hate speech detection. Hashtags are
added as input features serving either as sentiment-lexicons or extra context
information. However, our close investigation shows that directly leveraging
these features without considering their context may introduce noise to
classifiers. In this paper, we propose a novel approach to leverage sentiment
hashtags to enhance hate speech detection in a natural language inference
framework. We design a novel framework SRIC that simultaneously performs two
tasks: (1) semantic relation inference between online posts and sentiment
hashtags, and (2) sentiment classification on these posts. The semantic
relation inference aims to encourage the model to encode sentiment-indicative
information into representations of online posts. We conduct extensive
experiments on two real-world datasets and demonstrate the effectiveness of our
proposed framework compared with state-of-the-art representation learning
models."
Self-supervised Pre-training with Masked Shape Prediction for 3D Scene Understanding,0.522717,"Masked signal modeling has greatly advanced self-supervised pre-training for
language and 2D images. However, it is still not fully explored in 3D scene
understanding. Thus, this paper introduces Masked Shape Prediction (MSP), a new
framework to conduct masked signal modeling in 3D scenes. MSP uses the
essential 3D semantic cue, i.e., geometric shape, as the prediction target for
masked points. The context-enhanced shape target consisting of explicit shape
context and implicit deep shape feature is proposed to facilitate exploiting
contextual cues in shape prediction. Meanwhile, the pre-training architecture
in MSP is carefully designed to alleviate the masked shape leakage from point
coordinates. Experiments on multiple 3D understanding tasks on both indoor and
outdoor datasets demonstrate the effectiveness of MSP in learning good feature
representations to consistently boost downstream performance."
From Stance to Concern: Adaptation of Propositional Analysis to New Tasks and Domains,0.497203,"We present a generalized paradigm for adaptation of propositional analysis
(predicate-argument pairs) to new tasks and domains. We leverage an analogy
between stances (belief-driven sentiment) and concerns (topical issues with
moral dimensions/endorsements) to produce an explanatory representation. A key
contribution is the combination of semi-automatic resource building for
extraction of domain-dependent concern types (with 2-4 hours of human labor per
domain) and an entirely automatic procedure for extraction of
domain-independent moral dimensions and endorsement values. Prudent (automatic)
selection of terms from propositional structures for lexical expansion (via
semantic similarity) produces new moral dimension lexicons at three levels of
granularity beyond a strong baseline lexicon. We develop a ground truth (GT)
based on expert annotators and compare our concern detection output to GT, to
yield 231% improvement in recall over baseline, with only a 10% loss in
precision. F1 yields 66% improvement over baseline and 97.8% of human
performance. Our lexically based approach yields large savings over approaches
that employ costly human labor and model building. We provide to the community
a newly expanded moral dimension/value lexicon, annotation guidelines, and GT."
Empowering Graph Representation Learning with Test-Time Graph Transformation,0.967751,"As powerful tools for representation learning on graphs, graph neural
networks (GNNs) have facilitated various applications from drug discovery to
recommender systems. Nevertheless, the effectiveness of GNNs is immensely
challenged by issues related to data quality, such as distribution shift,
abnormal features and adversarial attacks. Recent efforts have been made on
tackling these issues from a modeling perspective which requires additional
cost of changing model architectures or re-training model parameters. In this
work, we provide a data-centric view to tackle these issues and propose a graph
transformation framework named GTrans which adapts and refines graph data at
test time to achieve better performance. We provide theoretical analysis on the
design of the framework and discuss why adapting graph data works better than
adapting the model. Extensive experiments have demonstrated the effectiveness
of GTrans on three distinct scenarios for eight benchmark datasets where
suboptimal data is presented. Remarkably, GTrans performs the best in most
cases with improvements up to 2.8%, 8.2% and 3.8% over the best baselines on
three experimental settings. Code is released at
https://github.com/ChandlerBang/GTrans."
Optimizing Test-Time Query Representations for Dense Retrieval,0.092549,"Recent developments of dense retrieval rely on quality representations of
queries and contexts from pre-trained query and context encoders. In this
paper, we introduce TOUR (Test-Time Optimization of Query Representations),
which further optimizes instance-level query representations guided by signals
from test-time retrieval results. We leverage a cross-encoder re-ranker to
provide fine-grained pseudo labels over retrieval results and iteratively
optimize query representations with gradient descent. Our theoretical analysis
reveals that TOUR can be viewed as a generalization of the classical Rocchio
algorithm for pseudo relevance feedback, and we present two variants that
leverage pseudo-labels as hard binary or soft continuous labels. We first apply
TOUR on phrase retrieval with our proposed phrase re-ranker, and also evaluate
its effectiveness on passage retrieval with an off-the-shelf re-ranker. TOUR
greatly improves end-to-end open-domain question answering accuracy, as well as
passage retrieval performance. TOUR also consistently improves direct
re-ranking by up to 2.0% while running 1.3-2.4x faster with an efficient
implementation."
End-to-End 3D Hand Pose Estimation from Stereo Cameras,0.692917,"This work proposes an end-to-end approach to estimate full 3D hand pose from
stereo cameras. Most existing methods of estimating hand pose from stereo
cameras apply stereo matching to obtain depth map and use depth-based solution
to estimate hand pose. In contrast, we propose to bypass the stereo matching
and directly estimate the 3D hand pose from the stereo image pairs. The
proposed neural network architecture extends from any keypoint predictor to
estimate the sparse disparity of the hand joints. In order to effectively train
the model, we propose a large scale synthetic dataset that is composed of
stereo image pairs and ground truth 3D hand pose annotations. Experiments show
that the proposed approach outperforms the existing methods based on the stereo
depth."
Signal Strength and Noise Drive Feature Preference in CNN Image Classifiers,0.0352007,"Feature preference in Convolutional Neural Network (CNN) image classifiers is
integral to their decision making process, and while the topic has been well
studied, it is still not understood at a fundamental level. We test a range of
task relevant feature attributes (including shape, texture, and color) with
varying degrees of signal and noise in highly controlled CNN image
classification experiments using synthetic datasets to determine feature
preferences. We find that CNNs will prefer features with stronger signal
strength and lower noise irrespective of whether the feature is texture, shape,
or color. This provides guidance for a predictive model for task relevant
feature preferences, demonstrates pathways for bias in machine models that can
be avoided with careful controls on experimental setup, and suggests that
comparisons between how humans and machines prefer task relevant features in
vision classification tasks should be revisited. Code to reproduce experiments
in this paper can be found at
\url{https://github.com/mwolff31/signal_preference}."
Toward Efficient Language Model Pretraining and Downstream Adaptation via Self-Evolution: A Case Study on SuperGLUE,0.823756,"This technical report briefly describes our JDExplore d-team's Vega v2
submission on the SuperGLUE leaderboard. SuperGLUE is more challenging than the
widely used general language understanding evaluation (GLUE) benchmark,
containing eight difficult language understanding tasks, including question
answering, natural language inference, word sense disambiguation, coreference
resolution, and reasoning. [Method] Instead of arbitrarily increasing the size
of a pretrained language model (PLM), our aim is to 1) fully extract knowledge
from the input pretraining data given a certain parameter budget, e.g., 6B, and
2) effectively transfer this knowledge to downstream tasks. To achieve goal 1),
we propose self-evolution learning for PLMs to wisely predict the informative
tokens that should be masked, and supervise the masked language modeling (MLM)
process with rectified smooth labels. For goal 2), we leverage the prompt
transfer technique to improve the low-resource tasks by transferring the
knowledge from the foundation model and related downstream tasks to the target
task. [Results] According to our submission record (Oct. 2022), with our
optimized pretraining and fine-tuning strategies, our 6B Vega method achieved
new state-of-the-art performance on 4/8 tasks, sitting atop the SuperGLUE
leaderboard on Oct. 8, 2022, with an average score of 91.3."
Artificial intelligence for topic modelling in Hindu philosophy: mapping themes between the Upanishads and the Bhagavad Gita,0.241744,"A distinct feature of Hindu religious and philosophical text is that they
come from a library of texts rather than single source. The Upanishads is known
as one of the oldest philosophical texts in the world that forms the foundation
of Hindu philosophy. The Bhagavad Gita is core text of Hindu philosophy and is
known as a text that summarises the key philosophies of the Upanishads with
major focus on the philosophy of karma. These texts have been translated into
many languages and there exists studies about themes and topics that are
prominent; however, there is not much study of topic modelling using language
models which are powered by deep learning. In this paper, we use advanced
language produces such as BERT to provide topic modelling of the key texts of
the Upanishads and the Bhagavad Gita. We analyse the distinct and overlapping
topics amongst the texts and visualise the link of selected texts of the
Upanishads with Bhagavad Gita. Our results show a very high similarity between
the topics of these two texts with the mean cosine similarity of 73%. We find
that out of the fourteen topics extracted from the Bhagavad Gita, nine of them
have a cosine similarity of more than 70% with the topics of the Upanishads. We
also found that topics generated by the BERT-based models show very high
coherence as compared to that of conventional models. Our best performing model
gives a coherence score of 73% on the Bhagavad Gita and 69% on The Upanishads.
The visualization of the low dimensional embeddings of these texts shows very
clear overlapping among their topics adding another level of validation to our
results."
Rolling Horizon based Temporal Decomposition for the Offline Pickup and Delivery Problem with Time Windows,0.236943,"The offline pickup and delivery problem with time windows (PDPTW) is a
classical combinatorial optimization problem in the transportation community,
which has proven to be very challenging computationally. Due to the complexity
of the problem, practical problem instances can be solved only via heuristics,
which trade-off solution quality for computational tractability. Among the
various heuristics, a common strategy is problem decomposition, that is, the
reduction of a large-scale problem into a collection of smaller sub-problems,
with spatial and temporal decompositions being two natural approaches. While
spatial decomposition has been successful in certain settings, effective
temporal decomposition has been challenging due to the difficulty of stitching
together the sub-problem solutions across the decomposition boundaries. In this
work, we introduce a novel temporal decomposition scheme for solving a class of
PDPTWs that have narrow time windows, for which it is able to provide both fast
and high-quality solutions. We utilize techniques that have been popularized
recently in the context of online dial-a-ride problems along with the general
idea of rolling horizon optimization. To the best of our knowledge, this is the
first attempt to solve offline PDPTWs using such an approach. To show the
performance and scalability of our framework, we use the optimization of
paratransit services as a motivating example. We compare our results with an
offline heuristic algorithm using Google OR-Tools. In smaller problem
instances, the baseline approach is as competitive as our framework. However,
in larger problem instances, our framework is more scalable and can provide
good solutions to problem instances of varying degrees of difficulty, while the
baseline algorithm often fails to find a feasible solution within comparable
compute times."
Elliptic PDE learning is provably data-efficient,0.17317,"PDE learning is an emerging field that combines physics and machine learning
to recover unknown physical systems from experimental data. While deep learning
models traditionally require copious amounts of training data, recent PDE
learning techniques achieve spectacular results with limited data availability.
Still, these results are empirical. Our work provides theoretical guarantees on
the number of input-output training pairs required in PDE learning.
Specifically, we exploit randomized numerical linear algebra and PDE theory to
derive a provably data-efficient algorithm that recovers solution operators of
3D uniformly elliptic PDEs from input-output data and achieves an exponential
convergence rate of the error with respect to the size of the training dataset
with an exceptionally high probability of success."
GIAOTracker: A comprehensive framework for MCMOT with global information and optimizing strategies in VisDrone 2021,0.86646,"In recent years, algorithms for multiple object tracking tasks have benefited
from great progresses in deep models and video quality. However, in challenging
scenarios like drone videos, they still suffer from problems, such as small
objects, camera movements and view changes. In this paper, we propose a new
multiple object tracker, which employs Global Information And some Optimizing
strategies, named GIAOTracker. It consists of three stages, i.e., online
tracking, global link and post-processing. Given detections in every frame, the
first stage generates reliable tracklets using information of camera motion,
object motion and object appearance. Then they are associated into trajectories
by exploiting global clues and refined through four post-processing methods.
With the effectiveness of the three stages, GIAOTracker achieves
state-of-the-art performance on the VisDrone MOT dataset and wins the 3rd place
in the VisDrone2021 MOT Challenge."
Multimodal Inverse Cloze Task for Knowledge-based Visual Question Answering,0.44431,"We present a new pre-training method, Multimodal Inverse Cloze Task, for
Knowledge-based Visual Question Answering about named Entities (KVQAE). KVQAE
is a recently introduced task that consists in answering questions about named
entities grounded in a visual context using a Knowledge Base. Therefore, the
interaction between the modalities is paramount to retrieve information and
must be captured with complex fusion models. As these models require a lot of
training data, we design this pre-training task from existing work in textual
Question Answering. It consists in considering a sentence as a pseudo-question
and its context as a pseudo-relevant passage and is extended by considering
images near texts in multimodal documents. Our method is applicable to
different neural network architectures and leads to a 9% relative-MRR and 15%
relative-F1 gain for retrieval and reading comprehension, respectively, over a
no-pre-training baseline."
Black-box Prompt Learning for Pre-trained Language Models,0.447845,"The increasing scale of general-purpose Pre-trained Language Models (PLMs)
necessitates the study of more efficient adaptation across different downstream
tasks. In this paper, we establish a Black-box Discrete Prompt Learning (BDPL)
to resonate with pragmatic interactions between the cloud infrastructure and
edge devices. Particularly, instead of fine-tuning the model in the cloud, we
adapt PLMs by prompt learning, which efficiently optimizes only a few
parameters of the discrete prompts. Moreover, we consider the scenario that we
do not have access to the parameters and gradients of the pre-trained models,
except for its outputs given inputs. This black-box setting secures the cloud
infrastructure from potential attack and misuse to cause a single-point
failure, which is preferable to the white-box counterpart by current
infrastructures. Under this black-box constraint, we apply a variance-reduced
policy gradient algorithm to estimate the gradients of parameters in the
categorical distribution of each discrete prompt. In light of our method, the
user devices can efficiently tune their tasks by querying the PLMs bounded by a
range of API calls. Our experiments on RoBERTa and GPT-3 demonstrate that the
proposed algorithm achieves significant improvement on eight benchmarks in a
cloud-device collaboration manner. Finally, we conduct in-depth case studies to
comprehensively analyze our method in terms of various data sizes, prompt
lengths, training budgets, optimization objectives, prompt transferability, and
explanations of the learned prompts. Our code will be available at
https://github.com/shizhediao/Black-Box-Prompt-Learning."
Findings of the WMT 2022 Shared Task on Translation Suggestion,0.046529,"We report the result of the first edition of the WMT shared task on
Translation Suggestion (TS). The task aims to provide alternatives for specific
words or phrases given the entire documents generated by machine translation
(MT). It consists two sub-tasks, namely, the naive translation suggestion and
translation suggestion with hints. The main difference is that some hints are
provided in sub-task two, therefore, it is easier for the model to generate
more accurate suggestions. For sub-task one, we provide the corpus for the
language pairs English-German and English-Chinese. And only English-Chinese
corpus is provided for the sub-task two.
  We received 92 submissions from 5 participating teams in sub-task one and 6
submissions for the sub-task 2, most of them covering all of the translation
directions. We used the automatic metric BLEU for evaluating the performance of
each submission."
Real-time volumetric rendering of dynamic humans,0.113959,"We present a method for fast 3D reconstruction and real-time rendering of
dynamic humans from monocular videos with accompanying parametric body fits.
Our method can reconstruct a dynamic human in less than 3h using a single GPU,
compared to recent state-of-the-art alternatives that take up to 72h. These
speedups are obtained by using a lightweight deformation model solely based on
linear blend skinning, and an efficient factorized volumetric representation
for modeling the shape and color of the person in canonical pose. Moreover, we
propose a novel local ray marching rendering which, by exploiting standard GPU
hardware and without any baking or conversion of the radiance field, allows
visualizing the neural human on a mobile VR device at 40 frames per second with
minimal loss of visual quality. Our experimental evaluation shows superior or
competitive results with state-of-the art methods while obtaining large
training speedup, using a simple model, and achieving real-time rendering."
UniDU: Towards A Unified Generative Dialogue Understanding Framework,0.216707,"With the development of pre-trained language models, remarkable success has
been witnessed in dialogue understanding (DU). However, current DU approaches
usually employ independent models for each distinct DU task without considering
shared knowledge across different DU tasks. In this paper, we propose a unified
generative dialogue understanding framework, named {\em UniDU}, to achieve
effective information exchange across diverse DU tasks. Here, we reformulate
all DU tasks into a unified prompt-based generative model paradigm. More
importantly, a novel model-agnostic multi-task training strategy (MATS) is
introduced to dynamically adapt the weights of diverse tasks for best knowledge
sharing during training, based on the nature and available data of each task.
Experiments on ten DU datasets covering five fundamental DU tasks show that the
proposed UniDU framework largely outperforms task-specific well-designed
methods on all tasks. MATS also reveals the knowledge-sharing structure of
these tasks. Finally, UniDU obtains promising performance in the unseen
dialogue domain, showing the great potential for generalization."
Motivating Physical Activity via Competitive Human-Robot Interaction,0.352892,"This project aims to motivate research in competitive human-robot interaction
by creating a robot competitor that can challenge human users in certain
scenarios such as physical exercise and games. With this goal in mind, we
introduce the Fencing Game, a human-robot competition used to evaluate both the
capabilities of the robot competitor and user experience. We develop the robot
competitor through iterative multi-agent reinforcement learning and show that
it can perform well against human competitors. Our user study additionally
found that our system was able to continuously create challenging and enjoyable
interactions that significantly increased human subjects' heart rates. The
majority of human subjects considered the system to be entertaining and
desirable for improving the quality of their exercise."
RuArg-2022: Argument Mining Evaluation,0.425209,"Argumentation analysis is a field of computational linguistics that studies
methods for extracting arguments from texts and the relationships between them,
as well as building argumentation structure of texts. This paper is a report of
the organizers on the first competition of argumentation analysis systems
dealing with Russian language texts within the framework of the Dialogue
conference. During the competition, the participants were offered two tasks:
stance detection and argument classification. A corpus containing 9,550
sentences (comments on social media posts) on three topics related to the
COVID-19 pandemic (vaccination, quarantine, and wearing masks) was prepared,
annotated, and used for training and testing. The system that won the first
place in both tasks used the NLI (Natural Language Inference) variant of the
BERT architecture, automatic translation into English to apply a specialized
BERT model, retrained on Twitter posts discussing COVID-19, as well as
additional masking of target entities. This system showed the following
results: for the stance detection task an F1-score of 0.6968, for the argument
classification task an F1-score of 0.7404. We hope that the prepared dataset
and baselines will help to foster further research on argument mining for the
Russian language."
Studying Bias in GANs through the Lens of Race,0.978034,"In this work, we study how the performance and evaluation of generative image
models are impacted by the racial composition of their training datasets. By
examining and controlling the racial distributions in various training
datasets, we are able to observe the impacts of different training
distributions on generated image quality and the racial distributions of the
generated images. Our results show that the racial compositions of generated
images successfully preserve that of the training data. However, we observe
that truncation, a technique used to generate higher quality images during
inference, exacerbates racial imbalances in the data. Lastly, when examining
the relationship between image quality and race, we find that the highest
perceived visual quality images of a given race come from a distribution where
that race is well-represented, and that annotators consistently prefer
generated images of white people over those of Black people."
Explainable Supervised Domain Adaptation,0.0543105,"Domain adaptation techniques have contributed to the success of deep
learning. Leveraging knowledge from an auxiliary source domain for learning in
labeled data-scarce target domain is fundamental to domain adaptation. While
these techniques result in increasing accuracy, the adaptation process,
particularly the knowledge leveraged from the source domain, remains unclear.
This paper proposes an explainable by design supervised domain adaptation
framework - XSDA-Net. We integrate a case-based reasoning mechanism into the
XSDA-Net to explain the prediction of a test instance in terms of
similar-looking regions in the source and target train images. We empirically
demonstrate the utility of the proposed framework by curating the domain
adaptation settings on datasets popularly known to exhibit part-based
explainability."
Aspect-based Sentiment Analysis through EDU-level Attentions,0.195967,"A sentence may express sentiments on multiple aspects. When these aspects are
associated with different sentiment polarities, a model's accuracy is often
adversely affected. We observe that multiple aspects in such hard sentences are
mostly expressed through multiple clauses, or formally known as elementary
discourse units (EDUs), and one EDU tends to express a single aspect with
unitary sentiment towards that aspect. In this paper, we propose to consider
EDU boundaries in sentence modeling, with attentions at both word and EDU
levels. Specifically, we highlight sentiment-bearing words in EDU through
word-level sparse attention. Then at EDU level, we force the model to attend to
the right EDU for the right aspect, by using EDU-level sparse attention and
orthogonal regularization. Experiments on three benchmark datasets show that
our simple EDU-Attention model outperforms state-of-the-art baselines. Because
EDU can be automatically segmented with high accuracy, our model can be applied
to sentences directly without the need of manual EDU boundary annotation."
Optimizing Prompts for Text-to-Image Generation,0.611494,"Well-designed prompts can guide text-to-image models to generate amazing
images. However, the performant prompts are often model-specific and misaligned
with user input. Instead of laborious human engineering, we propose prompt
adaptation, a general framework that automatically adapts original user input
to model-preferred prompts. Specifically, we first perform supervised
fine-tuning with a pretrained language model on a small collection of manually
engineered prompts. Then we use reinforcement learning to explore better
prompts. We define a reward function that encourages the policy to generate
more aesthetically pleasing images while preserving the original user
intentions. Experimental results on Stable Diffusion show that our method
outperforms manual prompt engineering in terms of both automatic metrics and
human preference ratings. Moreover, reinforcement learning further boosts
performance, especially on out-of-domain prompts. The pretrained checkpoints
are available at https://aka.ms/promptist. The demo can be found at
https://aka.ms/promptist-demo."
CVSS Corpus and Massively Multilingual Speech-to-Speech Translation,0.995253,"We introduce CVSS, a massively multilingual-to-English speech-to-speech
translation (S2ST) corpus, covering sentence-level parallel S2ST pairs from 21
languages into English. CVSS is derived from the Common Voice speech corpus and
the CoVoST 2 speech-to-text translation (ST) corpus, by synthesizing the
translation text from CoVoST 2 into speech using state-of-the-art TTS systems.
Two versions of translation speeches are provided: 1) CVSS-C: All the
translation speeches are in a single high-quality canonical voice; 2) CVSS-T:
The translation speeches are in voices transferred from the corresponding
source speeches. In addition, CVSS provides normalized translation text which
matches the pronunciation in the translation speech. On each version of CVSS,
we built baseline multilingual direct S2ST models and cascade S2ST models,
verifying the effectiveness of the corpus. To build strong cascade S2ST
baselines, we trained an ST model on CoVoST 2, which outperforms the previous
state-of-the-art trained on the corpus without extra data by 5.8 BLEU.
Nevertheless, the performance of the direct S2ST models approaches the strong
cascade baselines when trained from scratch, and with only 0.1 or 0.7 BLEU
difference on ASR transcribed translation when initialized from matching ST
models."
UstanceBR: a multimodal language resource for stance prediction,0.108154,"This work introduces UstanceBR, a multimodal corpus in the Brazilian
Portuguese Twitter domain for target-based stance prediction. The corpus
comprises 86.8 k labelled stances towards selected target topics, and extensive
network information about the users who published these stances on social
media. In this article we describe the corpus multimodal data, and a number of
usage examples in both in-domain and zero-shot stance prediction based on text-
and network-related information, which are intended to provide initial baseline
results for future studies in the field."
Knowledge Engineering for Wind Energy,0.250876,"With the rapid evolution of the wind energy sector, there is an
ever-increasing need to create value from the vast amounts of data made
available both from within the domain, as well as from other sectors. This
article addresses the challenges faced by wind energy domain experts in
converting data into domain knowledge, connecting and integrating it with other
sources of knowledge, and making it available for use in next generation
artificially intelligent systems. To this end, this article highlights the role
that knowledge engineering can play in the process of digital transformation of
the wind energy sector. It presents the main concepts underpinning
Knowledge-Based Systems and summarises previous work in the areas of knowledge
engineering and knowledge representation in a manner that is relevant and
accessible to domain experts. A systematic analysis of the current
state-of-the-art on knowledge engineering in the wind energy domain is
performed, with available tools put into perspective by establishing the main
domain actors and their needs and identifying key problematic areas. Finally,
guidelines for further development and improvement are provided."
Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback,1.0,"We apply preference modeling and reinforcement learning from human feedback
(RLHF) to finetune language models to act as helpful and harmless assistants.
We find this alignment training improves performance on almost all NLP
evaluations, and is fully compatible with training for specialized skills such
as python coding and summarization. We explore an iterated online mode of
training, where preference models and RL policies are updated on a weekly
cadence with fresh human feedback data, efficiently improving our datasets and
models. Finally, we investigate the robustness of RLHF training, and identify a
roughly linear relation between the RL reward and the square root of the KL
divergence between the policy and its initialization. Alongside our main
results, we perform peripheral analyses on calibration, competing objectives,
and the use of OOD detection, compare our models with human writers, and
provide samples from our models using prompts appearing in recent related work."
Overlap Bias Matching is Necessary for Point Cloud Registration,0.133406,"Point cloud registration is a fundamental problem in many domains.
Practically, the overlap between point clouds to be registered may be
relatively small. Most unsupervised methods lack effective initial evaluation
of overlap, leading to suboptimal registration accuracy. To address this issue,
we propose an unsupervised network Overlap Bias Matching Network (OBMNet) for
partial point cloud registration. Specifically, we propose a plug-and-play
Overlap Bias Matching Module (OBMM) comprising two integral components, overlap
sampling module and bias prediction module. These two components are utilized
to capture the distribution of overlapping regions and predict bias
coefficients of point cloud common structures, respectively. Then, we integrate
OBMM with the neighbor map matching module to robustly identify correspondences
by precisely merging matching scores of points within the neighborhood, which
addresses the ambiguities in single-point features. OBMNet can maintain
efficacy even in pair-wise registration scenarios with low overlap ratios.
Experimental results on extensive datasets demonstrate that our approach's
performance achieves a significant improvement compared to the state-of-the-art
registration approach."
Focal Length and Object Pose Estimation via Render and Compare,0.914306,"We introduce FocalPose, a neural render-and-compare method for jointly
estimating the camera-object 6D pose and camera focal length given a single RGB
input image depicting a known object. The contributions of this work are
twofold. First, we derive a focal length update rule that extends an existing
state-of-the-art render-and-compare 6D pose estimator to address the joint
estimation task. Second, we investigate several different loss functions for
jointly estimating the object pose and focal length. We find that a combination
of direct focal length regression with a reprojection loss disentangling the
contribution of translation, rotation, and focal length leads to improved
results. We show results on three challenging benchmark datasets that depict
known 3D models in uncontrolled settings. We demonstrate that our focal length
and 6D pose estimates have lower error than the existing state-of-the-art
methods."
Hidden Poison: Machine Unlearning Enables Camouflaged Poisoning Attacks,0.949666,"We introduce camouflaged data poisoning attacks, a new attack vector that
arises in the context of machine unlearning and other settings when model
retraining may be induced. An adversary first adds a few carefully crafted
points to the training dataset such that the impact on the model's predictions
is minimal. The adversary subsequently triggers a request to remove a subset of
the introduced points at which point the attack is unleashed and the model's
predictions are negatively affected. In particular, we consider clean-label
targeted attacks (in which the goal is to cause the model to misclassify a
specific test point) on datasets including CIFAR-10, Imagenette, and Imagewoof.
This attack is realized by constructing camouflage datapoints that mask the
effect of a poisoned dataset."
A Low Latency Adaptive Coding Spiking Framework for Deep Reinforcement Learning,0.0145814,"In recent years, spiking neural networks (SNNs) have been used in
reinforcement learning (RL) due to their low power consumption and event-driven
features. However, spiking reinforcement learning (SRL), which suffers from
fixed coding methods, still faces the problems of high latency and poor
versatility. In this paper, we use learnable matrix multiplication to encode
and decode spikes, improving the flexibility of the coders and thus reducing
latency. Meanwhile, we train the SNNs using the direct training method and use
two different structures for online and offline RL algorithms, which gives our
model a wider range of applications. Extensive experiments have revealed that
our method achieves optimal performance with ultra-low latency (as low as 0.8%
of other SRL methods) and excellent energy efficiency (up to 5X the DNNs) in
different algorithms and different environments."
Towards Out-of-Distribution Adversarial Robustness,0.334378,"Adversarial robustness continues to be a major challenge for deep learning. A
core issue is that robustness to one type of attack often fails to transfer to
other attacks. While prior work establishes a theoretical trade-off in
robustness against different $L_p$ norms, we show that there is potential for
improvement against many commonly used attacks by adopting a domain
generalisation approach. Concretely, we treat each type of attack as a domain,
and apply the Risk Extrapolation method (REx), which promotes similar levels of
robustness against all training attacks. Compared to existing methods, we
obtain similar or superior worst-case adversarial robustness on attacks seen
during training. Moreover, we achieve superior performance on families or
tunings of attacks only encountered at test time. On ensembles of attacks, our
approach improves the accuracy from 3.4% with the best existing baseline to
25.9% on MNIST, and from 16.9% to 23.5% on CIFAR10."
Sort by Structure: Language Model Ranking as Dependency Probing,0.156068,"Making an informed choice of pre-trained language model (LM) is critical for
performance, yet environmentally costly, and as such widely underexplored. The
field of Computer Vision has begun to tackle encoder ranking, with promising
forays into Natural Language Processing, however they lack coverage of
linguistic tasks such as structured prediction. We propose probing to rank LMs,
specifically for parsing dependencies in a given language, by measuring the
degree to which labeled trees are recoverable from an LM's contextualized
embeddings. Across 46 typologically and architecturally diverse LM-language
pairs, our probing approach predicts the best LM choice 79% of the time using
orders of magnitude less compute than training a full parser. Within this
study, we identify and analyze one recently proposed decoupled LM - RemBERT -
and find it strikingly contains less inherent dependency information, but often
yields the best parser after full fine-tuning. Without this outlier our
approach identifies the best LM in 89% of cases."
MCoNaLa: A Benchmark for Code Generation from Multiple Natural Languages,0.568546,"While there has been a recent burgeoning of applications at the intersection
of natural and programming languages, such as code generation and code
summarization, these applications are usually English-centric. This creates a
barrier for program developers who are not proficient in English. To mitigate
this gap in technology development across languages, we propose a multilingual
dataset, MCoNaLa, to benchmark code generation from natural language commands
extending beyond English. Modeled off of the methodology from the English
Code/Natural Language Challenge (CoNaLa) dataset, we annotated a total of 896
NL-code pairs in three languages: Spanish, Japanese, and Russian. We present a
quantitative evaluation of performance on the MCoNaLa dataset by testing with
state-of-the-art code generation systems. While the difficulties vary across
these three languages, all systems lag significantly behind their English
counterparts, revealing the challenges in adapting code generation to new
languages."
Topic Taxonomy Expansion via Hierarchy-Aware Topic Phrase Generation,0.566974,"Topic taxonomies display hierarchical topic structures of a text corpus and
provide topical knowledge to enhance various NLP applications. To dynamically
incorporate new topic information, several recent studies have tried to expand
(or complete) a topic taxonomy by inserting emerging topics identified in a set
of new documents. However, existing methods focus only on frequent terms in
documents and the local topic-subtopic relations in a taxonomy, which leads to
limited topic term coverage and fails to model the global topic hierarchy. In
this work, we propose a novel framework for topic taxonomy expansion, named
TopicExpan, which directly generates topic-related terms belonging to new
topics. Specifically, TopicExpan leverages the hierarchical relation structure
surrounding a new topic and the textual content of an input document for topic
term generation. This approach encourages newly-inserted topics to further
cover important but less frequent terms as well as to keep their relation
consistency within the taxonomy. Experimental results on two real-world text
corpora show that TopicExpan significantly outperforms other baseline methods
in terms of the quality of output taxonomies."
MonoJSG: Joint Semantic and Geometric Cost Volume for Monocular 3D Object Detection,0.847963,"Due to the inherent ill-posed nature of 2D-3D projection, monocular 3D object
detection lacks accurate depth recovery ability. Although the deep neural
network (DNN) enables monocular depth-sensing from high-level learned features,
the pixel-level cues are usually omitted due to the deep convolution mechanism.
To benefit from both the powerful feature representation in DNN and pixel-level
geometric constraints, we reformulate the monocular object depth estimation as
a progressive refinement problem and propose a joint semantic and geometric
cost volume to model the depth error. Specifically, we first leverage neural
networks to learn the object position, dimension, and dense normalized 3D
object coordinates. Based on the object depth, the dense coordinates patch
together with the corresponding object features is reprojected to the image
space to build a cost volume in a joint semantic and geometric error manner.
The final depth is obtained by feeding the cost volume to a refinement network,
where the distribution of semantic and geometric error is regularized by direct
depth supervision. Through effectively mitigating depth error by the refinement
framework, we achieve state-of-the-art results on both the KITTI and Waymo
datasets."
Results and findings of the 2021 Image Similarity Challenge,0.179247,"The 2021 Image Similarity Challenge introduced a dataset to serve as a new
benchmark to evaluate recent image copy detection methods. There were 200
participants to the competition. This paper presents a quantitative and
qualitative analysis of the top submissions. It appears that the most difficult
image transformations involve either severe image crops or hiding into
unrelated images, combined with local pixel perturbations. The key algorithmic
elements in the winning submissions are: training on strong augmentations,
self-supervised learning, score normalization, explicit overlay detection, and
global descriptor matching followed by pairwise image comparison."
Fast Vehicle Detection and Tracking on Fisheye Traffic Monitoring Video using CNN and Bounding Box Propagation,0.308985,"We design a fast car detection and tracking algorithm for traffic monitoring
fisheye video mounted on crossroads. We use ICIP 2020 VIP Cup dataset and adopt
YOLOv5 as the object detection base model. The nighttime video of this dataset
is very challenging, and the detection accuracy (AP50) of the base model is
about 54%. We design a reliable car detection and tracking algorithm based on
the concept of bounding box propagation among frames, which provides 17.9
percentage points (pp) and 6.2 pp. accuracy improvement over the base model for
the nighttime and daytime videos, respectively. To speed up, the grayscale
frame difference is used for the intermediate frames in a segment, which can
double the processing speed."
Convergence Rates for Localized Actor-Critic in Networked Markov Potential Games,0.663078,"We introduce a class of networked Markov potential games in which agents are
associated with nodes in a network. Each agent has its own local potential
function, and the reward of each agent depends only on the states and actions
of the agents within a neighborhood. In this context, we propose a localized
actor-critic algorithm. The algorithm is scalable since each agent uses only
local information and does not need access to the global state. Further, the
algorithm overcomes the curse of dimensionality through the use of function
approximation. Our main results provide finite-sample guarantees up to a
localization error and a function approximation error. Specifically, we achieve
an $\tilde{\mathcal{O}}(\tilde{\epsilon}^{-4})$ sample complexity measured by
the averaged Nash regret. This is the first finite-sample bound for multi-agent
competitive games that does not depend on the number of agents."
Beyond Masking: Demystifying Token-Based Pre-Training for Vision Transformers,0.273035,"The past year has witnessed a rapid development of masked image modeling
(MIM). MIM is mostly built upon the vision transformers, which suggests that
self-supervised visual representations can be done by masking input image parts
while requiring the target model to recover the missing contents. MIM has
demonstrated promising results on downstream tasks, yet we are interested in
whether there exist other effective ways to `learn by recovering missing
contents'. In this paper, we investigate this topic by designing five other
learning objectives that follow the same procedure as MIM but degrade the input
image in different ways. With extensive experiments, we manage to summarize a
few design principles for token-based pre-training of vision transformers. In
particular, the best practice is obtained by keeping the original image style
and enriching spatial masking with spatial misalignment -- this design achieves
superior performance over MIM in a series of downstream recognition tasks
without extra computational cost. The code is available at
https://github.com/sunsmarterjie/beyond_masking."
MixSKD: Self-Knowledge Distillation from Mixup for Image Recognition,0.780982,"Unlike the conventional Knowledge Distillation (KD), Self-KD allows a network
to learn knowledge from itself without any guidance from extra networks. This
paper proposes to perform Self-KD from image Mixture (MixSKD), which integrates
these two techniques into a unified framework. MixSKD mutually distills feature
maps and probability distributions between the random pair of original images
and their mixup images in a meaningful way. Therefore, it guides the network to
learn cross-image knowledge by modelling supervisory signals from mixup images.
Moreover, we construct a self-teacher network by aggregating multi-stage
feature maps for providing soft labels to supervise the backbone classifier,
further improving the efficacy of self-boosting. Experiments on image
classification and transfer learning to object detection and semantic
segmentation demonstrate that MixSKD outperforms other state-of-the-art Self-KD
and data augmentation methods. The code is available at
https://github.com/winycg/Self-KD-Lib."
Towards Designing a ChatGPT Conversational Companion for Elderly People,0.783826,"Loneliness and social isolation are serious and widespread problems among
older people, affecting their physical and mental health, quality of life, and
longevity. In this paper, we propose a ChatGPT-based conversational companion
system for elderly people. The system is designed to provide companionship and
help reduce feelings of loneliness and social isolation. The system was
evaluated with a preliminary study. The results showed that the system was able
to generate responses that were relevant to the created elderly personas.
However, it is essential to acknowledge the limitations of ChatGPT, such as
potential biases and misinformation, and to consider the ethical implications
of using AI-based companionship for the elderly, including privacy concerns."
Does Synthetic Data Make Large Language Models More Efficient?,0.036312,"Natural Language Processing (NLP) has undergone transformative changes with
the advent of deep learning methodologies. One challenge persistently
confronting researchers is the scarcity of high-quality, annotated datasets
that drive these models. This paper explores the nuances of synthetic data
generation in NLP, with a focal point on template-based question generation. By
assessing its advantages, including data augmentation potential and the
introduction of structured variety, we juxtapose these benefits against
inherent limitations, such as the risk of overfitting and the constraints posed
by pre-defined templates. Drawing from empirical evaluations, we demonstrate
the impact of template-based synthetic data on the performance of modern
transformer models. We conclude by emphasizing the delicate balance required
between synthetic and real-world data, and the future trajectories of
integrating synthetic data in model training pipelines. The findings aim to
guide NLP practitioners in harnessing synthetic data's potential, ensuring
optimal model performance in diverse applications."
JAMES: Normalizing Job Titles with Multi-Aspect Graph Embeddings and Reasoning,0.272866,"In online job marketplaces, it is important to establish a well-defined job
title taxonomy for various downstream tasks (e.g., job recommendation, users'
career analysis, and turnover prediction). Job Title Normalization (JTN) is
such a cleaning step to classify user-created non-standard job titles into
normalized ones. However, solving the JTN problem is non-trivial with
challenges: (1) semantic similarity of different job titles, (2) non-normalized
user-created job titles, and (3) large-scale and long-tailed job titles in
real-world applications. To this end, we propose a novel solution, named JAMES,
that constructs three unique embeddings (i.e., graph, contextual, and
syntactic) of a target job title to effectively capture its various traits. We
further propose a multi-aspect co-attention mechanism to attentively combine
these embeddings, and employ neural logical reasoning representations to
collaboratively estimate similarities between messy job titles and normalized
job titles in a reasoning space. To evaluate JAMES, we conduct comprehensive
experiments against ten competing models on a large-scale real-world dataset
with over 350,000 job titles. Our experimental results show that JAMES
significantly outperforms the best baseline by 10.06% in Precision@10 and by
17.52% in NDCG@10, respectively."
Generalized Strategic Classification and the Case of Aligned Incentives,0.609014,"Strategic classification studies learning in settings where self-interested
users can strategically modify their features to obtain favorable predictive
outcomes. A key working assumption, however, is that ""favorable"" always means
""positive""; this may be appropriate in some applications (e.g., loan approval),
but reduces to a fairly narrow view of what user interests can be. In this work
we argue for a broader perspective on what accounts for strategic user
behavior, and propose and study a flexible model of generalized strategic
classification. Our generalized model subsumes most current models but includes
other novel settings; among these, we identify and target one intriguing
sub-class of problems in which the interests of users and the system are
aligned. This setting reveals a surprising fact: that standard max-margin
losses are ill-suited for strategic inputs. Returning to our fully generalized
model, we propose a novel max-margin framework for strategic learning that is
practical and effective, and which we analyze theoretically. We conclude with a
set of experiments that empirically demonstrate the utility of our approach."
Pushing the limits of fairness impossibility: Who's the fairest of them all?,0.36658,"The impossibility theorem of fairness is a foundational result in the
algorithmic fairness literature. It states that outside of special cases, one
cannot exactly and simultaneously satisfy all three common and intuitive
definitions of fairness - demographic parity, equalized odds, and predictive
rate parity. This result has driven most works to focus on solutions for one or
two of the metrics. Rather than follow suit, in this paper we present a
framework that pushes the limits of the impossibility theorem in order to
satisfy all three metrics to the best extent possible. We develop an
integer-programming based approach that can yield a certifiably optimal
post-processing method for simultaneously satisfying multiple fairness criteria
under small violations. We show experiments demonstrating that our
post-processor can improve fairness across the different definitions
simultaneously with minimal model performance reduction. We also discuss
applications of our framework for model selection and fairness explainability,
thereby attempting to answer the question: who's the fairest of them all?"
SMART: Sentences as Basic Units for Text Evaluation,0.473387,"Widely used evaluation metrics for text generation either do not work well
with longer texts or fail to evaluate all aspects of text quality. In this
paper, we introduce a new metric called SMART to mitigate such limitations.
Specifically, We treat sentences as basic units of matching instead of tokens,
and use a sentence matching function to soft-match candidate and reference
sentences. Candidate sentences are also compared to sentences in the source
documents to allow grounding (e.g., factuality) evaluation. Our results show
that system-level correlations of our proposed metric with a model-based
matching function outperforms all competing metrics on the SummEval
summarization meta-evaluation dataset, while the same metric with a
string-based matching function is competitive with current model-based metrics.
The latter does not use any neural model, which is useful during model
development phases where resources can be limited and fast evaluation is
required. Finally, we also conducted extensive analyses showing that our
proposed metrics work well with longer summaries and are less biased towards
specific models."
WinoGAViL: Gamified Association Benchmark to Challenge Vision-and-Language Models,0.464394,"While vision-and-language models perform well on tasks such as visual
question answering, they struggle when it comes to basic human commonsense
reasoning skills. In this work, we introduce WinoGAViL: an online game of
vision-and-language associations (e.g., between werewolves and a full moon),
used as a dynamic evaluation benchmark. Inspired by the popular card game
Codenames, a spymaster gives a textual cue related to several visual
candidates, and another player tries to identify them. Human players are
rewarded for creating associations that are challenging for a rival AI model
but still solvable by other human players. We use the game to collect 3.5K
instances, finding that they are intuitive for humans (>90% Jaccard index) but
challenging for state-of-the-art AI models, where the best model (ViLT)
achieves a score of 52%, succeeding mostly where the cue is visually salient.
Our analysis as well as the feedback we collect from players indicate that the
collected associations require diverse reasoning skills, including general
knowledge, common sense, abstraction, and more. We release the dataset, the
code and the interactive game, allowing future data collection that can be used
to develop models with better association abilities."
BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation and Mining,0.999338,"Pre-trained language models have attracted increasing attention in the
biomedical domain, inspired by their great success in the general natural
language domain. Among the two main branches of pre-trained language models in
the general language domain, i.e., BERT (and its variants) and GPT (and its
variants), the first one has been extensively studied in the biomedical domain,
such as BioBERT and PubMedBERT. While they have achieved great success on a
variety of discriminative downstream biomedical tasks, the lack of generation
ability constrains their application scope. In this paper, we propose BioGPT, a
domain-specific generative Transformer language model pre-trained on large
scale biomedical literature. We evaluate BioGPT on six biomedical NLP tasks and
demonstrate that our model outperforms previous models on most tasks.
Especially, we get 44.98%, 38.42% and 40.76% F1 score on BC5CDR, KD-DTI and DDI
end-to-end relation extraction tasks respectively, and 78.2% accuracy on
PubMedQA, creating a new record. Our case study on text generation further
demonstrates the advantage of BioGPT on biomedical literature to generate
fluent descriptions for biomedical terms. Code is available at
https://github.com/microsoft/BioGPT."
HCL-TAT: A Hybrid Contrastive Learning Method for Few-shot Event Detection with Task-Adaptive Threshold,0.521845,"Conventional event detection models under supervised learning settings suffer
from the inability of transfer to newly-emerged event types owing to lack of
sufficient annotations. A commonly-adapted solution is to follow a
identify-then-classify manner, which first identifies the triggers and then
converts the classification task via a few-shot learning paradigm. However,
these methods still fall far short of expectations due to: (i) insufficient
learning of discriminative representations in low-resource scenarios, and (ii)
trigger misidentification caused by the overlap of the learned representations
of triggers and non-triggers. To address the problems, in this paper, we
propose a novel Hybrid Contrastive Learning method with a Task-Adaptive
Threshold (abbreviated as HCLTAT), which enables discriminative representation
learning with a two-view contrastive loss (support-support and
prototype-query), and devises a easily-adapted threshold to alleviate
misidentification of triggers. Extensive experiments on the benchmark dataset
FewEvent demonstrate the superiority of our method to achieve better results
compared to the state-of-the-arts. All the code and data of this paper will be
available for online public access."
Reachability Verification Based Reliability Assessment for Deep Reinforcement Learning Controlled Robotics and Autonomous Systems,0.493345,"Deep Reinforcement Learning (DRL) has achieved impressive performance in
robotics and autonomous systems (RAS). A key challenge to its deployment in
real-life operations is the presence of spuriously unsafe DRL policies.
Unexplored states may lead the agent to make wrong decisions that could result
in hazards, especially in applications where DRL-trained end-to-end controllers
govern the behaviour of RAS. This paper proposes a novel quantitative
reliability assessment framework for DRL-controlled RAS, leveraging
verification evidence generated from formal reliability analysis of neural
networks. A two-level verification framework is introduced to check the safety
property with respect to inaccurate observations that are due to, e.g.,
environmental noise and state changes. Reachability verification tools are
leveraged locally to generate safety evidence of trajectories. In contrast, at
the global level, we quantify the overall reliability as an aggregated metric
of local safety evidence, corresponding to a set of distinct tasks and their
occurrence probabilities. The effectiveness of the proposed verification
framework is demonstrated and validated via experiments on real RAS."
Parameter-Efficient Low-Resource Dialogue State Tracking by Prompt Tuning,0.339732,"Dialogue state tracking (DST) is an important step in dialogue management to
keep track of users' beliefs. Existing works fine-tune all language model (LM)
parameters to tackle the DST task, which requires significant data and
computing resources for training and hosting. The cost grows exponentially in
the real-world deployment where dozens of fine-tuned LM are used for different
domains and tasks. To reduce parameter size and better utilize cross-task
shared information, we propose to use soft prompt token embeddings to learn
task properties. Without tuning LM parameters, our method drastically reduces
the number of parameters needed to less than 0.5% of prior works while achieves
better low-resource DST performance."
Multiple Attribute Fairness: Application to Fraud Detection,0.0648778,"We propose a fairness measure relaxing the equality conditions in the popular
equal odds fairness regime for classification. We design an iterative,
model-agnostic, grid-based heuristic that calibrates the outcomes per sensitive
attribute value to conform to the measure. The heuristic is designed to handle
high arity attribute values and performs a per attribute sanitization of
outcomes across different protected attribute values. We also extend our
heuristic for multiple attributes. Highlighting our motivating application,
fraud detection, we show that the proposed heuristic is able to achieve
fairness across multiple values of a single protected attribute, multiple
protected attributes. When compared to current fairness techniques, that focus
on two groups, we achieve comparable performance across several public data
sets."
Splicing ViT Features for Semantic Appearance Transfer,0.990579,"We present a method for semantically transferring the visual appearance of
one natural image to another. Specifically, our goal is to generate an image in
which objects in a source structure image are ""painted"" with the visual
appearance of their semantically related objects in a target appearance image.
Our method works by training a generator given only a single
structure/appearance image pair as input. To integrate semantic information
into our framework - a pivotal component in tackling this task - our key idea
is to leverage a pre-trained and fixed Vision Transformer (ViT) model which
serves as an external semantic prior. Specifically, we derive novel
representations of structure and appearance extracted from deep ViT features,
untwisting them from the learned self-attention modules. We then establish an
objective function that splices the desired structure and appearance
representations, interweaving them together in the space of ViT features. Our
framework, which we term ""Splice"", does not involve adversarial training, nor
does it require any additional input information such as semantic segmentation
or correspondences, and can generate high-resolution results, e.g., work in HD.
We demonstrate high quality results on a variety of in-the-wild image pairs,
under significant variations in the number of objects, their pose and
appearance."
Simplifying Multilingual News Clustering Through Projection From a Shared Space,0.451759,"The task of organizing and clustering multilingual news articles for media
monitoring is essential to follow news stories in real time. Most approaches to
this task focus on high-resource languages (mostly English), with low-resource
languages being disregarded. With that in mind, we present a much simpler
online system that is able to cluster an incoming stream of documents without
depending on language-specific features. We empirically demonstrate that the
use of multilingual contextual embeddings as the document representation
significantly improves clustering quality. We challenge previous crosslingual
approaches by removing the precondition of building monolingual clusters. We
model the clustering process as a set of linear classifiers to aggregate
similar documents, and correct closely-related multilingual clusters through
merging in an online fashion. Our system achieves state-of-the-art results on a
multilingual news stream clustering dataset, and we introduce a new evaluation
for zero-shot news clustering in multiple languages. We make our code available
as open-source."
Who's in Charge? Roles and Responsibilities of Decision-Making Components in Conversational Robots,0.376197,"Software architectures for conversational robots typically consist of
multiple modules, each designed for a particular processing task or
functionality. Some of these modules are developed for the purpose of making
decisions about the next action that the robot ought to perform in the current
context. Those actions may relate to physical movements, such as driving
forward or grasping an object, but may also correspond to communicative acts,
such as asking a question to the human user. In this position paper, we reflect
on the organization of those decision modules in human-robot interaction
platforms. We discuss the relative benefits and limitations of modular vs.
end-to-end architectures, and argue that, despite the increasing popularity of
end-to-end approaches, modular architectures remain preferable when developing
conversational robots designed to execute complex tasks in collaboration with
human users. We also show that most practical HRI architectures tend to be
either robot-centric or dialogue-centric, depending on where developers wish to
place the ``command center'' of their system. While those design choices may be
justified in some application domains, they also limit the robot's ability to
flexibly interleave physical movements and conversational behaviours. We
contend that architectures placing ``action managers'' and ``interaction
managers'' on an equal footing may provide the best path forward for future
human-robot interaction systems."
Protecting Celebrities from DeepFake with Identity Consistency Transformer,0.985963,"In this work we propose Identity Consistency Transformer, a novel face
forgery detection method that focuses on high-level semantics, specifically
identity information, and detecting a suspect face by finding identity
inconsistency in inner and outer face regions. The Identity Consistency
Transformer incorporates a consistency loss for identity consistency
determination. We show that Identity Consistency Transformer exhibits superior
generalization ability not only across different datasets but also across
various types of image degradation forms found in real-world applications
including deepfake videos. The Identity Consistency Transformer can be easily
enhanced with additional identity information when such information is
available, and for this reason it is especially well-suited for detecting face
forgeries involving celebrities. Code will be released at
\url{https://github.com/LightDXY/ICT_DeepFake}"
Procedural Image Programs for Representation Learning,0.750991,"Learning image representations using synthetic data allows training neural
networks without some of the concerns associated with real images, such as
privacy and bias. Existing work focuses on a handful of curated generative
processes which require expert knowledge to design, making it hard to scale up.
To overcome this, we propose training with a large dataset of twenty-one
thousand programs, each one generating a diverse set of synthetic images. These
programs are short code snippets, which are easy to modify and fast to execute
using OpenGL. The proposed dataset can be used for both supervised and
unsupervised representation learning, and reduces the gap between pre-training
with real and procedurally generated images by 38%."
MonoDTR: Monocular 3D Object Detection with Depth-Aware Transformer,0.991098,"Monocular 3D object detection is an important yet challenging task in
autonomous driving. Some existing methods leverage depth information from an
off-the-shelf depth estimator to assist 3D detection, but suffer from the
additional computational burden and achieve limited performance caused by
inaccurate depth priors. To alleviate this, we propose MonoDTR, a novel
end-to-end depth-aware transformer network for monocular 3D object detection.
It mainly consists of two components: (1) the Depth-Aware Feature Enhancement
(DFE) module that implicitly learns depth-aware features with auxiliary
supervision without requiring extra computation, and (2) the Depth-Aware
Transformer (DTR) module that globally integrates context- and depth-aware
features. Moreover, different from conventional pixel-wise positional
encodings, we introduce a novel depth positional encoding (DPE) to inject depth
positional hints into transformers. Our proposed depth-aware modules can be
easily plugged into existing image-only monocular 3D object detectors to
improve the performance. Extensive experiments on the KITTI dataset demonstrate
that our approach outperforms previous state-of-the-art monocular-based methods
and achieves real-time detection. Code is available at
https://github.com/kuanchihhuang/MonoDTR"
Examining Autoexposure for Challenging Scenes,0.864665,"Autoexposure (AE) is a critical step applied by camera systems to ensure
properly exposed images. While current AE algorithms are effective in well-lit
environments with constant illumination, these algorithms still struggle in
environments with bright light sources or scenes with abrupt changes in
lighting. A significant hurdle in developing new AE algorithms for challenging
environments, especially those with time-varying lighting, is the lack of
suitable image datasets. To address this issue, we have captured a new 4D
exposure dataset that provides a large solution space (i.e., shutter speed
range from (1/500 to 15 seconds) over a temporal sequence with moving objects,
bright lights, and varying lighting. In addition, we have designed a software
platform to allow AE algorithms to be used in a plug-and-play manner with the
dataset. Our dataset and associate platform enable repeatable evaluation of
different AE algorithms and provide a much-needed starting point to develop
better AE methods. We examine several existing AE strategies using our dataset
and show that most users prefer a simple saliency method for challenging
lighting conditions."
DIRECTOR: Generator-Classifiers For Supervised Language Modeling,0.579006,"Current language models achieve low perplexity but their resulting
generations still suffer from toxic responses, repetitiveness and
contradictions. The standard language modeling setup fails to address these
issues. In this paper, we introduce a new architecture, {\sc Director}, that
consists of a unified generator-classifier with both a language modeling and a
classification head for each output token. Training is conducted jointly using
both standard language modeling data, and data labeled with desirable and
undesirable sequences. Experiments in several settings show that the model has
competitive training and decoding speed compared to standard language models
while yielding superior results, alleviating known issues while maintaining
generation quality. It also outperforms existing model guiding approaches in
terms of both accuracy and efficiency."
Reasoning about Complex Networks: A Logic Programming Approach,0.519312,"Reasoning about complex networks has in recent years become an important
topic of study due to its many applications: the adoption of commercial
products, spread of disease, the diffusion of an idea, etc. In this paper, we
present the MANCaLog language, a formalism based on logic programming that
satisfies a set of desiderata proposed in previous work as recommendations for
the development of approaches to reasoning in complex networks. To the best of
our knowledge, this is the first formalism that satisfies all such criteria. We
first focus on algorithms for finding minimal models (on which multi-attribute
analysis can be done), and then on how this formalism can be applied in certain
real world scenarios. Towards this end, we study the problem of deciding group
membership in social networks: given a social network and a set of groups where
group membership of only some of the individuals in the network is known, we
wish to determine a degree of membership for the remaining group-individual
pairs. We develop a prototype implementation that we use to obtain experimental
results on two real world datasets, including a current social network of
criminal gangs in a major U.S.\ city. We then show how the assignment of degree
of membership to nodes in this case allows for a better understanding of the
criminal gang problem when combined with other social network mining techniques
-- including detection of sub-groups and identification of core group members
-- which would not be possible without further identification of additional
group members."
"Deep Insights of Learning based Micro Expression Recognition: A Perspective on Promises, Challenges and Research Needs",0.547467,"Micro expression recognition (MER) is a very challenging area of research due
to its intrinsic nature and fine-grained changes. In the literature, the
problem of MER has been solved through handcrafted/descriptor-based techniques.
However, in recent times, deep learning (DL) based techniques have been adopted
to gain higher performance for MER. Also, rich survey articles on MER are
available by summarizing the datasets, experimental settings, conventional and
deep learning methods. In contrast, these studies lack the ability to convey
the impact of network design paradigms and experimental setting strategies for
DL-based MER. Therefore, this paper aims to provide a deep insight into the
DL-based MER frameworks with a perspective on promises in network model
designing, experimental strategies, challenges, and research needs. Also, the
detailed categorization of available MER frameworks is presented in various
aspects of model design and technical characteristics. Moreover, an empirical
analysis of the experimental and validation protocols adopted by MER methods is
presented. The challenges mentioned earlier and network design strategies may
assist the affective computing research community in forging ahead in MER
research. Finally, we point out the future directions, research needs, and draw
our conclusions."
Algebra Error Classification with Large Language Models,0.599918,"Automated feedback as students answer open-ended math questions has
significant potential in improving learning outcomes at large scale. A key part
of automated feedback systems is an error classification component, which
identifies student errors and enables appropriate, predefined feedback to be
deployed. Most existing approaches to error classification use a rule-based
method, which has limited capacity to generalize. Existing data-driven methods
avoid these limitations but specifically require mathematical expressions in
student responses to be parsed into syntax trees. This requirement is itself a
limitation, since student responses are not always syntactically valid and
cannot be converted into trees. In this work, we introduce a flexible method
for error classification using pre-trained large language models. We
demonstrate that our method can outperform existing methods in algebra error
classification, and is able to classify a larger set of student responses.
Additionally, we analyze common classification errors made by our method and
discuss limitations of automated error classification."
Exploiting Global and Local Hierarchies for Hierarchical Text Classification,0.306679,"Hierarchical text classification aims to leverage label hierarchy in
multi-label text classification. Existing methods encode label hierarchy in a
global view, where label hierarchy is treated as the static hierarchical
structure containing all labels. Since global hierarchy is static and
irrelevant to text samples, it makes these methods hard to exploit hierarchical
information. Contrary to global hierarchy, local hierarchy as a structured
labels hierarchy corresponding to each text sample. It is dynamic and relevant
to text samples, which is ignored in previous methods. To exploit global and
local hierarchies,we propose Hierarchy-guided BERT with Global and Local
hierarchies (HBGL), which utilizes the large-scale parameters and prior
language knowledge of BERT to model both global and local
hierarchies.Moreover,HBGL avoids the intentional fusion of semantic and
hierarchical modules by directly modeling semantic and hierarchical information
with BERT.Compared with the state-of-the-art method HGCLR,our method achieves
significant improvement on three benchmark datasets."
Hyper-X: A Unified Hypernetwork for Multi-Task Multilingual Transfer,0.664596,"Massively multilingual models are promising for transfer learning across
tasks and languages. However, existing methods are unable to fully leverage
training data when it is available in different task-language combinations. To
exploit such heterogeneous supervision, we propose Hyper-X, a single
hypernetwork that unifies multi-task and multilingual learning with efficient
adaptation. This model generates weights for adapter modules conditioned on
both tasks and language embeddings. By learning to combine task and
language-specific knowledge, our model enables zero-shot transfer for unseen
languages and task-language combinations. Our experiments on a diverse set of
languages demonstrate that Hyper-X achieves the best or competitive gain when a
mixture of multiple resources is available, while being on par with strong
baselines in the standard scenario. Hyper-X is also considerably more efficient
in terms of parameters and resources compared to methods that train separate
adapters. Finally, Hyper-X consistently produces strong results in few-shot
scenarios for new languages, showing the versatility of our approach beyond
zero-shot transfer."
Delving into Discrete Normalizing Flows on SO(3) Manifold for Probabilistic Rotation Modeling,0.382962,"Normalizing flows (NFs) provide a powerful tool to construct an expressive
distribution by a sequence of trackable transformations of a base distribution
and form a probabilistic model of underlying data. Rotation, as an important
quantity in computer vision, graphics, and robotics, can exhibit many
ambiguities when occlusion and symmetry occur and thus demands such
probabilistic models. Though much progress has been made for NFs in Euclidean
space, there are no effective normalizing flows without discontinuity or
many-to-one mapping tailored for SO(3) manifold. Given the unique non-Euclidean
properties of the rotation manifold, adapting the existing NFs to SO(3)
manifold is non-trivial. In this paper, we propose a novel normalizing flow on
SO(3) by combining a Mobius transformation-based coupling layer and a
quaternion affine transformation. With our proposed rotation normalizing flows,
one can not only effectively express arbitrary distributions on SO(3), but also
conditionally build the target distribution given input observations. Extensive
experiments show that our rotation normalizing flows significantly outperform
the baselines on both unconditional and conditional tasks."
Sockeye 3: Fast Neural Machine Translation with PyTorch,0.454404,"Sockeye 3 is the latest version of the Sockeye toolkit for Neural Machine
Translation (NMT). Now based on PyTorch, Sockeye 3 provides faster model
implementations and more advanced features with a further streamlined codebase.
This enables broader experimentation with faster iteration, efficient training
of stronger and faster models, and the flexibility to move new ideas quickly
from research to production. When running comparable models, Sockeye 3 is up to
126% faster than other PyTorch implementations on GPUs and up to 292% faster on
CPUs. Sockeye 3 is open source software released under the Apache 2.0 license."
UniKGQA: Unified Retrieval and Reasoning for Solving Multi-hop Question Answering Over Knowledge Graph,0.897289,"Multi-hop Question Answering over Knowledge Graph~(KGQA) aims to find the
answer entities that are multiple hops away from the topic entities mentioned
in a natural language question on a large-scale Knowledge Graph (KG). To cope
with the vast search space, existing work usually adopts a two-stage approach:
it first retrieves a relatively small subgraph related to the question and then
performs the reasoning on the subgraph to find the answer entities accurately.
Although these two stages are highly related, previous work employs very
different technical solutions for developing the retrieval and reasoning
models, neglecting their relatedness in task essence. In this paper, we propose
UniKGQA, a novel approach for multi-hop KGQA task, by unifying retrieval and
reasoning in both model architecture and parameter learning. For model
architecture, UniKGQA consists of a semantic matching module based on a
pre-trained language model~(PLM) for question-relation semantic matching, and a
matching information propagation module to propagate the matching information
along the directed edges on KGs. For parameter learning, we design a shared
pre-training task based on question-relation matching for both retrieval and
reasoning models, and then propose retrieval- and reasoning-oriented
fine-tuning strategies. Compared with previous studies, our approach is more
unified, tightly relating the retrieval and reasoning stages. Extensive
experiments on three benchmark datasets have demonstrated the effectiveness of
our method on the multi-hop KGQA task. Our codes and data are publicly
available at~\url{https://github.com/RUCAIBox/UniKGQA}."
Separating Invisible Sounds Toward Universal Audiovisual Scene-Aware Sound Separation,0.867137,"The audio-visual sound separation field assumes visible sources in videos,
but this excludes invisible sounds beyond the camera's view. Current methods
struggle with such sounds lacking visible cues. This paper introduces a novel
""Audio-Visual Scene-Aware Separation"" (AVSA-Sep) framework. It includes a
semantic parser for visible and invisible sounds and a separator for
scene-informed separation. AVSA-Sep successfully separates both sound types,
with joint training and cross-modal alignment enhancing effectiveness."
Fast and Robust Early-Exiting Framework for Autoregressive Language Models with Synchronized Parallel Decoding,0.678847,"To tackle the high inference latency exhibited by autoregressive language
models, previous studies have proposed an early-exiting framework that
allocates adaptive computation paths for each token based on the complexity of
generating the subsequent token. However, we observed several shortcomings,
including performance degradation caused by a state copying mechanism or
numerous exit paths, and sensitivity to exit confidence thresholds.
Consequently, we propose a Fast and Robust Early-Exiting (FREE) framework,
which incorporates a shallow-deep module and a synchronized parallel decoding.
Our framework enables faster inference by synchronizing the decoding process of
the current token with previously stacked early-exited tokens. Furthermore, as
parallel decoding allows us to observe predictions from both shallow and deep
models, we present a novel adaptive threshold estimator that exploits a Beta
mixture model to determine suitable confidence thresholds. We empirically
demonstrated the superiority of our proposed framework on extensive generation
tasks."
LOCL: Learning Object-Attribute Composition using Localization,0.225584,"This paper describes LOCL (Learning Object Attribute Composition using
Localization) that generalizes composition zero shot learning to objects in
cluttered and more realistic settings. The problem of unseen Object Attribute
(OA) associations has been well studied in the field, however, the performance
of existing methods is limited in challenging scenes. In this context, our key
contribution is a modular approach to localizing objects and attributes of
interest in a weakly supervised context that generalizes robustly to unseen
configurations. Localization coupled with a composition classifier
significantly outperforms state of the art (SOTA) methods, with an improvement
of about 12% on currently available challenging datasets. Further, the
modularity enables the use of localized feature extractor to be used with
existing OA compositional learning methods to improve their overall
performance."
Modeling Temporal-Modal Entity Graph for Procedural Multimodal Machine Comprehension,0.232142,"Procedural Multimodal Documents (PMDs) organize textual instructions and
corresponding images step by step. Comprehending PMDs and inducing their
representations for the downstream reasoning tasks is designated as Procedural
MultiModal Machine Comprehension (M3C). In this study, we approach Procedural
M3C at a fine-grained level (compared with existing explorations at a document
or sentence level), that is, entity. With delicate consideration, we model
entity both in its temporal and cross-modal relation and propose a novel
Temporal-Modal Entity Graph (TMEG). Specifically, graph structure is formulated
to capture textual and visual entities and trace their temporal-modal
evolution. In addition, a graph aggregation module is introduced to conduct
graph encoding and reasoning. Comprehensive experiments across three Procedural
M3C tasks are conducted on a traditional dataset RecipeQA and our new dataset
CraftQA, which can better evaluate the generalization of TMEG."
Data Representativity for Machine Learning and AI Systems,0.403268,"Data representativity is crucial when drawing inference from data through
machine learning models. Scholars have increased focus on unraveling the bias
and fairness in models, also in relation to inherent biases in the input data.
However, limited work exists on the representativity of samples (datasets) for
appropriate inference in AI systems. This paper reviews definitions and notions
of a representative sample and surveys their use in scientific AI literature.
We introduce three measurable concepts to help focus the notions and evaluate
different data samples. Furthermore, we demonstrate that the contrast between a
representative sample in the sense of coverage of the input space, versus a
representative sample mimicking the distribution of the target population is of
particular relevance when building AI systems. Through empirical demonstrations
on US Census data, we evaluate the opposing inherent qualities of these
concepts. Finally, we propose a framework of questions for creating and
documenting data with data representativity in mind, as an addition to existing
dataset documentation templates."
Constrained Optimization with Dynamic Bound-scaling for Effective NLPBackdoor Defense,0.822469,"We develop a novel optimization method for NLPbackdoor inversion. We leverage
a dynamically reducing temperature coefficient in the softmax function to
provide changing loss landscapes to the optimizer such that the process
gradually focuses on the ground truth trigger, which is denoted as a one-hot
value in a convex hull. Our method also features a temperature rollback
mechanism to step away from local optimals, exploiting the observation that
local optimals can be easily deter-mined in NLP trigger inversion (while not in
general optimization). We evaluate the technique on over 1600 models (with
roughly half of them having injected backdoors) on 3 prevailing NLP tasks, with
4 different backdoor attacks and 7 architectures. Our results show that the
technique is able to effectively and efficiently detect and remove backdoors,
outperforming 4 baseline methods."
De-risking Carbon Capture and Sequestration with Explainable CO2 Leakage Detection in Time-lapse Seismic Monitoring Images,0.63278,"With the growing global deployment of carbon capture and sequestration
technology to combat climate change, monitoring and detection of potential CO2
leakage through existing or storage induced faults are critical to the safe and
long-term viability of the technology. Recent work on time-lapse seismic
monitoring of CO2 storage has shown promising results in its ability to monitor
the growth of the CO2 plume from surface recorded seismic data. However, due to
the low sensitivity of seismic imaging to CO2 concentration, additional
developments are required to efficiently interpret the seismic images for
leakage. In this work, we introduce a binary classification of time-lapse
seismic images to delineate CO2 plumes (leakage) using state-of-the-art deep
learning models. Additionally, we localize the leakage region of CO2 plumes by
leveraging Class Activation Mapping methods."
Automated Scientific Discovery: From Equation Discovery to Autonomous Discovery Systems,0.418351,"The paper surveys automated scientific discovery, from equation discovery and
symbolic regression to autonomous discovery systems and agents. It discusses
the individual approaches from a ""big picture"" perspective and in context, but
also discusses open issues and recent topics like the various roles of deep
neural networks in this area, aiding in the discovery of human-interpretable
knowledge. Further, we will present closed-loop scientific discovery systems,
starting with the pioneering work on the Adam system up to current efforts in
fields from material science to astronomy. Finally, we will elaborate on
autonomy from a machine learning perspective, but also in analogy to the
autonomy levels in autonomous driving. The maximal level, level five, is
defined to require no human intervention at all in the production of scientific
knowledge. Achieving this is one step towards solving the Nobel Turing Grand
Challenge to develop AI Scientists: AI systems capable of making Nobel-quality
scientific discoveries highly autonomously at a level comparable, and possibly
superior, to the best human scientists by 2050."
Learning Visibility Field for Detailed 3D Human Reconstruction and Relighting,0.351132,"Detailed 3D reconstruction and photo-realistic relighting of digital humans
are essential for various applications. To this end, we propose a novel
sparse-view 3d human reconstruction framework that closely incorporates the
occupancy field and albedo field with an additional visibility field--it not
only resolves occlusion ambiguity in multiview feature aggregation, but can
also be used to evaluate light attenuation for self-shadowed relighting. To
enhance its training viability and efficiency, we discretize visibility onto a
fixed set of sample directions and supply it with coupled geometric 3D depth
feature and local 2D image feature. We further propose a novel
rendering-inspired loss, namely TransferLoss, to implicitly enforce the
alignment between visibility and occupancy field, enabling end-to-end joint
training. Results and extensive experiments demonstrate the effectiveness of
the proposed method, as it surpasses state-of-the-art in terms of
reconstruction accuracy while achieving comparably accurate relighting to
ray-traced ground truth."
Hybrid Indoor Localization via Reinforcement Learning-based Information Fusion,0.221736,"The paper is motivated by the importance of the Smart Cities (SC) concept for
future management of global urbanization. Among all Internet of Things
(IoT)-based communication technologies, Bluetooth Low Energy (BLE) plays a
vital role in city-wide decision making and services. Extreme fluctuations of
the Received Signal Strength Indicator (RSSI), however, prevent this technology
from being a reliable solution with acceptable accuracy in the dynamic indoor
tracking/localization approaches for ever-changing SC environments. The latest
version of the BLE v.5.1 introduced a better possibility for tracking users by
utilizing the direction finding approaches based on the Angle of Arrival (AoA),
which is more reliable. There are still some fundamental issues remaining to be
addressed. Existing works mainly focus on implementing stand-alone models
overlooking potentials fusion strategies. The paper addresses this gap and
proposes a novel Reinforcement Learning (RL)-based information fusion framework
(RL-IFF) by coupling AoA with RSSI-based particle filtering and Inertial
Measurement Unit (IMU)-based Pedestrian Dead Reckoning (PDR) frameworks. The
proposed RL-IFF solution is evaluated through a comprehensive set of
experiments illustrating superior performance compared to its counterparts."
"Can counterfactual explanations of AI systems' predictions skew lay users' causal intuitions about the world? If so, can we correct for that?",0.199887,"Counterfactual (CF) explanations have been employed as one of the modes of
explainability in explainable AI-both to increase the transparency of AI
systems and to provide recourse. Cognitive science and psychology, however,
have pointed out that people regularly use CFs to express causal relationships.
Most AI systems are only able to capture associations or correlations in data
so interpreting them as casual would not be justified. In this paper, we
present two experiment (total N = 364) exploring the effects of CF explanations
of AI system's predictions on lay people's causal beliefs about the real world.
In Experiment 1 we found that providing CF explanations of an AI system's
predictions does indeed (unjustifiably) affect people's causal beliefs
regarding factors/features the AI uses and that people are more likely to view
them as causal factors in the real world. Inspired by the literature on
misinformation and health warning messaging, Experiment 2 tested whether we can
correct for the unjustified change in causal beliefs. We found that pointing
out that AI systems capture correlations and not necessarily causal
relationships can attenuate the effects of CF explanations on people's causal
beliefs."
Generalized Delayed Feedback Model with Post-Click Information in Recommender Systems,0.300366,"Predicting conversion rate (e.g., the probability that a user will purchase
an item) is a fundamental problem in machine learning based recommender
systems. However, accurate conversion labels are revealed after a long delay,
which harms the timeliness of recommender systems. Previous literature
concentrates on utilizing early conversions to mitigate such a delayed feedback
problem. In this paper, we show that post-click user behaviors are also
informative to conversion rate prediction and can be used to improve
timeliness. We propose a generalized delayed feedback model (GDFM) that unifies
both post-click behaviors and early conversions as stochastic post-click
information, which could be utilized to train GDFM in a streaming manner
efficiently. Based on GDFM, we further establish a novel perspective that the
performance gap introduced by delayed feedback can be attributed to a temporal
gap and a sampling gap. Inspired by our analysis, we propose to measure the
quality of post-click information with a combination of temporal distance and
sample complexity. The training objective is re-weighted accordingly to
highlight informative and timely signals. We validate our analysis on public
datasets, and experimental performance confirms the effectiveness of our
method."
ShapeClipper: Scalable 3D Shape Learning from Single-View Images via Geometric and CLIP-based Consistency,0.69659,"We present ShapeClipper, a novel method that reconstructs 3D object shapes
from real-world single-view RGB images. Instead of relying on laborious 3D,
multi-view or camera pose annotation, ShapeClipper learns shape reconstruction
from a set of single-view segmented images. The key idea is to facilitate shape
learning via CLIP-based shape consistency, where we encourage objects with
similar CLIP encodings to share similar shapes. We also leverage off-the-shelf
normals as an additional geometric constraint so the model can learn better
bottom-up reasoning of detailed surface geometry. These two novel consistency
constraints, when used to regularize our model, improve its ability to learn
both global shape structure and local geometric details. We evaluate our method
over three challenging real-world datasets, Pix3D, Pascal3D+, and OpenImages,
where we achieve superior performance over state-of-the-art methods."
SUBS: Subtree Substitution for Compositional Semantic Parsing,0.345357,"Although sequence-to-sequence models often achieve good performance in
semantic parsing for i.i.d. data, their performance is still inferior in
compositional generalization. Several data augmentation methods have been
proposed to alleviate this problem. However, prior work only leveraged
superficial grammar or rules for data augmentation, which resulted in limited
improvement. We propose to use subtree substitution for compositional data
augmentation, where we consider subtrees with similar semantic functions as
exchangeable. Our experiments showed that such augmented data led to
significantly better performance on SCAN and GeoQuery, and reached new SOTA on
compositional split of GeoQuery."
TwiRGCN: Temporally Weighted Graph Convolution for Question Answering over Temporal Knowledge Graphs,0.655588,"Recent years have witnessed much interest in temporal reasoning over
knowledge graphs (KG) for complex question answering (QA), but there remains a
substantial gap in human capabilities. We explore how to generalize relational
graph convolutional networks (RGCN) for temporal KGQA. Specifically, we propose
a novel, intuitive and interpretable scheme to modulate the messages passed
through a KG edge during convolution, based on the relevance of its associated
time period to the question. We also introduce a gating device to predict if
the answer to a complex temporal question is likely to be a KG entity or time
and use this prediction to guide our scoring mechanism. We evaluate the
resulting system, which we call TwiRGCN, on TimeQuestions, a recently released,
challenging dataset for multi-hop complex temporal QA. We show that TwiRGCN
significantly outperforms state-of-the-art systems on this dataset across
diverse question types. Notably, TwiRGCN improves accuracy by 9--10 percentage
points for the most difficult ordinal and implicit question types."
Structured Pruning for Multi-Task Deep Neural Networks,0.166413,"Although multi-task deep neural network (DNN) models have computation and
storage benefits over individual single-task DNN models, they can be further
optimized via model compression. Numerous structured pruning methods are
already developed that can readily achieve speedups in single-task models, but
the pruning of multi-task networks has not yet been extensively studied. In
this work, we investigate the effectiveness of structured pruning on multi-task
models. We use an existing single-task filter pruning criterion and also
introduce an MTL-based filter pruning criterion for estimating the filter
importance scores. We prune the model using an iterative pruning strategy with
both pruning methods. We show that, with careful hyper-parameter tuning,
architectures obtained from different pruning methods do not have significant
differences in their performances across tasks when the number of parameters is
similar. We also show that iterative structure pruning may not be the best way
to achieve a well-performing pruned model because, at extreme pruning levels,
there is a high drop in performance across all tasks. But when the same models
are randomly initialized and re-trained, they show better results."
E-NER: Evidential Deep Learning for Trustworthy Named Entity Recognition,0.507972,"Most named entity recognition (NER) systems focus on improving model
performance, ignoring the need to quantify model uncertainty, which is critical
to the reliability of NER systems in open environments. Evidential deep
learning (EDL) has recently been proposed as a promising solution to explicitly
model predictive uncertainty for classification tasks. However, directly
applying EDL to NER applications faces two challenges, i.e., the problems of
sparse entities and OOV/OOD entities in NER tasks. To address these challenges,
we propose a trustworthy NER framework named E-NER by introducing two
uncertainty-guided loss terms to the conventional EDL, along with a series of
uncertainty-guided training strategies. Experiments show that E-NER can be
applied to multiple NER paradigms to obtain accurate uncertainty estimation.
Furthermore, compared to state-of-the-art baselines, the proposed method
achieves a better OOV/OOD detection performance and better generalization
ability on OOV entities."
SimA: Simple Softmax-free Attention for Vision Transformers,0.23239,"Recently, vision transformers have become very popular. However, deploying
them in many applications is computationally expensive partly due to the
Softmax layer in the attention block. We introduce a simple but effective,
Softmax-free attention block, SimA, which normalizes query and key matrices
with simple $\ell_1$-norm instead of using Softmax layer. Then, the attention
block in SimA is a simple multiplication of three matrices, so SimA can
dynamically change the ordering of the computation at the test time to achieve
linear computation on the number of tokens or the number of channels. We
empirically show that SimA applied to three SOTA variations of transformers,
DeiT, XCiT, and CvT, results in on-par accuracy compared to the SOTA models,
without any need for Softmax layer. Interestingly, changing SimA from
multi-head to single-head has only a small effect on the accuracy, which
simplifies the attention block further. The code is available here:
https://github.com/UCDvision/sima"
A Knowledge-Based Decision Support System for In Vitro Fertilization Treatment,0.393469,"In Vitro Fertilization (IVF) is the most widely used Assisted Reproductive
Technology (ART). IVF usually involves controlled ovarian stimulation, oocyte
retrieval, fertilization in the laboratory with subsequent embryo transfer. The
first two steps correspond with follicular phase of females and ovulation in
their menstrual cycle. Therefore, we refer to it as the treatment cycle in our
paper. The treatment cycle is crucial because the stimulation medications in
IVF treatment are applied directly on patients. In order to optimize the
stimulation effects and lower the side effects of the stimulation medications,
prompt treatment adjustments are in need. In addition, the quality and quantity
of the retrieved oocytes have a significant effect on the outcome of the
following procedures. To improve the IVF success rate, we propose a
knowledge-based decision support system that can provide medical advice on the
treatment protocol and medication adjustment for each patient visit during IVF
treatment cycle. Our system is efficient in data processing and light-weighted
which can be easily embedded into electronic medical record systems. Moreover,
an oocyte retrieval oriented evaluation demonstrates that our system performs
well in terms of accuracy of advice for the protocols and medications."
Towards the Generation of Musical Explanations with GPT-3,0.100646,"Open AI's language model, GPT-3, has shown great potential for many NLP
tasks, with applications in many different domains. In this work we carry out a
first study on GPT-3's capability to communicate musical decisions through
textual explanations when prompted with a textual representation of a piece of
music. Enabling a dialogue in human-AI music partnerships is an important step
towards more engaging and creative human-AI interactions. Our results show that
GPT-3 lacks the necessary intelligence to really understand musical decisions.
A major barrier to reach a better performance is the lack of data that includes
explanations of the creative process carried out by artists for musical pieces.
We believe such a resource would aid the understanding and collaboration with
AI music systems."
Carpe Diem: On the Evaluation of World Knowledge in Lifelong Language Models,0.149288,"The dynamic nature of knowledge in an ever-changing world presents challenges
for language models trained on static data; the model in the real world often
requires not only acquiring new knowledge but also overwriting outdated
information into updated ones. To study the ability of language models for
these time-dependent dynamics in human language, we introduce a novel task,
EvolvingQA, a temporally evolving question-answering benchmark designed for
training and evaluating LMs on an evolving Wikipedia database. The construction
of EvolvingQA is automated with our pipeline using large language models. We
uncover that existing continual learning baselines suffer from updating and
removing outdated knowledge. Our analysis suggests that models fail to rectify
knowledge due to small weight gradients. In addition, we elucidate that
language models particularly struggle to reflect the change of numerical or
temporal information. Our work aims to model the dynamic nature of real-world
information, suggesting faithful evaluations of the evolution-adaptability of
language models."
Sequence-aware multimodal page classification of Brazilian legal documents,0.202749,"The Brazilian Supreme Court receives tens of thousands of cases each
semester. Court employees spend thousands of hours to execute the initial
analysis and classification of those cases -- which takes effort away from
posterior, more complex stages of the case management workflow. In this paper,
we explore multimodal classification of documents from Brazil's Supreme Court.
We train and evaluate our methods on a novel multimodal dataset of 6,510
lawsuits (339,478 pages) with manual annotation assigning each page to one of
six classes. Each lawsuit is an ordered sequence of pages, which are stored
both as an image and as a corresponding text extracted through optical
character recognition. We first train two unimodal classifiers: a ResNet
pre-trained on ImageNet is fine-tuned on the images, and a convolutional
network with filters of multiple kernel sizes is trained from scratch on
document texts. We use them as extractors of visual and textual features, which
are then combined through our proposed Fusion Module. Our Fusion Module can
handle missing textual or visual input by using learned embeddings for missing
data. Moreover, we experiment with bi-directional Long Short-Term Memory
(biLSTM) networks and linear-chain conditional random fields to model the
sequential nature of the pages. The multimodal approaches outperform both
textual and visual classifiers, especially when leveraging the sequential
nature of the pages."
Phylogeny-Inspired Adaptation of Multilingual Models to New Languages,0.536357,"Large pretrained multilingual models, trained on dozens of languages, have
delivered promising results due to cross-lingual learning capabilities on
variety of language tasks. Further adapting these models to specific languages,
especially ones unseen during pre-training, is an important goal towards
expanding the coverage of language technologies. In this study, we show how we
can use language phylogenetic information to improve cross-lingual transfer
leveraging closely related languages in a structured, linguistically-informed
manner. We perform adapter-based training on languages from diverse language
families (Germanic, Uralic, Tupian, Uto-Aztecan) and evaluate on both syntactic
and semantic tasks, obtaining more than 20% relative performance improvements
over strong commonly used baselines, especially on languages unseen during
pre-training."
SpellMapper: A non-autoregressive neural spellchecker for ASR customization with candidate retrieval based on n-gram mappings,0.798104,"Contextual spelling correction models are an alternative to shallow fusion to
improve automatic speech recognition (ASR) quality given user vocabulary. To
deal with large user vocabularies, most of these models include candidate
retrieval mechanisms, usually based on minimum edit distance between fragments
of ASR hypothesis and user phrases. However, the edit-distance approach is
slow, non-trainable, and may have low recall as it relies only on common
letters. We propose: 1) a novel algorithm for candidate retrieval, based on
misspelled n-gram mappings, which gives up to 90% recall with just the top 10
candidates on Spoken Wikipedia; 2) a non-autoregressive neural model based on
BERT architecture, where the initial transcript and ten candidates are combined
into one input. The experiments on Spoken Wikipedia show 21.4% word error rate
improvement compared to a baseline ASR system."
Scaling Up Probabilistic Circuits by Latent Variable Distillation,0.881855,"Probabilistic Circuits (PCs) are a unified framework for tractable
probabilistic models that support efficient computation of various
probabilistic queries (e.g., marginal probabilities). One key challenge is to
scale PCs to model large and high-dimensional real-world datasets: we observe
that as the number of parameters in PCs increases, their performance
immediately plateaus. This phenomenon suggests that the existing optimizers
fail to exploit the full expressive power of large PCs. We propose to overcome
such bottleneck by latent variable distillation: we leverage the less tractable
but more expressive deep generative models to provide extra supervision over
the latent variables of PCs. Specifically, we extract information from
Transformer-based generative models to assign values to latent variables of
PCs, providing guidance to PC optimizers. Experiments on both image and
language modeling benchmarks (e.g., ImageNet and WikiText-2) show that latent
variable distillation substantially boosts the performance of large PCs
compared to their counterparts without latent variable distillation. In
particular, on the image modeling benchmarks, PCs achieve competitive
performance against some of the widely-used deep generative models, including
variational autoencoders and flow-based models, opening up new avenues for
tractable generative modeling."
A Local Optima Network Analysis of the Feedforward Neural Architecture Space,0.37027,"This study investigates the use of local optima network (LON) analysis, a
derivative of the fitness landscape of candidate solutions, to characterise and
visualise the neural architecture space. The search space of feedforward neural
network architectures with up to three layers, each with up to 10 neurons, is
fully enumerated by evaluating trained model performance on a selection of data
sets. Extracted LONs, while heterogeneous across data sets, all exhibit simple
global structures, with single global funnels in all cases but one. These
results yield early indication that LONs may provide a viable paradigm by which
to analyse and optimise neural architectures."
MetaEnhance: Metadata Quality Improvement for Electronic Theses and Dissertations of University Libraries,0.0756055,"Metadata quality is crucial for digital objects to be discovered through
digital library interfaces. However, due to various reasons, the metadata of
digital objects often exhibits incomplete, inconsistent, and incorrect values.
We investigate methods to automatically detect, correct, and canonicalize
scholarly metadata, using seven key fields of electronic theses and
dissertations (ETDs) as a case study. We propose MetaEnhance, a framework that
utilizes state-of-the-art artificial intelligence methods to improve the
quality of these fields. To evaluate MetaEnhance, we compiled a metadata
quality evaluation benchmark containing 500 ETDs, by combining subsets sampled
using multiple criteria. We tested MetaEnhance on this benchmark and found that
the proposed methods achieved nearly perfect F1-scores in detecting errors and
F1-scores in correcting errors ranging from 0.85 to 1.00 for five of seven
fields."
Planning as Theorem Proving with Heuristics,0.16237,"Planning as theorem proving in situation calculus was abandoned 50 years ago
as an impossible project. But we have developed a Theorem Proving Lifted
Heuristic (TPLH) planner that searches for a plan in a tree of situations using
the A* search algorithm. It is controlled by a delete relaxation-based domain
independent heuristic. We compare TPLH with Fast Downward (FD) and Best First
Width Search (BFWS) planners over several standard benchmarks. Since our
implementation of the heuristic function is not optimized, TPLH is slower than
FD and BFWS. But it computes shorter plans, and it explores fewer states. We
discuss previous research on planning within KR\&R and identify related
directions. Thus, we show that deductive lifted heuristic planning in situation
calculus is actually doable."
NAN: Noise-Aware NeRFs for Burst-Denoising,0.653369,"Burst denoising is now more relevant than ever, as computational photography
helps overcome sensitivity issues inherent in mobile phones and small cameras.
A major challenge in burst-denoising is in coping with pixel misalignment,
which was so far handled with rather simplistic assumptions of simple motion,
or the ability to align in pre-processing. Such assumptions are not realistic
in the presence of large motion and high levels of noise. We show that Neural
Radiance Fields (NeRFs), originally suggested for physics-based novel-view
rendering, can serve as a powerful framework for burst denoising. NeRFs have an
inherent capability of handling noise as they integrate information from
multiple images, but they are limited in doing so, mainly since they build on
pixel-wise operations which are suitable to ideal imaging conditions. Our
approach, termed NAN, leverages inter-view and spatial information in NeRFs to
better deal with noise. It achieves state-of-the-art results in burst denoising
and is especially successful in coping with large movement and occlusions,
under very high levels of noise. With the rapid advances in accelerating NeRFs,
it could provide a powerful platform for denoising in challenging environments."
IoV Scenario: Implementation of a Bandwidth Aware Algorithm in Wireless Network Communication Mode,0.396833,"The wireless network communication mode represented by the Internet of
vehicles (IoV) has been widely used. However, due to the limitations of
traditional network architecture, resource scheduling in wireless network
environment is still facing great challenges. This paper focuses on the
allocation of bandwidth resources in the virtual network environment. This
paper proposes a bandwidth aware multi domain virtual network embedding
algorithm (BA-VNE). The algorithm is mainly aimed at the problem that users
need a lot of bandwidth in wireless communication mode, and solves the problem
of bandwidth resource allocation from the perspective of virtual network
embedding (VNE). In order to improve the performance of the algorithm, we
introduce particle swarm optimization (PSO) algorithm to optimize the
performance of the algorithm. In order to verify the effectiveness of the
algorithm, we have carried out simulation experiments from link bandwidth,
mapping cost and virtual network request (VNR) acceptance rate. The final
results show that the proposed algorithm is better than other representative
algorithms in the above indicators."
A GOA-Based Fault-Tolerant Trajectory Tracking Control for an Underwater Vehicle of Multi-Thruster System without Actuator Saturation,0.698725,"This paper proposes an intelligent fault-tolerant control (FTC) strategy to
tackle the trajectory tracking problem of an underwater vehicle (UV) under
thruster damage (power loss) cases and meanwhile resolve the actuator
saturation brought by the vehicle's physical constraints. In the proposed
control strategy, the trajectory tracking component is formed by a refined
backstepping algorithm that controls the velocity variation and a sliding mode
control deducts the torque/force outputs; the fault-tolerant component is
established based on a Grasshopper Optimization Algorithm (GOA), which provides
fast convergence speed as well as satisfactory accuracy of deducting optimized
reallocation of the thruster forces to compensate for the power loss in
different fault cases. Simulations with or without environmental perturbations
under different fault cases and comparisons to other traditional FTCs are
presented, thus verifying the effectiveness and robustness of the proposed
GOA-based fault-tolerant trajectory tracking design."
DBARF: Deep Bundle-Adjusting Generalizable Neural Radiance Fields,0.696845,"Recent works such as BARF and GARF can bundle adjust camera poses with neural
radiance fields (NeRF) which is based on coordinate-MLPs. Despite the
impressive results, these methods cannot be applied to Generalizable NeRFs
(GeNeRFs) which require image feature extractions that are often based on more
complicated 3D CNN or transformer architectures. In this work, we first analyze
the difficulties of jointly optimizing camera poses with GeNeRFs, and then
further propose our DBARF to tackle these issues. Our DBARF which bundle
adjusts camera poses by taking a cost feature map as an implicit cost function
can be jointly trained with GeNeRFs in a self-supervised manner. Unlike BARF
and its follow-up works, which can only be applied to per-scene optimized NeRFs
and need accurate initial camera poses with the exception of forward-facing
scenes, our method can generalize across scenes and does not require any good
initialization. Experiments show the effectiveness and generalization ability
of our DBARF when evaluated on real-world datasets. Our code is available at
\url{https://aibluefisher.github.io/dbarf}."
Rational Sensibility: LLM Enhanced Empathetic Response Generation Guided by Self-presentation Theory,0.398691,"Having the ability to empathize is crucial for accurately representing human
behavior during conversations. Despite numerous research aim to improve the
cognitive capability of models by incorporating external knowledge, there has
been limited attention on the sensible and rational expression of the
conversation itself, which are crucial components of the cognitive empathy.
Guided by self-presentation theory in sociology, we have designed an innovative
categorical approach that segregates historical dialogues into sensible and
rational sentences and subsequently elucidate the context through the designed
attention mechanism. However, the rational information within the conversation
is restricted and the external knowledge used in previous methods have
limitations of semantic contradiction and narrow vision field. Considering the
impressive performance of LLM in the domain of intelligent agent. We employ
LLaMA2-70b as a rational brain to analyze the profound logical information
maintained in conversations, which assists the model assessing the balance of
sensibility and rationality to produce quality empathetic responses.
Experimental evaluations demonstrate that our method outperforms other
comparable methods on both automatic and human evaluations."
A Graph Isomorphism Network with Weighted Multiple Aggregators for Speech Emotion Recognition,0.447011,"Speech emotion recognition (SER) is an essential part of human-computer
interaction. In this paper, we propose an SER network based on a Graph
Isomorphism Network with Weighted Multiple Aggregators (WMA-GIN), which can
effectively handle the problem of information confusion when neighbour nodes'
features are aggregated together in GIN structure. Moreover, a Full-Adjacent
(FA) layer is adopted for alleviating the over-squashing problem, which is
existed in all Graph Neural Network (GNN) structures, including GIN.
Furthermore, a multi-phase attention mechanism and multi-loss training strategy
are employed to avoid missing the useful emotional information in the stacked
WMA-GIN layers. We evaluated the performance of our proposed WMA-GIN on the
popular IEMOCAP dataset. The experimental results show that WMA-GIN outperforms
other GNN-based methods and is comparable to some advanced non-graph-based
methods by achieving 72.48% of weighted accuracy (WA) and 67.72% of unweighted
accuracy (UA)."
"Explainable AI over the Internet of Things (IoT): Overview, State-of-the-Art and Future Directions",0.732028,"Explainable Artificial Intelligence (XAI) is transforming the field of
Artificial Intelligence (AI) by enhancing the trust of end-users in machines.
As the number of connected devices keeps on growing, the Internet of Things
(IoT) market needs to be trustworthy for the end-users. However, existing
literature still lacks a systematic and comprehensive survey work on the use of
XAI for IoT. To bridge this lacking, in this paper, we address the XAI
frameworks with a focus on their characteristics and support for IoT. We
illustrate the widely-used XAI services for IoT applications, such as security
enhancement, Internet of Medical Things (IoMT), Industrial IoT (IIoT), and
Internet of City Things (IoCT). We also suggest the implementation choice of
XAI models over IoT systems in these applications with appropriate examples and
summarize the key inferences for future works. Moreover, we present the
cutting-edge development in edge XAI structures and the support of
sixth-generation (6G) communication services for IoT applications, along with
key inferences. In a nutshell, this paper constitutes the first holistic
compilation on the development of XAI-based frameworks tailored for the demands
of future IoT use cases."
Focal-PETR: Embracing Foreground for Efficient Multi-Camera 3D Object Detection,0.752753,"The dominant multi-camera 3D detection paradigm is based on explicit 3D
feature construction, which requires complicated indexing of local image-view
features via 3D-to-2D projection. Other methods implicitly introduce geometric
positional encoding and perform global attention (e.g., PETR) to build the
relationship between image tokens and 3D objects. The 3D-to-2D perspective
inconsistency and global attention lead to a weak correlation between
foreground tokens and queries, resulting in slow convergence. We propose
Focal-PETR with instance-guided supervision and spatial alignment module to
adaptively focus object queries on discriminative foreground regions.
Focal-PETR additionally introduces a down-sampling strategy to reduce the
consumption of global attention. Due to the highly parallelized implementation
and down-sampling strategy, our model, without depth supervision, achieves
leading performance on the large-scale nuScenes benchmark and a superior speed
of 30 FPS on a single RTX3090 GPU. Extensive experiments show that our method
outperforms PETR while consuming 3x fewer training hours. The code will be made
publicly available."
Curiosity-Driven Multi-Agent Exploration with Mixed Objectives,0.4884,"Intrinsic rewards have been increasingly used to mitigate the sparse reward
problem in single-agent reinforcement learning. These intrinsic rewards
encourage the agent to look for novel experiences, guiding the agent to explore
the environment sufficiently despite the lack of extrinsic rewards.
Curiosity-driven exploration is a simple yet efficient approach that quantifies
this novelty as the prediction error of the agent's curiosity module, an
internal neural network that is trained to predict the agent's next state given
its current state and action. We show here, however, that naively using this
curiosity-driven approach to guide exploration in sparse reward cooperative
multi-agent environments does not consistently lead to improved results.
Straightforward multi-agent extensions of curiosity-driven exploration take
into consideration either individual or collective novelty only and thus, they
do not provide a distinct but collaborative intrinsic reward signal that is
essential for learning in cooperative multi-agent tasks. In this work, we
propose a curiosity-driven multi-agent exploration method that has the mixed
objective of motivating the agents to explore the environment in ways that are
individually and collectively novel. First, we develop a two-headed curiosity
module that is trained to predict the corresponding agent's next observation in
the first head and the next joint observation in the second head. Second, we
design the intrinsic reward formula to be the sum of the individual and joint
prediction errors of this curiosity module. We empirically show that the
combination of our curiosity module architecture and intrinsic reward
formulation guides multi-agent exploration more efficiently than baseline
approaches, thereby providing the best performance boost to MARL algorithms in
cooperative navigation environments with sparse rewards."
Scaling Laws for Associative Memories,0.968791,"Learning arguably involves the discovery and memorization of abstract rules.
The aim of this paper is to study associative memory mechanisms. Our model is
based on high-dimensional matrices consisting of outer products of embeddings,
which relates to the inner layers of transformer language models. We derive
precise scaling laws with respect to sample size and parameter size, and
discuss the statistical efficiency of different estimators, including
optimization-based algorithms. We provide extensive numerical experiments to
validate and interpret theoretical results, including fine-grained
visualizations of the stored memory associations."
Uncertainty-guided Source-free Domain Adaptation,0.991725,"Source-free domain adaptation (SFDA) aims to adapt a classifier to an
unlabelled target data set by only using a pre-trained source model. However,
the absence of the source data and the domain shift makes the predictions on
the target data unreliable. We propose quantifying the uncertainty in the
source model predictions and utilizing it to guide the target adaptation. For
this, we construct a probabilistic source model by incorporating priors on the
network parameters inducing a distribution over the model predictions.
Uncertainties are estimated by employing a Laplace approximation and
incorporated to identify target data points that do not lie in the source
manifold and to down-weight them when maximizing the mutual information on the
target data. Unlike recent works, our probabilistic treatment is
computationally lightweight, decouples source training and target adaptation,
and requires no specialized source training or changes of the model
architecture. We show the advantages of uncertainty-guided SFDA over
traditional SFDA in the closed-set and open-set settings and provide empirical
evidence that our approach is more robust to strong domain shifts even without
tuning."
Hero-Gang Neural Model For Named Entity Recognition,0.667511,"Named entity recognition (NER) is a fundamental and important task in NLP,
aiming at identifying named entities (NEs) from free text. Recently, since the
multi-head attention mechanism applied in the Transformer model can effectively
capture longer contextual information, Transformer-based models have become the
mainstream methods and have achieved significant performance in this task.
Unfortunately, although these models can capture effective global context
information, they are still limited in the local feature and position
information extraction, which is critical in NER. In this paper, to address
this limitation, we propose a novel Hero-Gang Neural structure (HGN), including
the Hero and Gang module, to leverage both global and local information to
promote NER. Specifically, the Hero module is composed of a Transformer-based
encoder to maintain the advantage of the self-attention mechanism, and the Gang
module utilizes a multi-window recurrent module to extract local features and
position information under the guidance of the Hero module. Afterward, the
proposed multi-window attention effectively combines global information and
multiple local features for predicting entity labels. Experimental results on
several benchmark datasets demonstrate the effectiveness of our proposed model."
WaveY-Net: Physics-augmented deep learning for high-speed electromagnetic simulation and optimization,0.844433,"The calculation of electromagnetic field distributions within structured
media is central to the optimization and validation of photonic devices. We
introduce WaveY-Net, a hybrid data- and physics-augmented convolutional neural
network that can predict electromagnetic field distributions with ultra fast
speeds and high accuracy for entire classes of dielectric photonic structures.
This accuracy is achieved by training the neural network to learn only the
magnetic near-field distributions of a system and to use a discrete formalism
of Maxwell's equations in two ways: as physical constraints in the loss
function and as a means to calculate the electric fields from the magnetic
fields. As a model system, we construct a surrogate simulator for periodic
silicon nanostructure arrays and show that the high speed simulator can be
directly and effectively used in the local and global freeform optimization of
metagratings. We anticipate that physics-augmented networks will serve as a
viable Maxwell simulator replacement for many classes of photonic systems,
transforming the way they are designed."
Uncertainty-aware Personal Assistant for Making Personalized Privacy Decisions,0.683977,"Many software systems, such as online social networks enable users to share
information about themselves. While the action of sharing is simple, it
requires an elaborate thought process on privacy: what to share, with whom to
share, and for what purposes. Thinking about these for each piece of content to
be shared is tedious. Recent approaches to tackle this problem build personal
assistants that can help users by learning what is private over time and
recommending privacy labels such as private or public to individual content
that a user considers sharing. However, privacy is inherently ambiguous and
highly personal. Existing approaches to recommend privacy decisions do not
address these aspects of privacy sufficiently. Ideally, a personal assistant
should be able to adjust its recommendation based on a given user, considering
that user's privacy understanding. Moreover, the personal assistant should be
able to assess when its recommendation would be uncertain and let the user make
the decision on her own. Accordingly, this paper proposes a personal assistant
that uses evidential deep learning to classify content based on its privacy
label. An important characteristic of the personal assistant is that it can
model its uncertainty in its decisions explicitly, determine that it does not
know the answer, and delegate from making a recommendation when its uncertainty
is high. By factoring in the user's own understanding of privacy, such as risk
factors or own labels, the personal assistant can personalize its
recommendations per user. We evaluate our proposed personal assistant using a
well-known data set. Our results show that our personal assistant can
accurately identify uncertain cases, personalize them to its user's needs, and
thus helps users preserve their privacy well."
Cone: Unsupervised Contrastive Opinion Extraction,0.251943,"Contrastive opinion extraction aims to extract a structured summary or key
points organised as positive and negative viewpoints towards a common aspect or
topic. Most recent works for unsupervised key point extraction is largely built
on sentence clustering or opinion summarisation based on the popularity of
opinions expressed in text. However, these methods tend to generate aspect
clusters with incoherent sentences, conflicting viewpoints, redundant aspects.
To address these problems, we propose a novel unsupervised Contrastive OpinioN
Extraction model, called Cone, which learns disentangled latent aspect and
sentiment representations based on pseudo aspect and sentiment labels by
combining contrastive learning with iterative aspect/sentiment clustering
refinement. Apart from being able to extract contrastive opinions, it is also
able to quantify the relative popularity of aspects and their associated
sentiment distributions. The model has been evaluated on both a hotel review
dataset and a Twitter dataset about COVID vaccines. The results show that
despite using no label supervision or aspect-denoted seed words, Cone
outperforms a number of competitive baselines on contrastive opinion
extraction. The results of Cone can be used to offer a better recommendation of
products and services online."
Graph Reinforcement Learning-based CNN Inference Offloading in Dynamic Edge Computing,0.169135,"This paper studies the computational offloading of CNN inference in dynamic
multi-access edge computing (MEC) networks. To address the uncertainties in
communication time and Edge servers' available capacity, we use early-exit
mechanism to terminate the computation earlier to meet the deadline of
inference tasks. We design a reward function to trade off the communication,
computation and inference accuracy, and formulate the offloading problem of CNN
inference as a maximization problem with the goal of maximizing the average
inference accuracy and throughput in long term. To solve the maximization
problem, we propose a graph reinforcement learning-based early-exit mechanism
(GRLE), which outperforms the state-of-the-art work, deep reinforcement
learning-based online offloading (DROO) and its enhanced method, DROO with
early-exit mechanism (DROOE), under different dynamic scenarios. The
experimental results show that GRLE achieves the average accuracy up to 3.41x
over graph reinforcement learning (GRL) and 1.45x over DROOE, which shows the
advantages of GRLE for offloading decision-making in dynamic MEC."
BALF: Simple and Efficient Blur Aware Local Feature Detector,0.296411,"Local feature detection is a key ingredient of many image processing and
computer vision applications, such as visual odometry and localization. Most
existing algorithms focus on feature detection from a sharp image. They would
thus have degraded performance once the image is blurred, which could happen
easily under low-lighting conditions. To address this issue, we propose a
simple yet both efficient and effective keypoint detection method that is able
to accurately localize the salient keypoints in a blurred image. Our method
takes advantages of a novel multi-layer perceptron (MLP) based architecture
that significantly improve the detection repeatability for a blurred image. The
network is also light-weight and able to run in real-time, which enables its
deployment for time-constrained applications. Extensive experimental results
demonstrate that our detector is able to improve the detection repeatability
with blurred images, while keeping comparable performance as existing
state-of-the-art detectors for sharp images."
Discrete Tree Flows via Tree-Structured Permutations,0.311907,"While normalizing flows for continuous data have been extensively researched,
flows for discrete data have only recently been explored. These prior models,
however, suffer from limitations that are distinct from those of continuous
flows. Most notably, discrete flow-based models cannot be straightforwardly
optimized with conventional deep learning methods because gradients of discrete
functions are undefined or zero. Previous works approximate pseudo-gradients of
the discrete functions but do not solve the problem on a fundamental level. In
addition to that, backpropagation can be computationally burdensome compared to
alternative discrete algorithms such as decision tree algorithms. Our approach
seeks to reduce computational burden and remove the need for pseudo-gradients
by developing a discrete flow based on decision trees -- building upon the
success of efficient tree-based methods for classification and regression for
discrete data. We first define a tree-structured permutation (TSP) that
compactly encodes a permutation of discrete data where the inverse is easy to
compute; thus, we can efficiently compute the density value and sample new
data. We then propose a decision tree algorithm to build TSPs that learns the
tree structure and permutations at each node via novel criteria. We empirically
demonstrate the feasibility of our method on multiple datasets."
TADA: Task-Agnostic Dialect Adapters for English,0.563746,"Large Language Models, the dominant starting point for Natural Language
Processing (NLP) applications, fail at a higher rate for speakers of English
dialects other than Standard American English (SAE). Prior work addresses this
using task-specific data or synthetic data augmentation, both of which require
intervention for each dialect and task pair. This poses a scalability issue
that prevents the broad adoption of robust dialectal English NLP. We introduce
a simple yet effective method for task-agnostic dialect adaptation by aligning
non-SAE dialects using adapters and composing them with task-specific adapters
from SAE. Task-Agnostic Dialect Adapters (TADA) improve dialectal robustness on
4 dialectal variants of the GLUE benchmark without task-specific supervision."
Ham2Pose: Animating Sign Language Notation into Pose Sequences,0.89581,"Translating spoken languages into Sign languages is necessary for open
communication between the hearing and hearing-impaired communities. To achieve
this goal, we propose the first method for animating a text written in
HamNoSys, a lexical Sign language notation, into signed pose sequences. As
HamNoSys is universal by design, our proposed method offers a generic solution
invariant to the target Sign language. Our method gradually generates pose
predictions using transformer encoders that create meaningful representations
of the text and poses while considering their spatial and temporal information.
We use weak supervision for the training process and show that our method
succeeds in learning from partial and inaccurate data. Additionally, we offer a
new distance measurement that considers missing keypoints, to measure the
distance between pose sequences using DTW-MJE. We validate its correctness
using AUTSL, a large-scale Sign language dataset, show that it measures the
distance between pose sequences more accurately than existing measurements, and
use it to assess the quality of our generated pose sequences. Code for the data
pre-processing, the model, and the distance measurement is publicly released
for future research."
"Trust, but Verify: Cross-Modality Fusion for HD Map Change Detection",0.940203,"High-definition (HD) map change detection is the task of determining when
sensor data and map data are no longer in agreement with one another due to
real-world changes. We collect the first dataset for the task, which we entitle
the Trust, but Verify (TbV) dataset, by mining thousands of hours of data from
over 9 months of autonomous vehicle fleet operations. We present learning-based
formulations for solving the problem in the bird's eye view and ego-view.
Because real map changes are infrequent and vector maps are easy to
synthetically manipulate, we lean on simulated data to train our model. Perhaps
surprisingly, we show that such models can generalize to real world
distributions. The dataset, consisting of maps and logs collected in six North
American cities, is one of the largest AV datasets to date with more than 7.8
million images. We make the data available to the public at
https://www.argoverse.org/av2.html#mapchange-link, along with code and models
at https://github.com/johnwlambert/tbv under the the CC BY-NC-SA 4.0 license."
ReFactor GNNs: Revisiting Factorisation-based Models from a Message-Passing Perspective,0.238352,"Factorisation-based Models (FMs), such as DistMult, have enjoyed enduring
success for Knowledge Graph Completion (KGC) tasks, often outperforming Graph
Neural Networks (GNNs). However, unlike GNNs, FMs struggle to incorporate node
features and generalise to unseen nodes in inductive settings. Our work bridges
the gap between FMs and GNNs by proposing ReFactor GNNs. This new architecture
draws upon both modelling paradigms, which previously were largely thought of
as disjoint. Concretely, using a message-passing formalism, we show how FMs can
be cast as GNNs by reformulating the gradient descent procedure as
message-passing operations, which forms the basis of our ReFactor GNNs. Across
a multitude of well-established KGC benchmarks, our ReFactor GNNs achieve
comparable transductive performance to FMs, and state-of-the-art inductive
performance while using an order of magnitude fewer parameters."
Joint one-sided synthetic unpaired image translation and segmentation for colorectal cancer prevention,0.12904,"Deep learning has shown excellent performance in analysing medical images.
However, datasets are difficult to obtain due privacy issues, standardization
problems, and lack of annotations. We address these problems by producing
realistic synthetic images using a combination of 3D technologies and
generative adversarial networks. We propose CUT-seg, a joint training where a
segmentation model and a generative model are jointly trained to produce
realistic images while learning to segment polyps. We take advantage of recent
one-sided translation models because they use significantly less memory,
allowing us to add a segmentation model in the training loop. CUT-seg performs
better, is computationally less expensive, and requires less real images than
other memory-intensive image translation approaches that require two stage
training. Promising results are achieved on five real polyp segmentation
datasets using only one real image and zero real annotations. As a part of this
study we release Synth-Colon, an entirely synthetic dataset that includes 20000
realistic colon images and additional details about depth and 3D geometry:
https://enric1994.github.io/synth-colon"
Aligned with Whom? Direct and social goals for AI systems,0.105199,"As artificial intelligence (AI) becomes more powerful and widespread, the AI
alignment problem - how to ensure that AI systems pursue the goals that we want
them to pursue - has garnered growing attention. This article distinguishes two
types of alignment problems depending on whose goals we consider, and analyzes
the different solutions necessitated by each. The direct alignment problem
considers whether an AI system accomplishes the goals of the entity operating
it. In contrast, the social alignment problem considers the effects of an AI
system on larger groups or on society more broadly. In particular, it also
considers whether the system imposes externalities on others. Whereas solutions
to the direct alignment problem center around more robust implementation,
social alignment problems typically arise because of conflicts between
individual and group-level goals, elevating the importance of AI governance to
mediate such conflicts. Addressing the social alignment problem requires both
enforcing existing norms on their developers and operators and designing new
norms that apply directly to AI systems."
TaSPM: Targeted Sequential Pattern Mining,0.671764,"Sequential pattern mining (SPM) is an important technique of pattern mining,
which has many applications in reality. Although many efficient sequential
pattern mining algorithms have been proposed, there are few studies can focus
on target sequences. Targeted querying sequential patterns can not only reduce
the number of sequences generated by SPM, but also improve the efficiency of
users in performing pattern analysis. The current algorithms available on
targeted sequence querying are based on specific scenarios and cannot be
generalized to other applications. In this paper, we formulate the problem of
targeted sequential pattern mining and propose a generic framework namely
TaSPM, based on the fast CM-SPAM algorithm. What's more, to improve the
efficiency of TaSPM on large-scale datasets and multiple-items-based sequence
datasets, we propose several pruning strategies to reduce meaningless
operations in mining processes. Totally four pruning strategies are designed in
TaSPM, and hence it can terminate unnecessary pattern extensions quickly and
achieve better performance. Finally, we conduct extensive experiments on
different datasets to compare the existing SPM algorithms with TaSPM.
Experiments show that the novel targeted mining algorithm TaSPM can achieve
faster running time and less memory consumption."
Enhancing In-Context Learning with Answer Feedback for Multi-Span Question Answering,0.40027,"Whereas the recent emergence of large language models (LLMs) like ChatGPT has
exhibited impressive general performance, it still has a large gap with
fully-supervised models on specific tasks such as multi-span question
answering. Previous researches found that in-context learning is an effective
approach to exploiting LLM, by using a few task-related labeled data as
demonstration examples to construct a few-shot prompt for answering new
questions. A popular implementation is to concatenate a few questions and their
correct answers through simple templates, informing LLM of the desired output.
In this paper, we propose a novel way of employing labeled data such that it
also informs LLM of some undesired output, by extending demonstration examples
with feedback about answers predicted by an off-the-shelf model, e.g., correct,
incorrect, or incomplete. Experiments on three multi-span question answering
datasets as well as a keyphrase extraction dataset show that our new prompting
strategy consistently improves LLM's in-context learning performance."
FinBERT-MRC: financial named entity recognition using BERT under the machine reading comprehension paradigm,0.872557,"Financial named entity recognition (FinNER) from literature is a challenging
task in the field of financial text information extraction, which aims to
extract a large amount of financial knowledge from unstructured texts. It is
widely accepted to use sequence tagging frameworks to implement FinNER tasks.
However, such sequence tagging models cannot fully take advantage of the
semantic information in the texts. Instead, we formulate the FinNER task as a
machine reading comprehension (MRC) problem and propose a new model termed
FinBERT-MRC. This formulation introduces significant prior information by
utilizing well-designed queries, and extracts start index and end index of
target entities without decoding modules such as conditional random fields
(CRF). We conduct experiments on a publicly available Chinese financial dataset
ChFinAnn and a real-word bussiness dataset AdminPunish. FinBERT-MRC model
achieves average F1 scores of 92.78% and 96.80% on the two datasets,
respectively, with average F1 gains +3.94% and +0.89% over some sequence
tagging models including BiLSTM-CRF, BERT-Tagger, and BERT-CRF. The source code
is available at https://github.com/zyz0000/FinBERT-MRC."
Better Smatch = Better Parser? AMR evaluation is not so simple anymore,0.665558,"Recently, astonishing advances have been observed in AMR parsing, as measured
by the structural Smatch metric. In fact, today's systems achieve performance
levels that seem to surpass estimates of human inter annotator agreement (IAA).
Therefore, it is unclear how well Smatch (still) relates to human estimates of
parse quality, as in this situation potentially fine-grained errors of similar
weight may impact the AMR's meaning to different degrees.
  We conduct an analysis of two popular and strong AMR parsers that --
according to Smatch -- reach quality levels on par with human IAA, and assess
how human quality ratings relate to Smatch and other AMR metrics. Our main
findings are: i) While high Smatch scores indicate otherwise, we find that AMR
parsing is far from being solved: we frequently find structurally small, but
semantically unacceptable errors that substantially distort sentence meaning.
ii) Considering high-performance parsers, better Smatch scores may not
necessarily indicate consistently better parsing quality. To obtain a
meaningful and comprehensive assessment of quality differences of parse(r)s, we
recommend augmenting evaluations with macro statistics, use of additional
metrics, and more human analysis."
Improving Question Answering with Generation of NQ-like Questions,0.0810173,"Question Answering (QA) systems require a large amount of annotated data
which is costly and time-consuming to gather. Converting datasets of existing
QA benchmarks are challenging due to different formats and complexities. To
address these issues, we propose an algorithm to automatically generate shorter
questions resembling day-to-day human communication in the Natural Questions
(NQ) dataset from longer trivia questions in Quizbowl (QB) dataset by
leveraging conversion in style among the datasets. This provides an automated
way to generate more data for our QA systems. To ensure quality as well as
quantity of data, we detect and remove ill-formed questions using a neural
classifier. We demonstrate that in a low resource setting, using the generated
data improves the QA performance over the baseline system on both NQ and QB
data. Our algorithm improves the scalability of training data while maintaining
quality of data for QA systems."
Induced Natural Language Rationales and Interleaved Markup Tokens Enable Extrapolation in Large Language Models,0.669671,"The ability to extrapolate, i.e., to make predictions on sequences that are
longer than those presented as training examples, is a challenging problem for
current deep learning models. Recent work shows that this limitation persists
in state-of-the-art Transformer-based models. Most solutions to this problem
use specific architectures or training methods that do not generalize to other
tasks. We demonstrate that large language models can succeed in extrapolation
without modifying their architecture or training procedure. Our experimental
results show that generating step-by-step rationales and introducing marker
tokens are both required for effective extrapolation. First, we induce a
language model to produce step-by-step rationales before outputting the answer
to effectively communicate the task to the model. However, as sequences become
longer, we find that current models struggle to keep track of token positions.
To address this issue, we interleave output tokens with markup tokens that act
as explicit positional and counting symbols. Our findings show how these two
complementary approaches enable remarkable sequence extrapolation and highlight
a limitation of current architectures to effectively generalize without
explicit surface form guidance. Code available at
https://github.com/MirelleB/induced-rationales-markup-tokens"
BiSyn-GAT+: Bi-Syntax Aware Graph Attention Network for Aspect-based Sentiment Analysis,0.969153,"Aspect-based sentiment analysis (ABSA) is a fine-grained sentiment analysis
task that aims to align aspects and corresponding sentiments for
aspect-specific sentiment polarity inference. It is challenging because a
sentence may contain multiple aspects or complicated (e.g., conditional,
coordinating, or adversative) relations. Recently, exploiting dependency syntax
information with graph neural networks has been the most popular trend. Despite
its success, methods that heavily rely on the dependency tree pose challenges
in accurately modeling the alignment of the aspects and their words indicative
of sentiment, since the dependency tree may provide noisy signals of unrelated
associations (e.g., the ""conj"" relation between ""great"" and ""dreadful"" in
Figure 2). In this paper, to alleviate this problem, we propose a Bi-Syntax
aware Graph Attention Network (BiSyn-GAT+). Specifically, BiSyn-GAT+ fully
exploits the syntax information (e.g., phrase segmentation and hierarchical
structure) of the constituent tree of a sentence to model the sentiment-aware
context of every single aspect (called intra-context) and the sentiment
relations across aspects (called inter-context) for learning. Experiments on
four benchmark datasets demonstrate that BiSyn-GAT+ outperforms the
state-of-the-art methods consistently."
IRISformer: Dense Vision Transformers for Single-Image Inverse Rendering in Indoor Scenes,0.627442,"Indoor scenes exhibit significant appearance variations due to myriad
interactions between arbitrarily diverse object shapes, spatially-changing
materials, and complex lighting. Shadows, highlights, and inter-reflections
caused by visible and invisible light sources require reasoning about
long-range interactions for inverse rendering, which seeks to recover the
components of image formation, namely, shape, material, and lighting. In this
work, our intuition is that the long-range attention learned by transformer
architectures is ideally suited to solve longstanding challenges in
single-image inverse rendering. We demonstrate with a specific instantiation of
a dense vision transformer, IRISformer, that excels at both single-task and
multi-task reasoning required for inverse rendering. Specifically, we propose a
transformer architecture to simultaneously estimate depths, normals,
spatially-varying albedo, roughness and lighting from a single image of an
indoor scene. Our extensive evaluations on benchmark datasets demonstrate
state-of-the-art results on each of the above tasks, enabling applications like
object insertion and material editing in a single unconstrained real image,
with greater photorealism than prior works. Code and data are publicly released
at https://github.com/ViLab-UCSD/IRISformer."
SGPT: GPT Sentence Embeddings for Semantic Search,0.999996,"Decoder transformers have continued increasing in scale reaching hundreds of
billions of parameters. Due to their scale the same decoder sets
state-of-the-art results on various language tasks via prompting or
fine-tuning. Yet, these large foundation models remain unusable for the related
fields of semantic search and sentence embeddings. This prevents possibly new
state-of-the-art results and forces organizations to train and maintain
separate models. To this end, we propose SGPT to use decoders for sentence
embeddings and semantic search via prompting or fine-tuning. At 5.8 billion
parameters SGPT improves on the previously best sentence embeddings by a margin
of 7% and outperforms a concurrent method with 175 billion parameters as
measured on the BEIR search benchmark. Code, models and result files are freely
available at https://github.com/Muennighoff/sgpt."
PTDE: Personalized Training with Distilled Execution for Multi-Agent Reinforcement Learning,0.418804,"Centralized Training with Decentralized Execution (CTDE) has emerged as a
widely adopted paradigm in multi-agent reinforcement learning, emphasizing the
utilization of global information for learning an enhanced joint $Q$-function
or centralized critic. In contrast, our investigation delves into harnessing
global information to directly enhance individual $Q$-functions or individual
actors. Notably, we discover that applying identical global information
universally across all agents proves insufficient for optimal performance.
Consequently, we advocate for the customization of global information tailored
to each agent, creating agent-personalized global information to bolster
overall performance. Furthermore, we introduce a novel paradigm named
Personalized Training with Distilled Execution (PTDE), wherein
agent-personalized global information is distilled into the agent's local
information. This distilled information is then utilized during decentralized
execution, resulting in minimal performance degradation. PTDE can be seamlessly
integrated with state-of-the-art algorithms, leading to notable performance
enhancements across diverse benchmarks, including the SMAC benchmark, Google
Research Football (GRF) benchmark, and Learning to Rank (LTR) task."
Contrastive Language-Image Pre-Training with Knowledge Graphs,0.584548,"Recent years have witnessed the fast development of large-scale pre-training
frameworks that can extract multi-modal representations in a unified form and
achieve promising performances when transferred to downstream tasks.
Nevertheless, existing approaches mainly focus on pre-training with simple
image-text pairs, while neglecting the semantic connections between concepts
from different modalities. In this paper, we propose a knowledge-based
pre-training framework, dubbed Knowledge-CLIP, which injects semantic
information into the widely used CLIP model. Through introducing
knowledge-based objectives in the pre-training process and utilizing different
types of knowledge graphs as training data, our model can semantically align
the representations in vision and language with higher quality, and enhance the
reasoning ability across scenarios and modalities. Extensive experiments on
various vision-language downstream tasks demonstrate the effectiveness of
Knowledge-CLIP compared with the original CLIP and competitive baselines."
A New Linear Scaling Rule for Private Adaptive Hyperparameter Optimization,0.726442,"An open problem in differentially private deep learning is hyperparameter
optimization (HPO). DP-SGD introduces new hyperparameters and complicates
existing ones, forcing researchers to painstakingly tune hyperparameters with
hundreds of trials, which in turn makes it impossible to account for the
privacy cost of HPO without destroying the utility. We propose an adaptive HPO
method that uses cheap trials (in terms of privacy cost and runtime) to
estimate optimal hyperparameters and scales them up. We obtain state-of-the-art
performance on 22 benchmark tasks, across computer vision and natural language
processing, across pretraining and finetuning, across architectures and a wide
range of $\varepsilon \in [0.01,8.0]$, all while accounting for the privacy
cost of HPO."
A Feature-space Multimodal Data Augmentation Technique for Text-video Retrieval,0.403549,"Every hour, huge amounts of visual contents are posted on social media and
user-generated content platforms. To find relevant videos by means of a natural
language query, text-video retrieval methods have received increased attention
over the past few years. Data augmentation techniques were introduced to
increase the performance on unseen test examples by creating new training
samples with the application of semantics-preserving techniques, such as color
space or geometric transformations on images. Yet, these techniques are usually
applied on raw data, leading to more resource-demanding solutions and also
requiring the shareability of the raw data, which may not always be true, e.g.
copyright issues with clips from movies or TV series. To address this
shortcoming, we propose a multimodal data augmentation technique which works in
the feature space and creates new videos and captions by mixing semantically
similar samples. We experiment our solution on a large scale public dataset,
EPIC-Kitchens-100, and achieve considerable improvements over a baseline
method, improved state-of-the-art performance, while at the same time
performing multiple ablation studies. We release code and pretrained models on
Github at https://github.com/aranciokov/FSMMDA_VideoRetrieval."
"Industrial Segment Anything -- a Case Study in Aircraft Manufacturing, Intralogistics, Maintenance, Repair, and Overhaul",0.538005,"Deploying deep learning-based applications in specialized domains like the
aircraft production industry typically suffers from the training data
availability problem. Only a few datasets represent non-everyday objects,
situations, and tasks. Recent advantages in research around Vision Foundation
Models (VFM) opened a new area of tasks and models with high generalization
capabilities in non-semantic and semantic predictions. As recently demonstrated
by the Segment Anything Project, exploiting VFM's zero-shot capabilities is a
promising direction in tackling the boundaries spanned by data, context, and
sensor variety. Although, investigating its application within specific domains
is subject to ongoing research. This paper contributes here by surveying
applications of the SAM in aircraft production-specific use cases. We include
manufacturing, intralogistics, as well as maintenance, repair, and overhaul
processes, also representing a variety of other neighboring industrial domains.
Besides presenting the various use cases, we further discuss the injection of
domain knowledge."
ViT-CX: Causal Explanation of Vision Transformers,0.173177,"Despite the popularity of Vision Transformers (ViTs) and eXplainable AI
(XAI), only a few explanation methods have been designed specially for ViTs
thus far. They mostly use attention weights of the [CLS] token on patch
embeddings and often produce unsatisfactory saliency maps. This paper proposes
a novel method for explaining ViTs called ViT-CX. It is based on patch
embeddings, rather than attentions paid to them, and their causal impacts on
the model output. Other characteristics of ViTs such as causal
overdetermination are also considered in the design of ViT-CX. The empirical
results show that ViT-CX produces more meaningful saliency maps and does a
better job revealing all important evidence for the predictions than previous
methods. The explanation generated by ViT-CX also shows significantly better
faithfulness to the model. The codes and appendix are available at
https://github.com/vaynexie/CausalX-ViT."
Continual Multimodal Knowledge Graph Construction,0.877479,"Current Multimodal Knowledge Graph Construction (MKGC) models struggle with
the real-world dynamism of continuously emerging entities and relations, often
succumbing to catastrophic forgetting-loss of previously acquired knowledge.
This study introduces benchmarks aimed at fostering the development of the
continual MKGC domain. We further introduce MSPT framework, designed to
surmount the shortcomings of existing MKGC approaches during multimedia data
processing. MSPT harmonizes the retention of learned knowledge (stability) and
the integration of new data (plasticity), outperforming current continual
learning and multimodal methods. Our results confirm MSPT's superior
performance in evolving knowledge environments, showcasing its capacity to
navigate balance between stability and plasticity."
PHEE: A Dataset for Pharmacovigilance Event Extraction from Text,0.951396,"The primary goal of drug safety researchers and regulators is to promptly
identify adverse drug reactions. Doing so may in turn prevent or reduce the
harm to patients and ultimately improve public health. Evaluating and
monitoring drug safety (i.e., pharmacovigilance) involves analyzing an ever
growing collection of spontaneous reports from health professionals,
physicians, and pharmacists, and information voluntarily submitted by patients.
In this scenario, facilitating analysis of such reports via automation has the
potential to rapidly identify safety signals. Unfortunately, public resources
for developing natural language models for this task are scant. We present
PHEE, a novel dataset for pharmacovigilance comprising over 5000 annotated
events from medical case reports and biomedical literature, making it the
largest such public dataset to date. We describe the hierarchical event schema
designed to provide coarse and fine-grained information about patients'
demographics, treatments and (side) effects. Along with the discussion of the
dataset, we present a thorough experimental evaluation of current
state-of-the-art approaches for biomedical event extraction, point out their
limitations, and highlight open challenges to foster future research in this
area."
Automatically Summarizing Evidence from Clinical Trials: A Prototype Highlighting Current Challenges,0.716113,"We present TrialsSummarizer, a system that aims to automatically summarize
evidence presented in the set of randomized controlled trials most relevant to
a given query. Building on prior work, the system retrieves trial publications
matching a query specifying a combination of condition, intervention(s), and
outcome(s), and ranks these according to sample size and estimated study
quality. The top-k such studies are passed through a neural multi-document
summarization system, yielding a synopsis of these trials. We consider two
architectures: A standard sequence-to-sequence model based on BART and a
multi-headed architecture intended to provide greater transparency to
end-users. Both models produce fluent and relevant summaries of evidence
retrieved for queries, but their tendency to introduce unsupported statements
render them inappropriate for use in this domain at present. The proposed
architecture may help users verify outputs allowing users to trace generated
tokens back to inputs."
EdgeFormer: A Parameter-Efficient Transformer for On-Device Seq2seq Generation,0.778965,"We introduce EdgeFormer -- a parameter-efficient Transformer for on-device
seq2seq generation under the strict computation and memory constraints.
Compared with the previous parameter-efficient Transformers, EdgeFormer applies
two novel principles for cost-effective parameterization, allowing it to
perform better given the same parameter budget; moreover, EdgeFormer is further
enhanced by layer adaptation innovation that is proposed for improving the
network with shared layers.
  Extensive experiments show EdgeFormer can effectively outperform previous
parameter-efficient Transformer baselines and achieve competitive results under
both the computation and memory constraints. Given the promising results, we
release EdgeLM -- the pretrained version of EdgeFormer, which is the first
publicly available pretrained on-device seq2seq model that can be easily
fine-tuned for seq2seq tasks with strong results, facilitating on-device
seq2seq generation in practice."
GenDR: A Generalized Differentiable Renderer,0.304559,"In this work, we present and study a generalized family of differentiable
renderers. We discuss from scratch which components are necessary for
differentiable rendering and formalize the requirements for each component. We
instantiate our general differentiable renderer, which generalizes existing
differentiable renderers like SoftRas and DIB-R, with an array of different
smoothing distributions to cover a large spectrum of reasonable settings. We
evaluate an array of differentiable renderer instantiations on the popular
ShapeNet 3D reconstruction benchmark and analyze the implications of our
results. Surprisingly, the simple uniform distribution yields the best overall
results when averaged over 13 classes; in general, however, the optimal choice
of distribution heavily depends on the task."
Learning Deep Sensorimotor Policies for Vision-based Autonomous Drone Racing,0.717279,"Autonomous drones can operate in remote and unstructured environments,
enabling various real-world applications. However, the lack of effective
vision-based algorithms has been a stumbling block to achieving this goal.
Existing systems often require hand-engineered components for state estimation,
planning, and control. Such a sequential design involves laborious tuning,
human heuristics, and compounding delays and errors. This paper tackles the
vision-based autonomous-drone-racing problem by learning deep sensorimotor
policies. We use contrastive learning to extract robust feature representations
from the input images and leverage a two-stage learning-by-cheating framework
for training a neural network policy. The resulting policy directly infers
control commands with feature representations learned from raw images, forgoing
the need for globally-consistent state estimation, trajectory planning, and
handcrafted control design. Our experimental results indicate that our
vision-based policy can achieve the same level of racing performance as the
state-based policy while being robust against different visual disturbances and
distractors. We believe this work serves as a stepping-stone toward developing
intelligent vision-based autonomous systems that control the drone purely from
image inputs, like human pilots."
TEMPERA: Test-Time Prompting via Reinforcement Learning,0.726416,"Careful prompt design is critical to the use of large language models in
zero-shot or few-shot learning. As a consequence, there is a growing interest
in automated methods to design optimal prompts. In this work, we propose
Test-time Prompt Editing using Reinforcement learning (TEMPERA). In contrast to
prior prompt generation methods, TEMPERA can efficiently leverage prior
knowledge, is adaptive to different queries and provides an interpretable
prompt for every query. To achieve this, we design a novel action space that
allows flexible editing of the initial prompts covering a wide set of
commonly-used components like instructions, few-shot exemplars, and
verbalizers. The proposed method achieves significant gains compared with
recent SoTA approaches like prompt tuning, AutoPrompt, and RLPrompt, across a
variety of tasks including sentiment analysis, topic classification, natural
language inference, and reading comprehension. Our method achieves 5.33x on
average improvement in sample efficiency when compared to the traditional
fine-tuning methods."
Computer Vision Estimation of Emotion Reaction Intensity in the Wild,0.518931,"Emotions play an essential role in human communication. Developing computer
vision models for automatic recognition of emotion expression can aid in a
variety of domains, including robotics, digital behavioral healthcare, and
media analytics. There are three types of emotional representations which are
traditionally modeled in affective computing research: Action Units, Valence
Arousal (VA), and Categorical Emotions. As part of an effort to move beyond
these representations towards more fine-grained labels, we describe our
submission to the newly introduced Emotional Reaction Intensity (ERI)
Estimation challenge in the 5th competition for Affective Behavior Analysis
in-the-Wild (ABAW). We developed four deep neural networks trained in the
visual domain and a multimodal model trained with both visual and audio
features to predict emotion reaction intensity. Our best performing model on
the Hume-Reaction dataset achieved an average Pearson correlation coefficient
of 0.4080 on the test set using a pre-trained ResNet50 model. This work
provides a first step towards the development of production-grade models which
predict emotion reaction intensities rather than discrete emotion categories."
ExPUNations: Augmenting Puns with Keywords and Explanations,0.283724,"The tasks of humor understanding and generation are challenging and
subjective even for humans, requiring commonsense and real-world knowledge to
master. Puns, in particular, add the challenge of fusing that knowledge with
the ability to interpret lexical-semantic ambiguity. In this paper, we present
the ExPUNations (ExPUN) dataset, in which we augment an existing dataset of
puns with detailed crowdsourced annotations of keywords denoting the most
distinctive words that make the text funny, pun explanations describing why the
text is funny, and fine-grained funniness ratings. This is the first humor
dataset with such extensive and fine-grained annotations specifically for puns.
Based on these annotations, we propose two tasks: explanation generation to aid
with pun classification and keyword-conditioned pun generation, to challenge
the current state-of-the-art natural language understanding and generation
models' ability to understand and generate humor. We showcase that the
annotated keywords we collect are helpful for generating better novel humorous
texts in human evaluation, and that our natural language explanations can be
leveraged to improve both the accuracy and robustness of humor classifiers."
An Intelligent Deterministic Scheduling Method for Ultra-Low Latency Communication in Edge Enabled Industrial Internet of Things,0.801563,"Edge enabled Industrial Internet of Things (IIoT) platform is of great
significance to accelerate the development of smart industry. However, with the
dramatic increase in real-time IIoT applications, it is a great challenge to
support fast response time, low latency, and efficient bandwidth utilization.
To address this issue, Time Sensitive Network (TSN) is recently researched to
realize low latency communication via deterministic scheduling. To the best of
our knowledge, the combinability of multiple flows, which can significantly
affect the scheduling performance, has never been systematically analyzed
before. In this article, we first analyze the combinability problem. Then a
non-collision theory based deterministic scheduling (NDS) method is proposed to
achieve ultra-low latency communication for the time-sensitive flows. Moreover,
to improve bandwidth utilization, a dynamic queue scheduling (DQS) method is
presented for the best-effort flows. Experiment results demonstrate that
NDS/DQS can well support deterministic ultra-low latency services and guarantee
efficient bandwidth utilization."
Benchmarking LLM-based Machine Translation on Cultural Awareness,0.770707,"Translating cultural-specific content is crucial for effective cross-cultural
communication. However, many MT systems still struggle to translate sentences
containing cultural-specific entities accurately and understandably. Recent
advancements in in-context learning utilize lightweight prompts to guide large
language models (LLMs) in machine translation tasks. Nevertheless, the
effectiveness of this approach in enhancing machine translation with cultural
awareness remains uncertain. To address this gap, we introduce a new data
curation pipeline to construct a culturally relevant parallel corpus, enriched
with annotations of cultural-specific items. Furthermore, we devise a novel
evaluation metric to assess the understandability of translations in a
reference-free manner by GPT-4. We evaluate a variety of neural machine
translation (NMT) and LLM-based MT systems using our dataset. Additionally, we
propose several prompting strategies for LLMs to incorporate external and
internal cultural knowledge into the translation process. Our results
demonstrate that eliciting explanations can significantly enhance the
understandability of cultural-specific entities, especially those without
well-known translations."
Local Perception-Aware Transformer for Aerial Tracking,0.214187,"Transformer-based visual object tracking has been utilized extensively.
However, the Transformer structure is lack of enough inductive bias. In
addition, only focusing on encoding the global feature does harm to modeling
local details, which restricts the capability of tracking in aerial robots.
Specifically, with local-modeling to global-search mechanism, the proposed
tracker replaces the global encoder by a novel local-recognition encoder. In
the employed encoder, a local-recognition attention and a local element
correction network are carefully designed for reducing the global redundant
information interference and increasing local inductive bias. Meanwhile, the
latter can model local object details precisely under aerial view through
detail-inquiry net. The proposed method achieves competitive accuracy and
robustness in several authoritative aerial benchmarks with 316 sequences in
total. The proposed tracker's practicability and efficiency have been validated
by the real-world tests."
Exploiting Neighborhood Structural Features for Change Detection,0.226176,"In this letter, a novel method for change detection is proposed using
neighborhood structure correlation. Because structure features are insensitive
to the intensity differences between bi-temporal images, we perform the
correlation analysis on structure features rather than intensity information.
First, we extract the structure feature maps by using multi-orientated gradient
information. Then, the structure feature maps are used to obtain the
Neighborhood Structural Correlation Image (NSCI), which can represent the
context structure information. In addition, we introduce a measure named
matching error which can be used to improve neighborhood information.
Subsequently, a change detection model based on the random forest is
constructed. The NSCI feature and matching error are used as the model inputs
for training and prediction. Finally, the decision tree voting is used to
produce the change detection result. To evaluate the performance of the
proposed method, it was compared with three state-of-the-art change detection
methods. The experimental results on two datasets demonstrated the
effectiveness and robustness of the proposed method."
Automatic Fine-grained Glomerular Lesion Recognition in Kidney Pathology,0.522108,"Recognition of glomeruli lesions is the key for diagnosis and treatment
planning in kidney pathology; however, the coexisting glomerular structures
such as mesangial regions exacerbate the difficulties of this task. In this
paper, we introduce a scheme to recognize fine-grained glomeruli lesions from
whole slide images. First, a focal instance structural similarity loss is
proposed to drive the model to locate all types of glomeruli precisely. Then an
Uncertainty Aided Apportionment Network is designed to carry out the
fine-grained visual classification without bounding-box annotations. This
double branch-shaped structure extracts common features of the child class from
the parent class and produces the uncertainty factor for reconstituting the
training dataset. Results of slide-wise evaluation illustrate the effectiveness
of the entire scheme, with an 8-22% improvement of the mean Average Precision
compared with remarkable detection methods. The comprehensive results clearly
demonstrate the effectiveness of the proposed method."
Universal Domain Adaptive Object Detector,0.539209,"Universal domain adaptive object detection (UniDAOD)is more challenging than
domain adaptive object detection (DAOD) since the label space of the source
domain may not be the same as that of the target and the scale of objects in
the universal scenarios can vary dramatically (i.e, category shift and scale
shift). To this end, we propose US-DAF, namely Universal Scale-Aware Domain
Adaptive Faster RCNN with Multi-Label Learning, to reduce the negative transfer
effect during training while maximizing transferability as well as
discriminability in both domains under a variety of scales. Specifically, our
method is implemented by two modules: 1) We facilitate the feature alignment of
common classes and suppress the interference of private classes by designing a
Filter Mechanism module to overcome the negative transfer caused by category
shift. 2) We fill the blank of scale-aware adaptation in object detection by
introducing a new Multi-Label Scale-Aware Adapter to perform individual
alignment between the corresponding scale for two domains. Experiments show
that US-DAF achieves state-of-the-art results on three scenarios (i.e,
Open-Set, Partial-Set, and Closed-Set) and yields 7.1% and 5.9% relative
improvement on benchmark datasets Clipart1k and Watercolor in particular."
What do we Really Know about State of the Art NER?,0.824037,"Named Entity Recognition (NER) is a well researched NLP task and is widely
used in real world NLP scenarios. NER research typically focuses on the
creation of new ways of training NER, with relatively less emphasis on
resources and evaluation. Further, state of the art (SOTA) NER models, trained
on standard datasets, typically report only a single performance measure
(F-score) and we don't really know how well they do for different entity types
and genres of text, or how robust are they to new, unseen entities. In this
paper, we perform a broad evaluation of NER using a popular dataset, that takes
into consideration various text genres and sources constituting the dataset at
hand. Additionally, we generate six new adversarial test sets through small
perturbations in the original test set, replacing select entities while
retaining the context. We also train and test our models on randomly generated
train/dev/test splits followed by an experiment where the models are trained on
a select set of genres but tested genres not seen in training. These
comprehensive evaluation strategies were performed using three SOTA NER models.
Based on our results, we recommend some useful reporting practices for NER
researchers, that could help in providing a better understanding of a SOTA
model's performance in future."
"Who is GPT-3? An Exploration of Personality, Values and Demographics",0.603332,"Language models such as GPT-3 have caused a furore in the research community.
Some studies found that GPT-3 has some creative abilities and makes mistakes
that are on par with human behaviour. This paper answers a related question:
Who is GPT-3? We administered two validated measurement tools to GPT-3 to
assess its personality, the values it holds and its self-reported demographics.
Our results show that GPT-3 scores similarly to human samples in terms of
personality and - when provided with a model response memory - in terms of the
values it holds. We provide the first evidence of psychological assessment of
the GPT-3 model and thereby add to our understanding of this language model. We
close with suggestions for future research that moves social science closer to
language models and vice versa."
RM-Depth: Unsupervised Learning of Recurrent Monocular Depth in Dynamic Scenes,0.922636,"Unsupervised methods have showed promising results on monocular depth
estimation. However, the training data must be captured in scenes without
moving objects. To push the envelope of accuracy, recent methods tend to
increase their model parameters. In this paper, an unsupervised learning
framework is proposed to jointly predict monocular depth and complete 3D motion
including the motions of moving objects and camera. (1) Recurrent modulation
units are used to adaptively and iteratively fuse encoder and decoder features.
This not only improves the single-image depth inference but also does not
overspend model parameters. (2) Instead of using a single set of filters for
upsampling, multiple sets of filters are devised for the residual upsampling.
This facilitates the learning of edge-preserving filters and leads to the
improved performance. (3) A warping-based network is used to estimate a motion
field of moving objects without using semantic priors. This breaks down the
requirement of scene rigidity and allows to use general videos for the
unsupervised learning. The motion field is further regularized by an
outlier-aware training loss. Despite the depth model just uses a single image
in test time and 2.97M parameters, it achieves state-of-the-art results on the
KITTI and Cityscapes benchmarks."
On Building Spoken Language Understanding Systems for Low Resourced Languages,0.172945,"Spoken dialog systems are slowly becoming and integral part of the human
experience due to their various advantages over textual interfaces. Spoken
language understanding (SLU) systems are fundamental building blocks of spoken
dialog systems. But creating SLU systems for low resourced languages is still a
challenge. In a large number of low resourced language, we don't have access to
enough data to build automatic speech recognition (ASR) technologies, which are
fundamental to any SLU system. Also, ASR based SLU systems do not generalize to
unwritten languages. In this paper, we present a series of experiments to
explore extremely low-resourced settings where we perform intent classification
with systems trained on as low as one data-point per intent and with only one
speaker in the dataset. We also work in a low-resourced setting where we do not
use language specific ASR systems to transcribe input speech, which compounds
the challenge of building SLU systems to simulate a true low-resourced setting.
We test our system on Belgian Dutch (Flemish) and English and find that using
phonetic transcriptions to make intent classification systems in such
low-resourced setting performs significantly better than using speech features.
Specifically, when using a phonetic transcription based system over a feature
based system, we see average improvements of 12.37% and 13.08% for binary and
four-class classification problems respectively, when averaged over 49
different experimental settings."
Evaluation of ChatGPT for NLP-based Mental Health Applications,0.999113,"Large language models (LLM) have been successful in several natural language
understanding tasks and could be relevant for natural language processing
(NLP)-based mental health application research. In this work, we report the
performance of LLM-based ChatGPT (with gpt-3.5-turbo backend) in three
text-based mental health classification tasks: stress detection (2-class
classification), depression detection (2-class classification), and suicidality
detection (5-class classification). We obtained annotated social media posts
for the three classification tasks from public datasets. Then ChatGPT API
classified the social media posts with an input prompt for classification. We
obtained F1 scores of 0.73, 0.86, and 0.37 for stress detection, depression
detection, and suicidality detection, respectively. A baseline model that
always predicted the dominant class resulted in F1 scores of 0.35, 0.60, and
0.19. The zero-shot classification accuracy obtained with ChatGPT indicates a
potential use of language models for mental health classification tasks."
Gloss Attention for Gloss-free Sign Language Translation,0.705029,"Most sign language translation (SLT) methods to date require the use of gloss
annotations to provide additional supervision information, however, the
acquisition of gloss is not easy. To solve this problem, we first perform an
analysis of existing models to confirm how gloss annotations make SLT easier.
We find that it can provide two aspects of information for the model, 1) it can
help the model implicitly learn the location of semantic boundaries in
continuous sign language videos, 2) it can help the model understand the sign
language video globally. We then propose \emph{gloss attention}, which enables
the model to keep its attention within video segments that have the same
semantics locally, just as gloss helps existing models do. Furthermore, we
transfer the knowledge of sentence-to-sentence similarity from the natural
language model to our gloss attention SLT network (GASLT) to help it understand
sign language videos at the sentence level. Experimental results on multiple
large-scale sign language datasets show that our proposed GASLT model
significantly outperforms existing methods. Our code is provided in
\url{https://github.com/YinAoXiong/GASLT}."
Physical Attack on Monocular Depth Estimation with Optimal Adversarial Patches,0.971271,"Deep learning has substantially boosted the performance of Monocular Depth
Estimation (MDE), a critical component in fully vision-based autonomous driving
(AD) systems (e.g., Tesla and Toyota). In this work, we develop an attack
against learning-based MDE. In particular, we use an optimization-based method
to systematically generate stealthy physical-object-oriented adversarial
patches to attack depth estimation. We balance the stealth and effectiveness of
our attack with object-oriented adversarial design, sensitive region
localization, and natural style camouflage. Using real-world driving scenarios,
we evaluate our attack on concurrent MDE models and a representative downstream
task for AD (i.e., 3D object detection). Experimental results show that our
method can generate stealthy, effective, and robust adversarial patches for
different target objects and models and achieves more than 6 meters mean depth
estimation error and 93% attack success rate (ASR) in object detection with a
patch of 1/9 of the vehicle's rear area. Field tests on three different driving
routes with a real vehicle indicate that we cause over 6 meters mean depth
estimation error and reduce the object detection rate from 90.70% to 5.16% in
continuous video frames."
"""FIJO"": a French Insurance Soft Skill Detection Dataset",0.447516,"Understanding the evolution of job requirements is becoming more important
for workers, companies and public organizations to follow the fast
transformation of the employment market. Fortunately, recent natural language
processing (NLP) approaches allow for the development of methods to
automatically extract information from job ads and recognize skills more
precisely. However, these efficient approaches need a large amount of annotated
data from the studied domain which is difficult to access, mainly due to
intellectual property. This article proposes a new public dataset, FIJO,
containing insurance job offers, including many soft skill annotations. To
understand the potential of this dataset, we detail some characteristics and
some limitations. Then, we present the results of skill detection algorithms
using a named entity recognition approach and show that transformers-based
models have good token-wise performances on this dataset. Lastly, we analyze
some errors made by our best model to emphasize the difficulties that may arise
when applying NLP approaches."
A Double-Graph Based Framework for Frame Semantic Parsing,0.739206,"Frame semantic parsing is a fundamental NLP task, which consists of three
subtasks: frame identification, argument identification and role
classification. Most previous studies tend to neglect relations between
different subtasks and arguments and pay little attention to ontological frame
knowledge defined in FrameNet. In this paper, we propose a Knowledge-guided
Incremental semantic parser with Double-graph (KID). We first introduce Frame
Knowledge Graph (FKG), a heterogeneous graph containing both frames and FEs
(Frame Elements) built on the frame knowledge so that we can derive
knowledge-enhanced representations for frames and FEs. Besides, we propose
Frame Semantic Graph (FSG) to represent frame semantic structures extracted
from the text with graph structures. In this way, we can transform frame
semantic parsing into an incremental graph construction problem to strengthen
interactions between subtasks and relations between arguments. Our experiments
show that KID outperforms the previous state-of-the-art method by up to 1.7
F1-score on two FrameNet datasets. Our code is availavle at
https://github.com/PKUnlp-icler/KID."
NerfDiff: Single-image View Synthesis with NeRF-guided Distillation from 3D-aware Diffusion,0.974691,"Novel view synthesis from a single image requires inferring occluded regions
of objects and scenes whilst simultaneously maintaining semantic and physical
consistency with the input. Existing approaches condition neural radiance
fields (NeRF) on local image features, projecting points to the input image
plane, and aggregating 2D features to perform volume rendering. However, under
severe occlusion, this projection fails to resolve uncertainty, resulting in
blurry renderings that lack details. In this work, we propose NerfDiff, which
addresses this issue by distilling the knowledge of a 3D-aware conditional
diffusion model (CDM) into NeRF through synthesizing and refining a set of
virtual views at test time. We further propose a novel NeRF-guided distillation
algorithm that simultaneously generates 3D consistent virtual views from the
CDM samples, and finetunes the NeRF based on the improved virtual views. Our
approach significantly outperforms existing NeRF-based and geometry-free
approaches on challenging datasets, including ShapeNet, ABO, and Clevr3D."
UniGeo: Unifying Geometry Logical Reasoning via Reformulating Mathematical Expression,0.370562,"Geometry problem solving is a well-recognized testbed for evaluating the
high-level multi-modal reasoning capability of deep models. In most existing
works, two main geometry problems: calculation and proving, are usually treated
as two specific tasks, hindering a deep model to unify its reasoning capability
on multiple math tasks. However, in essence, these two tasks have similar
problem representations and overlapped math knowledge which can improve the
understanding and reasoning ability of a deep model on both two tasks.
Therefore, we construct a large-scale Unified Geometry problem benchmark,
UniGeo, which contains 4,998 calculation problems and 9,543 proving problems.
Each proving problem is annotated with a multi-step proof with reasons and
mathematical expressions. The proof can be easily reformulated as a proving
sequence that shares the same formats with the annotated program sequence for
calculation problems. Naturally, we also present a unified multi-task Geometric
Transformer framework, Geoformer, to tackle calculation and proving problems
simultaneously in the form of sequence generation, which finally shows the
reasoning ability can be improved on both two tasks by unifying formulation.
Furthermore, we propose a Mathematical Expression Pretraining (MEP) method that
aims to predict the mathematical expressions in the problem solution, thus
improving the Geoformer model. Experiments on the UniGeo demonstrate that our
proposed Geoformer obtains state-of-the-art performance by outperforming
task-specific model NGS with over 5.6% and 3.2% accuracies on calculation and
proving problems, respectively."
"Think Global, Act Local: Dual-scale Graph Transformer for Vision-and-Language Navigation",0.95054,"Following language instructions to navigate in unseen environments is a
challenging problem for autonomous embodied agents. The agent not only needs to
ground languages in visual scenes, but also should explore the environment to
reach its target. In this work, we propose a dual-scale graph transformer
(DUET) for joint long-term action planning and fine-grained cross-modal
understanding. We build a topological map on-the-fly to enable efficient
exploration in global action space. To balance the complexity of large action
space reasoning and fine-grained language grounding, we dynamically combine a
fine-scale encoding over local observations and a coarse-scale encoding on a
global map via graph transformers. The proposed approach, DUET, significantly
outperforms state-of-the-art methods on goal-oriented vision-and-language
navigation (VLN) benchmarks REVERIE and SOON. It also improves the success rate
on the fine-grained VLN benchmark R2R."
MorphTE: Injecting Morphology in Tensorized Embeddings,0.2987,"In the era of deep learning, word embeddings are essential when dealing with
text tasks. However, storing and accessing these embeddings requires a large
amount of space. This is not conducive to the deployment of these models on
resource-limited devices. Combining the powerful compression capability of
tensor products, we propose a word embedding compression method with
morphological augmentation, Morphologically-enhanced Tensorized Embeddings
(MorphTE). A word consists of one or more morphemes, the smallest units that
bear meaning or have a grammatical function. MorphTE represents a word
embedding as an entangled form of its morpheme vectors via the tensor product,
which injects prior semantic and grammatical knowledge into the learning of
embeddings. Furthermore, the dimensionality of the morpheme vector and the
number of morphemes are much smaller than those of words, which greatly reduces
the parameters of the word embeddings. We conduct experiments on tasks such as
machine translation and question answering. Experimental results on four
translation datasets of different languages show that MorphTE can compress word
embedding parameters by about 20 times without performance loss and
significantly outperforms related embedding compression methods."
Multi-Level Modeling Units for End-to-End Mandarin Speech Recognition,0.0769842,"The choice of modeling units is crucial for automatic speech recognition
(ASR) tasks. In mandarin scenarios, the Chinese characters represent meaning
but are not directly related to the pronunciation. Thus only considering the
writing of Chinese characters as modeling units is insufficient to capture
speech features. In this paper, we present a novel method involves with
multi-level modeling units, which integrates multi-level information for
mandarin speech recognition. Specifically, the encoder block considers
syllables as modeling units and the decoder block deals with character-level
modeling units. To facilitate the incremental conversion from syllable features
to character features, we design an auxiliary task that applies cross-entropy
(CE) loss to intermediate decoder layers. During inference, the input feature
sequences are converted into syllable sequences by the encoder block and then
converted into Chinese characters by the decoder block. Experiments on the
widely used AISHELL-1 corpus demonstrate that our method achieves promising
results with CER of 4.1%/4.6% and 4.6%/5.2%, using the Conformer and the
Transformer backbones respectively."
"HealthEdge: A Machine Learning-Based Smart Healthcare Framework for Prediction of Type 2 Diabetes in an Integrated IoT, Edge, and Cloud Computing System",0.725276,"Diabetes Mellitus has no permanent cure to date and is one of the leading
causes of death globally. The alarming increase in diabetes calls for the need
to take precautionary measures to avoid/predict the occurrence of diabetes.
This paper proposes HealthEdge, a machine learning-based smart healthcare
framework for type 2 diabetes prediction in an integrated IoT-edge-cloud
computing system. Numerical experiments and comparative analysis were carried
out between the two most used machine learning algorithms in the literature,
Random Forest (RF) and Logistic Regression (LR), using two real-life diabetes
datasets. The results show that RF predicts diabetes with 6% more accuracy on
average compared to LR."
Referee: Reference-Free Sentence Summarization with Sharper Controllability through Symbolic Knowledge Distillation,0.447913,"We present Referee, a novel framework for sentence summarization that can be
trained reference-free (i.e., requiring no gold summaries for supervision),
while allowing direct control for compression ratio. Our work is the first to
demonstrate that reference-free, controlled sentence summarization is feasible
via the conceptual framework of Symbolic Knowledge Distillation (West et al.,
2022), where latent knowledge in pre-trained language models is distilled via
explicit examples sampled from the teacher models, further purified with three
types of filters: length, fidelity, and Information Bottleneck. Moreover, we
uniquely propose iterative distillation of knowledge, where student models from
the previous iteration of distillation serve as teacher models in the next
iteration. Starting off from a relatively modest set of GPT3-generated
summaries, we demonstrate how iterative knowledge distillation can lead to
considerably smaller, but better summarizers with sharper controllability. A
useful by-product of this iterative distillation process is a high-quality
dataset of sentence-summary pairs with varying degrees of compression ratios.
Empirical results demonstrate that the final student models vastly outperform
the much larger GPT3-Instruct model in terms of the controllability of
compression ratios, without compromising the quality of resulting
summarization."
Object Scan Context: Object-centric Spatial Descriptor for Place Recognition within 3D Point Cloud Map,0.0672233,"The integration of a SLAM algorithm with place recognition technology
empowers it with the ability to mitigate accumulated errors and to relocalize
itself. However, existing methods for point cloud-based place recognition
predominantly rely on the matching of descriptors, which are mostly
lidar-centric. These methods suffer from two major drawbacks: first, they
cannot perform place recognition when the distance between two point clouds is
significant, and second, they can only calculate the rotation angle without
considering the offset in the X and Y directions. To overcome these
limitations, we propose a novel local descriptor that is constructed around the
Main Object. By using a geometric method, we can accurately calculate the
relative pose. We have provided a theoretical analysis to demonstrate that this
method can overcome the aforementioned limitations. Furthermore, we conducted
extensive experiments on KITTI Odometry and KITTI360, which indicate that our
proposed method has significant advantages over state-of-the-art methods."
KwaiAgents: Generalized Information-seeking Agent System with Large Language Models,0.458342,"Driven by curiosity, humans have continually sought to explore and understand
the world around them, leading to the invention of various tools to satiate
this inquisitiveness. Despite not having the capacity to process and memorize
vast amounts of information in their brains, humans excel in critical thinking,
planning, reflection, and harnessing available tools to interact with and
interpret the world, enabling them to find answers efficiently. The recent
advancements in large language models (LLMs) suggest that machines might also
possess the aforementioned human-like capabilities, allowing them to exhibit
powerful abilities even with a constrained parameter count. In this paper, we
introduce KwaiAgents, a generalized information-seeking agent system based on
LLMs. Within KwaiAgents, we propose an agent system that employs LLMs as its
cognitive core, which is capable of understanding a user's query, behavior
guidelines, and referencing external documents. The agent can also update and
retrieve information from its internal memory, plan and execute actions using a
time-aware search-browse toolkit, and ultimately provide a comprehensive
response. We further investigate the system's performance when powered by LLMs
less advanced than GPT-4, and introduce the Meta-Agent Tuning (MAT) framework,
designed to ensure even an open-sourced 7B or 13B model performs well among
many agent systems. We exploit both benchmark and human evaluations to
systematically validate these capabilities. Extensive experiments show the
superiority of our agent system compared to other autonomous agents and
highlight the enhanced generalized agent-abilities of our fine-tuned LLMs."
Slot Induction via Pre-trained Language Model Probing and Multi-level Contrastive Learning,0.0999024,"Recent advanced methods in Natural Language Understanding for Task-oriented
Dialogue (TOD) Systems (e.g., intent detection and slot filling) require a
large amount of annotated data to achieve competitive performance. In reality,
token-level annotations (slot labels) are time-consuming and difficult to
acquire. In this work, we study the Slot Induction (SI) task whose objective is
to induce slot boundaries without explicit knowledge of token-level slot
annotations. We propose leveraging Unsupervised Pre-trained Language Model
(PLM) Probing and Contrastive Learning mechanism to exploit (1) unsupervised
semantic knowledge extracted from PLM, and (2) additional sentence-level intent
label signals available from TOD. Our approach is shown to be effective in SI
task and capable of bridging the gaps with token-level supervised models on two
NLU benchmark datasets. When generalized to emerging intents, our SI objectives
also provide enhanced slot label representations, leading to improved
performance on the Slot Filling tasks."
Masked and Adaptive Transformer for Exemplar Based Image Translation,0.44924,"We present a novel framework for exemplar based image translation. Recent
advanced methods for this task mainly focus on establishing cross-domain
semantic correspondence, which sequentially dominates image generation in the
manner of local style control. Unfortunately, cross-domain semantic matching is
challenging; and matching errors ultimately degrade the quality of generated
images. To overcome this challenge, we improve the accuracy of matching on the
one hand, and diminish the role of matching in image generation on the other
hand. To achieve the former, we propose a masked and adaptive transformer (MAT)
for learning accurate cross-domain correspondence, and executing context-aware
feature augmentation. To achieve the latter, we use source features of the
input and global style codes of the exemplar, as supplementary information, for
decoding an image. Besides, we devise a novel contrastive style learning
method, for acquire quality-discriminative style representations, which in turn
benefit high-quality image generation. Experimental results show that our
method, dubbed MATEBIT, performs considerably better than state-of-the-art
methods, in diverse image translation tasks. The codes are available at
\url{https://github.com/AiArt-HDU/MATEBIT}."
Human from Blur: Human Pose Tracking from Blurry Images,0.0545296,"We propose a method to estimate 3D human poses from substantially blurred
images. The key idea is to tackle the inverse problem of image deblurring by
modeling the forward problem with a 3D human model, a texture map, and a
sequence of poses to describe human motion. The blurring process is then
modeled by a temporal image aggregation step. Using a differentiable renderer,
we can solve the inverse problem by backpropagating the pixel-wise reprojection
error to recover the best human motion representation that explains a single or
multiple input images. Since the image reconstruction loss alone is
insufficient, we present additional regularization terms. To the best of our
knowledge, we present the first method to tackle this problem. Our method
consistently outperforms other methods on significantly blurry inputs since
they lack one or multiple key functionalities that our method unifies, i.e.
image deblurring with sub-frame accuracy and explicit 3D modeling of non-rigid
human motion."
Task Ambiguity in Humans and Language Models,0.400541,"Language models have recently achieved strong performance across a wide range
of NLP benchmarks. However, unlike benchmarks, real world tasks are often
poorly specified, and agents must deduce the user's intended behavior from a
combination of context, instructions, and examples. We investigate how both
humans and models behave in the face of such task ambiguity by proposing
AmbiBench, a new benchmark of six ambiguously-specified classification tasks.
We evaluate humans and models on AmbiBench by seeing how well they identify the
intended task using 1) instructions with varying degrees of ambiguity, and 2)
different numbers of labeled examples. We find that the combination of model
scaling (to 175B parameters) and training with human feedback data enables
models to approach or exceed the accuracy of human participants across tasks,
but that either one alone is not sufficient. In addition, we show how to
dramatically improve the accuracy of language models trained without
large-scale human feedback training by finetuning on a small number of
ambiguous in-context examples, providing a promising direction for teaching
models to generalize well in the face of ambiguity."
Learning Audio-Text Agreement for Open-vocabulary Keyword Spotting,0.802616,"In this paper, we propose a novel end-to-end user-defined keyword spotting
method that utilizes linguistically corresponding patterns between speech and
text sequences. Unlike previous approaches requiring speech keyword enrollment,
our method compares input queries with an enrolled text keyword sequence. To
place the audio and text representations within a common latent space, we adopt
an attention-based cross-modal matching approach that is trained in an
end-to-end manner with monotonic matching loss and keyword classification loss.
We also utilize a de-noising loss for the acoustic embedding network to improve
robustness in noisy environments. Additionally, we introduce the LibriPhrase
dataset, a new short-phrase dataset based on LibriSpeech for efficiently
training keyword spotting models. Our proposed method achieves competitive
results on various evaluation sets compared to other single-modal and
cross-modal baselines."
Data-Free Distillation of Language Model by Text-to-Text Transfer,0.252638,"Data-Free Knowledge Distillation (DFKD) plays a vital role in compressing the
model when original training data is unavailable. Previous works for DFKD in
NLP mainly focus on distilling encoder-only structures like BERT on
classification tasks, which overlook the notable progress of generative
language modeling. In this work, we propose a novel DFKD framework, namely
DFKD-T$^{3}$, where the pretrained generative language model can also serve as
a controllable data generator for model compression. This novel framework
DFKD-T$^{3}$ leads to an end-to-end learnable text-to-text framework to
transform the general domain corpus to compression-friendly task data,
targeting to improve both the \textit{specificity} and \textit{diversity}.
Extensive experiments show that our method can boost the distillation
performance in various downstream tasks such as sentiment analysis, linguistic
acceptability, and information extraction. Furthermore, we show that the
generated texts can be directly used for distilling other language models and
outperform the SOTA methods, making our method more appealing in a general DFKD
setting. Our code is available at
https://gitee.com/mindspore/models/tree/master/research/nlp/DFKD\_T3."
The COVMis-Stance dataset: Stance Detection on Twitter for COVID-19 Misinformation,0.0875039,"During the COVID-19 pandemic, large amounts of COVID-19 misinformation are
spreading on social media. We are interested in the stance of Twitter users
towards COVID-19 misinformation. However, due to the relative recent nature of
the pandemic, only a few stance detection datasets fit our task. We have
constructed a new stance dataset consisting of 2631 tweets annotated with the
stance towards COVID-19 misinformation. In contexts with limited labeled data,
we fine-tune our models by leveraging the MNLI dataset and two existing stance
detection datasets (RumourEval and COVIDLies), and evaluate the model
performance on our dataset. Our experimental results show that the model
performs the best when fine-tuned sequentially on the MNLI dataset and the
combination of the undersampled RumourEval and COVIDLies datasets. Our code and
dataset are publicly available at
https://github.com/yanfangh/covid-rumor-stance"
Deformable VisTR: Spatio temporal deformable attention for video instance segmentation,0.075154,"Video instance segmentation (VIS) task requires classifying, segmenting, and
tracking object instances over all frames in a video clip. Recently, VisTR has
been proposed as end-to-end transformer-based VIS framework, while
demonstrating state-of-the-art performance. However, VisTR is slow to converge
during training, requiring around 1000 GPU hours due to the high computational
cost of its transformer attention module. To improve the training efficiency,
we propose Deformable VisTR, leveraging spatio-temporal deformable attention
module that only attends to a small fixed set of key spatio-temporal sampling
points around a reference point. This enables Deformable VisTR to achieve
linear computation in the size of spatio-temporal feature maps. Moreover, it
can achieve on par performance as the original VisTR with 10$\times$ less GPU
training hours. We validate the effectiveness of our method on the Youtube-VIS
benchmark. Code is available at https://github.com/skrya/DefVIS."
On Adversarial Robustness of Deep Image Deblurring,0.534022,"Recent approaches employ deep learning-based solutions for the recovery of a
sharp image from its blurry observation. This paper introduces adversarial
attacks against deep learning-based image deblurring methods and evaluates the
robustness of these neural networks to untargeted and targeted attacks. We
demonstrate that imperceptible distortion can significantly degrade the
performance of state-of-the-art deblurring networks, even producing drastically
different content in the output, indicating the strong need to include
adversarially robust training not only in classification but also for image
recovery."
Global Sensing and Measurements Reuse for Image Compressed Sensing,0.483759,"Recently, deep network-based image compressed sensing methods achieved high
reconstruction quality and reduced computational overhead compared with
traditional methods. However, existing methods obtain measurements only from
partial features in the network and use them only once for image
reconstruction. They ignore there are low, mid, and high-level features in the
network\cite{zeiler2014visualizing} and all of them are essential for
high-quality reconstruction. Moreover, using measurements only once may not be
enough for extracting richer information from measurements. To address these
issues, we propose a novel Measurements Reuse Convolutional Compressed Sensing
Network (MR-CCSNet) which employs Global Sensing Module (GSM) to collect all
level features for achieving an efficient sensing and Measurements Reuse Block
(MRB) to reuse measurements multiple times on multi-scale. Finally,
experimental results on three benchmark datasets show that our model can
significantly outperform state-of-the-art methods."
Learning by Distilling Context,0.639441,"Language models significantly benefit from context tokens, such as prompts or
scratchpads. They perform better when prompted with informative instructions,
and they acquire new reasoning capabilities by generating a scratch-pad before
predicting the final answers. However, they do not \textit{internalize} these
performance gains, which disappear when the context tokens are gone. Our work
proposes to apply context distillation so that a language model can improve
itself by internalizing these gains. Concretely, given a synthetic unlabeled
input for the target task, we condition the model on ``[instructions] +
[task-input]'' to predict ``[scratch-pad] + [final answer]''; then we fine-tune
the same model to predict its own ``[final answer]'' conditioned on the
``[task-input]'', without seeing the ``[instructions]'' or using the
``[scratch-pad]''.
  We show that context distillation is a general method to train language
models, and it can effectively internalize 3 types of training signals. First,
it can internalize abstract task instructions and explanations, so we can
iteratively update the model parameters with new instructions and overwrite old
ones. Second, it can internalize step-by-step reasoning for complex tasks
(e.g., 8-digit addition), and such a newly acquired capability proves to be
useful for other downstream tasks. Finally, it can internalize concrete
training examples, and it outperforms directly learning with gradient descent
by 9\% on the SPIDER Text-to-SQL dataset; furthermore, combining context
distillation operations can internalize more training examples than the context
window size allows."
Tracking without Label: Unsupervised Multiple Object Tracking via Contrastive Similarity Learning,0.221418,"Unsupervised learning is a challenging task due to the lack of labels.
Multiple Object Tracking (MOT), which inevitably suffers from mutual object
interference, occlusion, etc., is even more difficult without label
supervision. In this paper, we explore the latent consistency of sample
features across video frames and propose an Unsupervised Contrastive Similarity
Learning method, named UCSL, including three contrast modules: self-contrast,
cross-contrast, and ambiguity contrast. Specifically, i) self-contrast uses
intra-frame direct and inter-frame indirect contrast to obtain discriminative
representations by maximizing self-similarity. ii) Cross-contrast aligns cross-
and continuous-frame matching results, mitigating the persistent negative
effect caused by object occlusion. And iii) ambiguity contrast matches
ambiguous objects with each other to further increase the certainty of
subsequent object association through an implicit manner. On existing
benchmarks, our method outperforms the existing unsupervised methods using only
limited help from ReID head, and even provides higher accuracy than lots of
fully supervised methods."
Betti numbers of attention graphs is all you really need,0.202947,"We apply methods of topological analysis to the attention graphs, calculated
on the attention heads of the BERT model ( arXiv:1810.04805v2 ). Our research
shows that the classifier built upon basic persistent topological features
(namely, Betti numbers) of the trained neural network can achieve
classification results on par with the conventional classification method. We
show the relevance of such topological text representation on three text
classification benchmarks. For the best of our knowledge, it is the first
attempt to analyze the topology of an attention-based neural network, widely
used for Natural Language Processing."
Product Market Demand Analysis Using NLP in Banglish Text with Sentiment Analysis and Named Entity Recognition,0.513833,"Product market demand analysis plays a significant role for originating
business strategies due to its noticeable impact on the competitive business
field. Furthermore, there are roughly 228 million native Bengali speakers, the
majority of whom use Banglish text to interact with one another on social
media. Consumers are buying and evaluating items on social media with Banglish
text as social media emerges as an online marketplace for entrepreneurs. People
use social media to find preferred smartphone brands and models by sharing
their positive and bad experiences with them. For this reason, our goal is to
gather Banglish text data and use sentiment analysis and named entity
identification to assess Bangladeshi market demand for smartphones in order to
determine the most popular smartphones by gender. We scraped product related
data from social media with instant data scrapers and crawled data from
Wikipedia and other sites for product information with python web scrapers.
Using Python's Pandas and Seaborn libraries, the raw data is filtered using NLP
methods. To train our datasets for named entity recognition, we utilized
Spacey's custom NER model, Amazon Comprehend Custom NER. A tensorflow
sequential model was deployed with parameter tweaking for sentiment analysis.
Meanwhile, we used the Google Cloud Translation API to estimate the gender of
the reviewers using the BanglaLinga library. In this article, we use natural
language processing (NLP) approaches and several machine learning models to
identify the most in-demand items and services in the Bangladeshi market. Our
model has an accuracy of 87.99% in Spacy Custom Named Entity recognition,
95.51% in Amazon Comprehend Custom NER, and 87.02% in the Sequential model for
demand analysis. After Spacy's study, we were able to manage 80% of mistakes
related to misspelled words using a mix of Levenshtein distance and ratio
algorithms."
Disparate Impact in Differential Privacy from Gradient Misalignment,0.812535,"As machine learning becomes more widespread throughout society, aspects
including data privacy and fairness must be carefully considered, and are
crucial for deployment in highly regulated industries. Unfortunately, the
application of privacy enhancing technologies can worsen unfair tendencies in
models. In particular, one of the most widely used techniques for private model
training, differentially private stochastic gradient descent (DPSGD),
frequently intensifies disparate impact on groups within data. In this work we
study the fine-grained causes of unfairness in DPSGD and identify gradient
misalignment due to inequitable gradient clipping as the most significant
source. This observation leads us to a new method for reducing unfairness by
preventing gradient misalignment in DPSGD."
Constant-Factor Approximation Algorithms for Socially Fair $k$-Clustering,0.717742,"We study approximation algorithms for the socially fair $(\ell_p,
k)$-clustering problem with $m$ groups, whose special cases include the
socially fair $k$-median ($p=1$) and socially fair $k$-means ($p=2$) problems.
We present (1) a polynomial-time $(5+2\sqrt{6})^p$-approximation with at most
$k+m$ centers (2) a $(5+2\sqrt{6}+\epsilon)^p$-approximation with $k$ centers
in time $n^{2^{O(p)}\cdot m^2}$, and (3) a $(15+6\sqrt{6})^p$ approximation
with $k$ centers in time $k^{m}\cdot\text{poly}(n)$. The first result is
obtained via a refinement of the iterative rounding method using a sequence of
linear programs. The latter two results are obtained by converting a solution
with up to $k+m$ centers to one with $k$ centers using sparsification methods
for (2) and via an exhaustive search for (3). We also compare the performance
of our algorithms with existing bicriteria algorithms as well as exactly $k$
center approximation algorithms on benchmark datasets, and find that our
algorithms also outperform existing methods in practice."
DoCoFL: Downlink Compression for Cross-Device Federated Learning,0.313495,"Many compression techniques have been proposed to reduce the communication
overhead of Federated Learning training procedures. However, these are
typically designed for compressing model updates, which are expected to decay
throughout training. As a result, such methods are inapplicable to downlink
(i.e., from the parameter server to clients) compression in the cross-device
setting, where heterogeneous clients $\textit{may appear only once}$ during
training and thus must download the model parameters. Accordingly, we propose
$\textsf{DoCoFL}$ -- a new framework for downlink compression in the
cross-device setting. Importantly, $\textsf{DoCoFL}$ can be seamlessly combined
with many uplink compression schemes, rendering it suitable for bi-directional
compression. Through extensive evaluation, we show that $\textsf{DoCoFL}$
offers significant bi-directional bandwidth reduction while achieving
competitive accuracy to that of a baseline without any compression."
A Formal Perspective on Byte-Pair Encoding,0.739265,"Byte-Pair Encoding (BPE) is a popular algorithm used for tokenizing data in
NLP, despite being devised initially as a compression method. BPE appears to be
a greedy algorithm at face value, but the underlying optimization problem that
BPE seeks to solve has not yet been laid down. We formalize BPE as a
combinatorial optimization problem. Via submodular functions, we prove that the
iterative greedy version is a
$\frac{1}{{\sigma(\boldsymbol{\mu}^\star)}}(1-e^{-{\sigma(\boldsymbol{\mu}^\star)}})$-approximation
of an optimal merge sequence, where ${\sigma(\boldsymbol{\mu}^\star)}$ is the
total backward curvature with respect to the optimal merge sequence
$\boldsymbol{\mu}^\star$. Empirically the lower bound of the approximation is
$\approx 0.37$.
  We provide a faster implementation of BPE which improves the runtime
complexity from $\mathcal{O}\left(N M\right)$ to $\mathcal{O}\left(N \log
M\right)$, where $N$ is the sequence length and $M$ is the merge count.
Finally, we optimize the brute-force algorithm for optimal BPE using
memoization."
IfQA: A Dataset for Open-domain Question Answering under Counterfactual Presuppositions,0.493701,"Although counterfactual reasoning is a fundamental aspect of intelligence,
the lack of large-scale counterfactual open-domain question-answering (QA)
benchmarks makes it difficult to evaluate and improve models on this ability.
To address this void, we introduce the first such dataset, named IfQA, where
each question is based on a counterfactual presupposition via an ""if"" clause.
For example, if Los Angeles was on the east coast of the U.S., what would be
the time difference between Los Angeles and Paris? Such questions require
models to go beyond retrieving direct factual knowledge from the Web: they must
identify the right information to retrieve and reason about an imagined
situation that may even go against the facts built into their parameters. The
IfQA dataset contains over 3,800 questions that were annotated annotated by
crowdworkers on relevant Wikipedia passages. Empirical analysis reveals that
the IfQA dataset is highly challenging for existing open-domain QA methods,
including supervised retrieve-then-read pipeline methods (EM score 36.2), as
well as recent few-shot approaches such as chain-of-thought prompting with
GPT-3 (EM score 27.4). The unique challenges posed by the IfQA benchmark will
push open-domain QA research on both retrieval and counterfactual reasoning
fronts."
Few-shot Open-set Recognition Using Background as Unknowns,0.321281,"Few-shot open-set recognition aims to classify both seen and novel images
given only limited training data of seen classes. The challenge of this task is
that the model is required not only to learn a discriminative classifier to
classify the pre-defined classes with few training data but also to reject
inputs from unseen classes that never appear at training time. In this paper,
we propose to solve the problem from two novel aspects. First, instead of
learning the decision boundaries between seen classes, as is done in standard
close-set classification, we reserve space for unseen classes, such that images
located in these areas are recognized as the unseen classes. Second, to
effectively learn such decision boundaries, we propose to utilize the
background features from seen classes. As these background regions do not
significantly contribute to the decision of close-set classification, it is
natural to use them as the pseudo unseen classes for classifier learning. Our
extensive experiments show that our proposed method not only outperforms
multiple baselines but also sets new state-of-the-art results on three popular
benchmarks, namely tieredImageNet, miniImageNet, and Caltech-USCD
Birds-200-2011 (CUB)."
Detecting Unintended Social Bias in Toxic Language Datasets,0.61076,"With the rise of online hate speech, automatic detection of Hate Speech,
Offensive texts as a natural language processing task is getting popular.
However, very little research has been done to detect unintended social bias
from these toxic language datasets. This paper introduces a new dataset
ToxicBias curated from the existing dataset of Kaggle competition named ""Jigsaw
Unintended Bias in Toxicity Classification"". We aim to detect social biases,
their categories, and targeted groups. The dataset contains instances annotated
for five different bias categories, viz., gender, race/ethnicity, religion,
political, and LGBTQ. We train transformer-based models using our curated
datasets and report baseline performance for bias identification, target
generation, and bias implications. Model biases and their mitigation are also
discussed in detail. Our study motivates a systematic extraction of social bias
data from toxic language datasets. All the codes and dataset used for
experiments in this work are publicly available"
DeepShadow: Neural Shape from Shadow,0.203798,"This paper presents DeepShadow, a one-shot method for recovering the depth
map and surface normals from photometric stereo shadow maps. Previous works
that try to recover the surface normals from photometric stereo images treat
cast shadows as a disturbance. We show that the self and cast shadows not only
do not disturb 3D reconstruction, but can be used alone, as a strong learning
signal, to recover the depth map and surface normals. We demonstrate that 3D
reconstruction from shadows can even outperform shape-from-shading in certain
cases. To the best of our knowledge, our method is the first to reconstruct 3D
shape-from-shadows using neural networks. The method does not require any
pre-training or expensive labeled data, and is optimized during inference time."
GSR: A Generalized Symbolic Regression Approach,0.244449,"Identifying the mathematical relationships that best describe a dataset
remains a very challenging problem in machine learning, and is known as
Symbolic Regression (SR). In contrast to neural networks which are often
treated as black boxes, SR attempts to gain insight into the underlying
relationships between the independent variables and the target variable of a
given dataset by assembling analytical functions. In this paper, we present
GSR, a Generalized Symbolic Regression approach, by modifying the conventional
SR optimization problem formulation, while keeping the main SR objective
intact. In GSR, we infer mathematical relationships between the independent
variables and some transformation of the target variable. We constrain our
search space to a weighted sum of basis functions, and propose a genetic
programming approach with a matrix-based encoding scheme. We show that our GSR
method is competitive with strong SR benchmark methods, achieving promising
experimental performance on the well-known SR benchmark problem sets. Finally,
we highlight the strengths of GSR by introducing SymSet, a new SR benchmark set
which is more challenging relative to the existing benchmarks."
Integrating Graphs with Large Language Models: Methods and Prospects,0.569045,"Large language models (LLMs) such as GPT-4 have emerged as frontrunners,
showcasing unparalleled prowess in diverse applications, including answering
queries, code generation, and more. Parallelly, graph-structured data, an
intrinsic data type, is pervasive in real-world scenarios. Merging the
capabilities of LLMs with graph-structured data has been a topic of keen
interest. This paper bifurcates such integrations into two predominant
categories. The first leverages LLMs for graph learning, where LLMs can not
only augment existing graph algorithms but also stand as prediction models for
various graph tasks. Conversely, the second category underscores the pivotal
role of graphs in advancing LLMs. Mirroring human cognition, we solve complex
tasks by adopting graphs in either reasoning or collaboration. Integrating with
such structures can significantly boost the performance of LLMs in various
complicated tasks. We also discuss and propose open questions for integrating
LLMs with graph-structured data for the future direction of the field."
Regularized Conventions: Equilibrium Computation as a Model of Pragmatic Reasoning,0.0311588,"We present a model of pragmatic language understanding, where utterances are
produced and understood by searching for regularized equilibria of signaling
games. In this model (which we call ReCo, for Regularized Conventions),
speakers and listeners search for contextually appropriate utterance--meaning
mappings that are both close to game-theoretically optimal conventions and
close to a shared, ''default'' semantics. By characterizing pragmatic
communication as equilibrium search, we obtain principled sampling algorithms
and formal guarantees about the trade-off between communicative success and
naturalness. Across several datasets capturing real and idealized human
judgments about pragmatic implicatures, ReCo matches or improves upon
predictions made by best response and rational speech act models of language
understanding."
S3E-GNN: Sparse Spatial Scene Embedding with Graph Neural Networks for Camera Relocalization,0.0373941,"Camera relocalization is the key component of simultaneous localization and
mapping (SLAM) systems. This paper proposes a learning-based approach, named
Sparse Spatial Scene Embedding with Graph Neural Networks (S3E-GNN), as an
end-to-end framework for efficient and robust camera relocalization. S3E-GNN
consists of two modules. In the encoding module, a trained S3E network encodes
RGB images into embedding codes to implicitly represent spatial and semantic
embedding code. With embedding codes and the associated poses obtained from a
SLAM system, each image is represented as a graph node in a pose graph. In the
GNN query module, the pose graph is transformed to form a embedding-aggregated
reference graph for camera relocalization. We collect various scene datasets in
the challenging environments to perform experiments. Our results demonstrate
that S3E-GNN method outperforms the traditional Bag-of-words (BoW) for camera
relocalization due to learning-based embedding and GNN powered scene matching
mechanism."
Depth Estimation Matters Most: Improving Per-Object Depth Estimation for Monocular 3D Detection and Tracking,0.750607,"Monocular image-based 3D perception has become an active research area in
recent years owing to its applications in autonomous driving. Approaches to
monocular 3D perception including detection and tracking, however, often yield
inferior performance when compared to LiDAR-based techniques. Through
systematic analysis, we identified that per-object depth estimation accuracy is
a major factor bounding the performance. Motivated by this observation, we
propose a multi-level fusion method that combines different representations
(RGB and pseudo-LiDAR) and temporal information across multiple frames for
objects (tracklets) to enhance per-object depth estimation. Our proposed fusion
method achieves the state-of-the-art performance of per-object depth estimation
on the Waymo Open Dataset, the KITTI detection dataset, and the KITTI MOT
dataset. We further demonstrate that by simply replacing estimated depth with
fusion-enhanced depth, we can achieve significant improvements in monocular 3D
perception tasks, including detection and tracking."
Tracking Progress in Multi-Agent Path Finding,0.89821,"Multi-Agent Path Finding (MAPF) is an important core problem for many new and
emerging industrial applications. Many works appear on this topic each year,
and a large number of substantial advancements and performance improvements
have been reported. Yet measuring overall progress in MAPF is difficult: there
are many potential competitors, and the computational burden for comprehensive
experimentation is prohibitively large. Moreover, detailed data from past
experimentation is usually unavailable. In this work, we introduce a set of
methodological and visualisation tools which can help the community establish
clear indicators for state-of-the-art MAPF performance and which can facilitate
large-scale comparisons between MAPF solvers. Our objectives are to lower the
barrier of entry for new researchers and to further promote the study of MAPF,
since progress in the area and the main challenges are made much clearer."
3D Masked Modelling Advances Lesion Classification in Axial T2w Prostate MRI,0.0522276,"Masked Image Modelling (MIM) has been shown to be an efficient
self-supervised learning (SSL) pre-training paradigm when paired with
transformer architectures and in the presence of a large amount of unlabelled
natural images. The combination of the difficulties in accessing and obtaining
large amounts of labeled data and the availability of unlabelled data in the
medical imaging domain makes MIM an interesting approach to advance deep
learning (DL) applications based on 3D medical imaging data. Nevertheless, SSL
and, in particular, MIM applications with medical imaging data are rather
scarce and there is still uncertainty. around the potential of such a learning
paradigm in the medical domain. We study MIM in the context of Prostate Cancer
(PCa) lesion classification with T2 weighted (T2w) axial magnetic resonance
imaging (MRI) data. In particular, we explore the effect of using MIM when
coupled with convolutional neural networks (CNNs) under different conditions
such as different masking strategies, obtaining better results in terms of AUC
than other pre-training strategies like ImageNet weight initialization."
DynaShare: Task and Instance Conditioned Parameter Sharing for Multi-Task Learning,0.0458591,"Multi-task networks rely on effective parameter sharing to achieve robust
generalization across tasks. In this paper, we present a novel parameter
sharing method for multi-task learning that conditions parameter sharing on
both the task and the intermediate feature representations at inference time.
In contrast to traditional parameter sharing approaches, which fix or learn a
deterministic sharing pattern during training and apply the same pattern to all
examples during inference, we propose to dynamically decide which parts of the
network to activate based on both the task and the input instance. Our approach
learns a hierarchical gating policy consisting of a task-specific policy for
coarse layer selection and gating units for individual input instances, which
work together to determine the execution path at inference time. Experiments on
the NYU v2, Cityscapes and MIMIC-III datasets demonstrate the potential of the
proposed approach and its applicability across problem domains."
Long Video Generation with Time-Agnostic VQGAN and Time-Sensitive Transformer,0.876453,"Videos are created to express emotion, exchange information, and share
experiences. Video synthesis has intrigued researchers for a long time. Despite
the rapid progress driven by advances in visual synthesis, most existing
studies focus on improving the frames' quality and the transitions between
them, while little progress has been made in generating longer videos. In this
paper, we present a method that builds on 3D-VQGAN and transformers to generate
videos with thousands of frames. Our evaluation shows that our model trained on
16-frame video clips from standard benchmarks such as UCF-101, Sky Time-lapse,
and Taichi-HD datasets can generate diverse, coherent, and high-quality long
videos. We also showcase conditional extensions of our approach for generating
meaningful long videos by incorporating temporal information with text and
audio. Videos and code can be found at
https://songweige.github.io/projects/tats/index.html."
Analogical Math Word Problems Solving with Enhanced Problem-Solution Association,0.250567,"Math word problem (MWP) solving is an important task in question answering
which requires human-like reasoning ability. Analogical reasoning has long been
used in mathematical education, as it enables students to apply common
relational structures of mathematical situations to solve new problems. In this
paper, we propose to build a novel MWP solver by leveraging analogical MWPs,
which advance the solver's generalization ability across different kinds of
MWPs. The key idea, named analogy identification, is to associate the
analogical MWP pairs in a latent space, i.e., encoding an MWP close to another
analogical MWP, while moving away from the non-analogical ones. Moreover, a
solution discriminator is integrated into the MWP solver to enhance the
association between the representations of MWPs and their true solutions. The
evaluation results verify that our proposed analogical learning strategy
promotes the performance of MWP-BERT on Math23k over the state-of-the-art model
Generate2Rank, with 5 times fewer parameters in the encoder. We also find that
our model has a stronger generalization ability in solving difficult MWPs due
to the analogical learning from easy MWPs."
Rich Knowledge Sources Bring Complex Knowledge Conflicts: Recalibrating Models to Reflect Conflicting Evidence,0.997513,"Question answering models can use rich knowledge sources -- up to one hundred
retrieved passages and parametric knowledge in the large-scale language model
(LM). Prior work assumes information in such knowledge sources is consistent
with each other, paying little attention to how models blend information stored
in their LM parameters with that from retrieved evidence documents. In this
paper, we simulate knowledge conflicts (i.e., where parametric knowledge
suggests one answer and different passages suggest different answers) and
examine model behaviors. We find retrieval performance heavily impacts which
sources models rely on, and current models mostly rely on non-parametric
knowledge in their best-performing settings. We discover a troubling trend that
contradictions among knowledge sources affect model confidence only marginally.
To address this issue, we present a new calibration study, where models are
discouraged from presenting any single answer when presented with multiple
conflicting answer candidates in retrieved evidences."
Revisiting Event-based Video Frame Interpolation,0.295783,"Dynamic vision sensors or event cameras provide rich complementary
information for video frame interpolation. Existing state-of-the-art methods
follow the paradigm of combining both synthesis-based and warping networks.
However, few of those methods fully respect the intrinsic characteristics of
events streams. Given that event cameras only encode intensity changes and
polarity rather than color intensities, estimating optical flow from events is
arguably more difficult than from RGB information. We therefore propose to
incorporate RGB information in an event-guided optical flow refinement
strategy. Moreover, in light of the quasi-continuous nature of the time signals
provided by event cameras, we propose a divide-and-conquer strategy in which
event-based intermediate frame synthesis happens incrementally in multiple
simplified stages rather than in a single, long stage. Extensive experiments on
both synthetic and real-world datasets show that these modifications lead to
more reliable and realistic intermediate frame results than previous video
frame interpolation methods. Our findings underline that a careful
consideration of event characteristics such as high temporal density and
elevated noise benefits interpolation accuracy."
Hyperdecoders: Instance-specific decoders for multi-task NLP,0.465664,"We investigate input-conditioned hypernetworks for multi-tasking in NLP,
generating parameter-efficient adaptations for a decoder using a hypernetwork
conditioned on the output of an encoder. This approach produces a unique
decoder adaptation for every input instance, allowing the network a larger
degree of flexibility than prior work that only produces one decoder adaptation
per task. We apply our method to sequence classification tasks, extractive QA,
and summarisation and find that it surpasses previous parameter efficient
fine-tuning methods and often outperforms fully finetuning the underlying
model. An analysis of the embeddings used by our hypernetwork shows that they
are sensitive to output label and type, suggesting that our approach better
maps from encoder representations to output labels. Our code is publicly
available at https://github.com/allenai/hyperdecoders."
CMDA: Cross-Modality Domain Adaptation for Nighttime Semantic Segmentation,0.390559,"Most nighttime semantic segmentation studies are based on domain adaptation
approaches and image input. However, limited by the low dynamic range of
conventional cameras, images fail to capture structural details and boundary
information in low-light conditions. Event cameras, as a new form of vision
sensors, are complementary to conventional cameras with their high dynamic
range. To this end, we propose a novel unsupervised Cross-Modality Domain
Adaptation (CMDA) framework to leverage multi-modality (Images and Events)
information for nighttime semantic segmentation, with only labels on daytime
images. In CMDA, we design the Image Motion-Extractor to extract motion
information and the Image Content-Extractor to extract content information from
images, in order to bridge the gap between different modalities (Images to
Events) and domains (Day to Night). Besides, we introduce the first image-event
nighttime semantic segmentation dataset. Extensive experiments on both the
public image dataset and the proposed image-event dataset demonstrate the
effectiveness of our proposed approach. We open-source our code, models, and
dataset at https://github.com/XiaRho/CMDA."
A Causal Lens for Controllable Text Generation,0.53668,"Controllable text generation concerns two fundamental tasks of wide
applications, namely generating text of given attributes (i.e.,
attribute-conditional generation), and minimally editing existing text to
possess desired attributes (i.e., text attribute transfer). Extensive prior
work has largely studied the two problems separately, and developed different
conditional models which, however, are prone to producing biased text (e.g.,
various gender stereotypes). This paper proposes to formulate controllable text
generation from a principled causal perspective which models the two tasks with
a unified framework. A direct advantage of the causal formulation is the use of
rich causality tools to mitigate generation biases and improve control. We
treat the two tasks as interventional and counterfactual causal inference based
on a structural causal model, respectively. We then apply the framework to the
challenging practical setting where confounding factors (that induce spurious
correlations) are observable only on a small fraction of data. Experiments show
significant superiority of the causal approach over previous conditional models
for improved control accuracy and reduced bias."
Improved and Efficient Conversational Slot Labeling through Question Answering,0.629633,"Transformer-based pretrained language models (PLMs) offer unmatched
performance across the majority of natural language understanding (NLU) tasks,
including a body of question answering (QA) tasks. We hypothesize that
improvements in QA methodology can also be directly exploited in dialog NLU;
however, dialog tasks must be \textit{reformatted} into QA tasks. In
particular, we focus on modeling and studying \textit{slot labeling} (SL), a
crucial component of NLU for dialog, through the QA optics, aiming to improve
both its performance and efficiency, and make it more effective and resilient
to working with limited task data. To this end, we make a series of
contributions: 1) We demonstrate how QA-tuned PLMs can be applied to the SL
task, reaching new state-of-the-art performance, with large gains especially
pronounced in such low-data regimes. 2) We propose to leverage contextual
information, required to tackle ambiguous values, simply through natural
language. 3) Efficiency and compactness of QA-oriented fine-tuning are boosted
through the use of lightweight yet effective adapter modules. 4) Trading-off
some of the quality of QA datasets for their size, we experiment with larger
automatically generated QA datasets for QA-tuning, arriving at even higher
performance. Finally, our analysis suggests that our novel QA-based slot
labeling models, supported by the PLMs, reach a performance ceiling in
high-data regimes, calling for more challenging and more nuanced benchmarks in
future work."
From Query Tools to Causal Architects: Harnessing Large Language Models for Advanced Causal Discovery from Data,0.703824,"Large Language Models (LLMs) exhibit exceptional abilities for causal
analysis between concepts in numerous societally impactful domains, including
medicine, science, and law. Recent research on LLM performance in various
causal discovery and inference tasks has given rise to a new ladder in the
classical three-stage framework of causality. In this paper, we advance the
current research of LLM-driven causal discovery by proposing a novel framework
that combines knowledge-based LLM causal analysis with data-driven causal
structure learning. To make LLM more than a query tool and to leverage its
power in discovering natural and new laws of causality, we integrate the
valuable LLM expertise on existing causal mechanisms into statistical analysis
of objective data to build a novel and practical baseline for causal structure
learning.
  We introduce a universal set of prompts designed to extract causal graphs
from given variables and assess the influence of LLM prior causality on
recovering causal structures from data. We demonstrate the significant
enhancement of LLM expertise on the quality of recovered causal structures from
data, while also identifying critical challenges and issues, along with
potential approaches to address them. As a pioneering study, this paper aims to
emphasize the new frontier that LLMs are opening for classical causal discovery
and inference, and to encourage the widespread adoption of LLM capabilities in
data-driven causal analysis."
ProtoCaps: A Fast and Non-Iterative Capsule Network Routing Method,0.433811,"Capsule Networks have emerged as a powerful class of deep learning
architectures, known for robust performance with relatively few parameters
compared to Convolutional Neural Networks (CNNs). However, their inherent
efficiency is often overshadowed by their slow, iterative routing mechanisms
which establish connections between Capsule layers, posing computational
challenges resulting in an inability to scale. In this paper, we introduce a
novel, non-iterative routing mechanism, inspired by trainable prototype
clustering. This innovative approach aims to mitigate computational complexity,
while retaining, if not enhancing, performance efficacy. Furthermore, we
harness a shared Capsule subspace, negating the need to project each
lower-level Capsule to each higher-level Capsule, thereby significantly
reducing memory requisites during training. Our approach demonstrates superior
results compared to the current best non-iterative Capsule Network and tests on
the Imagewoof dataset, which is too computationally demanding to handle
efficiently by iterative approaches. Our findings underscore the potential of
our proposed methodology in enhancing the operational efficiency and
performance of Capsule Networks, paving the way for their application in
increasingly complex computational scenarios. Code is available at
https://github.com/mileseverett/ProtoCaps."
Detecting fake accounts through Generative Adversarial Network in online social media,0.41979,"Online social media is integral to human life, facilitating messaging,
information sharing, and confidential communication while preserving privacy.
Platforms like Twitter, Instagram, and Facebook exemplify this phenomenon.
However, users face challenges due to network anomalies, often stemming from
malicious activities such as identity theft for financial gain or harm. This
paper proposes a novel method using user similarity measures and the Generative
Adversarial Network (GAN) algorithm to identify fake user accounts in the
Twitter dataset. Despite the problem's complexity, the method achieves an AUC
rate of 80\% in classifying and detecting fake accounts. Notably, the study
builds on previous research, highlighting advancements and insights into the
evolving landscape of anomaly detection in online social networks."
Can Unsupervised Knowledge Transfer from Social Discussions Help Argument Mining?,0.53124,"Identifying argument components from unstructured texts and predicting the
relationships expressed among them are two primary steps of argument mining.
The intrinsic complexity of these tasks demands powerful learning models. While
pretrained Transformer-based Language Models (LM) have been shown to provide
state-of-the-art results over different NLP tasks, the scarcity of manually
annotated data and the highly domain-dependent nature of argumentation restrict
the capabilities of such models. In this work, we propose a novel transfer
learning strategy to overcome these challenges. We utilize argumentation-rich
social discussions from the ChangeMyView subreddit as a source of unsupervised,
argumentative discourse-aware knowledge by finetuning pretrained LMs on a
selectively masked language modeling task. Furthermore, we introduce a novel
prompt-based strategy for inter-component relation prediction that compliments
our proposed finetuning method while leveraging on the discourse context.
Exhaustive experiments show the generalization capability of our method on
these two tasks over within-domain as well as out-of-domain datasets,
outperforming several existing and employed strong baselines."
A Graphical Modeling Language for Artificial Intelligence Applications in Automation Systems,0.0523109,"Artificial Intelligence (AI) applications in automation systems are usually
distributed systems whose development and integration involve several experts.
Each expert uses its own domain-specific modeling language and tools to model
the system elements. An interdisciplinary graphical modeling language that
enables the modeling of an AI application as an overall system comprehensible
to all disciplines does not yet exist. As a result, there is often a lack of
interdisciplinary system understanding, leading to increased development,
integration, and maintenance efforts. This paper therefore presents a graphical
modeling language that enables consistent and understandable modeling of AI
applications in automation systems at system level. This makes it possible to
subdivide individual subareas into domain specific subsystems and thus reduce
the existing efforts."
Modeling Multi-interest News Sequence for News Recommendation,0.0508147,"A session-based news recommender system recommends the next news to a user by
modeling the potential interests embedded in a sequence of news read/clicked by
her/him in a session. Generally, a user's interests are diverse, namely there
are multiple interests corresponding to different types of news, e.g., news of
distinct topics, within a session. %Modeling such multiple interests is
critical for precise news recommendation. However, most of existing methods
typically overlook such important characteristic and thus fail to distinguish
and model the potential multiple interests of a user, impeding accurate
recommendation of the next piece of news. Therefore, this paper proposes
multi-interest news sequence (MINS) model for news recommendation. In MINS, a
news encoder based on self-attention is devised on learn an informative
embedding for each piece of news, and then a novel parallel interest network is
devised to extract the potential multiple interests embedded in the news
sequence in preparation for the subsequent next-news recommendations. The
experimental results on a real-world dataset demonstrate that our model can
achieve better performance than the state-of-the-art compared models."
From Chaos to Clarity: Claim Normalization to Empower Fact-Checking,0.673253,"With the rise of social media, users are exposed to many misleading claims.
However, the pervasive noise inherent in these posts presents a challenge in
identifying precise and prominent claims that require verification. Extracting
the important claims from such posts is arduous and time-consuming, yet it is
an underexplored problem. Here, we aim to bridge this gap. We introduce a novel
task, Claim Normalization (aka ClaimNorm), which aims to decompose complex and
noisy social media posts into more straightforward and understandable forms,
termed normalized claims. We propose CACN, a pioneering approach that leverages
chain-of-thought and claim check-worthiness estimation, mimicking human
reasoning processes, to comprehend intricate claims. Moreover, we capitalize on
the in-context learning capabilities of large language models to provide
guidance and to improve claim normalization. To evaluate the effectiveness of
our proposed model, we meticulously compile a comprehensive real-world dataset,
CLAN, comprising more than 6k instances of social media posts alongside their
respective normalized claims. Our experiments demonstrate that CACN outperforms
several baselines across various evaluation measures. Finally, our rigorous
error analysis validates CACN's capabilities and pitfalls."
Reinforcement Learning with Stepwise Fairness Constraints,0.789104,"AI methods are used in societally important settings, ranging from credit to
employment to housing, and it is crucial to provide fairness in regard to
algorithmic decision making. Moreover, many settings are dynamic, with
populations responding to sequential decision policies. We introduce the study
of reinforcement learning (RL) with stepwise fairness constraints, requiring
group fairness at each time step. Our focus is on tabular episodic RL, and we
provide learning algorithms with strong theoretical guarantees in regard to
policy optimality and fairness violation. Our framework provides useful tools
to study the impact of fairness constraints in sequential settings and brings
up new challenges in RL."
Neural Machine Translation with Phrase-Level Universal Visual Representations,0.75501,"Multimodal machine translation (MMT) aims to improve neural machine
translation (NMT) with additional visual information, but most existing MMT
methods require paired input of source sentence and image, which makes them
suffer from shortage of sentence-image pairs. In this paper, we propose a
phrase-level retrieval-based method for MMT to get visual information for the
source input from existing sentence-image data sets so that MMT can break the
limitation of paired sentence-image input. Our method performs retrieval at the
phrase level and hence learns visual information from pairs of source phrase
and grounded region, which can mitigate data sparsity. Furthermore, our method
employs the conditional variational auto-encoder to learn visual
representations which can filter redundant visual information and only retain
visual information related to the phrase. Experiments show that the proposed
method significantly outperforms strong baselines on multiple MMT datasets,
especially when the textual context is limited."
Continual Learning as Computationally Constrained Reinforcement Learning,0.681186,"An agent that efficiently accumulates knowledge to develop increasingly
sophisticated skills over a long lifetime could advance the frontier of
artificial intelligence capabilities. The design of such agents, which remains
a long-standing challenge of artificial intelligence, is addressed by the
subject of continual learning. This monograph clarifies and formalizes concepts
of continual learning, introducing a framework and set of tools to stimulate
further research."
Development of Hybrid ASR Systems for Low Resource Medical Domain Conversational Telephone Speech,0.327231,"Language barriers present a great challenge in our increasingly connected and
global world. Especially within the medical domain, e.g. hospital or emergency
room, communication difficulties and delays may lead to malpractice and
non-optimal patient care. In the HYKIST project, we consider patient-physician
communication, more specifically between a German-speaking physician and an
Arabic- or Vietnamese-speaking patient. Currently, a doctor can call the
Triaphon service to get assistance from an interpreter in order to help
facilitate communication. The HYKIST goal is to support the usually
non-professional bilingual interpreter with an automatic speech translation
system to improve patient care and help overcome language barriers. In this
work, we present our ASR system development efforts for this conversational
telephone speech translation task in the medical domain for two languages
pairs, data collection, various acoustic model architectures and
dialect-induced difficulties."
The Third International Verification of Neural Networks Competition (VNN-COMP 2022): Summary and Results,0.857211,"This report summarizes the 3rd International Verification of Neural Networks
Competition (VNN-COMP 2022), held as a part of the 5th Workshop on Formal
Methods for ML-Enabled Autonomous Systems (FoMLAS), which was collocated with
the 34th International Conference on Computer-Aided Verification (CAV).
VNN-COMP is held annually to facilitate the fair and objective comparison of
state-of-the-art neural network verification tools, encourage the
standardization of tool interfaces, and bring together the neural network
verification community. To this end, standardized formats for networks (ONNX)
and specification (VNN-LIB) were defined, tools were evaluated on equal-cost
hardware (using an automatic evaluation pipeline based on AWS instances), and
tool parameters were chosen by the participants before the final test sets were
made public. In the 2022 iteration, 11 teams participated on a diverse set of
12 scored benchmarks. This report summarizes the rules, benchmarks,
participating tools, results, and lessons learned from this iteration of this
competition."
Knowledge Solver: Teaching LLMs to Search for Domain Knowledge from Knowledge Graphs,0.924968,"Large language models (LLMs), such as ChatGPT and GPT-4, are versatile and
can solve different tasks due to their emergent ability and generalizability.
However, LLMs sometimes lack domain-specific knowledge to perform tasks, which
would also cause hallucination during inference. In some previous works,
additional modules like graph neural networks (GNNs) are trained on retrieved
knowledge from external knowledge bases, aiming to mitigate the problem of
lacking domain-specific knowledge. However, incorporating additional modules:
1) would need retraining additional modules when encountering novel domains; 2)
would become a bottleneck since LLMs' strong abilities are not fully utilized
for retrieval. In this paper, we propose a paradigm, termed Knowledge Solver
(KSL), to teach LLMs to search for essential knowledge from external knowledge
bases by harnessing their own strong generalizability. Specifically, we design
a simple yet effective prompt to transform retrieval into a multi-hop decision
sequence, which empowers LLMs with searching knowledge ability in zero-shot
manner. Additionally, KSL is able to provide complete retrieval paths and
therefore increase explainability of LLMs' reasoning processes. We conduct
experiments on three datasets: CommonsenseQA, OpenbookQA, and MedQA-USMLE, and
found that our approach improves LLM baseline performance by a relatively large
margin."
Execution-Based Evaluation for Open-Domain Code Generation,0.879778,"To extend the scope of coding queries to more realistic settings, we propose
ODEX, the first Open-Domain EXecution-based natural language (NL) to Python
code generation dataset. ODEX has 945 NL-Code pairs spanning 79 diverse
libraries, along with 1,707 human-written test cases for execution. Our NL-Code
pairs are harvested from StackOverflow forums to encourage natural and
practical coding queries. Moreover, ODEX supports four natural languages as
intents, in English, Spanish, Japanese, and Russian. ODEX unveils intriguing
behavioral differences among top-performing code language models (LM). While
CODEX achieves better overall results, CODEGEN improves effectively via scaling
-- CODEGEN 6.1B performs comparably with CODEX 12B. Both models show
substantial gaps between open and closed domains, but CODEGEN gaps tend to
decrease with model size while CODEX gaps increase. We release ODEX to
facilitate research into open-domain problems for the code generation
community."
Large Language Models are few(1)-shot Table Reasoners,0.794004,"Recent literature has shown that large language models (LLMs) are generally
excellent few-shot reasoners to solve text reasoning tasks. However, the
capability of LLMs on table reasoning tasks is yet to be explored. In this
paper, we aim at understanding how well LLMs can perform table-related tasks
with few-shot in-context learning. Specifically, we evaluated LLMs on popular
table QA and fact verification datasets like WikiTableQuestion, FetaQA,
TabFact, and FEVEROUS and found that LLMs are competent at complex reasoning
over table structures, though these models are not pre-trained on any table
corpus. When combined with `chain of thoughts' prompting, LLMs can achieve very
strong performance with only a 1-shot demonstration, even on par with some SoTA
models. We show that LLMs are even more competent at generating comprehensive
long-form answers on FetaQA than tuned T5-large. We further manually studied
the reasoning chains elicited from LLMs and found that these reasoning chains
are highly consistent with the underlying semantic form. We believe that LLMs
can serve as a simple yet generic baseline for future research. The code and
data are released in https://github.com/wenhuchen/TableCoT."
Artificial General Intelligence for Medical Imaging,0.727174,"In this review, we explore the potential applications of Artificial General
Intelligence (AGI) models in healthcare, focusing on foundational Large
Language Models (LLMs), Large Vision Models, and Large Multimodal Models. We
emphasize the importance of integrating clinical expertise, domain knowledge,
and multimodal capabilities into AGI models. In addition, we lay out key
roadmaps that guide the development and deployment of healthcare AGI models.
Throughout the review, we provide critical perspectives on the potential
challenges and pitfalls associated with deploying large-scale AGI models in the
medical field. This comprehensive review aims to offer insights into the future
implications of AGI in medical imaging, healthcare and beyond."
Is More Always Better? The Effects of Personal Characteristics and Level of Detail on the Perception of Explanations in a Recommender System,0.879326,"Despite the acknowledgment that the perception of explanations may vary
considerably between end-users, explainable recommender systems (RS) have
traditionally followed a one-size-fits-all model, whereby the same explanation
level of detail is provided to each user, without taking into consideration
individual user's context, i.e., goals and personal characteristics. To fill
this research gap, we aim in this paper at a shift from a one-size-fits-all to
a personalized approach to explainable recommendation by giving users agency in
deciding which explanation they would like to see. We developed a transparent
Recommendation and Interest Modeling Application (RIMA) that provides on-demand
personalized explanations of the recommendations, with three levels of detail
(basic, intermediate, advanced) to meet the demands of different types of
end-users. We conducted a within-subject study (N=31) to investigate the
relationship between user's personal characteristics and the explanation level
of detail, and the effects of these two variables on the perception of the
explainable RS with regard to different explanation goals. Our results show
that the perception of explainable RS with different levels of detail is
affected to different degrees by the explanation goal and user type.
Consequently, we suggested some theoretical and design guidelines to support
the systematic design of explanatory interfaces in RS tailored to the user's
context."
Pushing Mixture of Experts to the Limit: Extremely Parameter Efficient MoE for Instruction Tuning,0.999377,"The Mixture of Experts (MoE) is a widely known neural architecture where an
ensemble of specialized sub-models optimizes overall performance with a
constant computational cost. However, conventional MoEs pose challenges at
scale due to the need to store all experts in memory. In this paper, we push
MoE to the limit. We propose extremely parameter-efficient MoE by uniquely
combining MoE architecture with lightweight experts.Our MoE architecture
outperforms standard parameter-efficient fine-tuning (PEFT) methods and is on
par with full fine-tuning by only updating the lightweight experts -- less than
1% of an 11B parameters model. Furthermore, our method generalizes to unseen
tasks as it does not depend on any prior task knowledge. Our research
underscores the versatility of the mixture of experts architecture, showcasing
its ability to deliver robust performance even when subjected to rigorous
parameter constraints. Our code used in all the experiments is publicly
available here: https://github.com/for-ai/parameter-efficient-moe."
Multi-Agent Adversarial Training Using Diffusion Learning,0.294378,"This work focuses on adversarial learning over graphs. We propose a general
adversarial training framework for multi-agent systems using diffusion
learning. We analyze the convergence properties of the proposed scheme for
convex optimization problems, and illustrate its enhanced robustness to
adversarial attacks."
An Intermediate-level Attack Framework on The Basis of Linear Regression,0.420282,"This paper substantially extends our work published at ECCV, in which an
intermediate-level attack was proposed to improve the transferability of some
baseline adversarial examples. Specifically, we advocate a framework in which a
direct linear mapping from the intermediate-level discrepancies (between
adversarial features and benign features) to prediction loss of the adversarial
example is established. By delving deep into the core components of such a
framework, we show that 1) a variety of linear regression models can all be
considered in order to establish the mapping, 2) the magnitude of the finally
obtained intermediate-level adversarial discrepancy is correlated with the
transferability, 3) further boost of the performance can be achieved by
performing multiple runs of the baseline attack with random initialization. In
addition, by leveraging these findings, we achieve new state-of-the-arts on
transfer-based $\ell_\infty$ and $\ell_2$ attacks. Our code is publicly
available at https://github.com/qizhangli/ila-plus-plus-lr."
Emotion Recognition based on Psychological Components in Guided Narratives for Emotion Regulation,0.684019,"Emotion regulation is a crucial element in dealing with emotional events and
has positive effects on mental health. This paper aims to provide a more
comprehensive understanding of emotional events by introducing a new French
corpus of emotional narratives collected using a questionnaire for emotion
regulation. We follow the theoretical framework of the Component Process Model
which considers emotions as dynamic processes composed of four interrelated
components (behavior, feeling, thinking and territory). Each narrative is
related to a discrete emotion and is structured based on all emotion components
by the writers. We study the interaction of components and their impact on
emotion classification with machine learning methods and pre-trained language
models. Our results show that each component improves prediction performance,
and that the best results are achieved by jointly considering all components.
Our results also show the effectiveness of pre-trained language models in
predicting discrete emotion from certain components, which reveal differences
in how emotion components are expressed."
Resolving Class Imbalance for LiDAR-based Object Detector by Dynamic Weight Average and Contextual Ground Truth Sampling,0.241618,"An autonomous driving system requires a 3D object detector, which must
perceive all present road agents reliably to navigate an environment safely.
However, real-world driving datasets often suffer from the problem of data
imbalance, which causes difficulties in training a model that works well across
all classes, resulting in an undesired imbalanced sub-optimal performance. In
this work, we propose a method to address this data imbalance problem. Our
method consists of two main components: (i) a LiDAR-based 3D object detector
with per-class multiple detection heads where losses from each head are
modified by dynamic weight average to be balanced. (ii) Contextual ground truth
(GT) sampling, where we improve conventional GT sampling techniques by
leveraging semantic information to augment point cloud with sampled ground
truth GT objects. Our experiment with KITTI and nuScenes datasets confirms our
proposed method's effectiveness in dealing with the data imbalance problem,
producing better detection accuracy compared to existing approaches."
Simulating Bandit Learning from User Feedback for Extractive Question Answering,0.182154,"We study learning from user feedback for extractive question answering by
simulating feedback using supervised data. We cast the problem as contextual
bandit learning, and analyze the characteristics of several learning scenarios
with focus on reducing data annotation. We show that systems initially trained
on a small number of examples can dramatically improve given feedback from
users on model-predicted answers, and that one can use existing datasets to
deploy systems in new domains without any annotation, but instead improving the
system on-the-fly via user feedback."
LingYi: Medical Conversational Question Answering System based on Multi-modal Knowledge Graphs,0.741724,"The medical conversational system can relieve the burden of doctors and
improve the efficiency of healthcare, especially during the pandemic. This
paper presents a medical conversational question answering (CQA) system based
on the multi-modal knowledge graph, namely ""LingYi"", which is designed as a
pipeline framework to maintain high flexibility. Our system utilizes automated
medical procedures including medical triage, consultation, image-text drug
recommendation and record. To conduct knowledge-grounded dialogues with
patients, we first construct a Chinese Medical Multi-Modal Knowledge Graph
(CM3KG) and collect a large-scale Chinese Medical CQA (CMCQA) dataset. Compared
with the other existing medical question-answering systems, our system adopts
several state-of-the-art technologies including medical entity disambiguation
and medical dialogue generation, which is more friendly to provide medical
services to patients. In addition, we have open-sourced our codes which contain
back-end models and front-end web pages at https://github.com/WENGSYX/LingYi.
The datasets including CM3KG at https://github.com/WENGSYX/CM3KG and CMCQA at
https://github.com/WENGSYX/CMCQA are also released to further promote future
research."
Fast Hierarchical Deep Unfolding Network for Image Compressed Sensing,0.431563,"By integrating certain optimization solvers with deep neural network, deep
unfolding network (DUN) has attracted much attention in recent years for image
compressed sensing (CS). However, there still exist several issues in existing
DUNs: 1) For each iteration, a simple stacked convolutional network is usually
adopted, which apparently limits the expressiveness of these models. 2) Once
the training is completed, most hyperparameters of existing DUNs are fixed for
any input content, which significantly weakens their adaptability. In this
paper, by unfolding the Fast Iterative Shrinkage-Thresholding Algorithm
(FISTA), a novel fast hierarchical DUN, dubbed FHDUN, is proposed for image
compressed sensing, in which a well-designed hierarchical unfolding
architecture is developed to cooperatively explore richer contextual prior
information in multi-scale spaces. To further enhance the adaptability, series
of hyperparametric generation networks are developed in our framework to
dynamically produce the corresponding optimal hyperparameters according to the
input content. Furthermore, due to the accelerated policy in FISTA, the newly
embedded acceleration module makes the proposed FHDUN save more than 50% of the
iterative loops against recent DUNs. Extensive CS experiments manifest that the
proposed FHDUN outperforms existing state-of-the-art CS methods, while
maintaining fewer iterations."
Addressing Segmentation Ambiguity in Neural Linguistic Steganography,0.205354,"Previous studies on neural linguistic steganography, except Ueoka et al.
(2021), overlook the fact that the sender must detokenize cover texts to avoid
arousing the eavesdropper's suspicion. In this paper, we demonstrate that
segmentation ambiguity indeed causes occasional decoding failures at the
receiver's side. With the near-ubiquity of subwords, this problem now affects
any language. We propose simple tricks to overcome this problem, which are even
applicable to languages without explicit word boundaries."
Hand Avatar: Free-Pose Hand Animation and Rendering from Monocular Video,0.707822,"We present HandAvatar, a novel representation for hand animation and
rendering, which can generate smoothly compositional geometry and
self-occlusion-aware texture. Specifically, we first develop a MANO-HD model as
a high-resolution mesh topology to fit personalized hand shapes. Sequentially,
we decompose hand geometry into per-bone rigid parts, and then re-compose
paired geometry encodings to derive an across-part consistent occupancy field.
As for texture modeling, we propose a self-occlusion-aware shading field
(SelF). In SelF, drivable anchors are paved on the MANO-HD surface to record
albedo information under a wide variety of hand poses. Moreover, directed soft
occupancy is designed to describe the ray-to-surface relation, which is
leveraged to generate an illumination field for the disentanglement of
pose-independent albedo and pose-dependent illumination. Trained from monocular
video data, our HandAvatar can perform free-pose hand animation and rendering
while at the same time achieving superior appearance fidelity. We also
demonstrate that HandAvatar provides a route for hand appearance editing.
Project website: https://seanchenxy.github.io/HandAvatarWeb."
MNL-Bandit in non-stationary environments,0.326501,"In this paper, we study the MNL-Bandit problem in a non-stationary
environment and present an algorithm with a worst-case expected regret of
$\tilde{O}\left( \min \left\{ \sqrt{NTL}\;,\;
N^{\frac{1}{3}}(\Delta_{\infty}^{K})^{\frac{1}{3}} T^{\frac{2}{3}} +
\sqrt{NT}\right\}\right)$. Here $N$ is the number of arms, $L$ is the number of
changes and $\Delta_{\infty}^{K}$ is a variation measure of the unknown
parameters. Furthermore, we show matching lower bounds on the expected regret
(up to logarithmic factors), implying that our algorithm is optimal. Our
approach builds upon the epoch-based algorithm for stationary MNL-Bandit in
Agrawal et al. 2016. However, non-stationarity poses several challenges and we
introduce new techniques and ideas to address these. In particular, we give a
tight characterization for the bias introduced in the estimators due to non
stationarity and derive new concentration bounds."
Placing Human Animations into 3D Scenes by Learning Interaction- and Geometry-Driven Keyframes,0.342415,"We present a novel method for placing a 3D human animation into a 3D scene
while maintaining any human-scene interactions in the animation. We use the
notion of computing the most important meshes in the animation for the
interaction with the scene, which we call ""keyframes."" These keyframes allow us
to better optimize the placement of the animation into the scene such that
interactions in the animations (standing, laying, sitting, etc.) match the
affordances of the scene (e.g., standing on the floor or laying in a bed). We
compare our method, which we call PAAK, with prior approaches, including POSA,
PROX ground truth, and a motion synthesis method, and highlight the benefits of
our method with a perceptual study. Human raters preferred our PAAK method over
the PROX ground truth data 64.6\% of the time. Additionally, in direct
comparisons, the raters preferred PAAK over competing methods including 61.5\%
compared to POSA."
"Explaining Groups of Instances Counterfactually for XAI: A Use Case, Algorithm and User Study for Group-Counterfactuals",0.428229,"Counterfactual explanations are an increasingly popular form of post hoc
explanation due to their (i) applicability across problem domains, (ii)
proposed legal compliance (e.g., with GDPR), and (iii) reliance on the
contrastive nature of human explanation. Although counterfactual explanations
are normally used to explain individual predictive-instances, we explore a
novel use case in which groups of similar instances are explained in a
collective fashion using ``group counterfactuals'' (e.g., to highlight a
repeating pattern of illness in a group of patients). These group
counterfactuals meet a human preference for coherent, broad explanations
covering multiple events/instances. A novel, group-counterfactual algorithm is
proposed to generate high-coverage explanations that are faithful to the
to-be-explained model. This explanation strategy is also evaluated in a large,
controlled user study (N=207), using objective (i.e., accuracy) and subjective
(i.e., confidence, explanation satisfaction, and trust) psychological measures.
The results show that group counterfactuals elicit modest but definite
improvements in people's understanding of an AI system. The implications of
these findings for counterfactual methods and for XAI are discussed."
SoftEdge: Regularizing Graph Classification with Random Soft Edges,0.115952,"Augmented graphs play a vital role in regularizing Graph Neural Networks
(GNNs), which leverage information exchange along edges in graphs, in the form
of message passing, for learning. Due to their effectiveness, simple edge and
node manipulations (e.g., addition and deletion) have been widely used in graph
augmentation. Nevertheless, such common augmentation techniques can
dramatically change the semantics of the original graph, causing overaggressive
augmentation and thus under-fitting in the GNN learning. To address this
problem arising from dropping or adding graph edges and nodes, we propose
SoftEdge, which assigns random weights to a portion of the edges of a given
graph for augmentation. The synthetic graph generated by SoftEdge maintains the
same nodes and their connectivities as the original graph, thus mitigating the
semantic changes of the original graph. We empirically show that this simple
method obtains superior accuracy to popular node and edge manipulation
approaches and notable resilience to the accuracy degradation with the GNN
depth."
ChatGPT and a New Academic Reality: Artificial Intelligence-Written Research Papers and the Ethics of the Large Language Models in Scholarly Publishing,0.998579,"This paper discusses OpenAIs ChatGPT, a generative pre-trained transformer,
which uses natural language processing to fulfill text-based user requests
(i.e., a chatbot). The history and principles behind ChatGPT and similar models
are discussed. This technology is then discussed in relation to its potential
impact on academia and scholarly research and publishing. ChatGPT is seen as a
potential model for the automated preparation of essays and other types of
scholarly manuscripts. Potential ethical issues that could arise with the
emergence of large language models like GPT-3, the underlying technology behind
ChatGPT, and its usage by academics and researchers, are discussed and situated
within the context of broader advancements in artificial intelligence, machine
learning, and natural language processing for research and scholarly
publishing."
Rethinking the role of normalization and residual blocks for spiking neural networks,0.567148,"Biologically inspired spiking neural networks (SNNs) are widely used to
realize ultralow-power energy consumption. However, deep SNNs are not easy to
train due to the excessive firing of spiking neurons in the hidden layers. To
tackle this problem, we propose a novel but simple normalization technique
called postsynaptic potential normalization. This normalization removes the
subtraction term from the standard normalization and uses the second raw moment
instead of the variance as the division term. The spike firing can be
controlled, enabling the training to proceed appropriating, by conducting this
simple normalization to the postsynaptic potential. The experimental results
show that SNNs with our normalization outperformed other models using other
normalizations. Furthermore, through the pre-activation residual blocks, the
proposed model can train with more than 100 layers without other special
techniques dedicated to SNNs."
"Theories of ""Gender"" in NLP Bias Research",0.859482,"The rise of concern around Natural Language Processing (NLP) technologies
containing and perpetuating social biases has led to a rich and rapidly growing
area of research. Gender bias is one of the central biases being analyzed, but
to date there is no comprehensive analysis of how ""gender"" is theorized in the
field. We survey nearly 200 articles concerning gender bias in NLP to discover
how the field conceptualizes gender both explicitly (e.g. through definitions
of terms) and implicitly (e.g. through how gender is operationalized in
practice). In order to get a better idea of emerging trajectories of thought,
we split these articles into two sections by time.
  We find that the majority of the articles do not make their theorization of
gender explicit, even if they clearly define ""bias."" Almost none use a model of
gender that is intersectional or inclusive of nonbinary genders; and many
conflate sex characteristics, social gender, and linguistic gender in ways that
disregard the existence and experience of trans, nonbinary, and intersex
people. There is an increase between the two time-sections in statements
acknowledging that gender is a complicated reality, however, very few articles
manage to put this acknowledgment into practice. In addition to analyzing these
findings, we provide specific recommendations to facilitate interdisciplinary
work, and to incorporate theory and methodology from Gender Studies. Our hope
is that this will produce more inclusive gender bias research in NLP."
Writer Recognition Using Off-line Handwritten Single Block Characters,0.104666,"Block characters are often used when filling paper forms for a variety of
purposes. We investigate if there is biometric information contained within
individual digits of handwritten text. In particular, we use personal identity
numbers consisting of the six digits of the date of birth, DoB. We evaluate two
recognition approaches, one based on handcrafted features that compute contour
directional measurements, and another based on deep features from a ResNet50
model. We use a self-captured database of 317 individuals and 4920 written DoBs
in total. Results show the presence of identity-related information in a piece
of handwritten information as small as six digits with the DoB. We also analyze
the impact of the amount of enrolment samples, varying its number between one
and ten. Results with such small amount of data are promising. With ten
enrolment samples, the Top-1 accuracy with deep features is around 94%, and
reaches nearly 100% by Top-10. The verification accuracy is more modest, with
EER>20%with any given feature and enrolment set size, showing that there is
still room for improvement."
Table-To-Text generation and pre-training with TabT5,0.919649,"Encoder-only transformer models have been successfully applied to different
table understanding tasks, as in TAPAS (Herzig et al., 2020). A major
limitation of these architectures is that they are constrained to
classification-like tasks such as cell selection or entailment detection. We
present TABT5, an encoder-decoder model that generates natural language text
based on tables and textual inputs. TABT5 overcomes the encoder-only limitation
by incorporating a decoder component and leverages the input structure with
table specific embeddings and pre-training. TABT5 achieves new state-of-the-art
results on several domains, including spreadsheet formula prediction with a 15%
increase in sequence accuracy, QA with a 2.5% increase in sequence accuracy and
data-to-text generation with a 2.5% increase in BLEU."
Balancing Privacy and Progress in Artificial Intelligence: Anonymization in Histopathology for Biomedical Research and Education,0.329497,"The advancement of biomedical research heavily relies on access to large
amounts of medical data. In the case of histopathology, Whole Slide Images
(WSI) and clinicopathological information are valuable for developing
Artificial Intelligence (AI) algorithms for Digital Pathology (DP).
Transferring medical data ""as open as possible"" enhances the usability of the
data for secondary purposes but poses a risk to patient privacy. At the same
time, existing regulations push towards keeping medical data ""as closed as
necessary"" to avoid re-identification risks. Generally, these legal regulations
require the removal of sensitive data but do not consider the possibility of
data linkage attacks due to modern image-matching algorithms. In addition, the
lack of standardization in DP makes it harder to establish a single solution
for all formats of WSIs. These challenges raise problems for bio-informatics
researchers in balancing privacy and progress while developing AI algorithms.
This paper explores the legal regulations and terminologies for medical
data-sharing. We review existing approaches and highlight challenges from the
histopathological perspective. We also present a data-sharing guideline for
histological data to foster multidisciplinary research and education."
ReFit: Recurrent Fitting Network for 3D Human Recovery,0.654738,"We present Recurrent Fitting (ReFit), a neural network architecture for
single-image, parametric 3D human reconstruction. ReFit learns a
feedback-update loop that mirrors the strategy of solving an inverse problem
through optimization. At each iterative step, it reprojects keypoints from the
human model to feature maps to query feedback, and uses a recurrent-based
updater to adjust the model to fit the image better. Because ReFit encodes
strong knowledge of the inverse problem, it is faster to train than previous
regression models. At the same time, ReFit improves state-of-the-art
performance on standard benchmarks. Moreover, ReFit applies to other
optimization settings, such as multi-view fitting and single-view shape
fitting. Project website: https://yufu-wang.github.io/refit_humans/"
On the Role of Parallel Data in Cross-lingual Transfer Learning,0.543287,"While prior work has established that the use of parallel data is conducive
for cross-lingual learning, it is unclear if the improvements come from the
data itself, or if it is the modeling of parallel interactions that matters.
Exploring this, we examine the usage of unsupervised machine translation to
generate synthetic parallel data, and compare it to supervised machine
translation and gold parallel data. We find that even model generated parallel
data can be useful for downstream tasks, in both a general setting (continued
pretraining) as well as the task-specific setting (translate-train), although
our best results are still obtained using real parallel data. Our findings
suggest that existing multilingual models do not exploit the full potential of
monolingual data, and prompt the community to reconsider the traditional
categorization of cross-lingual learning approaches."
Arbitrary Shape Text Detection using Transformers,0.439119,"Recent text detection frameworks require several handcrafted components such
as anchor generation, non-maximum suppression (NMS), or multiple processing
stages (e.g. label generation) to detect arbitrarily shaped text images. In
contrast, we propose an end-to-end trainable architecture based on Detection
using Transformers (DETR), that outperforms previous state-of-the-art methods
in arbitrary-shaped text detection. At its core, our proposed method leverages
a bounding box loss function that accurately measures the arbitrary detected
text regions' changes in scale and aspect ratio. This is possible due to a
hybrid shape representation made from Bezier curves, that are further split
into piece-wise polygons. The proposed loss function is then a combination of a
generalized-split-intersection-over-union loss defined over the piece-wise
polygons and regularized by a Smooth-$\ln$ regression over the Bezier curve's
control points. We evaluate our proposed model using Total-Text and CTW-1500
datasets for curved text, and MSRA-TD500 and ICDAR15 datasets for
multi-oriented text, and show that the proposed method outperforms the previous
state-of-the-art methods in arbitrary-shape text detection tasks."
Style-Aware Radiology Report Generation with RadGraph and Few-Shot Prompting,0.772749,"Automatically generated reports from medical images promise to improve the
workflow of radiologists. Existing methods consider an image-to-report modeling
task by directly generating a fully-fledged report from an image. However, this
conflates the content of the report (e.g., findings and their attributes) with
its style (e.g., format and choice of words), which can lead to clinically
inaccurate reports. To address this, we propose a two-step approach for
radiology report generation. First, we extract the content from an image; then,
we verbalize the extracted content into a report that matches the style of a
specific radiologist. For this, we leverage RadGraph -- a graph representation
of reports -- together with large language models (LLMs). In our quantitative
evaluations, we find that our approach leads to beneficial performance. Our
human evaluation with clinical raters highlights that the AI-generated reports
are indistinguishably tailored to the style of individual radiologist despite
leveraging only a few examples as context."
CLAD: A Contrastive Learning based Approach for Background Debiasing,0.120624,"Convolutional neural networks (CNNs) have achieved superhuman performance in
multiple vision tasks, especially image classification. However, unlike humans,
CNNs leverage spurious features, such as background information to make
decisions. This tendency creates different problems in terms of robustness or
weak generalization performance. Through our work, we introduce a contrastive
learning-based approach (CLAD) to mitigate the background bias in CNNs. CLAD
encourages semantic focus on object foregrounds and penalizes learning features
from irrelavant backgrounds. Our method also introduces an efficient way of
sampling negative samples. We achieve state-of-the-art results on the
Background Challenge dataset, outperforming the previous benchmark with a
margin of 4.1\%. Our paper shows how CLAD serves as a proof of concept for
debiasing of spurious features, such as background and texture (in
supplementary material)."
Thermal to Visible Image Synthesis under Atmospheric Turbulence,0.217419,"In many practical applications of long-range imaging such as biometrics and
surveillance, thermal imagining modalities are often used to capture images in
low-light and nighttime conditions. However, such imaging systems often suffer
from atmospheric turbulence, which introduces severe blur and deformation
artifacts to the captured images. Such an issue is unavoidable in long-range
imaging and significantly decreases the face verification accuracy. In this
paper, we first investigate the problem with a turbulence simulation method on
real-world thermal images. An end-to-end reconstruction method is then proposed
which can directly transform thermal images into visible-spectrum images by
utilizing natural image priors based on a pre-trained StyleGAN2 network.
Compared with the existing two-steps methods of consecutive turbulence
mitigation and thermal to visible image translation, our method is demonstrated
to be effective in terms of both the visual quality of the reconstructed
results and face verification accuracy. Moreover, to the best of our knowledge,
this is the first work that studies the problem of thermal to visible image
translation under atmospheric turbulence."
Detecting Harmful Online Conversational Content towards LGBTQIA+ Individuals,0.367215,"Online discussions, panels, talk page edits, etc., often contain harmful
conversational content i.e., hate speech, death threats and offensive language,
especially towards certain demographic groups. For example, individuals who
identify as members of the LGBTQIA+ community and/or BIPOC (Black, Indigenous,
People of Color) are at higher risk for abuse and harassment online. In this
work, we first introduce a real-world dataset that will enable us to study and
understand harmful online conversational content. Then, we conduct several
exploratory data analysis experiments to gain deeper insights from the dataset.
We later describe our approach for detecting harmful online Anti-LGBTQIA+
conversational content, and finally, we implement two baseline machine learning
models (i.e., Support Vector Machine and Logistic Regression), and fine-tune 3
pre-trained large language models (BERT, RoBERTa, and HateBERT). Our findings
verify that large language models can achieve very promising performance on
detecting online Anti-LGBTQIA+ conversational content detection tasks."
Benchmarking fixed-length Fingerprint Representations across different Embedding Sizes and Sensor Types,0.319943,"Traditional minutiae-based fingerprint representations consist of a
variable-length set of minutiae. This necessitates a more complex comparison
causing the drawback of high computational cost in one-to-many comparison.
Recently, deep neural networks have been proposed to extract fixed-length
embeddings from fingerprints. In this paper, we explore to what extent
fingerprint texture information contained in such embeddings can be reduced in
terms of dimension while preserving high biometric performance. This is of
particular interest since it would allow to reduce the number of operations
incurred at comparisons. We also study the impact in terms of recognition
performance of the fingerprint textural information for two sensor types, i.e.
optical and capacitive. Furthermore, the impact of rotation and translation of
fingerprint images on the extraction of fingerprint embeddings is analysed.
Experimental results conducted on a publicly available database reveal an
optimal embedding size of 512 feature elements for the texture-based embedding
part of fixed-length fingerprint representations. In addition, differences in
performance between sensor types can be perceived."
Foundational theories of hesitant fuzzy sets and hesitant fuzzy information systems and their applications for multi-strength intelligent classifiers,0.324298,"Hesitant fuzzy sets are widely used in certain instances of uncertainty and
hesitation. In sets, the inclusion relationship is an important and
foundational definition. Thus, as a kind of set, hesitant fuzzy sets require an
explicit definition of inclusion relationship. Based on the hesitant fuzzy
membership degree of discrete form, several kinds of inclusion relationships
for hesitant fuzzy sets are proposed in this work. Then, some foundational
propositions of hesitant fuzzy sets are presented, along with propositions of
families of hesitant fuzzy sets. Some foundational propositions of hesitant
fuzzy information systems are proposed with respect to parameter reductions and
an example and an algorithm are given to illustrate the processes of parameter
reduction. Finally, a multi-strength intelligent classifier is proposed to make
health state diagnoses for complex systems."
Learning New Skills after Deployment: Improving open-domain internet-driven dialogue with human feedback,0.978953,"Frozen models trained to mimic static datasets can never improve their
performance. Models that can employ internet-retrieval for up-to-date
information and obtain feedback from humans during deployment provide the
promise of both adapting to new information, and improving their performance.
In this work we study how to improve internet-driven conversational skills in
such a learning framework. We collect deployment data, which we make publicly
available, of human interactions, and collect various types of human feedback
-- including binary quality measurements, free-form text feedback, and
fine-grained reasons for failure. We then study various algorithms for
improving from such feedback, including standard supervised learning, rejection
sampling, model-guiding and reward-based learning, in order to make
recommendations on which type of feedback and algorithms work best. We find the
recently introduced Director model (Arora et al., '22) shows significant
improvements over other existing approaches."
ML_LTU at SemEval-2022 Task 4: T5 Towards Identifying Patronizing and Condescending Language,0.819908,"This paper describes the system used by the Machine Learning Group of LTU in
subtask 1 of the SemEval-2022 Task 4: Patronizing and Condescending Language
(PCL) Detection. Our system consists of finetuning a pretrained
Text-to-Text-Transfer Transformer (T5) and innovatively reducing its
out-of-class predictions. The main contributions of this paper are 1) the
description of the implementation details of the T5 model we used, 2) analysis
of the successes & struggles of the model in this task, and 3) ablation studies
beyond the official submission to ascertain the relative importance of data
split. Our model achieves an F1 score of 0.5452 on the official test set."
Content-oriented learned image compression,0.617872,"In recent years, with the development of deep neural networks, end-to-end
optimized image compression has made significant progress and exceeded the
classic methods in terms of rate-distortion performance. However, most
learning-based image compression methods are unlabeled and do not consider
image semantics or content when optimizing the model. In fact, human eyes have
different sensitivities to different content, so the image content also needs
to be considered. In this paper, we propose a content-oriented image
compression method, which handles different kinds of image contents with
different strategies. Extensive experiments show that the proposed method
achieves competitive subjective results compared with state-of-the-art
end-to-end learned image compression methods or classic methods."
Causal interventions expose implicit situation models for commonsense language understanding,0.118805,"Accounts of human language processing have long appealed to implicit
``situation models'' that enrich comprehension with relevant but unstated world
knowledge. Here, we apply causal intervention techniques to recent transformer
models to analyze performance on the Winograd Schema Challenge (WSC), where a
single context cue shifts interpretation of an ambiguous pronoun. We identify a
relatively small circuit of attention heads that are responsible for
propagating information from the context word that guides which of the
candidate noun phrases the pronoun ultimately attends to. We then compare how
this circuit behaves in a closely matched ``syntactic'' control where the
situation model is not strictly necessary. These analyses suggest distinct
pathways through which implicit situation models are constructed to guide
pronoun resolution."
A Multi-Modal Transformer Network for Action Detection,0.740992,"This paper proposes a novel multi-modal transformer network for detecting
actions in untrimmed videos. To enrich the action features, our transformer
network utilizes a new multi-modal attention mechanism that computes the
correlations between different spatial and motion modalities combinations.
Exploring such correlations for actions has not been attempted previously. To
use the motion and spatial modality more effectively, we suggest an algorithm
that corrects the motion distortion caused by camera movement. Such motion
distortion, common in untrimmed videos, severely reduces the expressive power
of motion features such as optical flow fields. Our proposed algorithm
outperforms the state-of-the-art methods on two public benchmarks, THUMOS14 and
ActivityNet. We also conducted comparative experiments on our new instructional
activity dataset, including a large set of challenging classroom videos
captured from elementary schools."
Ghost-free High Dynamic Range Imaging with Context-aware Transformer,0.999934,"High dynamic range (HDR) deghosting algorithms aim to generate ghost-free HDR
images with realistic details. Restricted by the locality of the receptive
field, existing CNN-based methods are typically prone to producing ghosting
artifacts and intensity distortions in the presence of large motion and severe
saturation. In this paper, we propose a novel Context-Aware Vision Transformer
(CA-ViT) for ghost-free high dynamic range imaging. The CA-ViT is designed as a
dual-branch architecture, which can jointly capture both global and local
dependencies. Specifically, the global branch employs a window-based
Transformer encoder to model long-range object movements and intensity
variations to solve ghosting. For the local branch, we design a local context
extractor (LCE) to capture short-range image features and use the channel
attention mechanism to select informative local details across the extracted
features to complement the global branch. By incorporating the CA-ViT as basic
components, we further build the HDR-Transformer, a hierarchical network to
reconstruct high-quality ghost-free HDR images. Extensive experiments on three
benchmark datasets show that our approach outperforms state-of-the-art methods
qualitatively and quantitatively with considerably reduced computational
budgets. Codes are available at
https://github.com/megvii-research/HDR-Transformer"
Applying Automatic Text Summarization for Fake News Detection,0.562473,"The distribution of fake news is not a new but a rapidly growing problem. The
shift to news consumption via social media has been one of the drivers for the
spread of misleading and deliberately wrong information, as in addition to it
of easy use there is rarely any veracity monitoring. Due to the harmful effects
of such fake news on society, the detection of these has become increasingly
important. We present an approach to the problem that combines the power of
transformer-based language models while simultaneously addressing one of their
inherent problems. Our framework, CMTR-BERT, combines multiple text
representations, with the goal of circumventing sequential limits and related
loss of information the underlying transformer architecture typically suffers
from. Additionally, it enables the incorporation of contextual information.
Extensive experiments on two very different, publicly available datasets
demonstrates that our approach is able to set new state-of-the-art performance
benchmarks. Apart from the benefit of using automatic text summarization
techniques we also find that the incorporation of contextual information
contributes to performance gains."
HeGeL: A Novel Dataset for Geo-Location from Hebrew Text,0.620955,"The task of textual geolocation - retrieving the coordinates of a place based
on a free-form language description - calls for not only grounding but also
natural language understanding and geospatial reasoning. Even though there are
quite a few datasets in English used for geolocation, they are currently based
on open-source data (Wikipedia and Twitter), where the location of the
described place is mostly implicit, such that the location retrieval resolution
is limited. Furthermore, there are no datasets available for addressing the
problem of textual geolocation in morphologically rich and resource-poor
languages, such as Hebrew. In this paper, we present the Hebrew Geo-Location
(HeGeL) corpus, designed to collect literal place descriptions and analyze
lingual geospatial reasoning. We crowdsourced 5,649 literal Hebrew place
descriptions of various place types in three cities in Israel. Qualitative and
empirical analysis show that the data exhibits abundant use of geospatial
reasoning and requires a novel environmental representation."
Detecting Agreement in Multi-party Conversational AI,0.350768,"Today, conversational systems are expected to handle conversations in
multi-party settings, especially within Socially Assistive Robots (SARs).
However, practical usability remains difficult as there are additional
challenges to overcome, such as speaker recognition, addressee recognition, and
complex turn-taking. In this paper, we present our work on a multi-party
conversational system, which invites two users to play a trivia quiz game. The
system detects users' agreement or disagreement on a final answer and responds
accordingly. Our evaluation includes both performance and user assessment
results, with a focus on detecting user agreement. Our annotated transcripts
and the code for the proposed system have been released open-source on GitHub."
SCB-dataset: A Dataset for Detecting Student Classroom Behavior,0.622878,"The use of deep learning methods for automatic detection of students'
classroom behavior is a promising approach to analyze their class performance
and enhance teaching effectiveness. However, the lack of publicly available
datasets on student behavior poses a challenge for researchers in this field.
To address this issue, we propose a Student Classroom Behavior dataset
(SCB-dataset) that reflects real-life scenarios. Our dataset includes 11,248
labels and 4,003 images, with a focus on hand-raising behavior. We evaluated
the dataset using the YOLOv7 algorithm, achieving a mean average precision
(map) of up to 85.3%. We believe that our dataset can serve as a robust
foundation for future research in the field of student behavior detection and
promote further advancements in this area.Our SCB-dataset can be downloaded
from: https://github.com/Whiffe/SCB-dataset"
UGformer for Robust Left Atrium and Scar Segmentation Across Scanners,0.0757199,"Thanks to the capacity for long-range dependencies and robustness to
irregular shapes, vision transformers and deformable convolutions are emerging
as powerful vision techniques of segmentation.Meanwhile, Graph Convolution
Networks (GCN) optimize local features based on global topological relationship
modeling. Particularly, they have been proved to be effective in addressing
issues in medical imaging segmentation tasks including multi-domain
generalization for low-quality images. In this paper, we present a novel,
effective, and robust framework for medical image segmentation, namely,
UGformer. It unifies novel transformer blocks, GCN bridges, and convolution
decoders originating from U-Net to predict left atriums (LAs) and LA scars. We
have identified two appealing findings of the proposed UGformer: 1). an
enhanced transformer module with deformable convolutions to improve the
blending of the transformer information with convolutional information and help
predict irregular LAs and scar shapes. 2). Using a bridge incorporating GCN to
further overcome the difficulty of capturing condition inconsistency across
different Magnetic Resonance Images scanners with various inconsistent domain
information. The proposed UGformer model exhibits outstanding ability to
segment the left atrium and scar on the LAScarQS 2022 dataset, outperforming
several recent state-of-the-arts."
$$-GNF : A Novel Sensitivity Analysis Approach Under Unobserved Confounders,0.0775631,"We propose a new sensitivity analysis model that combines copulas and
normalizing flows for causal inference under unobserved confounding. We refer
to the new model as $\rho$-GNF ($\rho$-Graphical Normalizing Flow), where
$\rho{\in}[-1,+1]$ is a bounded sensitivity parameter representing the backdoor
non-causal association due to unobserved confounding modeled using the most
well studied and widely popular Gaussian copula. Specifically, $\rho$-GNF
enables us to estimate and analyse the frontdoor causal effect or average
causal effect (ACE) as a function of $\rho$. We call this the $\rho_{curve}$.
The $\rho_{curve}$ enables us to specify the confounding strength required to
nullify the ACE. We call this the $\rho_{value}$. Further, the $\rho_{curve}$
also enables us to provide bounds for the ACE given an interval of $\rho$
values. We illustrate the benefits of $\rho$-GNF with experiments on simulated
and real-world data in terms of our empirical ACE bounds being narrower than
other popular ACE bounds."
Three multi-objective memtic algorithms for observation scheduling problem of active-imaging AEOS,0.0572937,"Observation scheduling problem for agile earth observation satellites
(OSPFAS) plays a critical role in management of agile earth observation
satellites (AEOSs). Active imaging enriches the extension of OSPFAS, we call
the novel problem as observation scheduling problem for AEOS with variable
image duration (OSWVID). A cumulative image quality and a detailed energy
consumption is proposed to build OSWVID as a bi-objective optimization model.
Three multi-objective memetic algorithms, PD+NSGA-II, LA+NSGA-II and
ALNS+NSGA-II, are then designed to solve OSWVID. Considering the heuristic
knowledge summarized in our previous research, several operators are designed
for improving these three algorithms respectively. Based on existing instances,
we analyze the critical parameters optimization, operators evolution, and
efficiency of these three algorithms according to extensive simulation
experiments."
Differentiable Agent-based Epidemiology,0.478819,"Mechanistic simulators are an indispensable tool for epidemiology to explore
the behavior of complex, dynamic infections under varying conditions and
navigate uncertain environments. Agent-based models (ABMs) are an increasingly
popular simulation paradigm that can represent the heterogeneity of contact
interactions with granular detail and agency of individual behavior. However,
conventional ABM frameworks are not differentiable and present challenges in
scalability; due to which it is non-trivial to connect them to auxiliary data
sources. In this paper, we introduce GradABM: a scalable, differentiable design
for agent-based modeling that is amenable to gradient-based learning with
automatic differentiation. GradABM can quickly simulate million-size
populations in few seconds on commodity hardware, integrate with deep neural
networks and ingest heterogeneous data sources. This provides an array of
practical benefits for calibration, forecasting, and evaluating policy
interventions. We demonstrate the efficacy of GradABM via extensive experiments
with real COVID-19 and influenza datasets."
Improving Keyphrase Extraction with Data Augmentation and Information Filtering,0.045145,"Keyphrase extraction is one of the essential tasks for document understanding
in NLP. While the majority of the prior works are dedicated to the formal
setting, e.g., books, news or web-blogs, informal texts such as video
transcripts are less explored. To address this limitation, in this work we
present a novel corpus and method for keyphrase extraction from the transcripts
of the videos streamed on the Behance platform. More specifically, in this
work, a novel data augmentation is proposed to enrich the model with the
background knowledge about the keyphrase extraction task from other domains.
Extensive experiments on the proposed dataset dataset show the effectiveness of
the introduced method."
VQ3D: Learning a 3D-Aware Generative Model on ImageNet,0.370057,"Recent work has shown the possibility of training generative models of 3D
content from 2D image collections on small datasets corresponding to a single
object class, such as human faces, animal faces, or cars. However, these models
struggle on larger, more complex datasets. To model diverse and unconstrained
image collections such as ImageNet, we present VQ3D, which introduces a
NeRF-based decoder into a two-stage vector-quantized autoencoder. Our Stage 1
allows for the reconstruction of an input image and the ability to change the
camera position around the image, and our Stage 2 allows for the generation of
new 3D scenes. VQ3D is capable of generating and reconstructing 3D-aware images
from the 1000-class ImageNet dataset of 1.2 million training images. We achieve
an ImageNet generation FID score of 16.8, compared to 69.8 for the next best
baseline method."
Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks,0.999661,"How well can NLP models generalize to a variety of unseen tasks when provided
with task instructions? To address this question, we first introduce
Super-NaturalInstructions, a benchmark of 1,616 diverse NLP tasks and their
expert-written instructions. Our collection covers 76 distinct task types,
including but not limited to classification, extraction, infilling, sequence
tagging, text rewriting, and text composition. This large and diverse
collection of tasks enables rigorous benchmarking of cross-task generalization
under instructions -- training models to follow instructions on a subset of
tasks and evaluating them on the remaining unseen ones. Furthermore, we build
Tk-Instruct, a transformer model trained to follow a variety of in-context
instructions (plain language task definitions or k-shot examples). Our
experiments show that Tk-Instruct outperforms existing instruction-following
models such as InstructGPT by over 9% on our benchmark despite being an order
of magnitude smaller. We further analyze generalization as a function of
various scaling parameters, such as the number of observed tasks, the number of
instances per task, and model sizes. We hope our dataset and model facilitate
future progress towards more general-purpose NLP models."
Beyond original Research Articles Categorization via NLP,0.351011,"This work proposes a novel approach to text categorization -- for unknown
categories -- in the context of scientific literature, using Natural Language
Processing techniques. The study leverages the power of pre-trained language
models, specifically SciBERT, to extract meaningful representations of
abstracts from the ArXiv dataset. Text categorization is performed using the
K-Means algorithm, and the optimal number of clusters is determined based on
the Silhouette score. The results demonstrate that the proposed approach
captures subject information more effectively than the traditional arXiv
labeling system, leading to improved text categorization. The approach offers
potential for better navigation and recommendation systems in the rapidly
growing landscape of scientific research literature."
StereoKG: Data-Driven Knowledge Graph Construction for Cultural Knowledge and Stereotypes,0.274136,"Analyzing ethnic or religious bias is important for improving fairness,
accountability, and transparency of natural language processing models.
However, many techniques rely on human-compiled lists of bias terms, which are
expensive to create and are limited in coverage. In this study, we present a
fully data-driven pipeline for generating a knowledge graph (KG) of cultural
knowledge and stereotypes. Our resulting KG covers 5 religious groups and 5
nationalities and can easily be extended to include more entities. Our human
evaluation shows that the majority (59.2%) of non-singleton entries are
coherent and complete stereotypes. We further show that performing intermediate
masked language model training on the verbalized KG leads to a higher level of
cultural awareness in the model and has the potential to increase
classification performance on knowledge-crucial samples on a related task,
i.e., hate speech detection."
Know What I don't Know: Handling Ambiguous and Unanswerable Questions for Text-to-SQL,0.320832,"The task of text-to-SQL aims to convert a natural language question into its
corresponding SQL query within the context of relational tables. Existing
text-to-SQL parsers generate a ""plausible"" SQL query for an arbitrary user
question, thereby failing to correctly handle problematic user questions. To
formalize this problem, we conduct a preliminary study on the observed
ambiguous and unanswerable cases in text-to-SQL and summarize them into 6
feature categories. Correspondingly, we identify the causes behind each
category and propose requirements for handling ambiguous and unanswerable
questions. Following this study, we propose a simple yet effective
counterfactual example generation approach that automatically produces
ambiguous and unanswerable text-to-SQL examples. Furthermore, we propose a
weakly supervised DTE (Detecting-Then-Explaining) model for error detection,
localization, and explanation. Experimental results show that our model
achieves the best result on both real-world examples and generated examples
compared with various baselines. We release our data and code at:
\href{https://github.com/wbbeyourself/DTE}{https://github.com/wbbeyourself/DTE}."
ShadowNeuS: Neural SDF Reconstruction by Shadow Ray Supervision,0.507428,"By supervising camera rays between a scene and multi-view image planes, NeRF
reconstructs a neural scene representation for the task of novel view
synthesis. On the other hand, shadow rays between the light source and the
scene have yet to be considered. Therefore, we propose a novel shadow ray
supervision scheme that optimizes both the samples along the ray and the ray
location. By supervising shadow rays, we successfully reconstruct a neural SDF
of the scene from single-view images under multiple lighting conditions. Given
single-view binary shadows, we train a neural network to reconstruct a complete
scene not limited by the camera's line of sight. By further modeling the
correlation between the image colors and the shadow rays, our technique can
also be effectively extended to RGB inputs. We compare our method with previous
works on challenging tasks of shape reconstruction from single-view binary
shadow or RGB images and observe significant improvements. The code and data
are available at https://github.com/gerwang/ShadowNeuS."
Structuring ontologies in a context of collaborative system modelling,0.127887,"Prospective studies require discussing and collaborating with the
stakeholders to create scenarios of the possible evolution of the studied
value-chain. However, stakeholders don't always use the same words when
referring to one idea. Constructing an ontology and homogenizing vocabularies
is thus crucial to identify key variables which serve in the construction of
the needed scenarios. Nevertheless, it is a very complex and timeconsuming
task. In this paper we present the method we used to manually build ontologies
adapted to the needs of two complementary system-analysis models (namely the
""Godet"" and the ""MyChoice"" models), starting from interviews of the agri-food
system's stakeholders."
Designing Biological Sequences via Meta-Reinforcement Learning and Bayesian Optimization,0.171368,"The ability to accelerate the design of biological sequences can have a
substantial impact on the progress of the medical field. The problem can be
framed as a global optimization problem where the objective is an expensive
black-box function such that we can query large batches restricted with a
limitation of a low number of rounds. Bayesian Optimization is a principled
method for tackling this problem. However, the astronomically large state space
of biological sequences renders brute-force iterating over all possible
sequences infeasible. In this paper, we propose MetaRLBO where we train an
autoregressive generative model via Meta-Reinforcement Learning to propose
promising sequences for selection via Bayesian Optimization. We pose this
problem as that of finding an optimal policy over a distribution of MDPs
induced by sampling subsets of the data acquired in the previous rounds. Our
in-silico experiments show that meta-learning over such ensembles provides
robustness against reward misspecification and achieves competitive results
compared to existing strong baselines."
INSCIT: Information-Seeking Conversations with Mixed-Initiative Interactions,0.589321,"In an information-seeking conversation, a user may ask questions that are
under-specified or unanswerable. An ideal agent would interact by initiating
different response types according to the available knowledge sources. However,
most current studies either fail to or artificially incorporate such agent-side
initiative. This work presents InSCIt, a dataset for Information-Seeking
Conversations with mixed-initiative Interactions. It contains 4.7K user-agent
turns from 805 human-human conversations where the agent searches over
Wikipedia and either directly answers, asks for clarification, or provides
relevant information to address user queries. The data supports two subtasks,
evidence passage identification and response generation, as well as a human
evaluation protocol to assess model performance. We report results of two
systems based on state-of-the-art models of conversational knowledge
identification and open-domain question answering. Both systems significantly
underperform humans, suggesting ample room for improvement in future studies."
Cooperative Multi-Agent Deep Reinforcement Learning for Reliable Surveillance via Autonomous Multi-UAV Control,0.992423,"CCTV-based surveillance using unmanned aerial vehicles (UAVs) is considered a
key technology for security in smart city environments. This paper creates a
case where the UAVs with CCTV-cameras fly over the city area for flexible and
reliable surveillance services. UAVs should be deployed to cover a large area
while minimize overlapping and shadow areas for a reliable surveillance system.
However, the operation of UAVs is subject to high uncertainty, necessitating
autonomous recovery systems. This work develops a multi-agent deep
reinforcement learning-based management scheme for reliable industry
surveillance in smart city applications. The core idea this paper employs is
autonomously replenishing the UAV's deficient network requirements with
communications. Via intensive simulations, our proposed algorithm outperforms
the state-of-the-art algorithms in terms of surveillance coverage, user support
capability, and computational costs."
StegaNeRF: Embedding Invisible Information within Neural Radiance Fields,0.581078,"Recent advances in neural rendering imply a future of widespread visual data
distributions through sharing NeRF model weights. However, while common visual
data (images and videos) have standard approaches to embed ownership or
copyright information explicitly or subtly, the problem remains unexplored for
the emerging NeRF format. We present StegaNeRF, a method for steganographic
information embedding in NeRF renderings. We design an optimization framework
allowing accurate hidden information extractions from images rendered by NeRF,
while preserving its original visual quality. We perform experimental
evaluations of our method under several potential deployment scenarios, and we
further discuss the insights discovered through our analysis. StegaNeRF
signifies an initial exploration into the novel problem of instilling
customizable, imperceptible, and recoverable information to NeRF renderings,
with minimal impact to rendered images. Project page:
https://xggnet.github.io/StegaNeRF/."
Verified Probabilistic Policies for Deep Reinforcement Learning,0.11092,"Deep reinforcement learning is an increasingly popular technique for
synthesising policies to control an agent's interaction with its environment.
There is also growing interest in formally verifying that such policies are
correct and execute safely. Progress has been made in this area by building on
existing work for verification of deep neural networks and of continuous-state
dynamical systems. In this paper, we tackle the problem of verifying
probabilistic policies for deep reinforcement learning, which are used to, for
example, tackle adversarial environments, break symmetries and manage
trade-offs. We propose an abstraction approach, based on interval Markov
decision processes, that yields probabilistic guarantees on a policy's
execution, and present techniques to build and solve these models using
abstract interpretation, mixed-integer linear programming, entropy-based
refinement and probabilistic model checking. We implement our approach and
illustrate its effectiveness on a selection of reinforcement learning
benchmarks."
TemporalWiki: A Lifelong Benchmark for Training and Evaluating Ever-Evolving Language Models,0.964854,"Language Models (LMs) become outdated as the world changes; they often fail
to perform tasks requiring recent factual information which was absent or
different during training, a phenomenon called temporal misalignment. This is
especially a challenging problem because the research community still lacks a
coherent dataset for assessing the adaptability of LMs to frequently-updated
knowledge corpus such as Wikipedia. To this end, we introduce TemporalWiki, a
lifelong benchmark for ever-evolving LMs that utilizes the difference between
consecutive snapshots of English Wikipedia and English Wikidata for training
and evaluation, respectively. The benchmark hence allows researchers to
periodically track an LM's ability to retain previous knowledge and acquire
updated/new knowledge at each point in time. We also find that training an LM
on the diff data through continual learning methods achieves similar or better
perplexity than on the entire snapshot in our benchmark with 12 times less
computational cost, which verifies that factual knowledge in LMs can be safely
updated with minimal training data via continual learning. The dataset and the
code are available at https://github.com/joeljang/temporalwiki."
Improving Intrinsic Exploration with Language Abstractions,0.837003,"Reinforcement learning (RL) agents are particularly hard to train when
rewards are sparse. One common solution is to use intrinsic rewards to
encourage agents to explore their environment. However, recent intrinsic
exploration methods often use state-based novelty measures which reward
low-level exploration and may not scale to domains requiring more abstract
skills. Instead, we explore natural language as a general medium for
highlighting relevant abstractions in an environment. Unlike previous work, we
evaluate whether language can improve over existing exploration methods by
directly extending (and comparing to) competitive intrinsic exploration
baselines: AMIGo (Campero et al., 2021) and NovelD (Zhang et al., 2021). These
language-based variants outperform their non-linguistic forms by 47-85% across
13 challenging tasks from the MiniGrid and MiniHack environment suites."
minicons: Enabling Flexible Behavioral and Representational Analyses of Transformer Language Models,0.362375,"We present minicons, an open source library that provides a standard API for
researchers interested in conducting behavioral and representational analyses
of transformer-based language models (LMs). Specifically, minicons enables
researchers to apply analysis methods at two levels: (1) at the prediction
level -- by providing functions to efficiently extract word/sentence level
probabilities; and (2) at the representational level -- by also facilitating
efficient extraction of word/phrase level vectors from one or more layers. In
this paper, we describe the library and apply it to two motivating case
studies: One focusing on the learning dynamics of the BERT architecture on
relative grammatical judgments, and the other on benchmarking 23 different LMs
on zero-shot abductive reasoning. minicons is available at
https://github.com/kanishkamisra/minicons"
PolyFormer: Referring Image Segmentation as Sequential Polygon Generation,0.853552,"In this work, instead of directly predicting the pixel-level segmentation
masks, the problem of referring image segmentation is formulated as sequential
polygon generation, and the predicted polygons can be later converted into
segmentation masks. This is enabled by a new sequence-to-sequence framework,
Polygon Transformer (PolyFormer), which takes a sequence of image patches and
text query tokens as input, and outputs a sequence of polygon vertices
autoregressively. For more accurate geometric localization, we propose a
regression-based decoder, which predicts the precise floating-point coordinates
directly, without any coordinate quantization error. In the experiments,
PolyFormer outperforms the prior art by a clear margin, e.g., 5.40% and 4.52%
absolute improvements on the challenging RefCOCO+ and RefCOCOg datasets. It
also shows strong generalization ability when evaluated on the referring video
segmentation task without fine-tuning, e.g., achieving competitive 61.5% J&F on
the Ref-DAVIS17 dataset."
The Best of Both Worlds: Combining Human and Machine Translations for Multilingual Semantic Parsing with Active Learning,0.4696,"Multilingual semantic parsing aims to leverage the knowledge from the
high-resource languages to improve low-resource semantic parsing, yet commonly
suffers from the data imbalance problem. Prior works propose to utilize the
translations by either humans or machines to alleviate such issues. However,
human translations are expensive, while machine translations are cheap but
prone to error and bias. In this work, we propose an active learning approach
that exploits the strengths of both human and machine translations by
iteratively adding small batches of human translations into the
machine-translated training set. Besides, we propose novel aggregated
acquisition criteria that help our active learning method select utterances to
be manually translated. Our experiments demonstrate that an ideal utterance
selection can significantly reduce the error and bias in the translated data,
resulting in higher parser accuracies than the parsers merely trained on the
machine-translated data."
GuidedMixup: An Efficient Mixup Strategy Guided by Saliency Maps,0.483634,"Data augmentation is now an essential part of the image training process, as
it effectively prevents overfitting and makes the model more robust against
noisy datasets. Recent mixing augmentation strategies have advanced to generate
the mixup mask that can enrich the saliency information, which is a supervisory
signal. However, these methods incur a significant computational burden to
optimize the mixup mask. From this motivation, we propose a novel
saliency-aware mixup method, GuidedMixup, which aims to retain the salient
regions in mixup images with low computational overhead. We develop an
efficient pairing algorithm that pursues to minimize the conflict of salient
regions of paired images and achieve rich saliency in mixup images. Moreover,
GuidedMixup controls the mixup ratio for each pixel to better preserve the
salient region by interpolating two paired images smoothly. The experiments on
several datasets demonstrate that GuidedMixup provides a good trade-off between
augmentation overhead and generalization performance on classification
datasets. In addition, our method shows good performance in experiments with
corrupted or reduced datasets."
A Strategy-Oriented Bayesian Soft Actor-Critic Model,0.163176,"Adopting reasonable strategies is challenging but crucial for an intelligent
agent with limited resources working in hazardous, unstructured, and dynamic
environments to improve the system's utility, decrease the overall cost, and
increase mission success probability. This paper proposes a novel hierarchical
strategy decomposition approach based on the Bayesian chain rule to separate an
intricate policy into several simple sub-policies and organize their
relationships as Bayesian strategy networks (BSN). We integrate this approach
into the state-of-the-art DRL method -- soft actor-critic (SAC) and build the
corresponding Bayesian soft actor-critic (BSAC) model by organizing several
sub-policies as a joint policy. We compare the proposed BSAC method with the
SAC and other state-of-the-art approaches such as TD3, DDPG, and PPO on the
standard continuous control benchmarks -- Hopper-v2, Walker2d-v2, and
Humanoid-v2 -- in MuJoCo with the OpenAI Gym environment. The results
demonstrate that the promising potential of the BSAC method significantly
improves training efficiency."
Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages,0.912235,"Scaling multilingual representation learning beyond the hundred most frequent
languages is challenging, in particular to cover the long tail of low-resource
languages. A promising approach has been to train one-for-all multilingual
models capable of cross-lingual transfer, but these models often suffer from
insufficient capacity and interference between unrelated languages. Instead, we
move away from this approach and focus on training multiple language (family)
specific representations, but most prominently enable all languages to still be
encoded in the same representational space. To achieve this, we focus on
teacher-student training, allowing all encoders to be mutually compatible for
bitext mining, and enabling fast learning of new languages. We introduce a new
teacher-student training scheme which combines supervised and self-supervised
training, allowing encoders to take advantage of monolingual training data,
which is valuable in the low-resource setting.
  Our approach significantly outperforms the original LASER encoder. We study
very low-resource languages and handle 50 African languages, many of which are
not covered by any other model. For these languages, we train sentence
encoders, mine bitexts, and validate the bitexts by training NMT systems."
The Goldilocks of Pragmatic Understanding: Fine-Tuning Strategy Matters for Implicature Resolution by LLMs,0.487016,"Despite widespread use of LLMs as conversational agents, evaluations of
performance fail to capture a crucial aspect of communication: interpreting
language in context -- incorporating its pragmatics. Humans interpret language
using beliefs and prior knowledge about the world. For example, we intuitively
understand the response ""I wore gloves"" to the question ""Did you leave
fingerprints?"" as meaning ""No"". To investigate whether LLMs have the ability to
make this type of inference, known as an implicature, we design a simple task
and evaluate four categories of widely used state-of-the-art models. We find
that, despite only evaluating on utterances that require a binary inference
(yes or no), models in three of these categories perform close to random.
However, LLMs instruction-tuned at the example-level perform significantly
better. These results suggest that certain fine-tuning strategies are far
better at inducing pragmatic understanding in models. We present our findings
as the starting point for further research into evaluating how LLMs interpret
language in context and to drive the development of more pragmatic and useful
models of human discourse."
Shape-aware Text-driven Layered Video Editing,0.631658,"Temporal consistency is essential for video editing applications. Existing
work on layered representation of videos allows propagating edits consistently
to each frame. These methods, however, can only edit object appearance rather
than object shape changes due to the limitation of using a fixed UV mapping
field for texture atlas. We present a shape-aware, text-driven video editing
method to tackle this challenge. To handle shape changes in video editing, we
first propagate the deformation field between the input and edited keyframe to
all frames. We then leverage a pre-trained text-conditioned diffusion model as
guidance for refining shape distortion and completing unseen regions. The
experimental results demonstrate that our method can achieve shape-aware
consistent video editing and compare favorably with the state-of-the-art."
Contrastive Learning for Joint Normal Estimation and Point Cloud Filtering,0.200536,"Point cloud filtering and normal estimation are two fundamental research
problems in the 3D field. Existing methods usually perform normal estimation
and filtering separately and often show sensitivity to noise and/or inability
to preserve sharp geometric features such as corners and edges. In this paper,
we propose a novel deep learning method to jointly estimate normals and filter
point clouds. We first introduce a 3D patch based contrastive learning
framework, with noise corruption as an augmentation, to train a feature encoder
capable of generating faithful representations of point cloud patches while
remaining robust to noise. These representations are consumed by a simple
regression network and supervised by a novel joint loss, simultaneously
estimating point normals and displacements that are used to filter the patch
centers. Experimental results show that our method well supports the two tasks
simultaneously and preserves sharp features and fine details. It generally
outperforms state-of-the-art techniques on both tasks. Our source code is
available at https://github.com/ddsediri/CLJNEPCF."
Few-shot Transfer Learning for Knowledge Base Question Answering: Fusing Supervised Models with In-Context Learning,0.341735,"Existing Knowledge Base Question Answering (KBQA) architectures are hungry
for annotated data, which make them costly and time-consuming to deploy. We
introduce the problem of few-shot transfer learning for KBQA, where the target
domain offers only a few labeled examples, but a large labeled training dataset
is available in a source domain. We propose a novel KBQA architecture called
FuSIC-KBQA that performs KB-retrieval using multiple source-trained retrievers,
re-ranks using an LLM and uses this as input for LLM few-shot in-context
learning to generate logical forms. These are further refined using
execution-guided feedback. Experiments over multiple source-target KBQA pairs
of varying complexity show that FuSIC-KBQA significantly outperforms
adaptations of SoTA KBQA models for this setting. Additional experiments show
that FuSIC-KBQA also outperforms SoTA KBQA models in the in-domain setting when
training data is limited."
Unleash the Potential of Image Branch for Cross-modal 3D Object Detection,0.386793,"To achieve reliable and precise scene understanding, autonomous vehicles
typically incorporate multiple sensing modalities to capitalize on their
complementary attributes. However, existing cross-modal 3D detectors do not
fully utilize the image domain information to address the bottleneck issues of
the LiDAR-based detectors. This paper presents a new cross-modal 3D object
detector, namely UPIDet, which aims to unleash the potential of the image
branch from two aspects. First, UPIDet introduces a new 2D auxiliary task
called normalized local coordinate map estimation. This approach enables the
learning of local spatial-aware features from the image modality to supplement
sparse point clouds. Second, we discover that the representational capability
of the point cloud backbone can be enhanced through the gradients
backpropagated from the training objectives of the image branch, utilizing a
succinct and effective point-to-pixel module. Extensive experiments and
ablation studies validate the effectiveness of our method. Notably, we achieved
the top rank in the highly competitive cyclist class of the KITTI benchmark at
the time of submission. The source code is available at
https://github.com/Eaphan/UPIDet."
Assessing the nature of large language models: A caution against anthropocentrism,0.0286404,"Generative AI models garnered a large amount of public attention and
speculation with the release of OpenAIs chatbot, ChatGPT. At least two opinion
camps exist: one excited about possibilities these models offer for fundamental
changes to human tasks, and another highly concerned about power these models
seem to have. To address these concerns, we assessed several LLMs, primarily
GPT 3.5, using standard, normed, and validated cognitive and personality
measures. For this seedling project, we developed a battery of tests that
allowed us to estimate the boundaries of some of these models capabilities, how
stable those capabilities are over a short period of time, and how they compare
to humans. Our results indicate that LLMs are unlikely to have developed
sentience, although its ability to respond to personality inventories is
interesting. GPT3.5 did display large variability in both cognitive and
personality measures over repeated observations, which is not expected if it
had a human-like personality. Variability notwithstanding, LLMs display what in
a human would be considered poor mental health, including low self-esteem,
marked dissociation from reality, and in some cases narcissism and psychopathy,
despite upbeat and helpful responses."
Benchmark dataset and instance generator for Real-World Three-Dimensional Bin Packing Problems,0.748593,"In this article, a benchmark for real-world bin packing problems is proposed.
This dataset consists of 12 instances of varying levels of complexity regarding
size (with the number of packages ranging from 38 to 53) and user-defined
requirements. In fact, several real-world-oriented restrictions were taken into
account to build these instances: i) item and bin dimensions, ii) weight
restrictions, iii) affinities among package categories iv) preferences for
package ordering and v) load balancing. Besides the data, we also offer an own
developed Python script for the dataset generation, coined Q4RealBPP-DataGen.
The benchmark was initially proposed to evaluate the performance of quantum
solvers. Therefore, the characteristics of this set of instances were designed
according to the current limitations of quantum devices. Additionally, the
dataset generator is included to allow the construction of general-purpose
benchmarks. The data introduced in this article provides a baseline that will
encourage quantum computing researchers to work on real-world bin packing
problems."
Open Vocabulary Semantic Segmentation with Patch Aligned Contrastive Learning,0.858513,"We introduce Patch Aligned Contrastive Learning (PACL), a modified
compatibility function for CLIP's contrastive loss, intending to train an
alignment between the patch tokens of the vision encoder and the CLS token of
the text encoder. With such an alignment, a model can identify regions of an
image corresponding to a given text input, and therefore transfer seamlessly to
the task of open vocabulary semantic segmentation without requiring any
segmentation annotations during training. Using pre-trained CLIP encoders with
PACL, we are able to set the state-of-the-art on the task of open vocabulary
zero-shot segmentation on 4 different segmentation benchmarks: Pascal VOC,
Pascal Context, COCO Stuff and ADE20K. Furthermore, we show that PACL is also
applicable to image-level predictions and when used with a CLIP backbone,
provides a general improvement in zero-shot classification accuracy compared to
CLIP, across a suite of 12 image classification datasets."
Universal Distributional Decision-based Black-box Adversarial Attack with Reinforcement Learning,0.0964557,"The vulnerability of the high-performance machine learning models implies a
security risk in applications with real-world consequences. Research on
adversarial attacks is beneficial in guiding the development of machine
learning models on the one hand and finding targeted defenses on the other.
However, most of the adversarial attacks today leverage the gradient or logit
information from the models to generate adversarial perturbation. Works in the
more realistic domain: decision-based attacks, which generate adversarial
perturbation solely based on observing the output label of the targeted model,
are still relatively rare and mostly use gradient-estimation strategies. In
this work, we propose a pixel-wise decision-based attack algorithm that finds a
distribution of adversarial perturbation through a reinforcement learning
algorithm. We call this method Decision-based Black-box Attack with
Reinforcement learning (DBAR). Experiments show that the proposed approach
outperforms state-of-the-art decision-based attacks with a higher attack
success rate and greater transferability."
(De-)Randomized Smoothing for Decision Stump Ensembles,0.337509,"Tree-based models are used in many high-stakes application domains such as
finance and medicine, where robustness and interpretability are of utmost
importance. Yet, methods for improving and certifying their robustness are
severely under-explored, in contrast to those focusing on neural networks.
Targeting this important challenge, we propose deterministic smoothing for
decision stump ensembles. Whereas most prior work on randomized smoothing
focuses on evaluating arbitrary base models approximately under input
randomization, the key insight of our work is that decision stump ensembles
enable exact yet efficient evaluation via dynamic programming. Importantly, we
obtain deterministic robustness certificates, even jointly over numerical and
categorical features, a setting ubiquitous in the real world. Further, we
derive an MLE-optimal training method for smoothed decision stumps under
randomization and propose two boosting approaches to improve their provable
robustness. An extensive experimental evaluation on computer vision and tabular
data tasks shows that our approach yields significantly higher certified
accuracies than the state-of-the-art for tree-based models. We release all code
and trained models at https://github.com/eth-sri/drs."
Action Recognition for American Sign Language,0.20595,"In this research, we present our findings to recognize American Sign Language
from series of hand gestures. While most researches in literature focus only on
static handshapes, our work target dynamic hand gestures. Since dynamic signs
dataset are very few, we collect an initial dataset of 150 videos for 10 signs
and an extension of 225 videos for 15 signs. We apply transfer learning models
in combination with deep neural networks and background subtraction for videos
in different temporal settings. Our primarily results show that we can get an
accuracy of $0.86$ and $0.71$ using DenseNet201, LSTM with video sequence of 12
frames accordingly."
Research on road object detection algorithm based on improved YOLOX,0.0614466,"Road object detection is an important branch of automatic driving technology,
The model with higher detection accuracy is more conducive to the safe driving
of vehicles. In road object detection, the omission of small objects and
occluded objects is an important problem. therefore, reducing the missed rate
of the object is of great significance for safe driving. In the work of this
paper, based on the YOLOX object detection algorithm to improve, proposes
DecIoU boundary box regression loss function to improve the shape consistency
of the predicted and real box, and Push Loss is introduced to further optimize
the boundary box regression loss function, in order to detect more occluded
objects. In addition, the dynamic anchor box mechanism is also used to improve
the accuracy of the confidence label, improve the label inaccuracy of object
detection model without anchor box. A large number of experiments on KITTI
dataset demonstrate the effectiveness of the proposed method, the improved
YOLOX-s achieved 88.9% mAP and 91.0% mAR on the KITTI dataset, compared to the
baseline version improvements of 2.77% and 4.24%; the improved YOLOX-m achieved
89.1% mAP and 91.4% mAR, compared to the baseline version improvements of 2.30%
and 4.10%."
CNSNet: A Cleanness-Navigated-Shadow Network for Shadow Removal,0.520938,"The key to shadow removal is recovering the contents of the shadow regions
with the guidance of the non-shadow regions. Due to the inadequate long-range
modeling, the CNN-based approaches cannot thoroughly investigate the
information from the non-shadow regions. To solve this problem, we propose a
novel cleanness-navigated-shadow network (CNSNet), with a shadow-oriented
adaptive normalization (SOAN) module and a shadow-aware aggregation with
transformer (SAAT) module based on the shadow mask. Under the guidance of the
shadow mask, the SOAN module formulates the statistics from the non-shadow
region and adaptively applies them to the shadow region for region-wise
restoration. The SAAT module utilizes the shadow mask to precisely guide the
restoration of each shadowed pixel by considering the highly relevant pixels
from the shadow-free regions for global pixel-wise restoration. Extensive
experiments on three benchmark datasets (ISTD, ISTD+, and SRD) show that our
method achieves superior de-shadowing performance."
Provably Efficient Fictitious Play Policy Optimization for Zero-Sum Markov Games with Structured Transitions,0.763198,"While single-agent policy optimization in a fixed environment has attracted a
lot of research attention recently in the reinforcement learning community,
much less is known theoretically when there are multiple agents playing in a
potentially competitive environment. We take steps forward by proposing and
analyzing new fictitious play policy optimization algorithms for zero-sum
Markov games with structured but unknown transitions. We consider two classes
of transition structures: factored independent transition and single-controller
transition. For both scenarios, we prove tight
$\widetilde{\mathcal{O}}(\sqrt{K})$ regret bounds after $K$ episodes in a
two-agent competitive game scenario. The regret of each agent is measured
against a potentially adversarial opponent who can choose a single best policy
in hindsight after observing the full policy sequence. Our algorithms feature a
combination of Upper Confidence Bound (UCB)-type optimism and fictitious play
under the scope of simultaneous policy optimization in a non-stationary
environment. When both players adopt the proposed algorithms, their overall
optimality gap is $\widetilde{\mathcal{O}}(\sqrt{K})$."
Incorporating Explicit Knowledge in Pre-trained Language Models for Passage Re-ranking,0.554433,"Passage re-ranking is to obtain a permutation over the candidate passage set
from retrieval stage. Re-rankers have been boomed by Pre-trained Language
Models (PLMs) due to their overwhelming advantages in natural language
understanding. However, existing PLM based re-rankers may easily suffer from
vocabulary mismatch and lack of domain specific knowledge. To alleviate these
problems, explicit knowledge contained in knowledge graph is carefully
introduced in our work. Specifically, we employ the existing knowledge graph
which is incomplete and noisy, and first apply it in passage re-ranking task.
To leverage a reliable knowledge, we propose a novel knowledge graph
distillation method and obtain a knowledge meta graph as the bridge between
query and passage. To align both kinds of embedding in the latent space, we
employ PLM as text encoder and graph neural network over knowledge meta graph
as knowledge encoder. Besides, a novel knowledge injector is designed for the
dynamic interaction between text and knowledge encoder. Experimental results
demonstrate the effectiveness of our method especially in queries requiring
in-depth domain knowledge."
Polarimetric Multi-View Inverse Rendering,0.434152,"A polarization camera has great potential for 3D reconstruction since the
angle of polarization (AoP) and the degree of polarization (DoP) of reflected
light are related to an object's surface normal. In this paper, we propose a
novel 3D reconstruction method called Polarimetric Multi-View Inverse Rendering
(Polarimetric MVIR) that effectively exploits geometric, photometric, and
polarimetric cues extracted from input multi-view color-polarization images. We
first estimate camera poses and an initial 3D model by geometric reconstruction
with a standard structure-from-motion and multi-view stereo pipeline. We then
refine the initial model by optimizing photometric rendering errors and
polarimetric errors using multi-view RGB, AoP, and DoP images, where we propose
a novel polarimetric cost function that enables an effective constraint on the
estimated surface normal of each vertex, while considering four possible
ambiguous azimuth angles revealed from the AoP measurement. The weight for the
polarimetric cost is effectively determined based on the DoP measurement, which
is regarded as the reliability of polarimetric information. Experimental
results using both synthetic and real data demonstrate that our Polarimetric
MVIR can reconstruct a detailed 3D shape without assuming a specific surface
material and lighting condition."
Learning to Automate Follow-up Question Generation using Process Knowledge for Depression Triage on Reddit Posts,0.916104,"Conversational Agents (CAs) powered with deep language models (DLMs) have
shown tremendous promise in the domain of mental health. Prominently, the CAs
have been used to provide informational or therapeutic services to patients.
However, the utility of CAs to assist in mental health triaging has not been
explored in the existing work as it requires a controlled generation of
follow-up questions (FQs), which are often initiated and guided by the mental
health professionals (MHPs) in clinical settings. In the context of depression,
our experiments show that DLMs coupled with process knowledge in a mental
health questionnaire generate 12.54% and 9.37% better FQs based on similarity
and longest common subsequence matches to questions in the PHQ-9 dataset
respectively, when compared with DLMs without process knowledge support.
Despite coupling with process knowledge, we find that DLMs are still prone to
hallucination, i.e., generating redundant, irrelevant, and unsafe FQs. We
demonstrate the challenge of using existing datasets to train a DLM for
generating FQs that adhere to clinical process knowledge. To address this
limitation, we prepared an extended PHQ-9 based dataset, PRIMATE, in
collaboration with MHPs. PRIMATE contains annotations regarding whether a
particular question in the PHQ-9 dataset has already been answered in the
user's initial description of the mental health condition. We used PRIMATE to
train a DLM in a supervised setting to identify which of the PHQ-9 questions
can be answered directly from the user's post and which ones would require more
information from the user. Using performance analysis based on MCC scores, we
show that PRIMATE is appropriate for identifying questions in PHQ-9 that could
guide generative DLMs towards controlled FQ generation suitable for aiding
triaging. Dataset created as a part of this research:
https://github.com/primate-mh/Primate2022"
HIT at SemEval-2022 Task 2: Pre-trained Language Model for Idioms Detection,0.0379321,"The same multi-word expressions may have different meanings in different
sentences. They can be mainly divided into two categories, which are literal
meaning and idiomatic meaning. Non-contextual-based methods perform poorly on
this problem, and we need contextual embedding to understand the idiomatic
meaning of multi-word expressions correctly. We use a pre-trained language
model, which can provide a context-aware sentence embedding, to detect whether
multi-word expression in the sentence is idiomatic usage."
Cooperation or Competition: Avoiding Player Domination for Multi-Target Robustness via Adaptive Budgets,0.105895,"Despite incredible advances, deep learning has been shown to be susceptible
to adversarial attacks. Numerous approaches have been proposed to train robust
networks both empirically and certifiably. However, most of them defend against
only a single type of attack, while recent work takes steps forward in
defending against multiple attacks. In this paper, to understand multi-target
robustness, we view this problem as a bargaining game in which different
players (adversaries) negotiate to reach an agreement on a joint direction of
parameter updating. We identify a phenomenon named player domination in the
bargaining game, namely that the existing max-based approaches, such as MAX and
MSD, do not converge. Based on our theoretical analysis, we design a novel
framework that adjusts the budgets of different adversaries to avoid any player
dominance. Experiments on standard benchmarks show that employing the proposed
framework to the existing approaches significantly advances multi-target
robustness."
SingleSketch2Mesh : Generating 3D Mesh model from Sketch,0.412296,"Sketching is an important activity in any design process. Designers and
stakeholders share their ideas through hand-drawn sketches. These sketches are
further used to create 3D models. Current methods to generate 3D models from
sketches are either manual or tightly coupled with 3D modeling platforms.
Therefore, it requires users to have an experience of sketching on such
platform. Moreover, most of the existing approaches are based on geometric
manipulation and thus cannot be generalized. We propose a novel AI based
ensemble approach, SingleSketch2Mesh, for generating 3D models from hand-drawn
sketches. Our approach is based on Generative Networks and Encoder-Decoder
Architecture to generate 3D mesh model from a hand-drawn sketch. We evaluate
our solution with existing solutions. Our approach outperforms existing
approaches on both - quantitative and qualitative evaluation criteria."
EgoPCA: A New Framework for Egocentric Hand-Object Interaction Understanding,0.379022,"With the surge in attention to Egocentric Hand-Object Interaction (Ego-HOI),
large-scale datasets such as Ego4D and EPIC-KITCHENS have been proposed.
However, most current research is built on resources derived from third-person
video action recognition. This inherent domain gap between first- and
third-person action videos, which have not been adequately addressed before,
makes current Ego-HOI suboptimal. This paper rethinks and proposes a new
framework as an infrastructure to advance Ego-HOI recognition by Probing,
Curation and Adaption (EgoPCA). We contribute comprehensive pre-train sets,
balanced test sets and a new baseline, which are complete with a
training-finetuning strategy. With our new framework, we not only achieve
state-of-the-art performance on Ego-HOI benchmarks but also build several new
and effective mechanisms and settings to advance further research. We believe
our data and the findings will pave a new way for Ego-HOI understanding. Code
and data are available at https://mvig-rhos.com/ego_pca"
Transcending Scaling Laws with 0.1% Extra Compute,0.508321,"Scaling language models improves performance but comes with significant
computational costs. This paper proposes UL2R, a method that substantially
improves existing language models and their scaling curves with a relatively
tiny amount of extra compute. The key idea is to continue training a
state-of-the-art large language model (e.g., PaLM) on a few more steps with
UL2's mixture-of-denoiser objective. We show that, with almost negligible extra
computational costs and no new sources of data, we are able to substantially
improve the scaling properties of large language models on downstream metrics.
In this paper, we continue training PaLM with UL2R, introducing a new set of
models at 8B, 62B, and 540B scale which we call U-PaLM. Impressively, at 540B
scale, we show an approximately 2x computational savings rate where U-PaLM
achieves the same performance as the final PaLM 540B model at around half its
computational budget (i.e., saving $\sim$4.4 million TPUv4 hours). We further
show that this improved scaling curve leads to 'emergent abilities' on
challenging BIG-Bench tasks -- for instance, U-PaLM does much better than PaLM
on some tasks or demonstrates better quality at much smaller scale (62B as
opposed to 540B). Overall, we show that U-PaLM outperforms PaLM on many
few-shot setups, i.e., English NLP tasks (e.g., commonsense reasoning, question
answering), reasoning tasks with chain-of-thought (e.g., GSM8K), multilingual
tasks (MGSM, TydiQA), MMLU and challenging BIG-Bench tasks. Finally, we provide
qualitative examples showing the new capabilities of U-PaLM for single and
multi-span infilling."
A Data Fusion Framework for Multi-Domain Morality Learning,0.774198,"Language models can be trained to recognize the moral sentiment of text,
creating new opportunities to study the role of morality in human life. As
interest in language and morality has grown, several ground truth datasets with
moral annotations have been released. However, these datasets vary in the
method of data collection, domain, topics, instructions for annotators, etc.
Simply aggregating such heterogeneous datasets during training can yield models
that fail to generalize well. We describe a data fusion framework for training
on multiple heterogeneous datasets that improve performance and
generalizability. The model uses domain adversarial training to align the
datasets in feature space and a weighted loss function to deal with label
shift. We show that the proposed framework achieves state-of-the-art
performance in different datasets compared to prior works in morality
inference."
Sample Constrained Treatment Effect Estimation,0.513598,"Treatment effect estimation is a fundamental problem in causal inference. We
focus on designing efficient randomized controlled trials, to accurately
estimate the effect of some treatment on a population of $n$ individuals. In
particular, we study sample-constrained treatment effect estimation, where we
must select a subset of $s \ll n$ individuals from the population to experiment
on. This subset must be further partitioned into treatment and control groups.
Algorithms for partitioning the entire population into treatment and control
groups, or for choosing a single representative subset, have been well-studied.
The key challenge in our setting is jointly choosing a representative subset
and a partition for that set.
  We focus on both individual and average treatment effect estimation, under a
linear effects model. We give provably efficient experimental designs and
corresponding estimators, by identifying connections to discrepancy
minimization and leverage-score-based sampling used in randomized numerical
linear algebra. Our theoretical results obtain a smooth transition to known
guarantees when $s$ equals the population size. We also empirically demonstrate
the performance of our algorithms."
Towards General Text Embeddings with Multi-stage Contrastive Learning,0.996546,"We present GTE, a general-purpose text embedding model trained with
multi-stage contrastive learning. In line with recent advancements in unifying
various NLP tasks into a single format, we train a unified text embedding model
by employing contrastive learning over a diverse mixture of datasets from
multiple sources. By significantly increasing the number of training data
during both unsupervised pre-training and supervised fine-tuning stages, we
achieve substantial performance gains over existing embedding models. Notably,
even with a relatively modest parameter count of 110M, GTE$_\text{base}$
outperforms the black-box embedding API provided by OpenAI and even surpasses
10x larger text embedding models on the massive text embedding benchmark.
Furthermore, without additional fine-tuning on each programming language
individually, our model outperforms previous best code retrievers of similar
size by treating code as text. In summary, our model achieves impressive
results by effectively harnessing multi-stage contrastive learning, offering a
powerful and efficient text embedding model with broad applicability across
various NLP and code-related tasks."
Generative AI in Mafia-like Game Simulation,0.0433638,"In this research, we explore the efficacy and potential of Generative AI
models, specifically focusing on their application in role-playing simulations
exemplified through Spyfall, a renowned mafia-style game. By leveraging GPT-4's
advanced capabilities, the study aimed to showcase the model's potential in
understanding, decision-making, and interaction during game scenarios.
Comparative analyses between GPT-4 and its predecessor, GPT-3.5-turbo,
demonstrated GPT-4's enhanced adaptability to the game environment, with
significant improvements in posing relevant questions and forming human-like
responses. However, challenges such as the model;s limitations in bluffing and
predicting opponent moves emerged. Reflections on game development, financial
constraints, and non-verbal limitations of the study were also discussed. The
findings suggest that while GPT-4 exhibits promising advancements over earlier
models, there remains potential for further development, especially in
instilling more human-like attributes in AI."
Ethical Design of Computers: From Semiconductors to IoT and Artificial Intelligence,0.249199,"Computing systems are tightly integrated today into our professional, social,
and private lives. An important consequence of this growing ubiquity of
computing is that it can have significant ethical implications of which
computing professionals should take account. In most real-world scenarios, it
is not immediately obvious how particular technical choices during the design
and use of computing systems could be viewed from an ethical perspective. This
article provides a perspective on the ethical challenges within semiconductor
chip design, IoT applications, and the increasing use of artificial
intelligence in the design processes, tools, and hardware-software stacks of
these systems."
Do Language Models Learn Position-Role Mappings?,0.18696,"How is knowledge of position-role mappings in natural language learned? We
explore this question in a computational setting, testing whether a variety of
well-performing pertained language models (BERT, RoBERTa, and DistilBERT)
exhibit knowledge of these mappings, and whether this knowledge persists across
alternations in syntactic, structural, and lexical alternations. In Experiment
1, we show that these neural models do indeed recognize distinctions between
theme and recipient roles in ditransitive constructions, and that these
distinct patterns are shared across construction type. We strengthen this
finding in Experiment 2 by showing that fine-tuning these language models on
novel theme- and recipient-like tokens in one paradigm allows the models to
make correct predictions about their placement in other paradigms, suggesting
that the knowledge of these mappings is shared rather than independently
learned. We do, however, observe some limitations of this generalization when
tasks involve constructions with novel ditransitive verbs, hinting at a degree
of lexical specificity which underlies model performance."
Adversarial Attacks on Monocular Pose Estimation,0.293795,"Advances in deep learning have resulted in steady progress in computer vision
with improved accuracy on tasks such as object detection and semantic
segmentation. Nevertheless, deep neural networks are vulnerable to adversarial
attacks, thus presenting a challenge in reliable deployment. Two of the
prominent tasks in 3D scene-understanding for robotics and advanced drive
assistance systems are monocular depth and pose estimation, often learned
together in an unsupervised manner. While studies evaluating the impact of
adversarial attacks on monocular depth estimation exist, a systematic
demonstration and analysis of adversarial perturbations against pose estimation
are lacking. We show how additive imperceptible perturbations can not only
change predictions to increase the trajectory drift but also catastrophically
alter its geometry. We also study the relation between adversarial
perturbations targeting monocular depth and pose estimation networks, as well
as the transferability of perturbations to other networks with different
architectures and losses. Our experiments show how the generated perturbations
lead to notable errors in relative rotation and translation predictions and
elucidate vulnerabilities of the networks."
Approximation analysis of CNNs from a feature extraction view,0.0999623,"Deep learning based on deep neural networks has been very successful in many
practical applications, but it lacks enough theoretical understanding due to
the network architectures and structures. In this paper we establish some
analysis for linear feature extraction by a deep multi-channel convolutional
neural networks (CNNs), which demonstrates the power of deep learning over
traditional linear transformations, like Fourier, wavelets, redundant
dictionary coding methods. Moreover, we give an exact construction presenting
how linear features extraction can be conducted efficiently with multi-channel
CNNs. It can be applied to lower the essential dimension for approximating a
high dimensional function. Rates of function approximation by such deep
networks implemented with channels and followed by fully-connected layers are
investigated as well. Harmonic analysis for factorizing linear features into
multi-resolution convolutions plays an essential role in our work.
Nevertheless, a dedicate vectorization of matrices is constructed, which
bridges 1D CNN and 2D CNN and allows us to have corresponding 2D analysis."
PromptST: Prompt-Enhanced Spatio-Temporal Multi-Attribute Prediction,0.73799,"In the era of information explosion, spatio-temporal data mining serves as a
critical part of urban management. Considering the various fields demanding
attention, e.g., traffic state, human activity, and social event, predicting
multiple spatio-temporal attributes simultaneously can alleviate regulatory
pressure and foster smart city construction. However, current research can not
handle the spatio-temporal multi-attribute prediction well due to the complex
relationships between diverse attributes. The key challenge lies in how to
address the common spatio-temporal patterns while tackling their distinctions.
In this paper, we propose an effective solution for spatio-temporal
multi-attribute prediction, PromptST. We devise a spatio-temporal transformer
and a parameter-sharing training scheme to address the common knowledge among
different spatio-temporal attributes. Then, we elaborate a spatio-temporal
prompt tuning strategy to fit the specific attributes in a lightweight manner.
Through the pretrain and prompt tuning phases, our PromptST is able to enhance
the specific spatio-temoral characteristic capture by prompting the backbone
model to fit the specific target attribute while maintaining the learned common
knowledge. Extensive experiments on real-world datasets verify that our
PromptST attains state-of-the-art performance. Furthermore, we also prove
PromptST owns good transferability on unseen spatio-temporal attributes, which
brings promising application potential in urban computing. The implementation
code is available to ease reproducibility."
Language-enhanced RNR-Map: Querying Renderable Neural Radiance Field maps with natural language,0.262078,"We present Le-RNR-Map, a Language-enhanced Renderable Neural Radiance map for
Visual Navigation with natural language query prompts. The recently proposed
RNR-Map employs a grid structure comprising latent codes positioned at each
pixel. These latent codes, which are derived from image observation, enable: i)
image rendering given a camera pose, since they are converted to Neural
Radiance Field; ii) image navigation and localization with astonishing
accuracy. On top of this, we enhance RNR-Map with CLIP-based embedding latent
codes, allowing natural language search without additional label data. We
evaluate the effectiveness of this map in single and multi-object searches. We
also investigate its compatibility with a Large Language Model as an
""affordance query resolver"". Code and videos are available at
https://intelligolabs.github.io/Le-RNR-Map/"
A Persian ASR-based SER: Modification of Sharif Emotional Speech Database and Investigation of Persian Text Corpora,0.125941,"Speech Emotion Recognition (SER) is one of the essential perceptual methods
of humans in understanding the situation and how to interact with others,
therefore, in recent years, it has been tried to add the ability to recognize
emotions to human-machine communication systems. Since the SER process relies
on labeled data, databases are essential for it. Incomplete, low-quality or
defective data may lead to inaccurate predictions. In this paper, we fixed the
inconsistencies in Sharif Emotional Speech Database (ShEMO), as a Persian
database, by using an Automatic Speech Recognition (ASR) system and
investigating the effect of Farsi language models obtained from accessible
Persian text corpora. We also introduced a Persian/Farsi ASR-based SER system
that uses linguistic features of the ASR outputs and Deep Learning-based
models."
TrueType Transformer: Character and Font Style Recognition in Outline Format,0.318308,"We propose TrueType Transformer (T3), which can perform character and font
style recognition in an outline format. The outline format, such as TrueType,
represents each character as a sequence of control points of stroke contours
and is frequently used in born-digital documents. T3 is organized by a deep
neural network, so-called Transformer. Transformer is originally proposed for
sequential data, such as text, and therefore appropriate for handling the
outline data. In other words, T3 directly accepts the outline data without
converting it into a bitmap image. Consequently, T3 realizes a
resolution-independent classification. Moreover, since the locations of the
control points represent the fine and local structures of the font style, T3 is
suitable for font style classification, where such structures are very
important. In this paper, we experimentally show the applicability of T3 in
character and font style recognition tasks, while observing how the individual
control points contribute to classification results."
"Reduce, Reuse, Recycle: Selective Reincarnation in Multi-Agent Reinforcement Learning",0.255328,"'Reincarnation' in reinforcement learning has been proposed as a
formalisation of reusing prior computation from past experiments when training
an agent in an environment. In this paper, we present a brief foray into the
paradigm of reincarnation in the multi-agent (MA) context. We consider the case
where only some agents are reincarnated, whereas the others are trained from
scratch -- selective reincarnation. In the fully-cooperative MA setting with
heterogeneous agents, we demonstrate that selective reincarnation can lead to
higher returns than training fully from scratch, and faster convergence than
training with full reincarnation. However, the choice of which agents to
reincarnate in a heterogeneous system is vitally important to the outcome of
the training -- in fact, a poor choice can lead to considerably worse results
than the alternatives. We argue that a rich field of work exists here, and we
hope that our effort catalyses further energy in bringing the topic of
reincarnation to the multi-agent realm."
Byzantine-Robust Learning on Heterogeneous Data via Gradient Splitting,0.233985,"Federated learning has exhibited vulnerabilities to Byzantine attacks, where
the Byzantine attackers can send arbitrary gradients to a central server to
destroy the convergence and performance of the global model. A wealth of robust
AGgregation Rules (AGRs) have been proposed to defend against Byzantine
attacks. However, Byzantine clients can still circumvent robust AGRs when data
is non-Identically and Independently Distributed (non-IID). In this paper, we
first reveal the root causes of performance degradation of current robust AGRs
in non-IID settings: the curse of dimensionality and gradient heterogeneity. In
order to address this issue, we propose GAS, a \shorten approach that can
successfully adapt existing robust AGRs to non-IID settings. We also provide a
detailed convergence analysis when the existing robust AGRs are combined with
GAS. Experiments on various real-world datasets verify the efficacy of our
proposed GAS. The implementation code is provided in
https://github.com/YuchenLiu-a/byzantine-gas."
A Multiset Version of Even-Odd Permutations Identity,0.191666,"In this paper, we give a new bijective proof of a multiset analogue of
even-odd permutations identity. This multiset version is equivalent to the
original coin arrangements lemma which is a key combinatorial lemma in the
Sherman's Proof of a conjecture of Feynman about an identity on paths in planar
graphs related to combinatorial solution of two dimensional Ising model in
statistical physics."
DetIE: Multilingual Open Information Extraction Inspired by Object Detection,0.45841,"State of the art neural methods for open information extraction (OpenIE)
usually extract triplets (or tuples) iteratively in an autoregressive or
predicate-based manner in order not to produce duplicates. In this work, we
propose a different approach to the problem that can be equally or more
successful. Namely, we present a novel single-pass method for OpenIE inspired
by object detection algorithms from computer vision. We use an order-agnostic
loss based on bipartite matching that forces unique predictions and a
Transformer-based encoder-only architecture for sequence labeling. The proposed
approach is faster and shows superior or similar performance in comparison with
state of the art models on standard benchmarks in terms of both quality metrics
and inference time. Our model sets the new state of the art performance of
67.7% F1 on CaRB evaluated as OIE2016 while being 3.35x faster at inference
than previous state of the art. We also evaluate the multilingual version of
our model in the zero-shot setting for two languages and introduce a strategy
for generating synthetic multilingual data to fine-tune the model for each
specific language. In this setting, we show performance improvement 15% on
multilingual Re-OIE2016, reaching 75% F1 for both Portuguese and Spanish
languages. Code and models are available at
https://github.com/sberbank-ai/DetIE."
f-Divergence Minimization for Sequence-Level Knowledge Distillation,0.928757,"Knowledge distillation (KD) is the process of transferring knowledge from a
large model to a small one. It has gained increasing attention in the natural
language processing community, driven by the demands of compressing
ever-growing language models. In this work, we propose an f-DISTILL framework,
which formulates sequence-level knowledge distillation as minimizing a
generalized f-divergence function. We propose four distilling variants under
our framework and show that existing SeqKD and ENGINE approaches are
approximations of our f-DISTILL methods. We further derive step-wise
decomposition for our f-DISTILL, reducing intractable sequence-level divergence
to word-level losses that can be computed in a tractable manner. Experiments
across four datasets show that our methods outperform existing KD approaches,
and that our symmetric distilling losses can better force the student to learn
from the teacher distribution."
Path-Aware Graph Attention for HD Maps in Motion Prediction,0.786419,"The success of motion prediction for autonomous driving relies on integration
of information from the HD maps. As maps are naturally graph-structured,
investigation on graph neural networks (GNNs) for encoding HD maps is
burgeoning in recent years. However, unlike many other applications where GNNs
have been straightforwardly deployed, HD maps are heterogeneous graphs where
vertices (lanes) are connected by edges (lane-lane interaction relationships)
of various nature, and most graph-based models are not designed to understand
the variety of edge types which provide crucial cues for predicting how the
agents would travel the lanes. To overcome this challenge, we propose
Path-Aware Graph Attention, a novel attention architecture that infers the
attention between two vertices by parsing the sequence of edges forming the
paths that connect them. Our analysis illustrates how the proposed attention
mechanism can facilitate learning in a didactic problem where existing graph
networks like GCN struggle. By improving map encoding, the proposed model
surpasses previous state of the art on the Argoverse Motion Forecasting
dataset, and won the first place in the 2021 Argoverse Motion Forecasting
Competition."
On the Neural Tangent Kernel of Equilibrium Models,0.889757,"This work studies the neural tangent kernel (NTK) of the deep equilibrium
(DEQ) model, a practical ``infinite-depth'' architecture which directly
computes the infinite-depth limit of a weight-tied network via root-finding.
Even though the NTK of a fully-connected neural network can be stochastic if
its width and depth both tend to infinity simultaneously, we show that
contrarily a DEQ model still enjoys a deterministic NTK despite its width and
depth going to infinity at the same time under mild conditions. Moreover, this
deterministic NTK can be found efficiently via root-finding."
Learning Foresightful Dense Visual Affordance for Deformable Object Manipulation,0.843233,"Understanding and manipulating deformable objects (e.g., ropes and fabrics)
is an essential yet challenging task with broad applications. Difficulties come
from complex states and dynamics, diverse configurations and high-dimensional
action space of deformable objects. Besides, the manipulation tasks usually
require multiple steps to accomplish, and greedy policies may easily lead to
local optimal states. Existing studies usually tackle this problem using
reinforcement learning or imitating expert demonstrations, with limitations in
modeling complex states or requiring hand-crafted expert policies. In this
paper, we study deformable object manipulation using dense visual affordance,
with generalization towards diverse states, and propose a novel kind of
foresightful dense affordance, which avoids local optima by estimating states'
values for long-term manipulation. We propose a framework for learning this
representation, with novel designs such as multi-stage stable learning and
efficient self-supervised data collection without experts. Experiments
demonstrate the superiority of our proposed foresightful dense affordance.
Project page: https://hyperplane-lab.github.io/DeformableAffordance"
AmbiCoref: Evaluating Human and Model Sensitivity to Ambiguous Coreference,0.238031,"Given a sentence ""Abby told Brittney that she upset Courtney"", one would
struggle to understand who ""she"" refers to, and ask for clarification. However,
if the word ""upset"" were replaced with ""hugged"", ""she"" unambiguously refers to
Abby. We study if modern coreference resolution models are sensitive to such
pronominal ambiguity. To this end, we construct AmbiCoref, a diagnostic corpus
of minimal sentence pairs with ambiguous and unambiguous referents. Our
examples generalize psycholinguistic studies of human perception of ambiguity
around particular arrangements of verbs and their arguments. Analysis shows
that (1) humans are less sure of referents in ambiguous AmbiCoref examples than
unambiguous ones, and (2) most coreference models show little difference in
output between ambiguous and unambiguous pairs. We release AmbiCoref as a
diagnostic corpus for testing whether models treat ambiguity similarly to
humans."
Information Extraction from Scanned Invoice Images using Text Analysis and Layout Features,0.414656,"While storing invoice content as metadata to avoid paper document processing
may be the future trend, almost all of daily issued invoices are still printed
on paper or generated in digital formats such as PDFs. In this paper, we
introduce the OCRMiner system for information extraction from scanned document
images which is based on text analysis techniques in combination with layout
features to extract indexing metadata of (semi-)structured documents. The
system is designed to process the document in a similar way a human reader
uses, i.e. to employ different layout and text attributes in a coordinated
decision. The system consists of a set of interconnected modules that start
with (possibly erroneous) character-based output from a standard OCR system and
allow to apply different techniques and to expand the extracted knowledge at
each step. Using an open source OCR, the system is able to recover the invoice
data in 90% for English and in 88% for the Czech set."
AI applications in forest monitoring need remote sensing benchmark datasets,0.308907,"With the rise in high resolution remote sensing technologies there has been
an explosion in the amount of data available for forest monitoring, and an
accompanying growth in artificial intelligence applications to automatically
derive forest properties of interest from these datasets. Many studies use
their own data at small spatio-temporal scales, and demonstrate an application
of an existing or adapted data science method for a particular task. This
approach often involves intensive and time-consuming data collection and
processing, but generates results restricted to specific ecosystems and sensor
types. There is a lack of widespread acknowledgement of how the types and
structures of data used affects performance and accuracy of analysis
algorithms. To accelerate progress in the field more efficiently, benchmarking
datasets upon which methods can be tested and compared are sorely needed.
  Here, we discuss how lack of standardisation impacts confidence in estimation
of key forest properties, and how considerations of data collection need to be
accounted for in assessing method performance. We present pragmatic
requirements and considerations for the creation of rigorous, useful
benchmarking datasets for forest monitoring applications, and discuss how tools
from modern data science can improve use of existing data. We list a set of
example large-scale datasets that could contribute to benchmarking, and present
a vision for how community-driven, representative benchmarking initiatives
could benefit the field."
SDOH-NLI: a Dataset for Inferring Social Determinants of Health from Clinical Notes,0.476595,"Social and behavioral determinants of health (SDOH) play a significant role
in shaping health outcomes, and extracting these determinants from clinical
notes is a first step to help healthcare providers systematically identify
opportunities to provide appropriate care and address disparities. Progress on
using NLP methods for this task has been hindered by the lack of high-quality
publicly available labeled data, largely due to the privacy and regulatory
constraints on the use of real patients' information. This paper introduces a
new dataset, SDOH-NLI, that is based on publicly available notes and which we
release publicly. We formulate SDOH extraction as a natural language inference
(NLI) task, and provide binary textual entailment labels obtained from human
raters for a cross product of a set of social history snippets as premises and
SDOH factors as hypotheses. Our dataset differs from standard NLI benchmarks in
that our premises and hypotheses are obtained independently. We evaluate both
""off-the-shelf"" entailment models as well as models fine-tuned on our data, and
highlight the ways in which our dataset appears more challenging than commonly
used NLI datasets."
Deep Learning-based Quality Assessment of Clinical Protocol Adherence in Fetal Ultrasound Dating Scans,0.115858,"To assess fetal health during pregnancy, doctors use the gestational age (GA)
calculation based on the Crown Rump Length (CRL) measurement in order to check
for fetal size and growth trajectory. However, GA estimation based on CRL,
requires proper positioning of calipers on the fetal crown and rump view, which
is not always an easy plane to find, especially for an inexperienced
sonographer. Finding a slightly oblique view from the true CRL view could lead
to a different CRL value and therefore incorrect estimation of GA. This study
presents an AI-based method for a quality assessment of the CRL view by
verifying 7 clinical scoring criteria that are used to verify the correctness
of the acquired plane. We show how our proposed solution achieves high accuracy
on the majority of the scoring criteria when compared to an expert. We also
show that if such scoring system is used, it helps identify poorly acquired
images accurately and hence may help sonographers acquire better images which
could potentially lead to a better assessment of conditions such as
Intrauterine Growth Restriction (IUGR)."
Auto-MLM: Improved Contrastive Learning for Self-supervised Multi-lingual Knowledge Retrieval,0.105521,"Contrastive learning (CL) has become a ubiquitous approach for several
natural language processing (NLP) downstream tasks, especially for question
answering (QA). However, the major challenge, how to efficiently train the
knowledge retrieval model in an unsupervised manner, is still unresolved.
Recently the commonly used methods are composed of CL and masked language model
(MLM). Unexpectedly, MLM ignores the sentence-level training, and CL also
neglects extraction of the internal info from the query. To optimize the CL
hardly obtain internal information from the original query, we introduce a
joint training method by combining CL and Auto-MLM for self-supervised
multi-lingual knowledge retrieval. First, we acquire the fixed dimensional
sentence vector. Then, mask some words among the original sentences with random
strategy. Finally, we generate a new token representation for predicting the
masked tokens. Experimental results show that our proposed approach
consistently outperforms all the previous SOTA methods on both AliExpress $\&$
LAZADA service corpus and openly available corpora in 8 languages."
CNN-BiLSTM model for English Handwriting Recognition: Comprehensive Evaluation on the IAM Dataset,0.59811,"We present a CNN-BiLSTM system for the problem of offline English handwriting
recognition, with extensive evaluations on the public IAM dataset, including
the effects of model size, data augmentation and the lexicon. Our best model
achieves 3.59\% CER and 9.44\% WER using CNN-BiLSTM network with CTC layer.
Test time augmentation with rotation and shear transformations applied to the
input image, is proposed to increase recognition of difficult cases and found
to reduce the word error rate by 2.5\% points. We also conduct an error
analysis of our proposed method on IAM dataset, show hard cases of handwriting
images and explore samples with erroneous labels. We provide our source code as
public-domain, to foster further research to encourage scientific
reproducibility."
Zero-1-to-3: Domain-level Zero-shot Cognitive Diagnosis via One Batch of Early-bird Students towards Three Diagnostic Objectives,0.548665,"Cognitive diagnosis seeks to estimate the cognitive states of students by
exploring their logged practice quiz data. It plays a pivotal role in
personalized learning guidance within intelligent education systems. In this
paper, we focus on an important, practical, yet often underexplored task:
domain-level zero-shot cognitive diagnosis (DZCD), which arises due to the
absence of student practice logs in newly launched domains. Recent cross-domain
diagnostic models have been demonstrated to be a promising strategy for DZCD.
These methods primarily focus on how to transfer student states across domains.
However, they might inadvertently incorporate non-transferable information into
student representations, thereby limiting the efficacy of knowledge transfer.
To tackle this, we propose Zero-1-to-3, a domain-level zero-shot cognitive
diagnosis framework via one batch of early-bird students towards three
diagnostic objectives. Our approach initiates with pre-training a diagnosis
model with dual regularizers, which decouples student states into domain-shared
and domain-specific parts. The shared cognitive signals can be transferred to
the target domain, enriching the cognitive priors for the new domain, which
ensures the cognitive state propagation objective. Subsequently, we devise a
strategy to generate simulated practice logs for cold-start students through
analyzing the behavioral patterns from early-bird students, fulfilling the
domain-adaption goal. Consequently, we refine the cognitive states of
cold-start students as diagnostic outcomes via virtual data, aligning with the
diagnosis-oriented goal. Finally, extensive experiments on six real-world
datasets highlight the efficacy of our model for DZCD and its practical
application in question recommendation. The code is publicly available at
https://github.com/bigdata-ustc/Zero-1-to-3."
Sound Localization from Motion: Jointly Learning Sound Direction and Camera Rotation,0.333623,"The images and sounds that we perceive undergo subtle but geometrically
consistent changes as we rotate our heads. In this paper, we use these cues to
solve a problem we call Sound Localization from Motion (SLfM): jointly
estimating camera rotation and localizing sound sources. We learn to solve
these tasks solely through self-supervision. A visual model predicts camera
rotation from a pair of images, while an audio model predicts the direction of
sound sources from binaural sounds. We train these models to generate
predictions that agree with one another. At test time, the models can be
deployed independently. To obtain a feature representation that is well-suited
to solving this challenging problem, we also propose a method for learning an
audio-visual representation through cross-view binauralization: estimating
binaural sound from one view, given images and sound from another. Our model
can successfully estimate accurate rotations on both real and synthetic scenes,
and localize sound sources with accuracy competitive with state-of-the-art
self-supervised approaches. Project site: https://ificl.github.io/SLfM/"
Non-isotropy Regularization for Proxy-based Deep Metric Learning,0.944865,"Deep Metric Learning (DML) aims to learn representation spaces on which
semantic relations can simply be expressed through predefined distance metrics.
Best performing approaches commonly leverage class proxies as sample stand-ins
for better convergence and generalization. However, these proxy-methods solely
optimize for sample-proxy distances. Given the inherent non-bijectiveness of
used distance functions, this can induce locally isotropic sample
distributions, leading to crucial semantic context being missed due to
difficulties resolving local structures and intraclass relations between
samples. To alleviate this problem, we propose non-isotropy regularization
($\mathbb{NIR}$) for proxy-based Deep Metric Learning. By leveraging
Normalizing Flows, we enforce unique translatability of samples from their
respective class proxies. This allows us to explicitly induce a non-isotropic
distribution of samples around a proxy to optimize for. In doing so, we equip
proxy-based objectives to better learn local structures. Extensive experiments
highlight consistent generalization benefits of $\mathbb{NIR}$ while achieving
competitive and state-of-the-art performance on the standard benchmarks
CUB200-2011, Cars196 and Stanford Online Products. In addition, we find the
superior convergence properties of proxy-based methods to still be retained or
even improved, making $\mathbb{NIR}$ very attractive for practical usage. Code
available at https://github.com/ExplainableML/NonIsotropicProxyDML."
Representation Compensation Networks for Continual Semantic Segmentation,0.761386,"In this work, we study the continual semantic segmentation problem, where the
deep neural networks are required to incorporate new classes continually
without catastrophic forgetting. We propose to use a structural
re-parameterization mechanism, named representation compensation (RC) module,
to decouple the representation learning of both old and new knowledge. The RC
module consists of two dynamically evolved branches with one frozen and one
trainable. Besides, we design a pooled cube knowledge distillation strategy on
both spatial and channel dimensions to further enhance the plasticity and
stability of the model. We conduct experiments on two challenging continual
semantic segmentation scenarios, continual class segmentation and continual
domain segmentation. Without any extra computational overhead and parameters
during inference, our method outperforms state-of-the-art performance. The code
is available at \url{https://github.com/zhangchbin/RCIL}."
Image Segmentation-based Unsupervised Multiple Objects Discovery,0.543427,"Unsupervised object discovery aims to localize objects in images, while
removing the dependence on annotations required by most deep learning-based
methods. To address this problem, we propose a fully unsupervised, bottom-up
approach, for multiple objects discovery. The proposed approach is a two-stage
framework. First, instances of object parts are segmented by using the
intra-image similarity between self-supervised local features. The second step
merges and filters the object parts to form complete object instances. The
latter is performed by two CNN models that capture semantic information on
objects from the entire dataset. We demonstrate that the pseudo-labels
generated by our method provide a better precision-recall trade-off than
existing single and multiple objects discovery methods. In particular, we
provide state-of-the-art results for both unsupervised class-agnostic object
detection and unsupervised image segmentation."
JIFF: Jointly-aligned Implicit Face Function for High Quality Single View Clothed Human Reconstruction,0.884259,"This paper addresses the problem of single view 3D human reconstruction.
Recent implicit function based methods have shown impressive results, but they
fail to recover fine face details in their reconstructions. This largely
degrades user experience in applications like 3D telepresence. In this paper,
we focus on improving the quality of face in the reconstruction and propose a
novel Jointly-aligned Implicit Face Function (JIFF) that combines the merits of
the implicit function based approach and model based approach. We employ a 3D
morphable face model as our shape prior and compute space-aligned 3D features
that capture detailed face geometry information. Such space-aligned 3D features
are combined with pixel-aligned 2D features to jointly predict an implicit face
function for high quality face reconstruction. We further extend our pipeline
and introduce a coarse-to-fine architecture to predict high quality texture for
our detailed face model. Extensive evaluations have been carried out on public
datasets and our proposed JIFF has demonstrates superior performance (both
quantitatively and qualitatively) over existing state-of-the-arts."
Predicting Future Occupancy Grids in Dynamic Environment with Spatio-Temporal Learning,0.685907,"Reliably predicting future occupancy of highly dynamic urban environments is
an important precursor for safe autonomous navigation. Common challenges in the
prediction include forecasting the relative position of other vehicles,
modelling the dynamics of vehicles subjected to different traffic conditions,
and vanishing surrounding objects. To tackle these challenges, we propose a
spatio-temporal prediction network pipeline that takes the past information
from the environment and semantic labels separately for generating future
occupancy predictions. Compared to the current SOTA, our approach predicts
occupancy for a longer horizon of 3 seconds and in a relatively complex
environment from the nuScenes dataset. Our experimental results demonstrate the
ability of spatio-temporal networks to understand scene dynamics without the
need for HD-Maps and explicit modeling dynamic objects. We publicly release our
occupancy grid dataset based on nuScenes to support further research."
Evaluating Speech Synthesis by Training Recognizers on Synthetic Speech,0.230109,"Modern speech synthesis systems have improved significantly, with synthetic
speech being indistinguishable from real speech. However, efficient and
holistic evaluation of synthetic speech still remains a significant challenge.
Human evaluation using Mean Opinion Score (MOS) is ideal, but inefficient due
to high costs. Therefore, researchers have developed auxiliary automatic
metrics like Word Error Rate (WER) to measure intelligibility. Prior works
focus on evaluating synthetic speech based on pre-trained speech recognition
models, however, this can be limiting since this approach primarily measures
speech intelligibility. In this paper, we propose an evaluation technique
involving the training of an ASR model on synthetic speech and assessing its
performance on real speech. Our main assumption is that by training the ASR
model on the synthetic speech, the WER on real speech reflects the similarity
between distributions, a broader assessment of synthetic speech quality beyond
intelligibility. Our proposed metric demonstrates a strong correlation with
both MOS naturalness and MOS intelligibility when compared to SpeechLMScore and
MOSNet on three recent Text-to-Speech (TTS) systems: MQTTS, StyleTTS, and
YourTTS."
Visual Storytelling with Question-Answer Plans,0.0611293,"Visual storytelling aims to generate compelling narratives from image
sequences. Existing models often focus on enhancing the representation of the
image sequence, e.g., with external knowledge sources or advanced graph
structures. Despite recent progress, the stories are often repetitive,
illogical, and lacking in detail. To mitigate these issues, we present a novel
framework which integrates visual representations with pretrained language
models and planning. Our model translates the image sequence into a visual
prefix, a sequence of continuous embeddings which language models can
interpret. It also leverages a sequence of question-answer pairs as a blueprint
plan for selecting salient visual concepts and determining how they should be
assembled into a narrative. Automatic and human evaluation on the VIST
benchmark (Huang et al., 2016) demonstrates that blueprint-based models
generate stories that are more coherent, interesting, and natural compared to
competitive baselines and state-of-the-art systems."
D4: a Chinese Dialogue Dataset for Depression-Diagnosis-Oriented Chat,0.867956,"In a depression-diagnosis-directed clinical session, doctors initiate a
conversation with ample emotional support that guides the patients to expose
their symptoms based on clinical diagnosis criteria. Such a dialogue system is
distinguished from existing single-purpose human-machine dialog systems, as it
combines task-oriented and chit-chats with uniqueness in dialogue topics and
procedures. However, due to the social stigma associated with mental illness,
the dialogue data related to depression consultation and diagnosis are rarely
disclosed. Based on clinical depression diagnostic criteria ICD-11 and DSM-5,
we designed a 3-phase procedure to construct D$^4$: a Chinese Dialogue Dataset
for Depression-Diagnosis-Oriented Chat, which simulates the dialogue between
doctors and patients during the diagnosis of depression, including diagnosis
results and symptom summary given by professional psychiatrists for each
conversation. Upon the newly-constructed dataset, four tasks mirroring the
depression diagnosis process are established: response generation, topic
prediction, dialog summary, and severity classification of depressive episode
and suicide risk. Multi-scale evaluation results demonstrate that a more
empathy-driven and diagnostic-accurate consultation dialogue system trained on
our dataset can be achieved compared to rule-based bots."
Semi-Supervised Relational Contrastive Learning,0.0906789,"Disease diagnosis from medical images via supervised learning is usually
dependent on tedious, error-prone, and costly image labeling by medical
experts. Alternatively, semi-supervised learning and self-supervised learning
offer effectiveness through the acquisition of valuable insights from readily
available unlabeled images. We present Semi-Supervised Relational Contrastive
Learning (SRCL), a novel semi-supervised learning model that leverages
self-supervised contrastive loss and sample relation consistency for the more
meaningful and effective exploitation of unlabeled data. Our experimentation
with the SRCL model explores both pre-train/fine-tune and joint learning of the
pretext (contrastive learning) and downstream (diagnostic classification)
tasks. We validate against the ISIC 2018 Challenge benchmark skin lesion
classification dataset and demonstrate the effectiveness of our semi-supervised
method on varying amounts of labeled data."
Robots-Dont-Cry: Understanding Falsely Anthropomorphic Utterances in Dialog Systems,0.592743,"Dialog systems are often designed or trained to output human-like responses.
However, some responses may be impossible for a machine to truthfully say (e.g.
""that movie made me cry""). Highly anthropomorphic responses might make users
uncomfortable or implicitly deceive them into thinking they are interacting
with a human. We collect human ratings on the feasibility of approximately 900
two-turn dialogs sampled from 9 diverse data sources. Ratings are for two
hypothetical machine embodiments: a futuristic humanoid robot and a digital
assistant. We find that for some data-sources commonly used to train dialog
systems, 20-30% of utterances are not viewed as possible for a machine. Rating
is marginally affected by machine embodiment. We explore qualitative and
quantitative reasons for these ratings. Finally, we build classifiers and
explore how modeling configuration might affect output permissibly, and discuss
implications for building less falsely anthropomorphic dialog systems."
Weakly Supervised Data Augmentation Through Prompting for Dialogue Understanding,0.349816,"Dialogue understanding tasks often necessitate abundant annotated data to
achieve good performance and that presents challenges in low-resource settings.
To alleviate this barrier, we explore few-shot data augmentation for dialogue
understanding by prompting large pre-trained language models and present a
novel approach that iterates on augmentation quality by applying
weakly-supervised filters. We evaluate our methods on the emotion and act
classification tasks in DailyDialog and the intent classification task in
Facebook Multilingual Task-Oriented Dialogue. Models fine-tuned on our
augmented data mixed with few-shot ground truth data are able to approach or
surpass existing state-of-the-art performance on both datasets. For DailyDialog
specifically, using 10% of the ground truth data we outperform the current
state-of-the-art model which uses 100% of the data."
InstantAvatar: Learning Avatars from Monocular Video in 60 Seconds,0.884219,"In this paper, we take a significant step towards real-world applicability of
monocular neural avatar reconstruction by contributing InstantAvatar, a system
that can reconstruct human avatars from a monocular video within seconds, and
these avatars can be animated and rendered at an interactive rate. To achieve
this efficiency we propose a carefully designed and engineered system, that
leverages emerging acceleration structures for neural fields, in combination
with an efficient empty space-skipping strategy for dynamic scenes. We also
contribute an efficient implementation that we will make available for research
purposes. Compared to existing methods, InstantAvatar converges 130x faster and
can be trained in minutes instead of hours. It achieves comparable or even
better reconstruction quality and novel pose synthesis results. When given the
same time budget, our method significantly outperforms SoTA methods.
InstantAvatar can yield acceptable visual quality in as little as 10 seconds
training time."
Discovering Multiple Algorithm Configurations,0.135793,"Many practitioners in robotics regularly depend on classic, hand-designed
algorithms. Often the performance of these algorithms is tuned across a dataset
of annotated examples which represent typical deployment conditions. Automatic
tuning of these settings is traditionally known as algorithm configuration. In
this work, we extend algorithm configuration to automatically discover multiple
modes in the tuning dataset. Unlike prior work, these configuration modes
represent multiple dataset instances and are detected automatically during the
course of optimization. We propose three methods for mode discovery: a post hoc
method, a multi-stage method, and an online algorithm using a multi-armed
bandit. Our results characterize these methods on synthetic test functions and
in multiple robotics application domains: stereoscopic depth estimation,
differentiable rendering, motion planning, and visual odometry. We show the
clear benefits of detecting multiple modes in algorithm configuration space."
Cross-View Image Sequence Geo-localization,0.577879,"Cross-view geo-localization aims to estimate the GPS location of a query
ground-view image by matching it to images from a reference database of
geo-tagged aerial images. To address this challenging problem, recent
approaches use panoramic ground-view images to increase the range of
visibility. Although appealing, panoramic images are not readily available
compared to the videos of limited Field-Of-View (FOV) images. In this paper, we
present the first cross-view geo-localization method that works on a sequence
of limited FOV images. Our model is trained end-to-end to capture the temporal
structure that lies within the frames using the attention-based temporal
feature aggregation module. To robustly tackle different sequences length and
GPS noises during inference, we propose to use a sequential dropout scheme to
simulate variant length sequences. To evaluate the proposed approach in
realistic settings, we present a new large-scale dataset containing ground-view
sequences along with the corresponding aerial-view images. Extensive
experiments and comparisons demonstrate the superiority of the proposed
approach compared to several competitive baselines."
Leveraging QA Datasets to Improve Generative Data Augmentation,0.368318,"The ability of generative language models (GLMs) to generate text has
improved considerably in the last few years, enabling their use for generative
data augmentation. In this work, we propose CONDA, an approach to further
improve GLMs' ability to generate synthetic data by reformulating data
generation as context generation for a given question-answer (QA) pair and
leveraging QA datasets for training context generators. Then, we cast
downstream tasks into the same question answering format and adapt the
fine-tuned context generators to the target task domain. Finally, we use the
fine-tuned GLM to generate relevant contexts, which are in turn used as
synthetic training data for their corresponding tasks. We perform extensive
experiments on multiple classification datasets and demonstrate substantial
improvements in performance for both few- and zero-shot settings. Our analysis
reveals that QA datasets that require high-level reasoning abilities (e.g.,
abstractive and common-sense QA datasets) tend to give the best boost in
performance in both few-shot and zero-shot settings."
Visual Fault Detection of Multi-scale Key Components in Freight Trains,0.689047,"Fault detection for key components in the braking system of freight trains is
critical for ensuring railway transportation safety. Despite the frequently
employed methods based on deep learning, these fault detectors are highly
reliant on hardware resources and are complex to implement. In addition, no
train fault detectors consider the drop in accuracy induced by scale variation
of fault parts. This paper proposes a lightweight anchor-free framework to
solve the above problems. Specifically, to reduce the amount of computation and
model size, we introduce a lightweight backbone and adopt an anchor-free method
for localization and regression. To improve detection accuracy for multi-scale
parts, we design a feature pyramid network to generate rectangular layers of
different sizes to map parts with similar aspect ratios. Experiments on four
fault datasets show that our framework achieves 98.44% accuracy while the model
size is only 22.5 MB, outperforming state-of-the-art detectors."
Continual Source-Free Unsupervised Domain Adaptation,0.33108,"Existing Source-free Unsupervised Domain Adaptation (SUDA) approaches
inherently exhibit catastrophic forgetting. Typically, models trained on a
labeled source domain and adapted to unlabeled target data improve performance
on the target while dropping performance on the source, which is not available
during adaptation. In this study, our goal is to cope with the challenging
problem of SUDA in a continual learning setting, i.e., adapting to the
target(s) with varying distributional shifts while maintaining performance on
the source. The proposed framework consists of two main stages: i) a SUDA model
yielding cleaner target labels -- favoring good performance on target, and ii)
a novel method for synthesizing class-conditioned source-style images by
leveraging only the source model and pseudo-labeled target data as a prior. An
extensive pool of experiments on major benchmarks, e.g., PACS, Visda-C, and
DomainNet demonstrates that the proposed Continual SUDA (C-SUDA) framework
enables preserving satisfactory performance on the source domain without
exploiting the source data at all."
Multiple Representation Transfer from Large Language Models to End-to-End ASR Systems,0.412486,"Transferring the knowledge of large language models (LLMs) is a promising
technique to incorporate linguistic knowledge into end-to-end automatic speech
recognition (ASR) systems. However, existing works only transfer a single
representation of LLM (e.g. the last layer of pretrained BERT), while the
representation of a text is inherently non-unique and can be obtained variously
from different layers, contexts and models. In this work, we explore a wide
range of techniques to obtain and transfer multiple representations of LLMs
into a transducer-based ASR system. While being conceptually simple, we show
that transferring multiple representations of LLMs can be an effective
alternative to transferring only a single representation."
Normalizing Flow based Feature Synthesis for Outlier-Aware Object Detection,0.791661,"Real-world deployment of reliable object detectors is crucial for
applications such as autonomous driving. However, general-purpose object
detectors like Faster R-CNN are prone to providing overconfident predictions
for outlier objects. Recent outlier-aware object detection approaches estimate
the density of instance-wide features with class-conditional Gaussians and
train on synthesized outlier features from their low-likelihood regions.
However, this strategy does not guarantee that the synthesized outlier features
will have a low likelihood according to the other class-conditional Gaussians.
We propose a novel outlier-aware object detection framework that distinguishes
outliers from inlier objects by learning the joint data distribution of all
inlier classes with an invertible normalizing flow. The appropriate sampling of
the flow model ensures that the synthesized outliers have a lower likelihood
than inliers of all object classes, thereby modeling a better decision boundary
between inlier and outlier objects. Our approach significantly outperforms the
state-of-the-art for outlier-aware object detection on both image and video
datasets. Code available at https://github.com/nish03/FFS"
What changes when you randomly choose BPE merge operations? Not much,0.43554,"We introduce three simple randomized variants of byte pair encoding (BPE) and
explore whether randomizing the selection of merge operations substantially
affects a downstream machine translation task. We focus on translation into
morphologically rich languages, hypothesizing that this task may show
sensitivity to the method of choosing subwords. Analysis using a Bayesian
linear model indicates that two of the variants perform nearly
indistinguishably compared to standard BPE while the other degrades performance
less than we anticipated. We conclude that although standard BPE is widely
used, there exists an interesting universe of potential variations on it worth
investigating. Our code is available at: https://github.com/bltlab/random-bpe."
Exploring Mode Connectivity for Pre-trained Language Models,0.546781,"Recent years have witnessed the prevalent application of pre-trained language
models (PLMs) in NLP. From the perspective of parameter space, PLMs provide
generic initialization, starting from which high-performance minima could be
found. Although plenty of works have studied how to effectively and efficiently
adapt PLMs to high-performance minima, little is known about the connection of
various minima reached under different adaptation configurations. In this
paper, we investigate the geometric connections of different minima through the
lens of mode connectivity, which measures whether two minima can be connected
with a low-loss path. We conduct empirical analyses to investigate three
questions: (1) how could hyperparameters, specific tuning methods, and training
data affect PLM's mode connectivity? (2) How does mode connectivity change
during pre-training? (3) How does the PLM's task knowledge change along the
path connecting two minima? In general, exploring the mode connectivity of PLMs
conduces to understanding the geometric connection of different minima, which
may help us fathom the inner workings of PLM downstream adaptation."
Does Manipulating Tokenization Aid Cross-Lingual Transfer? A Study on POS Tagging for Non-Standardized Languages,0.495302,"One of the challenges with finetuning pretrained language models (PLMs) is
that their tokenizer is optimized for the language(s) it was pretrained on, but
brittle when it comes to previously unseen variations in the data. This can for
instance be observed when finetuning PLMs on one language and evaluating them
on data in a closely related language variety with no standardized orthography.
Despite the high linguistic similarity, tokenization no longer corresponds to
meaningful representations of the target data, leading to low performance in,
e.g., part-of-speech tagging.
  In this work, we finetune PLMs on seven languages from three different
families and analyze their zero-shot performance on closely related,
non-standardized varieties. We consider different measures for the divergence
in the tokenization of the source and target data, and the way they can be
adjusted by manipulating the tokenization during the finetuning step. Overall,
we find that the similarity between the percentage of words that get split into
subwords in the source and target data (the split word ratio difference) is the
strongest predictor for model performance on target data."
Can LLMs Augment Low-Resource Reading Comprehension Datasets? Opportunities and Challenges,0.213675,"Large Language Models (LLMs) have demonstrated impressive zero shot
performance on a wide range of NLP tasks, demonstrating the ability to reason
and apply commonsense. A relevant application is to use them for creating high
quality synthetic datasets for downstream tasks. In this work, we probe whether
GPT-4 can be used to augment existing extractive reading comprehension
datasets. Automating data annotation processes has the potential to save large
amounts of time, money and effort that goes into manually labelling datasets.
In this paper, we evaluate the performance of GPT-4 as a replacement for human
annotators for low resource reading comprehension tasks, by comparing
performance after fine tuning, and the cost associated with annotation. This
work serves to be the first analysis of LLMs as synthetic data augmenters for
QA systems, highlighting the unique opportunities and challenges. Additionally,
we release augmented versions of low resource datasets, that will allow the
research community to create further benchmarks for evaluation of generated
datasets."
Lightweight reranking for language model generations,0.050444,"Large Language Models (LLMs) can exhibit considerable variation in the
quality of their sampled outputs. Reranking and selecting the best generation
from the sampled set is a popular way of obtaining strong gains in generation
quality. In this paper, we present a novel approach for reranking LLM
generations. Unlike other techniques that might involve additional inferences
or training a specialized reranker, our approach relies on easy to compute
pairwise statistics between the generations that have minimal compute overhead.
We show that our approach can be formalized as an extension of self-consistency
and analyze its performance in that framework, theoretically as well as via
simulations. We show strong improvements for selecting the best k generations
for code generation tasks as well as robust improvements for the best
generation for the tasks of autoformalization, summarization, and translation.
While our approach only assumes black-box access to LLMs, we show that
additional access to token probabilities can improve performance even further."
Edit Everything: A Text-Guided Generative System for Images Editing,0.603802,"We introduce a new generative system called Edit Everything, which can take
image and text inputs and produce image outputs. Edit Everything allows users
to edit images using simple text instructions. Our system designs prompts to
guide the visual module in generating requested images. Experiments demonstrate
that Edit Everything facilitates the implementation of the visual aspects of
Stable Diffusion with the use of Segment Anything model and CLIP. Our system is
publicly available at https://github.com/DefengXie/Edit_Everything."
A Psychological Theory of Explainability,0.320897,"The goal of explainable Artificial Intelligence (XAI) is to generate
human-interpretable explanations, but there are no computationally precise
theories of how humans interpret AI generated explanations. The lack of theory
means that validation of XAI must be done empirically, on a case-by-case basis,
which prevents systematic theory-building in XAI. We propose a psychological
theory of how humans draw conclusions from saliency maps, the most common form
of XAI explanation, which for the first time allows for precise prediction of
explainee inference conditioned on explanation. Our theory posits that absent
explanation humans expect the AI to make similar decisions to themselves, and
that they interpret an explanation by comparison to the explanations they
themselves would give. Comparison is formalized via Shepard's universal law of
generalization in a similarity space, a classic theory from cognitive science.
A pre-registered user study on AI image classifications with saliency map
explanations demonstrate that our theory quantitatively matches participants'
predictions of the AI."
Convolutional Neural Networks: Basic Concepts and Applications in Manufacturing,0.16055,"We discuss basic concepts of convolutional neural networks (CNNs) and outline
uses in manufacturing. We begin by discussing how different types of data
objects commonly encountered in manufacturing (e.g., time series, images,
micrographs, videos, spectra, molecular structures) can be represented in a
flexible manner using tensors and graphs. We then discuss how CNNs use
convolution operations to extract informative features (e.g., geometric
patterns and textures) from the such representations to predict emergent
properties and phenomena and/or to identify anomalies. We also discuss how CNNs
can exploit color as a key source of information, which enables the use of
modern computer vision hardware (e.g., infrared, thermal, and hyperspectral
cameras). We illustrate the concepts using diverse case studies arising in
spectral analysis, molecule design, sensor design, image-based control, and
multivariate process monitoring."
Diverse Multiple Trajectory Prediction Using a Two-stage Prediction Network Trained with Lane Loss,0.630542,"Prior arts in the field of motion predictions for autonomous driving tend to
focus on finding a trajectory that is close to the ground truth trajectory.
Such problem formulations and approaches, however, frequently lead to loss of
diversity and biased trajectory predictions. Therefore, they are unsuitable for
real-world autonomous driving where diverse and road-dependent multimodal
trajectory predictions are critical for safety. To this end, this study
proposes a novel loss function, \textit{Lane Loss}, that ensures map-adaptive
diversity and accommodates geometric constraints. A two-stage trajectory
prediction architecture with a novel trajectory candidate proposal module,
\textit{Trajectory Prediction Attention (TPA)}, is trained with Lane Loss
encourages multiple trajectories to be diversely distributed, covering feasible
maneuvers in a map-aware manner. Furthermore, considering that the existing
trajectory performance metrics are focusing on evaluating the accuracy based on
the ground truth future trajectory, a quantitative evaluation metric is also
suggested to evaluate the diversity of predicted multiple trajectories. The
experiments performed on the Argoverse dataset show that the proposed method
significantly improves the diversity of the predicted trajectories without
sacrificing the prediction accuracy."
Variational Reasoning over Incomplete Knowledge Graphs for Conversational Recommendation,0.629163,"Conversational recommender systems (CRSs) often utilize external knowledge
graphs (KGs) to introduce rich semantic information and recommend relevant
items through natural language dialogues. However, original KGs employed in
existing CRSs are often incomplete and sparse, which limits the reasoning
capability in recommendation. Moreover, only few of existing studies exploit
the dialogue context to dynamically refine knowledge from KGs for better
recommendation. To address the above issues, we propose the Variational
Reasoning over Incomplete KGs Conversational Recommender (VRICR). Our key idea
is to incorporate the large dialogue corpus naturally accompanied with CRSs to
enhance the incomplete KGs; and perform dynamic knowledge reasoning conditioned
on the dialogue context. Specifically, we denote the dialogue-specific
subgraphs of KGs as latent variables with categorical priors for adaptive
knowledge graphs refactor. We propose a variational Bayesian method to
approximate posterior distributions over dialogue-specific subgraphs, which not
only leverages the dialogue corpus for restructuring missing entity relations
but also dynamically selects knowledge based on the dialogue context. Finally,
we infuse the dialogue-specific subgraphs to decode the recommendation and
responses. We conduct experiments on two benchmark CRSs datasets. Experimental
results confirm the effectiveness of our proposed method."
MetaGait: Learning to Learn an Omni Sample Adaptive Representation for Gait Recognition,0.975688,"Gait recognition, which aims at identifying individuals by their walking
patterns, has recently drawn increasing research attention. However, gait
recognition still suffers from the conflicts between the limited binary visual
clues of the silhouette and numerous covariates with diverse scales, which
brings challenges to the model's adaptiveness. In this paper, we address this
conflict by developing a novel MetaGait that learns to learn an omni sample
adaptive representation. Towards this goal, MetaGait injects meta-knowledge,
which could guide the model to perceive sample-specific properties, into the
calibration network of the attention mechanism to improve the adaptiveness from
the omni-scale, omni-dimension, and omni-process perspectives. Specifically, we
leverage the meta-knowledge across the entire process, where Meta Triple
Attention and Meta Temporal Pooling are presented respectively to adaptively
capture omni-scale dependency from spatial/channel/temporal dimensions
simultaneously and to adaptively aggregate temporal information through
integrating the merits of three complementary temporal aggregation methods.
Extensive experiments demonstrate the state-of-the-art performance of the
proposed MetaGait. On CASIA-B, we achieve rank-1 accuracy of 98.7%, 96.0%, and
89.3% under three conditions, respectively. On OU-MVLP, we achieve rank-1
accuracy of 92.4%."
OCR Improves Machine Translation for Low-Resource Languages,0.789373,"We aim to investigate the performance of current OCR systems on low resource
languages and low resource scripts. We introduce and make publicly available a
novel benchmark, OCR4MT, consisting of real and synthetic data, enriched with
noise, for 60 low-resource languages in low resource scripts. We evaluate
state-of-the-art OCR systems on our benchmark and analyse most common errors.
We show that OCR monolingual data is a valuable resource that can increase
performance of Machine Translation models, when used in backtranslation. We
then perform an ablation study to investigate how OCR errors impact Machine
Translation performance and determine what is the minimum level of OCR quality
needed for the monolingual data to be useful for Machine Translation."
ILSGAN: Independent Layer Synthesis for Unsupervised Foreground-Background Segmentation,0.319388,"Unsupervised foreground-background segmentation aims at extracting salient
objects from cluttered backgrounds, where Generative Adversarial Network (GAN)
approaches, especially layered GANs, show great promise. However, without human
annotations, they are typically prone to produce foreground and background
layers with non-negligible semantic and visual confusion, dubbed ""information
leakage"", resulting in notable degeneration of the generated segmentation mask.
To alleviate this issue, we propose a simple-yet-effective explicit layer
independence modeling approach, termed Independent Layer Synthesis GAN
(ILSGAN), pursuing independent foreground-background layer generation by
encouraging their discrepancy. Specifically, it targets minimizing the mutual
information between visible and invisible regions of the foreground and
background to spur interlayer independence. Through in-depth theoretical and
experimental analyses, we justify that explicit layer independence modeling is
critical to suppressing information leakage and contributes to impressive
segmentation performance gains. Also, our ILSGAN achieves strong
state-of-the-art generation quality and segmentation performance on complex
real-world data. Code is available at: https://github.com/qrzou/ILSGAN"
Uncertainty Estimation for Language Reward Models,0.879378,"Language models can learn a range of capabilities from unsupervised training
on text corpora. However, to solve a particular problem (such as text
summarization) it is typically necessary to fine-tune them on a task-specific
dataset. It is often easier for humans to choose between options than to
provide labeled data, and prior work has achieved state-of-the-art performance
by training a reward model from such preference comparisons. However,
collecting a large preference comparison dataset is still expensive -- and the
learned reward models are unreliable out-of-distribution. We seek to address
these problems via uncertainty estimation, which can improve sample efficiency
and robustness using active learning and risk-averse reinforcement learning
(RL). Specifically, we use bootstrap aggregating (bagging) to train an ensemble
of reward models differing in the initialization of their final layer.
Ensembles have proved successful in prior applications of active learning, but
we find that in our setting ensemble active learning does not outperform random
sampling. Further experiments show that while the aggregate predictions are
well-calibrated, the ensemble's estimated epistemic uncertainty is only weakly
correlated with model error. We suspect this is because the ensemble members
are fine-tuned from a single model and so are similar to one another. This
suggests current pre-training methods will need to be modified to support
uncertainty estimation, e.g. by training multiple language models."
Relationformer: A Unified Framework for Image-to-Graph Generation,0.850821,"A comprehensive representation of an image requires understanding objects and
their mutual relationship, especially in image-to-graph generation, e.g., road
network extraction, blood-vessel network extraction, or scene graph generation.
Traditionally, image-to-graph generation is addressed with a two-stage approach
consisting of object detection followed by a separate relation prediction,
which prevents simultaneous object-relation interaction. This work proposes a
unified one-stage transformer-based framework, namely Relationformer, that
jointly predicts objects and their relations. We leverage direct set-based
object prediction and incorporate the interaction among the objects to learn an
object-relation representation jointly. In addition to existing [obj]-tokens,
we propose a novel learnable token, namely [rln]-token. Together with
[obj]-tokens, [rln]-token exploits local and global semantic reasoning in an
image through a series of mutual associations. In combination with the
pair-wise [obj]-token, the [rln]-token contributes to a computationally
efficient relation prediction. We achieve state-of-the-art performance on
multiple, diverse and multi-domain datasets that demonstrate our approach's
effectiveness and generalizability."
Context-Preserving Instance-Level Augmentation and Deformable Convolution Networks for SAR Ship Detection,0.327584,"Shape deformation of targets in SAR image due to random orientation and
partial information loss caused by occlusion of the radar signal, is an
essential challenge in SAR ship detection. In this paper, we propose a data
augmentation method to train a deep network that is robust to partial
information loss within the targets. Taking advantage of ground-truth
annotations for bounding box and instance segmentation mask, we present a
simple and effective pipeline to simulate information loss on targets in
instance-level, while preserving contextual information. Furthermore, we adopt
deformable convolutional network to adaptively extract shape-invariant deep
features from geometrically translated targets. By learning sampling offset to
the grid of standard convolution, the network can robustly extract the features
from targets with shape variations for SAR ship detection. Experiments on the
HRSID dataset including comparisons with other deep networks and augmentation
methods, as well as ablation study, demonstrate the effectiveness of our
proposed method."
Multi-modal Emotion Estimation for in-the-wild Videos,0.849121,"In this paper, we briefly introduce our submission to the Valence-Arousal
Estimation Challenge of the 3rd Affective Behavior Analysis in-the-wild (ABAW)
competition. Our method utilizes the multi-modal information, i.e., the visual
and audio information, and employs a temporal encoder to model the temporal
context in the videos. Besides, a smooth processor is applied to get more
reasonable predictions, and a model ensemble strategy is used to improve the
performance of our proposed method. The experiment results show that our method
achieves 65.55% ccc for valence and 70.88% ccc for arousal on the validation
set of the Aff-Wild2 dataset, which prove the effectiveness of our proposed
method."
COPEN: Probing Conceptual Knowledge in Pre-trained Language Models,0.664647,"Conceptual knowledge is fundamental to human cognition and knowledge bases.
However, existing knowledge probing works only focus on evaluating factual
knowledge of pre-trained language models (PLMs) and ignore conceptual
knowledge. Since conceptual knowledge often appears as implicit commonsense
behind texts, designing probes for conceptual knowledge is hard. Inspired by
knowledge representation schemata, we comprehensively evaluate conceptual
knowledge of PLMs by designing three tasks to probe whether PLMs organize
entities by conceptual similarities, learn conceptual properties, and
conceptualize entities in contexts, respectively. For the tasks, we collect and
annotate 24k data instances covering 393 concepts, which is COPEN, a COnceptual
knowledge Probing bENchmark. Extensive experiments on different sizes and types
of PLMs show that existing PLMs systematically lack conceptual knowledge and
suffer from various spurious correlations. We believe this is a critical
bottleneck for realizing human-like cognition in PLMs. COPEN and our codes are
publicly released at https://github.com/THU-KEG/COPEN."
Identifying and Manipulating the Personality Traits of Language Models,0.972791,"Psychology research has long explored aspects of human personality such as
extroversion, agreeableness and emotional stability. Categorizations like the
`Big Five' personality traits are commonly used to assess and diagnose
personality types. In this work, we explore the question of whether the
perceived personality in language models is exhibited consistently in their
language generation. For example, is a language model such as GPT2 likely to
respond in a consistent way if asked to go out to a party? We also investigate
whether such personality traits can be controlled. We show that when provided
different types of contexts (such as personality descriptions, or answers to
diagnostic questions about personality traits), language models such as BERT
and GPT2 can consistently identify and reflect personality markers in those
contexts. This behavior illustrates an ability to be manipulated in a highly
predictable way, and frames them as tools for identifying personality traits
and controlling personas in applications such as dialog systems. We also
contribute a crowd-sourced data-set of personality descriptions of human
subjects paired with their `Big Five' personality assessment data, and a
data-set of personality descriptions collated from Reddit."
Ensembling Handcrafted Features with Deep Features: An Analytical Study for Classification of Routine Colon Cancer Histopathological Nuclei Images,0.183064,"The use of Deep Learning (DL) based methods in medical histopathology images
have been one of the most sought after solutions to classify, segment, and
detect diseased biopsy samples. However, given the complex nature of medical
datasets due to the presence of intra-class variability and heterogeneity, the
use of complex DL models might not give the optimal performance up to the level
which is suitable for assisting pathologists. Therefore, ensemble DL methods
with the scope of including domain agnostic handcrafted Features (HC-F)
inspired this work. We have, through experiments, tried to highlight that a
single DL network (domain-specific or state of the art pre-trained models)
cannot be directly used as the base model without proper analysis with the
relevant dataset. We have used F1-measure, Precision, Recall, AUC, and
Cross-Entropy Loss to analyse the performance of our approaches. We observed
from the results that the DL features ensemble bring a marked improvement in
the overall performance of the model, whereas, domain agnostic HC-F remains
dormant on the performance of the DL models."
Bootstrapped Transformer for Offline Reinforcement Learning,0.697955,"Offline reinforcement learning (RL) aims at learning policies from previously
collected static trajectory data without interacting with the real environment.
Recent works provide a novel perspective by viewing offline RL as a generic
sequence generation problem, adopting sequence models such as Transformer
architecture to model distributions over trajectories, and repurposing beam
search as a planning algorithm. However, the training datasets utilized in
general offline RL tasks are quite limited and often suffer from insufficient
distribution coverage, which could be harmful to training sequence generation
models yet has not drawn enough attention in the previous works. In this paper,
we propose a novel algorithm named Bootstrapped Transformer, which incorporates
the idea of bootstrapping and leverages the learned model to self-generate more
offline data to further boost the sequence model training. We conduct extensive
experiments on two offline RL benchmarks and demonstrate that our model can
largely remedy the existing offline RL training limitations and beat other
strong baseline methods. We also analyze the generated pseudo data and the
revealed characteristics may shed some light on offline RL training. The codes
are available at https://seqml.github.io/bootorl."
RenderNet: Visual Relocalization Using Virtual Viewpoints in Large-Scale Indoor Environments,0.123444,"Visual relocalization has been a widely discussed problem in 3D vision: given
a pre-constructed 3D visual map, the 6 DoF (Degrees-of-Freedom) pose of a query
image is estimated. Relocalization in large-scale indoor environments enables
attractive applications such as augmented reality and robot navigation.
However, appearance changes fast in such environments when the camera moves,
which is challenging for the relocalization system. To address this problem, we
propose a virtual view synthesis-based approach, RenderNet, to enrich the
database and refine poses regarding this particular scenario. Instead of
rendering real images which requires high-quality 3D models, we opt to directly
render the needed global and local features of virtual viewpoints and apply
them in the subsequent image retrieval and feature matching operations
respectively. The proposed method can largely improve the performance in
large-scale indoor environments, e.g., achieving an improvement of 7.1\% and
12.2\% on the Inloc dataset."
Outpainting by Queries,0.393231,"Image outpainting, which is well studied with Convolution Neural Network
(CNN) based framework, has recently drawn more attention in computer vision.
However, CNNs rely on inherent inductive biases to achieve effective sample
learning, which may degrade the performance ceiling. In this paper, motivated
by the flexible self-attention mechanism with minimal inductive biases in
transformer architecture, we reframe the generalised image outpainting problem
as a patch-wise sequence-to-sequence autoregression problem, enabling
query-based image outpainting. Specifically, we propose a novel hybrid
vision-transformer-based encoder-decoder framework, named \textbf{Query}
\textbf{O}utpainting \textbf{TR}ansformer (\textbf{QueryOTR}), for
extrapolating visual context all-side around a given image. Patch-wise mode's
global modeling capacity allows us to extrapolate images from the attention
mechanism's query standpoint. A novel Query Expansion Module (QEM) is designed
to integrate information from the predicted queries based on the encoder's
output, hence accelerating the convergence of the pure transformer even with a
relatively small dataset. To further enhance connectivity between each patch,
the proposed Patch Smoothing Module (PSM) re-allocates and averages the
overlapped regions, thus providing seamless predicted images. We experimentally
show that QueryOTR could generate visually appealing results smoothly and
realistically against the state-of-the-art image outpainting approaches."
Doc2Graph: a Task Agnostic Document Understanding Framework based on Graph Neural Networks,0.360218,"Geometric Deep Learning has recently attracted significant interest in a wide
range of machine learning fields, including document analysis. The application
of Graph Neural Networks (GNNs) has become crucial in various document-related
tasks since they can unravel important structural patterns, fundamental in key
information extraction processes. Previous works in the literature propose
task-driven models and do not take into account the full power of graphs. We
propose Doc2Graph, a task-agnostic document understanding framework based on a
GNN model, to solve different tasks given different types of documents. We
evaluated our approach on two challenging datasets for key information
extraction in form understanding, invoice layout analysis and table detection.
Our code is freely accessible on https://github.com/andreagemelli/doc2graph."
CopyRNeRF: Protecting the CopyRight of Neural Radiance Fields,0.480495,"Neural Radiance Fields (NeRF) have the potential to be a major representation
of media. Since training a NeRF has never been an easy task, the protection of
its model copyright should be a priority. In this paper, by analyzing the pros
and cons of possible copyright protection solutions, we propose to protect the
copyright of NeRF models by replacing the original color representation in NeRF
with a watermarked color representation. Then, a distortion-resistant rendering
scheme is designed to guarantee robust message extraction in 2D renderings of
NeRF. Our proposed method can directly protect the copyright of NeRF models
while maintaining high rendering quality and bit accuracy when compared among
optional solutions."
AugTriever: Unsupervised Dense Retrieval by Scalable Data Augmentation,0.665693,"Dense retrievers have made significant strides in text retrieval and
open-domain question answering, even though most achievements were made
possible only with large amounts of human supervision. In this work, we aim to
develop unsupervised methods by proposing two methods that create pseudo
query-document pairs and train dense retrieval models in an annotation-free and
scalable manner: query extraction and transferred query generation. The former
method produces pseudo queries by selecting salient spans from the original
document. The latter utilizes generation models trained for other NLP tasks
(e.g., summarization) to produce pseudo queries. Extensive experiments show
that models trained with the proposed augmentation methods can perform
comparably well (or better) to multiple strong baselines. Combining those
strategies leads to further improvements, achieving the state-of-the-art
performance of unsupervised dense retrieval on both BEIR and ODQA datasets."
Multi-modality Associative Bridging through Memory: Speech Sound Recollected from Face Video,0.828145,"In this paper, we introduce a novel audio-visual multi-modal bridging
framework that can utilize both audio and visual information, even with
uni-modal inputs. We exploit a memory network that stores source (i.e., visual)
and target (i.e., audio) modal representations, where source modal
representation is what we are given, and target modal representations are what
we want to obtain from the memory network. We then construct an associative
bridge between source and target memories that considers the interrelationship
between the two memories. By learning the interrelationship through the
associative bridge, the proposed bridging framework is able to obtain the
target modal representations inside the memory network, even with the source
modal input only, and it provides rich information for its downstream tasks. We
apply the proposed framework to two tasks: lip reading and speech
reconstruction from silent video. Through the proposed associative bridge and
modality-specific memories, each task knowledge is enriched with the recalled
audio context, achieving state-of-the-art performance. We also verify that the
associative bridge properly relates the source and target memories."
Open-Set Face Identification on Few-Shot Gallery by Fine-Tuning,0.177517,"In this paper, we focus on addressing the open-set face identification
problem on a few-shot gallery by fine-tuning. The problem assumes a realistic
scenario for face identification, where only a small number of face images is
given for enrollment and any unknown identity must be rejected during
identification. We observe that face recognition models pretrained on a large
dataset and naively fine-tuned models perform poorly for this task. Motivated
by this issue, we propose an effective fine-tuning scheme with classifier
weight imprinting and exclusive BatchNorm layer tuning. For further improvement
of rejection accuracy on unknown identities, we propose a novel matcher called
Neighborhood Aware Cosine (NAC) that computes similarity based on neighborhood
information. We validate the effectiveness of the proposed schemes thoroughly
on large-scale face benchmarks across different convolutional neural network
architectures. The source code for this project is available at:
https://github.com/1ho0jin1/OSFI-by-FineTuning"
Counterfactual Recipe Generation: Exploring Compositional Generalization in a Realistic Scenario,0.0322774,"People can acquire knowledge in an unsupervised manner by reading, and
compose the knowledge to make novel combinations. In this paper, we investigate
whether pretrained language models can perform compositional generalization in
a realistic setting: recipe generation. We design the counterfactual recipe
generation task, which asks models to modify a base recipe according to the
change of an ingredient. This task requires compositional generalization at two
levels: the surface level of incorporating the new ingredient into the base
recipe, and the deeper level of adjusting actions related to the changing
ingredient. We collect a large-scale recipe dataset in Chinese for models to
learn culinary knowledge, and a subset of action-level fine-grained annotations
for evaluation. We finetune pretrained language models on the recipe corpus,
and use unsupervised counterfactual generation methods to generate modified
recipes. Results show that existing models have difficulties in modifying the
ingredients while preserving the original text style, and often miss actions
that need to be adjusted. Although pretrained language models can generate
fluent recipe texts, they fail to truly learn and use the culinary knowledge in
a compositional way. Code and data are available at
https://github.com/xxxiaol/counterfactual-recipe-generation."
The Eval4NLP 2023 Shared Task on Prompting Large Language Models as Explainable Metrics,0.199105,"With an increasing number of parameters and pre-training data, generative
large language models (LLMs) have shown remarkable capabilities to solve tasks
with minimal or no task-related examples. Notably, LLMs have been successfully
employed as evaluation metrics in text generation tasks. Within this context,
we introduce the Eval4NLP 2023 shared task that asks participants to explore
prompting and score extraction for machine translation (MT) and summarization
evaluation. Specifically, we propose a novel competition setting in which we
select a list of allowed LLMs and disallow fine-tuning to ensure a focus on
prompting. We present an overview of participants' approaches and evaluate them
on a new reference-free test set spanning three language pairs for MT and a
summarization dataset. Notably, despite the task's restrictions, the
best-performing systems achieve results on par with or even surpassing recent
reference-free metrics developed using larger models, including GEMBA and
Comet-Kiwi-XXL. Finally, as a separate track, we perform a small-scale human
evaluation of the plausibility of explanations given by the LLMs."
CascadER: Cross-Modal Cascading for Knowledge Graph Link Prediction,0.466698,"Knowledge graph (KG) link prediction is a fundamental task in artificial
intelligence, with applications in natural language processing, information
retrieval, and biomedicine. Recently, promising results have been achieved by
leveraging cross-modal information in KGs, using ensembles that combine
knowledge graph embeddings (KGEs) and contextual language models (LMs).
However, existing ensembles are either (1) not consistently effective in terms
of ranking accuracy gains or (2) impractically inefficient on larger datasets
due to the combinatorial explosion problem of pairwise ranking with deep
language models. In this paper, we propose a novel tiered ranking architecture
CascadER to maintain the ranking accuracy of full ensembling while improving
efficiency considerably. CascadER uses LMs to rerank the outputs of more
efficient base KGEs, relying on an adaptive subset selection scheme aimed at
invoking the LMs minimally while maximizing accuracy gain over the KGE.
Extensive experiments demonstrate that CascadER improves MRR by up to 9 points
over KGE baselines, setting new state-of-the-art performance on four benchmarks
while improving efficiency by one or more orders of magnitude over competitive
cross-modal baselines. Our empirical analyses reveal that diversity of models
across modalities and preservation of individual models' confidence signals
help explain the effectiveness of CascadER, and suggest promising directions
for cross-modal cascaded architectures. Code and pretrained models are
available at https://github.com/tsafavi/cascader."
Causal Transportability for Visual Recognition,0.759686,"Visual representations underlie object recognition tasks, but they often
contain both robust and non-robust features. Our main observation is that image
classifiers may perform poorly on out-of-distribution samples because spurious
correlations between non-robust features and labels can be changed in a new
environment. By analyzing procedures for out-of-distribution generalization
with a causal graph, we show that standard classifiers fail because the
association between images and labels is not transportable across settings.
However, we then show that the causal effect, which severs all sources of
confounding, remains invariant across domains. This motivates us to develop an
algorithm to estimate the causal effect for image classification, which is
transportable (i.e., invariant) across source and target environments. Without
observing additional variables, we show that we can derive an estimand for the
causal effect under empirical assumptions using representations in deep models
as proxies. Theoretical analysis, empirical results, and visualizations show
that our approach captures causal invariances and improves overall
generalization."
Trustworthiness of Children Stories Generated by Large Language Models,0.0397229,"Large Language Models (LLMs) have shown a tremendous capacity for generating
literary text. However, their effectiveness in generating children's stories
has yet to be thoroughly examined. In this study, we evaluate the
trustworthiness of children's stories generated by LLMs using various measures,
and we compare and contrast our results with both old and new children's
stories to better assess their significance. Our findings suggest that LLMs
still struggle to generate children's stories at the level of quality and
nuance found in actual stories"
Unsupervised Out-of-Distribution Dialect Detection with Mahalanobis Distance,0.0453415,"Dialect classification is used in a variety of applications, such as machine
translation and speech recognition, to improve the overall performance of the
system. In a real-world scenario, a deployed dialect classification model can
encounter anomalous inputs that differ from the training data distribution,
also called out-of-distribution (OOD) samples. Those OOD samples can lead to
unexpected outputs, as dialects of those samples are unseen during model
training. Out-of-distribution detection is a new research area that has
received little attention in the context of dialect classification. Towards
this, we proposed a simple yet effective unsupervised Mahalanobis distance
feature-based method to detect out-of-distribution samples. We utilize the
latent embeddings from all intermediate layers of a wav2vec 2.0
transformer-based dialect classifier model for multi-task learning. Our
proposed approach outperforms other state-of-the-art OOD detection methods
significantly."
Modeling Human Behavior Part I -- Learning and Belief Approaches,0.165002,"There is a clear desire to model and comprehend human behavior. Trends in
research covering this topic show a clear assumption that many view human
reasoning as the presupposed standard in artificial reasoning. As such, topics
such as game theory, theory of mind, machine learning, etc. all integrate
concepts which are assumed components of human reasoning. These serve as
techniques to attempt to both replicate and understand the behaviors of humans.
In addition, next generation autonomous and adaptive systems will largely
include AI agents and humans working together as teams. To make this possible,
autonomous agents will require the ability to embed practical models of human
behavior, which allow them not only to replicate human models as a technique to
""learn"", but to to understand the actions of users and anticipate their
behavior, so as to truly operate in symbiosis with them. The main objective of
this paper it to provide a succinct yet systematic review of the most important
approaches in two areas dealing with quantitative models of human behaviors.
Specifically, we focus on (i) techniques which learn a model or policy of
behavior through exploration and feedback, such as Reinforcement Learning, and
(ii) directly model mechanisms of human reasoning, such as beliefs and bias,
without going necessarily learning via trial-and-error."
A Retrieve-and-Read Framework for Knowledge Graph Link Prediction,0.253656,"Knowledge graph (KG) link prediction aims to infer new facts based on
existing facts in the KG. Recent studies have shown that using the graph
neighborhood of a node via graph neural networks (GNNs) provides more useful
information compared to just using the query information. Conventional GNNs for
KG link prediction follow the standard message-passing paradigm on the entire
KG, which leads to superfluous computation, over-smoothing of node
representations, and also limits their expressive power. On a large scale, it
becomes computationally expensive to aggregate useful information from the
entire KG for inference. To address the limitations of existing KG link
prediction frameworks, we propose a novel retrieve-and-read framework, which
first retrieves a relevant subgraph context for the query and then jointly
reasons over the context and the query with a high-capacity reader. As part of
our exemplar instantiation for the new framework, we propose a novel
Transformer-based GNN as the reader, which incorporates graph-based attention
structure and cross-attention between query and context for deep fusion. This
simple yet effective design enables the model to focus on salient context
information relevant to the query. Empirical results on two standard KG link
prediction datasets demonstrate the competitive performance of the proposed
method. Furthermore, our analysis yields valuable insights for designing
improved retrievers within the framework."
Fairness in Visual Clustering: A Novel Transformer Clustering Approach,0.854114,"Promoting fairness for deep clustering models in unsupervised clustering
settings to reduce demographic bias is a challenging goal. This is because of
the limitation of large-scale balanced data with well-annotated labels for
sensitive or protected attributes. In this paper, we first evaluate demographic
bias in deep clustering models from the perspective of cluster purity, which is
measured by the ratio of positive samples within a cluster to their correlation
degree. This measurement is adopted as an indication of demographic bias. Then,
a novel loss function is introduced to encourage a purity consistency for all
clusters to maintain the fairness aspect of the learned clustering model.
Moreover, we present a novel attention mechanism, Cross-attention, to measure
correlations between multiple clusters, strengthening faraway positive samples
and improving the purity of clusters during the learning process. Experimental
results on a large-scale dataset with numerous attribute settings have
demonstrated the effectiveness of the proposed approach on both clustering
accuracy and fairness enhancement on several sensitive attributes."
Quantified Reproducibility Assessment of NLP Results,0.715595,"This paper describes and tests a method for carrying out quantified
reproducibility assessment (QRA) that is based on concepts and definitions from
metrology. QRA produces a single score estimating the degree of reproducibility
of a given system and evaluation measure, on the basis of the scores from, and
differences between, different reproductions. We test QRA on 18 system and
evaluation measure combinations (involving diverse NLP tasks and types of
evaluation), for each of which we have the original results and one to seven
reproduction results. The proposed QRA method produces
degree-of-reproducibility scores that are comparable across multiple
reproductions not only of the same, but of different original studies. We find
that the proposed method facilitates insights into causes of variation between
reproductions, and allows conclusions to be drawn about what changes to system
and/or evaluation design might lead to improved reproducibility."
Word sense extension,0.756963,"Humans often make creative use of words to express novel senses. A
long-standing effort in natural language processing has been focusing on word
sense disambiguation (WSD), but little has been explored about how the sense
inventory of a word may be extended toward novel meanings. We present a
paradigm of word sense extension (WSE) that enables words to spawn new senses
toward novel context. We develop a framework that simulates novel word sense
extension by first partitioning a polysemous word type into two pseudo-tokens
that mark its different senses, and then inferring whether the meaning of a
pseudo-token can be extended to convey the sense denoted by the token
partitioned from the same word type. Our framework combines cognitive models of
chaining with a learning scheme that transforms a language model embedding
space to support various types of word sense extension. We evaluate our
framework against several competitive baselines and show that it is superior in
predicting plausible novel senses for over 7,500 English words. Furthermore, we
show that our WSE framework improves performance over a range of
transformer-based WSD models in predicting rare word senses with few or zero
mentions in the training data."
Conditioned Human Trajectory Prediction using Iterative Attention Blocks,0.0461703,"Human motion prediction is key to understand social environments, with direct
applications in robotics, surveillance, etc. We present a simple yet effective
pedestrian trajectory prediction model aimed at pedestrians positions
prediction in urban-like environments conditioned by the environment: map and
surround agents. Our model is a neural-based architecture that can run several
layers of attention blocks and transformers in an iterative sequential fashion,
allowing to capture the important features in the environment that improve
prediction. We show that without explicit introduction of social masks,
dynamical models, social pooling layers, or complicated graph-like structures,
it is possible to produce on par results with SoTA models, which makes our
approach easily extendable and configurable, depending on the data available.
We report results performing similarly with SoTA models on publicly available
and extensible-used datasets with unimodal prediction metrics ADE and FDE."
Smooth Non-Stationary Bandits,0.611182,"In many applications of online decision making, the environment is
non-stationary and it is therefore crucial to use bandit algorithms that handle
changes. Most existing approaches are designed to protect against non-smooth
changes, constrained only by total variation or Lipschitzness over time, where
they guarantee $\tilde \Theta(T^{2/3})$ regret. However, in practice
environments are often changing {\bf smoothly}, so such algorithms may incur
higher-than-necessary regret in these settings and do not leverage information
on the rate of change. We study a non-stationary two-armed bandits problem
where we assume that an arm's mean reward is a $\beta$-H\""older function over
(normalized) time, meaning it is $(\beta-1)$-times Lipschitz-continuously
differentiable. We show the first separation between the smooth and non-smooth
regimes by presenting a policy with $\tilde O(T^{3/5})$ regret for $\beta=2$.
We complement this result by an $\Omg(T^{(\beta+1)/(2\beta+1)})$ lower bound
for any integer $\beta\ge 1$, which matches our upper bound for $\beta=2$."
Domain Generalization Strategy to Train Classifiers Robust to Spatial-Temporal Shift,0.637755,"Deep learning-based weather prediction models have advanced significantly in
recent years. However, data-driven models based on deep learning are difficult
to apply to real-world applications because they are vulnerable to
spatial-temporal shifts. A weather prediction task is especially susceptible to
spatial-temporal shifts when the model is overfitted to locality and
seasonality. In this paper, we propose a training strategy to make the weather
prediction model robust to spatial-temporal shifts. We first analyze the effect
of hyperparameters and augmentations of the existing training strategy on the
spatial-temporal shift robustness of the model. Next, we propose an optimal
combination of hyperparameters and augmentation based on the analysis results
and a test-time augmentation. We performed all experiments on the W4C22
Transfer dataset and achieved the 1st performance."
Towards No.1 in CLUE Semantic Matching Challenge: Pre-trained Language Model Erlangshen with Propensity-Corrected Loss,0.0399084,"This report describes a pre-trained language model Erlangshen with
propensity-corrected loss, the No.1 in CLUE Semantic Matching Challenge. In the
pre-training stage, we construct a dynamic masking strategy based on knowledge
in Masked Language Modeling (MLM) with whole word masking. Furthermore, by
observing the specific structure of the dataset, the pre-trained Erlangshen
applies propensity-corrected loss (PCL) in the fine-tuning phase. Overall, we
achieve 72.54 points in F1 Score and 78.90 points in Accuracy on the test set.
Our code is publicly available at:
https://github.com/IDEA-CCNL/Fengshenbang-LM/tree/hf-ds/fengshen/examples/clue_sim."
With a Little Help from the Authors: Reproducing Human Evaluation of an MT Error Detector,0.628339,"This work presents our efforts to reproduce the results of the human
evaluation experiment presented in the paper of Vamvas and Sennrich (2022),
which evaluated an automatic system detecting over- and undertranslations
(translations containing more or less information than the original) in machine
translation (MT) outputs. Despite the high quality of the documentation and
code provided by the authors, we discuss some problems we found in reproducing
the exact experimental setup and offer recommendations for improving
reproducibility. Our replicated results generally confirm the conclusions of
the original study, but in some cases, statistically significant differences
were observed, suggesting a high variability of human annotation."
Pre-trained Language Models Can be Fully Zero-Shot Learners,0.246877,"How can we extend a pre-trained model to many language understanding tasks,
without labeled or additional unlabeled data? Pre-trained language models
(PLMs) have been effective for a wide range of NLP tasks. However, existing
approaches either require fine-tuning on downstream labeled datasets or
manually constructing proper prompts. In this paper, we propose nonparametric
prompting PLM (NPPrompt) for fully zero-shot language understanding. Unlike
previous methods, NPPrompt uses only pre-trained language models and does not
require any labeled data or additional raw corpus for further fine-tuning, nor
does it rely on humans to construct a comprehensive set of prompt label words.
We evaluate NPPrompt against previous major few-shot and zero-shot learning
methods on diverse NLP tasks: including text classification, text entailment,
similar text retrieval, and paraphrasing. Experimental results demonstrate that
our NPPrompt outperforms the previous best fully zero-shot method by big
margins, with absolute gains of 12.8% in accuracy on text classification and
18.9% on the GLUE benchmark."
Understanding the Effect of Smartphone Cameras on Estimating Munsell Soil Colors from Imagery,0.689699,"The Munsell soil color chart (MSCC) is a in laboratories under controlled
conditions. To support an appbased solution, this paper explores three research
areas including: (i) identifying the most effective color space, (ii)
establishing then important reference for many professionals in the area of
soil color analysis. Currently, the functionality to identify Munsell soil
colors (MSCs) automatically from an image is only feasible color difference
calculation method with the highest accuracy and (iii) evaluating the effects
of smartphone cameras on estimating the MSCs. The existing methods that we have
analysed have returned promising results and will help inform other researchers
to better understand and develop informed solutions. This study provides both
researchers and developers with an insight into the best methods for
automatically predicting MSCs. Future research is needed to improve the
reliability of results under differing environmental conditions."
Evaluating BERT-based Pre-training Language Models for Detecting Misinformation,0.0636933,"It is challenging to control the quality of online information due to the
lack of supervision over all the information posted online. Manual checking is
almost impossible given the vast number of posts made on online media and how
quickly they spread. Therefore, there is a need for automated rumour detection
techniques to limit the adverse effects of spreading misinformation. Previous
studies mainly focused on finding and extracting the significant features of
text data. However, extracting features is time-consuming and not a highly
effective process. This study proposes the BERT- based pre-trained language
models to encode text data into vectors and utilise neural network models to
classify these vectors to detect misinformation. Furthermore, different
language models (LM) ' performance with different trainable parameters was
compared. The proposed technique is tested on different short and long text
datasets. The result of the proposed technique has been compared with the
state-of-the-art techniques on the same datasets. The results show that the
proposed technique performs better than the state-of-the-art techniques. We
also tested the proposed technique by combining the datasets. The results
demonstrated that the large data training and testing size considerably
improves the technique's performance."
Semantic Guided Level-Category Hybrid Prediction Network for Hierarchical Image Classification,0.163349,"Hierarchical classification (HC) assigns each object with multiple labels
organized into a hierarchical structure. The existing deep learning based HC
methods usually predict an instance starting from the root node until a leaf
node is reached. However, in the real world, images interfered by noise,
occlusion, blur, or low resolution may not provide sufficient information for
the classification at subordinate levels. To address this issue, we propose a
novel semantic guided level-category hybrid prediction network (SGLCHPN) that
can jointly perform the level and category prediction in an end-to-end manner.
SGLCHPN comprises two modules: a visual transformer that extracts feature
vectors from the input images, and a semantic guided cross-attention module
that uses categories word embeddings as queries to guide learning
category-specific representations. In order to evaluate the proposed method, we
construct two new datasets in which images are at a broad range of quality and
thus are labeled to different levels (depths) in the hierarchy according to
their individual quality. Experimental results demonstrate the effectiveness of
our proposed HC method."
Unsupervised Cross-Task Generalization via Retrieval Augmentation,0.925157,"Humans can perform unseen tasks by recalling relevant skills acquired
previously and then generalizing them to the target tasks, even if there is no
supervision at all. In this paper, we aim to improve this kind of cross-task
generalization ability of massive multi-task language models, such as T0 and
FLAN, in an unsupervised setting. We propose a retrieval-augmentation method
named ReCross that takes a few unlabelled examples as queries to retrieve a
small subset of upstream data and uses them to update the multi-task model for
better generalization. ReCross is a straightforward yet effective retrieval
method that combines both efficient dense retrieval and effective pair-wise
reranking. Our results and analysis show that it significantly outperforms both
non-retrieval methods and other baseline methods."
Mask Detection and Classification in Thermal Face Images,0.581183,"Face masks are recommended to reduce the transmission of many viruses,
especially SARS-CoV-2. Therefore, the automatic detection of whether there is a
mask on the face, what type of mask is worn, and how it is worn is an important
research topic. In this work, the use of thermal imaging was considered to
analyze the possibility of detecting (localizing) a mask on the face, as well
as to check whether it is possible to classify the type of mask on the face.
The previously proposed dataset of thermal images was extended and annotated
with the description of a type of mask and a location of a mask within a face.
Different deep learning models were adapted. The best model for face mask
detection turned out to be the Yolov5 model in the ""nano"" version, reaching mAP
higher than 97% and precision of about 95%. High accuracy was also obtained for
mask type classification. The best results were obtained for the convolutional
neural network model built on an autoencoder initially trained in the thermal
image reconstruction problem. The pretrained encoder was used to train a
classifier which achieved an accuracy of 91%."
Diagnostic Reasoning Prompts Reveal the Potential for Large Language Model Interpretability in Medicine,0.862896,"One of the major barriers to using large language models (LLMs) in medicine
is the perception they use uninterpretable methods to make clinical decisions
that are inherently different from the cognitive processes of clinicians. In
this manuscript we develop novel diagnostic reasoning prompts to study whether
LLMs can perform clinical reasoning to accurately form a diagnosis. We find
that GPT4 can be prompted to mimic the common clinical reasoning processes of
clinicians without sacrificing diagnostic accuracy. This is significant because
an LLM that can use clinical reasoning to provide an interpretable rationale
offers physicians a means to evaluate whether LLMs can be trusted for patient
care. Novel prompting methods have the potential to expose the black box of
LLMs, bringing them one step closer to safe and effective use in medicine."
Neural Face Identification in a 2D Wireframe Projection of a Manifold Object,0.72608,"In computer-aided design (CAD) systems, 2D line drawings are commonly used to
illustrate 3D object designs. To reconstruct the 3D models depicted by a single
2D line drawing, an important key is finding the edge loops in the line drawing
which correspond to the actual faces of the 3D object. In this paper, we
approach the classical problem of face identification from a novel data-driven
point of view. We cast it as a sequence generation problem: starting from an
arbitrary edge, we adopt a variant of the popular Transformer model to predict
the edges associated with the same face in a natural order. This allows us to
avoid searching the space of all possible edge loops with various hand-crafted
rules and heuristics as most existing methods do, deal with challenging cases
such as curved surfaces and nested edge loops, and leverage additional cues
such as face types. We further discuss how possibly imperfect predictions can
be used for 3D object reconstruction."
Diffeomorphic Counterfactuals with Generative Models,0.510276,"Counterfactuals can explain classification decisions of neural networks in a
human interpretable way. We propose a simple but effective method to generate
such counterfactuals. More specifically, we perform a suitable diffeomorphic
coordinate transformation and then perform gradient ascent in these coordinates
to find counterfactuals which are classified with great confidence as a
specified target class. We propose two methods to leverage generative models to
construct such suitable coordinate systems that are either exactly or
approximately diffeomorphic. We analyze the generation process theoretically
using Riemannian differential geometry and validate the quality of the
generated counterfactuals using various qualitative and quantitative measures."
Detecting Methane Plumes using PRISMA: Deep Learning Model and Data Augmentation,0.764123,"The new generation of hyperspectral imagers, such as PRISMA, has improved
significantly our detection capability of methane (CH4) plumes from space at
high spatial resolution (30m). We present here a complete framework to identify
CH4 plumes using images from the PRISMA satellite mission and a deep learning
model able to detect plumes over large areas. To compensate for the relative
scarcity of PRISMA images, we trained our model by transposing high resolution
plumes from Sentinel-2 to PRISMA. Our methodology thus avoids computationally
expensive synthetic plume generation from Large Eddy Simulations by generating
a broad and realistic training database, and paves the way for large-scale
detection of methane plumes using future hyperspectral sensors (EnMAP, EMIT,
CarbonMapper)."
Entity-driven Fact-aware Abstractive Summarization of Biomedical Literature,0.408179,"As part of the large number of scientific articles being published every
year, the publication rate of biomedical literature has been increasing.
Consequently, there has been considerable effort to harness and summarize the
massive amount of biomedical research articles. While transformer-based
encoder-decoder models in a vanilla source document-to-summary setting have
been extensively studied for abstractive summarization in different domains,
their major limitations continue to be entity hallucination (a phenomenon where
generated summaries constitute entities not related to or present in source
article(s)) and factual inconsistency. This problem is exacerbated in a
biomedical setting where named entities and their semantics (which can be
captured through a knowledge base) constitute the essence of an article. The
use of named entities and facts mined from background knowledge bases
pertaining to the named entities to guide abstractive summarization has not
been studied in biomedical article summarization literature. In this paper, we
propose an entity-driven fact-aware framework for training end-to-end
transformer-based encoder-decoder models for abstractive summarization of
biomedical articles. We call the proposed approach, whose building block is a
transformer-based model, EFAS, Entity-driven Fact-aware Abstractive
Summarization. We conduct experiments using five state-of-the-art
transformer-based models (two of which are specifically designed for long
document summarization) and demonstrate that injecting knowledge into the
training/inference phase of these models enables the models to achieve
significantly better performance than the standard source document-to-summary
setting in terms of entity-level factual accuracy, N-gram novelty, and semantic
equivalence while performing comparably on ROUGE metrics. The proposed approach
is evaluated on ICD-11-Summ-1000, and PubMed-50k."
Bidirectional Generative Framework for Cross-domain Aspect-based Sentiment Analysis,0.702697,"Cross-domain aspect-based sentiment analysis (ABSA) aims to perform various
fine-grained sentiment analysis tasks on a target domain by transferring
knowledge from a source domain. Since labeled data only exists in the source
domain, a model is expected to bridge the domain gap for tackling cross-domain
ABSA. Though domain adaptation methods have proven to be effective, most of
them are based on a discriminative model, which needs to be specifically
designed for different ABSA tasks. To offer a more general solution, we propose
a unified bidirectional generative framework to tackle various cross-domain
ABSA tasks. Specifically, our framework trains a generative model in both
text-to-label and label-to-text directions. The former transforms each task
into a unified format to learn domain-agnostic features, and the latter
generates natural sentences from noisy labels for data augmentation, with which
a more accurate model can be trained. To investigate the effectiveness and
generality of our framework, we conduct extensive experiments on four
cross-domain ABSA tasks and present new state-of-the-art results on all tasks.
Our data and code are publicly available at
\url{https://github.com/DAMO-NLP-SG/BGCA}."
Leveraging Equivariant Features for Absolute Pose Regression,0.382017,"While end-to-end approaches have achieved state-of-the-art performance in
many perception tasks, they are not yet able to compete with 3D geometry-based
methods in pose estimation. Moreover, absolute pose regression has been shown
to be more related to image retrieval. As a result, we hypothesize that the
statistical features learned by classical Convolutional Neural Networks do not
carry enough geometric information to reliably solve this inherently geometric
task. In this paper, we demonstrate how a translation and rotation equivariant
Convolutional Neural Network directly induces representations of camera motions
into the feature space. We then show that this geometric property allows for
implicitly augmenting the training data under a whole group of image
plane-preserving transformations. Therefore, we argue that directly learning
equivariant features is preferable than learning data-intensive intermediate
representations. Comprehensive experimental validation demonstrates that our
lightweight model outperforms existing ones on standard datasets."
Facing Changes: Continual Entity Alignment for Growing Knowledge Graphs,0.427999,"Entity alignment is a basic and vital technique in knowledge graph (KG)
integration. Over the years, research on entity alignment has resided on the
assumption that KGs are static, which neglects the nature of growth of
real-world KGs. As KGs grow, previous alignment results face the need to be
revisited while new entity alignment waits to be discovered. In this paper, we
propose and dive into a realistic yet unexplored setting, referred to as
continual entity alignment. To avoid retraining an entire model on the whole
KGs whenever new entities and triples come, we present a continual alignment
method for this task. It reconstructs an entity's representation based on
entity adjacency, enabling it to generate embeddings for new entities quickly
and inductively using their existing neighbors. It selects and replays partial
pre-aligned entity pairs to train only parts of KGs while extracting
trustworthy alignment for knowledge augmentation. As growing KGs inevitably
contain non-matchable entities, different from previous works, the proposed
method employs bidirectional nearest neighbor matching to find new entity
alignment and update old alignment. Furthermore, we also construct new datasets
by simulating the growth of multilingual DBpedia. Extensive experiments
demonstrate that our continual alignment method is more effective than
baselines based on retraining or inductive learning."
GPTFUZZER: Red Teaming Large Language Models with Auto-Generated Jailbreak Prompts,0.984922,"Large language models (LLMs) have recently experienced tremendous popularity
and are widely used from casual conversations to AI-driven programming.
However, despite their considerable success, LLMs are not entirely reliable and
can give detailed guidance on how to conduct harmful or illegal activities.
While safety measures can reduce the risk of such outputs, adversarial
jailbreak attacks can still exploit LLMs to produce harmful content. These
jailbreak templates are typically manually crafted, making large-scale testing
challenging.
  In this paper, we introduce GPTFuzz, a novel black-box jailbreak fuzzing
framework inspired by the AFL fuzzing framework. Instead of manual engineering,
GPTFuzz automates the generation of jailbreak templates for red-teaming LLMs.
At its core, GPTFuzz starts with human-written templates as initial seeds, then
mutates them to produce new templates. We detail three key components of
GPTFuzz: a seed selection strategy for balancing efficiency and variability,
mutate operators for creating semantically equivalent or similar sentences, and
a judgment model to assess the success of a jailbreak attack.
  We evaluate GPTFuzz against various commercial and open-source LLMs,
including ChatGPT, LLaMa-2, and Vicuna, under diverse attack scenarios. Our
results indicate that GPTFuzz consistently produces jailbreak templates with a
high success rate, surpassing human-crafted templates. Remarkably, GPTFuzz
achieves over 90% attack success rates against ChatGPT and Llama-2 models, even
with suboptimal initial seed templates. We anticipate that GPTFuzz will be
instrumental for researchers and practitioners in examining LLM robustness and
will encourage further exploration into enhancing LLM safety."
Unsupervised Video Object Segmentation via Prototype Memory Network,0.469987,"Unsupervised video object segmentation aims to segment a target object in the
video without a ground truth mask in the initial frame. This challenging task
requires extracting features for the most salient common objects within a video
sequence. This difficulty can be solved by using motion information such as
optical flow, but using only the information between adjacent frames results in
poor connectivity between distant frames and poor performance. To solve this
problem, we propose a novel prototype memory network architecture. The proposed
model effectively extracts the RGB and motion information by extracting
superpixel-based component prototypes from the input RGB images and optical
flow maps. In addition, the model scores the usefulness of the component
prototypes in each frame based on a self-learning algorithm and adaptively
stores the most useful prototypes in memory and discards obsolete prototypes.
We use the prototypes in the memory bank to predict the next query frames mask,
which enhances the association between distant frames to help with accurate
mask prediction. Our method is evaluated on three datasets, achieving
state-of-the-art performance. We prove the effectiveness of the proposed model
with various ablation studies."
USA: Universal Sentiment Analysis Model & Construction of Japanese Sentiment Text Classification and Part of Speech Dataset,0.134066,"Sentiment analysis is a pivotal task in the domain of natural language
processing. It encompasses both text-level sentiment polarity classification
and word-level Part of Speech(POS) sentiment polarity determination. Such
analysis challenges models to understand text holistically while also
extracting nuanced information. With the rise of Large Language Models(LLMs),
new avenues for sentiment analysis have opened. This paper proposes enhancing
performance by leveraging the Mutual Reinforcement Effect(MRE) between
individual words and the overall text. It delves into how word polarity
influences the overarching sentiment of a passage. To support our research, we
annotated four novel Sentiment Text Classification and Part of Speech(SCPOS)
datasets, building upon existing sentiment classification datasets.
Furthermore, we developed a Universal Sentiment Analysis(USA) model, with a
7-billion parameter size. Experimental results revealed that our model
surpassed the performance of gpt-3.5-turbo across all four datasets,
underscoring the significance of MRE in sentiment analysis."
Using Paraphrases to Study Properties of Contextual Embeddings,0.154894,"We use paraphrases as a unique source of data to analyze contextualized
embeddings, with a particular focus on BERT. Because paraphrases naturally
encode consistent word and phrase semantics, they provide a unique lens for
investigating properties of embeddings. Using the Paraphrase Database's
alignments, we study words within paraphrases as well as phrase
representations. We find that contextual embeddings effectively handle
polysemous words, but give synonyms surprisingly different representations in
many cases. We confirm previous findings that BERT is sensitive to word order,
but find slightly different patterns than prior work in terms of the level of
contextualization across BERT's layers."
NeurMiPs: Neural Mixture of Planar Experts for View Synthesis,0.301974,"We present Neural Mixtures of Planar Experts (NeurMiPs), a novel planar-based
scene representation for modeling geometry and appearance. NeurMiPs leverages a
collection of local planar experts in 3D space as the scene representation.
Each planar expert consists of the parameters of the local rectangular shape
representing geometry and a neural radiance field modeling the color and
opacity. We render novel views by calculating ray-plane intersections and
composite output colors and densities at intersected points to the image.
NeurMiPs blends the efficiency of explicit mesh rendering and flexibility of
the neural radiance field. Experiments demonstrate superior performance and
speed of our proposed method, compared to other 3D representations in novel
view synthesis."
Predicting Spine Geometry and Scoliosis from DXA Scans,0.551582,"Our objective in this paper is to estimate spine curvature in DXA scans. To
this end we first train a neural network to predict the middle spine curve in
the scan, and then use an integral-based method to determine the curvature
along the spine curve. We use the curvature to compare to the standard angle
scoliosis measure obtained using the DXA Scoliosis Method (DSM). The
performance improves over the prior work of Jamaludin et al. 2018. We show that
the maximum curvature can be used as a scoring function for ordering the
severity of spinal deformation."
Medical Dataset Classification for Kurdish Short Text over Social Media,0.0932752,"The Facebook application is used as a resource for collecting the comments of
this dataset, The dataset consists of 6756 comments to create a Medical Kurdish
Dataset (MKD). The samples are comments of users, which are gathered from
different posts of pages (Medical, News, Economy, Education, and Sport). Six
steps as a preprocessing technique are performed on the raw dataset to clean
and remove noise in the comments by replacing characters. The comments (short
text) are labeled for positive class (medical comment) and negative class
(non-medical comment) as text classification. The percentage ratio of the
negative class is 55% while the positive class is 45%."
Assessing the Effects of Hyperparameters on Knowledge Graph Embedding Quality,0.107027,"Embedding knowledge graphs into low-dimensional spaces is a popular method
for applying approaches, such as link prediction or node classification, to
these databases. This embedding process is very costly in terms of both
computational time and space. Part of the reason for this is the optimisation
of hyperparameters, which involves repeatedly sampling, by random, guided, or
brute-force selection, from a large hyperparameter space and testing the
resulting embeddings for their quality. However, not all hyperparameters in
this search space will be equally important. In fact, with prior knowledge of
the relative importance of the hyperparameters, some could be eliminated from
the search altogether without significantly impacting the overall quality of
the outputted embeddings. To this end, we ran a Sobol sensitivity analysis to
evaluate the effects of tuning different hyperparameters on the variance of
embedding quality. This was achieved by performing thousands of embedding
trials, each time measuring the quality of embeddings produced by different
hyperparameter configurations. We regressed the embedding quality on those
hyperparameter configurations, using this model to generate Sobol sensitivity
indices for each of the hyperparameters. By evaluating the correlation between
Sobol indices, we find substantial variability in the hyperparameter
sensitivities between knowledge graphs, with differing dataset characteristics
being the probable cause of these inconsistencies. As an additional
contribution of this work we identify several relations in the UMLS knowledge
graph that may cause data leakage via inverse relations, and derive and present
UMLS-43, a leakage-robust variant of that graph."
Glass Segmentation with RGB-Thermal Image Pairs,0.34831,"This paper proposes a new glass segmentation method utilizing paired RGB and
thermal images. Due to the large difference between the transmission property
of visible light and that of the thermal energy through the glass where most
glass is transparent to the visible light but opaque to thermal energy, glass
regions of a scene are made more distinguishable with a pair of RGB and thermal
images than solely with an RGB image. To exploit such a unique property, we
propose a neural network architecture that effectively combines an RGB-thermal
image pair with a new multi-modal fusion module based on attention, and
integrate CNN and transformer to extract local features and non-local
dependencies, respectively. As well, we have collected a new dataset containing
5551 RGB-thermal image pairs with ground-truth segmentation annotations. The
qualitative and quantitative evaluations demonstrate the effectiveness of the
proposed approach on fusing RGB and thermal data for glass segmentation. Our
code and data are available at
https://github.com/Dong-Huo/RGB-T-Glass-Segmentation."
Surgical Fine-Tuning Improves Adaptation to Distribution Shifts,0.906729,"A common approach to transfer learning under distribution shift is to
fine-tune the last few layers of a pre-trained model, preserving learned
features while also adapting to the new task. This paper shows that in such
settings, selectively fine-tuning a subset of layers (which we term surgical
fine-tuning) matches or outperforms commonly used fine-tuning approaches.
Moreover, the type of distribution shift influences which subset is more
effective to tune: for example, for image corruptions, fine-tuning only the
first few layers works best. We validate our findings systematically across
seven real-world data tasks spanning three types of distribution shifts.
Theoretically, we prove that for two-layer neural networks in an idealized
setting, first-layer tuning can outperform fine-tuning all layers. Intuitively,
fine-tuning more parameters on a small target dataset can cause information
learned during pre-training to be forgotten, and the relevant information
depends on the type of shift."
Enhancing Cross-lingual Transfer via Phonemic Transcription Integration,0.49446,"Previous cross-lingual transfer methods are restricted to orthographic
representation learning via textual scripts. This limitation hampers
cross-lingual transfer and is biased towards languages sharing similar
well-known scripts. To alleviate the gap between languages from different
writing scripts, we propose PhoneXL, a framework incorporating phonemic
transcriptions as an additional linguistic modality beyond the traditional
orthographic transcriptions for cross-lingual transfer. Particularly, we
propose unsupervised alignment objectives to capture (1) local one-to-one
alignment between the two different modalities, (2) alignment via
multi-modality contexts to leverage information from additional modalities, and
(3) alignment via multilingual contexts where additional bilingual dictionaries
are incorporated. We also release the first phonemic-orthographic alignment
dataset on two token-level tasks (Named Entity Recognition and Part-of-Speech
Tagging) among the understudied but interconnected
Chinese-Japanese-Korean-Vietnamese (CJKV) languages. Our pilot study reveals
phonemic transcription provides essential information beyond the orthography to
enhance cross-lingual transfer and bridge the gap among CJKV languages, leading
to consistent improvements on cross-lingual token-level tasks over
orthographic-based multilingual PLMs."
Knowledge Base Question Answering by Case-based Reasoning over Subgraphs,0.87951,"Question answering (QA) over knowledge bases (KBs) is challenging because of
the diverse, essentially unbounded, types of reasoning patterns needed.
However, we hypothesize in a large KB, reasoning patterns required to answer a
query type reoccur for various entities in their respective subgraph
neighborhoods. Leveraging this structural similarity between local
neighborhoods of different subgraphs, we introduce a semiparametric model
(CBR-SUBG) with (i) a nonparametric component that for each query, dynamically
retrieves other similar $k$-nearest neighbor (KNN) training queries along with
query-specific subgraphs and (ii) a parametric component that is trained to
identify the (latent) reasoning patterns from the subgraphs of KNN queries and
then apply them to the subgraph of the target query. We also propose an
adaptive subgraph collection strategy to select a query-specific compact
subgraph, allowing us to scale to full Freebase KB containing billions of
facts. We show that CBR-SUBG can answer queries requiring subgraph reasoning
patterns and performs competitively with the best models on several KBQA
benchmarks. Our subgraph collection strategy also produces more compact
subgraphs (e.g. 55\% reduction in size for WebQSP while increasing answer
recall by 4.85\%)\footnote{Code, model, and subgraphs are available at
\url{https://github.com/rajarshd/CBR-SUBG}}."
PIZZA: A Powerful Image-only Zero-Shot Zero-CAD Approach to 6 DoF Tracking,0.190899,"Estimating the relative pose of a new object without prior knowledge is a
hard problem, while it is an ability very much needed in robotics and Augmented
Reality. We present a method for tracking the 6D motion of objects in RGB video
sequences when neither the training images nor the 3D geometry of the objects
are available. In contrast to previous works, our method can therefore consider
unknown objects in open world instantly, without requiring any prior
information or a specific training phase. We consider two architectures, one
based on two frames, and the other relying on a Transformer Encoder, which can
exploit an arbitrary number of past frames. We train our architectures using
only synthetic renderings with domain randomization. Our results on challenging
datasets are on par with previous works that require much more information
(training images of the target objects, 3D models, and/or depth data). Our
source code is available at https://github.com/nv-nguyen/pizza"
Inverse scaling can become U-shaped,0.796758,"Scaling up language models has been empirically shown to improve performance
on a wide range of downstream tasks. However, if we were to observe worse
performance as a function of scale (""inverse scaling"") on certain tasks, this
would indicate that scaling can also encourage behaviors that are misaligned
with human preferences. The Inverse Scaling Prize (McKenzie et al. 2022)
identified eleven such inverse scaling tasks, evaluated on models of up to 280B
parameters and up to 500 zettaFLOPs of training compute. This paper takes a
closer look at these inverse scaling tasks. We evaluate models of up to 540B
parameters, trained on five times more compute than those evaluated in the
Inverse Scaling Prize. With this increased range of model sizes and training
compute, only four out of the eleven tasks remain inverse scaling. Six out of
the eleven tasks exhibit ""U-shaped scaling"", where performance decreases up to
a certain size, and then increases again up to the largest model evaluated (the
one remaining task displays positive scaling). In addition, we find that 1-shot
examples and chain-of-thought can help mitigate undesirable scaling patterns
even further. U-shaped scaling suggests that the inverse scaling trend observed
in McKenzie et al. (2022) may not continue to hold for larger models, which we
attribute to the presence of distractor tasks that only sufficiently large
models can avoid."
CorrI2P: Deep Image-to-Point Cloud Registration via Dense Correspondence,0.999313,"Motivated by the intuition that the critical step of localizing a 2D image in
the corresponding 3D point cloud is establishing 2D-3D correspondence between
them, we propose the first feature-based dense correspondence framework for
addressing the image-to-point cloud registration problem, dubbed CorrI2P, which
consists of three modules, i.e., feature embedding, symmetric overlapping
region detection, and pose estimation through the established correspondence.
Specifically, given a pair of a 2D image and a 3D point cloud, we first
transform them into high-dimensional feature space and feed the resulting
features into a symmetric overlapping region detector to determine the region
where the image and point cloud overlap each other. Then we use the features of
the overlapping regions to establish the 2D-3D correspondence before running
EPnP within RANSAC to estimate the camera's pose. Experimental results on KITTI
and NuScenes datasets show that our CorrI2P outperforms state-of-the-art
image-to-point cloud registration methods significantly. We will make the code
publicly available."
WiCV 2022: The Tenth Women In Computer Vision Workshop,0.632121,"In this paper, we present the details of Women in Computer Vision Workshop -
WiCV 2022, organized alongside the hybrid CVPR 2022 in New Orleans, Louisiana.
It provides a voice to a minority (female) group in the computer vision
community and focuses on increasing the visibility of these researchers, both
in academia and industry. WiCV believes that such an event can play an
important role in lowering the gender imbalance in the field of computer
vision. WiCV is organized each year where it provides a) opportunity for
collaboration between researchers from minority groups, b) mentorship to female
junior researchers, c) financial support to presenters to overcome monetary
burden and d) large and diverse choice of role models, who can serve as
examples to younger researchers at the beginning of their careers. In this
paper, we present a report on the workshop program, trends over the past years,
a summary of statistics regarding presenters, attendees, and sponsorship for
the WiCV 2022 workshop."
Help Me Explore: Minimal Social Interventions for Graph-Based Autotelic Agents,0.572333,"In the quest for autonomous agents learning open-ended repertoires of skills,
most works take a Piagetian perspective: learning trajectories are the results
of interactions between developmental agents and their physical environment.
The Vygotskian perspective, on the other hand, emphasizes the centrality of the
socio-cultural environment: higher cognitive functions emerge from
transmissions of socio-cultural processes internalized by the agent. This paper
argues that both perspectives could be coupled within the learning of autotelic
agents to foster their skill acquisition. To this end, we make two
contributions: 1) a novel social interaction protocol called Help Me Explore
(HME), where autotelic agents can benefit from both individual and socially
guided exploration. In social episodes, a social partner suggests goals at the
frontier of the learning agent knowledge. In autotelic episodes, agents can
either learn to master their own discovered goals or autonomously rehearse
failed social goals; 2) GANGSTR, a graph-based autotelic agent for manipulation
domains capable of decomposing goals into sequences of intermediate sub-goals.
We show that when learning within HME, GANGSTR overcomes its individual
learning limits by mastering the most complex configurations (e.g. stacks of 5
blocks) with only few social interventions."
A Boosted Model Ensembling Approach to Ball Action Spotting in Videos: The Runner-Up Solution to CVPR'23 SoccerNet Challenge,0.761796,"This technical report presents our solution to Ball Action Spotting in
videos. Our method reached second place in the CVPR'23 SoccerNet Challenge.
Details of this challenge can be found at
https://www.soccer-net.org/tasks/ball-action-spotting. Our approach is
developed based on a baseline model termed E2E-Spot, which was provided by the
organizer of this competition. We first generated several variants of the
E2E-Spot model, resulting in a candidate model set. We then proposed a strategy
for selecting appropriate model members from this set and assigning an
appropriate weight to each model. The aim of this strategy is to boost the
performance of the resulting model ensemble. Therefore, we call our approach
Boosted Model Ensembling (BME). Our code is available at
https://github.com/ZJLAB-AMMI/E2E-Spot-MBS."
Semi-supervised Semantic Segmentation with Mutual Knowledge Distillation,0.322371,"Consistency regularization has been widely studied in recent semisupervised
semantic segmentation methods, and promising performance has been achieved. In
this work, we propose a new consistency regularization framework, termed mutual
knowledge distillation (MKD), combined with data and feature augmentation. We
introduce two auxiliary mean-teacher models based on consistency
regularization. More specifically, we use the pseudo-labels generated by a mean
teacher to supervise the student network to achieve a mutual knowledge
distillation between the two branches. In addition to using image-level strong
and weak augmentation, we also discuss feature augmentation. This involves
considering various sources of knowledge to distill the student network. Thus,
we can significantly increase the diversity of the training samples.
Experiments on public benchmarks show that our framework outperforms previous
state-of-the-art (SOTA) methods under various semi-supervised settings. Code is
available at semi-mmseg."
AutoHall: Automated Hallucination Dataset Generation for Large Language Models,0.0617634,"While Large language models (LLMs) have garnered widespread applications
across various domains due to their powerful language understanding and
generation capabilities, the detection of non-factual or hallucinatory content
generated by LLMs remains scarce. Currently, one significant challenge in
hallucination detection is the laborious task of time-consuming and expensive
manual annotation of the hallucinatory generation. To address this issue, this
paper first introduces a method for automatically constructing model-specific
hallucination datasets based on existing fact-checking datasets called
AutoHall. Furthermore, we propose a zero-resource and black-box hallucination
detection method based on self-contradiction. We conduct experiments towards
prevalent open-/closed-source LLMs, achieving superior hallucination detection
performance compared to extant baselines. Moreover, our experiments reveal
variations in hallucination proportions and types among different models."
The four-fifths rule is not disparate impact: a woeful tale of epistemic trespassing in algorithmic fairness,0.732937,"Computer scientists are trained to create abstractions that simplify and
generalize. However, a premature abstraction that omits crucial contextual
details creates the risk of epistemic trespassing, by falsely asserting its
relevance into other contexts. We study how the field of responsible AI has
created an imperfect synecdoche by abstracting the four-fifths rule (a.k.a. the
4/5 rule or 80% rule), a single part of disparate impact discrimination law,
into the disparate impact metric. This metric incorrectly introduces a new
deontic nuance and new potentials for ethical harms that were absent in the
original 4/5 rule. We also survey how the field has amplified the potential for
harm in codifying the 4/5 rule into popular AI fairness software toolkits. The
harmful erasure of legal nuances is a wake-up call for computer scientists to
self-critically re-evaluate the abstractions they create and use, particularly
in the interdisciplinary field of AI ethics."
Online Auction-Based Incentive Mechanism Design for Horizontal Federated Learning with Budget Constraint,0.255587,"Federated learning makes it possible for all parties with data isolation to
train the model collaboratively and efficiently while satisfying privacy
protection. To obtain a high-quality model, an incentive mechanism is necessary
to motivate more high-quality workers with data and computing power. The
existing incentive mechanisms are applied in offline scenarios, where the task
publisher collects all bids and selects workers before the task. However, it is
practical that different workers arrive online in different orders before or
during the task. Therefore, we propose a reverse auction-based online incentive
mechanism for horizontal federated learning with budget constraint. Workers
submit bids when they arrive online. The task publisher with a limited budget
leverages the information of the arrived workers to decide on whether to select
the new worker. Theoretical analysis proves that our mechanism satisfies budget
feasibility, computational efficiency, individual rationality, consumer
sovereignty, time truthfulness, and cost truthfulness with a sufficient budget.
The experimental results show that our online mechanism is efficient and can
obtain high-quality models."
Container Localisation and Mass Estimation with an RGB-D Camera,0.404713,"In the research area of human-robot interactions, the automatic estimation of
the mass of a container manipulated by a person leveraging only visual
information is a challenging task. The main challenges consist of occlusions,
different filling materials and lighting conditions. The mass of an object
constitutes key information for the robot to correctly regulate the force
required to grasp the container. We propose a single RGB-D camera-based method
to locate a manipulated container and estimate its empty mass i.e.,
independently of the presence of the content. The method first automatically
selects a number of candidate containers based on the distance with the fixed
frontal view, then averages the mass predictions of a lightweight model to
provide the final estimation. Results on the CORSMAL Containers Manipulation
dataset show that the proposed method estimates empty container mass obtaining
a score of 71.08% under different lighting or filling conditions."
Distribution-Aligned Diffusion for Human Mesh Recovery,0.696941,"Recovering a 3D human mesh from a single RGB image is a challenging task due
to depth ambiguity and self-occlusion, resulting in a high degree of
uncertainty. Meanwhile, diffusion models have recently seen much success in
generating high-quality outputs by progressively denoising noisy inputs.
Inspired by their capability, we explore a diffusion-based approach for human
mesh recovery, and propose a Human Mesh Diffusion (HMDiff) framework which
frames mesh recovery as a reverse diffusion process. We also propose a
Distribution Alignment Technique (DAT) that infuses prior distribution
information into the mesh distribution diffusion process, and provides useful
prior knowledge to facilitate the mesh recovery task. Our method achieves
state-of-the-art performance on three widely used datasets. Project page:
https://gongjia0208.github.io/HMDiff/."
Multimodal Token Fusion for Vision Transformers,0.998234,"Many adaptations of transformers have emerged to address the single-modal
vision tasks, where self-attention modules are stacked to handle input sources
like images. Intuitively, feeding multiple modalities of data to vision
transformers could improve the performance, yet the inner-modal attentive
weights may also be diluted, which could thus undermine the final performance.
In this paper, we propose a multimodal token fusion method (TokenFusion),
tailored for transformer-based vision tasks. To effectively fuse multiple
modalities, TokenFusion dynamically detects uninformative tokens and
substitutes these tokens with projected and aggregated inter-modal features.
Residual positional alignment is also adopted to enable explicit utilization of
the inter-modal alignments after fusion. The design of TokenFusion allows the
transformer to learn correlations among multimodal features, while the
single-modal transformer architecture remains largely intact. Extensive
experiments are conducted on a variety of homogeneous and heterogeneous
modalities and demonstrate that TokenFusion surpasses state-of-the-art methods
in three typical vision tasks: multimodal image-to-image translation, RGB-depth
semantic segmentation, and 3D object detection with point cloud and images. Our
code is available at https://github.com/yikaiw/TokenFusion."
Fast-DetectGPT: Efficient Zero-Shot Detection of Machine-Generated Text via Conditional Probability Curvature,0.824431,"Large language models (LLMs) have shown the ability to produce fluent and
cogent content, presenting both productivity opportunities and societal risks.
To build trustworthy AI systems, it is imperative to distinguish between
machine-generated and human-authored content. The leading zero-shot detector,
DetectGPT, showcases commendable performance but is marred by its intensive
computational costs. In this paper, we introduce the concept of conditional
probability curvature to elucidate discrepancies in word choices between LLMs
and humans within a given context. Utilizing this curvature as a foundational
metric, we present **Fast-DetectGPT**, an optimized zero-shot detector, which
substitutes DetectGPT's perturbation step with a more efficient sampling step.
Our evaluations on various datasets, source models, and test conditions
indicate that Fast-DetectGPT not only surpasses DetectGPT by a relative around
75% in both the white-box and black-box settings but also accelerates the
detection process by a factor of 340, as detailed in Table 1. See
\url{https://github.com/baoguangsheng/fast-detect-gpt} for code, data, and
results."
Data Augmentation using Transformers and Similarity Measures for Improving Arabic Text Classification,0.124493,"The performance of learning models heavily relies on the availability and
adequacy of training data. To address the dataset adequacy issue, researchers
have extensively explored data augmentation (DA) as a promising approach. DA
generates new data instances through transformations applied to the available
data, thereby increasing dataset size and variability. This approach has
enhanced model performance and accuracy, particularly in addressing class
imbalance problems in classification tasks. However, few studies have explored
DA for the Arabic language, relying on traditional approaches such as
paraphrasing or noising-based techniques. In this paper, we propose a new
Arabic DA method that employs the recent powerful modeling technique, namely
the AraGPT-2, for the augmentation process. The generated sentences are
evaluated in terms of context, semantics, diversity, and novelty using the
Euclidean, cosine, Jaccard, and BLEU distances. Finally, the AraBERT
transformer is used on sentiment classification tasks to evaluate the
classification performance of the augmented Arabic dataset. The experiments
were conducted on four sentiment Arabic datasets: AraSarcasm, ASTD, ATT, and
MOVIE. The selected datasets vary in size, label number, and unbalanced
classes. The results show that the proposed methodology enhanced the Arabic
sentiment text classification on all datasets with an increase in F1 score by
4% in AraSarcasm, 6% in ASTD, 9% in ATT, and 13% in MOVIE."
Descartes: Generating Short Descriptions of Wikipedia Articles,0.0304576,"Wikipedia is one of the richest knowledge sources on the Web today. In order
to facilitate navigating, searching, and maintaining its content, Wikipedia's
guidelines state that all articles should be annotated with a so-called short
description indicating the article's topic (e.g., the short description of beer
is ""Alcoholic drink made from fermented cereal grains""). Nonetheless, a large
fraction of articles (ranging from 10.2% in Dutch to 99.7% in Kazakh) have no
short description yet, with detrimental effects for millions of Wikipedia
users. Motivated by this problem, we introduce the novel task of automatically
generating short descriptions for Wikipedia articles and propose Descartes, a
multilingual model for tackling it. Descartes integrates three sources of
information to generate an article description in a target language: the text
of the article in all its language versions, the already-existing descriptions
(if any) of the article in other languages, and semantic type information
obtained from a knowledge graph. We evaluate a Descartes model trained for
handling 25 languages simultaneously, showing that it beats baselines
(including a strong translation-based baseline) and performs on par with
monolingual models tailored for specific languages. A human evaluation on three
languages further shows that the quality of Descartes's descriptions is largely
indistinguishable from that of human-written descriptions; e.g., 91.3% of our
English descriptions (vs. 92.1% of human-written descriptions) pass the bar for
inclusion in Wikipedia, suggesting that Descartes is ready for production, with
the potential to support human editors in filling a major gap in today's
Wikipedia across languages."
An End-to-End OCR Framework for Robust Arabic-Handwriting Recognition using a Novel Transformers-based Model and an Innovative 270 Million-Words Multi-Font Corpus of Classical Arabic with Diacritics,0.556323,"This research is the second phase in a series of investigations on developing
an Optical Character Recognition (OCR) of Arabic historical documents and
examining how different modeling procedures interact with the problem. The
first research studied the effect of Transformers on our custom-built Arabic
dataset. One of the downsides of the first research was the size of the
training data, a mere 15000 images from our 30 million images, due to lack of
resources. Also, we add an image enhancement layer, time and space
optimization, and Post-Correction layer to aid the model in predicting the
correct word for the correct context. Notably, we propose an end-to-end text
recognition approach using Vision Transformers as an encoder, namely BEIT, and
vanilla Transformer as a decoder, eliminating CNNs for feature extraction and
reducing the model's complexity. The experiments show that our end-to-end model
outperforms Convolutions Backbones. The model attained a CER of 4.46%."
Multi-Granularity Prompts for Topic Shift Detection in Dialogue,0.637737,"The goal of dialogue topic shift detection is to identify whether the current
topic in a conversation has changed or needs to change. Previous work focused
on detecting topic shifts using pre-trained models to encode the utterance,
failing to delve into the various levels of topic granularity in the dialogue
and understand dialogue contents. To address the above issues, we take a
prompt-based approach to fully extract topic information from dialogues at
multiple-granularity, i.e., label, turn, and topic. Experimental results on our
annotated Chinese Natural Topic Dialogue dataset CNTD and the publicly
available English TIAGE dataset show that the proposed model outperforms the
baselines. Further experiments show that the information extracted at different
levels of granularity effectively helps the model comprehend the conversation
topics."
Distance Matters in Human-Object Interaction Detection,0.53429,"Human-Object Interaction (HOI) detection has received considerable attention
in the context of scene understanding. Despite the growing progress on
benchmarks, we realize that existing methods often perform unsatisfactorily on
distant interactions, where the leading causes are two-fold: 1) Distant
interactions are by nature more difficult to recognize than close ones. A
natural scene often involves multiple humans and objects with intricate spatial
relations, making the interaction recognition for distant human-object largely
affected by complex visual context. 2) Insufficient number of distant
interactions in benchmark datasets results in under-fitting on these instances.
To address these problems, in this paper, we propose a novel two-stage method
for better handling distant interactions in HOI detection. One essential
component in our method is a novel Far Near Distance Attention module. It
enables information propagation between humans and objects, whereby the spatial
distance is skillfully taken into consideration. Besides, we devise a novel
Distance-Aware loss function which leads the model to focus more on distant yet
rare interactions. We conduct extensive experiments on two challenging datasets
- HICO-DET and V-COCO. The results demonstrate that the proposed method can
surpass existing approaches by a large margin, resulting in new
state-of-the-art performance."
Towards CausalGPT: A Multi-Agent Approach for Faithful Knowledge Reasoning via Promoting Causal Consistency in LLMs,0.40485,"Despite advancements in LLMs, knowledge-based reasoning remains a
longstanding issue due to the fragility of knowledge recall and inference.
Existing methods primarily encourage LLMs to autonomously plan and solve
problems or to extensively sample reasoning chains without addressing the
conceptual and inferential fallacies. Attempting to alleviate inferential
fallacies and drawing inspiration from multi-agent collaboration, we present a
framework to increase faithfulness and causality for knowledge-based reasoning.
Specifically, we propose to employ multiple intelligent agents (i.e., reasoners
and an evaluator) to work collaboratively in a reasoning-and-consensus paradigm
for elevated reasoning faithfulness. The reasoners focus on providing solutions
with human-like causality to solve open-domain problems. On the other hand, the
\textit{evaluator} agent scrutinizes if a solution is deducible from a
non-causal perspective and if it still holds when challenged by a
counterfactual candidate. According to the extensive and comprehensive
evaluations on a variety of knowledge reasoning tasks (e.g., science question
answering and commonsense reasoning), our framework outperforms all compared
state-of-the-art approaches by large margins."
k-MS: A novel clustering algorithm based on morphological reconstruction,0.154115,"This work proposes a clusterization algorithm called k-Morphological Sets
(k-MS), based on morphological reconstruction and heuristics. k-MS is faster
than the CPU-parallel k-Means in worst case scenarios and produces enhanced
visualizations of the dataset as well as very distinct clusterizations. It is
also faster than similar clusterization methods that are sensitive to density
and shapes such as Mitosis and TRICLUST. In addition, k-MS is deterministic and
has an intrinsic sense of maximal clusters that can be created for a given
input sample and input parameters, differing from k-Means and other
clusterization algorithms. In other words, given a constant k, a structuring
element and a dataset, k-MS produces k or less clusters without using random/
pseudo-random functions. Finally, the proposed algorithm also provides a
straightforward means for removing noise from images or datasets in general."
Randomized Smoothing with Masked Inference for Adversarially Robust Text Classifications,0.789293,"Large-scale pre-trained language models have shown outstanding performance in
a variety of NLP tasks. However, they are also known to be significantly
brittle against specifically crafted adversarial examples, leading to
increasing interest in probing the adversarial robustness of NLP systems. We
introduce RSMI, a novel two-stage framework that combines randomized smoothing
(RS) with masked inference (MI) to improve the adversarial robustness of NLP
systems. RS transforms a classifier into a smoothed classifier to obtain robust
representations, whereas MI forces a model to exploit the surrounding context
of a masked token in an input sequence. RSMI improves adversarial robustness by
2 to 3 times over existing state-of-the-art methods on benchmark datasets. We
also perform in-depth qualitative analysis to validate the effectiveness of the
different stages of RSMI and probe the impact of its components through
extensive ablations. By empirically proving the stability of RSMI, we put it
forward as a practical method to robustly train large-scale NLP models. Our
code and datasets are available at https://github.com/Han8931/rsmi_nlp"
Questioning the Validity of Summarization Datasets and Improving Their Factual Consistency,0.439587,"The topic of summarization evaluation has recently attracted a surge of
attention due to the rapid development of abstractive summarization systems.
However, the formulation of the task is rather ambiguous, neither the
linguistic nor the natural language processing community has succeeded in
giving a mutually agreed-upon definition. Due to this lack of well-defined
formulation, a large number of popular abstractive summarization datasets are
constructed in a manner that neither guarantees validity nor meets one of the
most essential criteria of summarization: factual consistency. In this paper,
we address this issue by combining state-of-the-art factual consistency models
to identify the problematic instances present in popular summarization
datasets. We release SummFC, a filtered summarization dataset with improved
factual consistency, and demonstrate that models trained on this dataset
achieve improved performance in nearly all quality aspects. We argue that our
dataset should become a valid benchmark for developing and evaluating
summarization systems."
Pedestrian Behavior Maps for Safety Advisories: CHAMP Framework and Real-World Data Analysis,0.385562,"It is critical for vehicles to prevent any collisions with pedestrians.
Current methods for pedestrian collision prevention focus on integrating visual
pedestrian detectors with Automatic Emergency Braking (AEB) systems which can
trigger warnings and apply brakes as a pedestrian enters a vehicle's path.
Unfortunately, pedestrian-detection-based systems can be hindered in certain
situations such as night-time or when pedestrians are occluded. Our system
addresses such issues using an online, map-based pedestrian detection
aggregation system where common pedestrian locations are learned after repeated
passes of locations. Using a carefully collected and annotated dataset in La
Jolla, CA, we demonstrate the system's ability to learn pedestrian zones and
generate advisory notices when a vehicle is approaching a pedestrian despite
challenges like dark lighting or pedestrian occlusion. Using the number of
correct advisories, false advisories, and missed advisories to define precision
and recall performance metrics, we evaluate our system and discuss future
positive effects with further data collection. We have made our code available
at https://github.com/s7desai/ped-mapping, and a video demonstration of the
CHAMP system at https://youtu.be/dxeCrS_Gpkw."
Prototypical VoteNet for Few-Shot 3D Point Cloud Object Detection,0.351018,"Most existing 3D point cloud object detection approaches heavily rely on
large amounts of labeled training data. However, the labeling process is costly
and time-consuming. This paper considers few-shot 3D point cloud object
detection, where only a few annotated samples of novel classes are needed with
abundant samples of base classes. To this end, we propose Prototypical VoteNet
to recognize and localize novel instances, which incorporates two new modules:
Prototypical Vote Module (PVM) and Prototypical Head Module (PHM).
Specifically, as the 3D basic geometric structures can be shared among
categories, PVM is designed to leverage class-agnostic geometric prototypes,
which are learned from base classes, to refine local features of novel
categories.Then PHM is proposed to utilize class prototypes to enhance the
global feature of each object, facilitating subsequent object localization and
classification, which is trained by the episodic training strategy. To evaluate
the model in this new setting, we contribute two new benchmark datasets,
FS-ScanNet and FS-SUNRGBD. We conduct extensive experiments to demonstrate the
effectiveness of Prototypical VoteNet, and our proposed method shows
significant and consistent improvements compared to baselines on two benchmark
datasets."
Graph Neural Networks for Multimodal Single-Cell Data Integration,0.889528,"Recent advances in multimodal single-cell technologies have enabled
simultaneous acquisitions of multiple omics data from the same cell, providing
deeper insights into cellular states and dynamics. However, it is challenging
to learn the joint representations from the multimodal data, model the
relationship between modalities, and, more importantly, incorporate the vast
amount of single-modality datasets into the downstream analyses. To address
these challenges and correspondingly facilitate multimodal single-cell data
analyses, three key tasks have been introduced: $\textit{modality prediction}$,
$\textit{modality matching}$ and $\textit{joint embedding}$. In this work, we
present a general Graph Neural Network framework $\textit{scMoGNN}$ to tackle
these three tasks and show that $\textit{scMoGNN}$ demonstrates superior
results in all three tasks compared with the state-of-the-art and conventional
approaches. Our method is an official winner in the overall ranking of
$\textit{Modality prediction}$ from NeurIPS 2021 Competition, and all
implementations of our methods have been integrated into DANCE
package~\url{https://github.com/OmicsML/dance}."
BAD: BiAs Detection for Large Language Models in the context of candidate screening,0.617272,"Application Tracking Systems (ATS) have allowed talent managers, recruiters,
and college admissions committees to process large volumes of potential
candidate applications efficiently. Traditionally, this screening process was
conducted manually, creating major bottlenecks due to the quantity of
applications and introducing many instances of human bias. The advent of large
language models (LLMs) such as ChatGPT and the potential of adopting methods to
current automated application screening raises additional bias and fairness
issues that must be addressed. In this project, we wish to identify and
quantify the instances of social bias in ChatGPT and other OpenAI LLMs in the
context of candidate screening in order to demonstrate how the use of these
models could perpetuate existing biases and inequalities in the hiring process."
Guideline Learning for In-context Information Extraction,0.665379,"Large language models (LLMs) can perform a new task by merely conditioning on
task instructions and a few input-output examples, without optimizing any
parameters. This is called In-Context Learning (ICL). In-context Information
Extraction (IE) has recently garnered attention in the research community.
However, the performance of In-context IE generally lags behind the
state-of-the-art supervised expert models. We highlight a key reason for this
shortfall: underspecified task description. The limited-length context
struggles to thoroughly express the intricate IE task instructions and various
edge cases, leading to misalignment in task comprehension with humans. In this
paper, we propose a Guideline Learning (GL) framework for In-context IE which
reflectively learns and follows guidelines. During the learning phrase, GL
automatically synthesizes a set of guidelines based on a few error cases, and
during inference, GL retrieves helpful guidelines for better ICL. Moreover, we
propose a self-consistency-based active learning method to enhance the
efficiency of GL. Experiments on event extraction and relation extraction show
that GL can significantly improve the performance of in-context IE."
Learning to Predict Navigational Patterns from Partial Observations,0.0954803,"Human beings cooperatively navigate rule-constrained environments by adhering
to mutually known navigational patterns, which may be represented as
directional pathways or road lanes. Inferring these navigational patterns from
incompletely observed environments is required for intelligent mobile robots
operating in unmapped locations. However, algorithmically defining these
navigational patterns is nontrivial. This paper presents the first
self-supervised learning (SSL) method for learning to infer navigational
patterns in real-world environments from partial observations only. We explain
how geometric data augmentation, predictive world modeling, and an
information-theoretic regularizer enables our model to predict an unbiased
local directional soft lane probability (DSLP) field in the limit of infinite
data. We demonstrate how to infer global navigational patterns by fitting a
maximum likelihood graph to the DSLP field. Experiments show that our SSL model
outperforms two SOTA supervised lane graph prediction models on the nuScenes
dataset. We propose our SSL method as a scalable and interpretable continual
learning paradigm for navigation by perception. Code is available at
https://github.com/robin-karlsson0/dslp."
Attentive Dual Stream Siamese U-net for Flood Detection on Multi-temporal Sentinel-1 Data,0.160519,"Due to climate and land-use change, natural disasters such as flooding have
been increasing in recent years. Timely and reliable flood detection and
mapping can help emergency response and disaster management. In this work, we
propose a flood detection network using bi-temporal SAR acquisitions. The
proposed segmentation network has an encoder-decoder architecture with two
Siamese encoders for pre and post-flood images. The network's feature maps are
fused and enhanced using attention blocks to achieve more accurate detection of
the flooded areas. Our proposed network is evaluated on publicly available
Sen1Flood11 benchmark dataset. The network outperformed the existing
state-of-the-art (uni-temporal) flood detection method by 6\% IOU. The
experiments highlight that the combination of bi-temporal SAR data with an
effective network architecture achieves more accurate flood detection than
uni-temporal methods."
HoloDiffusion: Training a 3D Diffusion Model using 2D Images,0.821449,"Diffusion models have emerged as the best approach for generative modeling of
2D images. Part of their success is due to the possibility of training them on
millions if not billions of images with a stable learning objective. However,
extending these models to 3D remains difficult for two reasons. First, finding
a large quantity of 3D training data is much more complex than for 2D images.
Second, while it is conceptually trivial to extend the models to operate on 3D
rather than 2D grids, the associated cubic growth in memory and compute
complexity makes this infeasible. We address the first challenge by introducing
a new diffusion setup that can be trained, end-to-end, with only posed 2D
images for supervision; and the second challenge by proposing an image
formation model that decouples model memory from spatial memory. We evaluate
our method on real-world data, using the CO3D dataset which has not been used
to train 3D generative models before. We show that our diffusion models are
scalable, train robustly, and are competitive in terms of sample quality and
fidelity to existing approaches for 3D generative modeling."
Benchmarking Robustness of 3D Point Cloud Recognition Against Common Corruptions,0.996341,"Deep neural networks on 3D point cloud data have been widely used in the real
world, especially in safety-critical applications. However, their robustness
against corruptions is less studied. In this paper, we present ModelNet40-C,
the first comprehensive benchmark on 3D point cloud corruption robustness,
consisting of 15 common and realistic corruptions. Our evaluation shows a
significant gap between the performances on ModelNet40 and ModelNet40-C for
state-of-the-art (SOTA) models. To reduce the gap, we propose a simple but
effective method by combining PointCutMix-R and TENT after evaluating a wide
range of augmentation and test-time adaptation strategies. We identify a number
of critical insights for future studies on corruption robustness in point cloud
recognition. For instance, we unveil that Transformer-based architectures with
proper training recipes achieve the strongest robustness. We hope our in-depth
analysis will motivate the development of robust training strategies or
architecture designs in the 3D point cloud domain. Our codebase and dataset are
included in https://github.com/jiachens/ModelNet40-C"
Clinical Trial Recommendations Using Semantics-Based Inductive Inference and Knowledge Graph Embeddings,0.192463,"Designing a new clinical trial entails many decisions, such as defining a
cohort and setting the study objectives to name a few, and therefore can
benefit from recommendations based on exhaustive mining of past clinical trial
records. Here, we propose a novel recommendation methodology, based on neural
embeddings trained on a first-of-a-kind knowledge graph of clinical trials. We
addressed several important research questions in this context, including
designing a knowledge graph (KG) for clinical trial data, effectiveness of
various KG embedding (KGE) methods for it, a novel inductive inference using
KGE, and its use in generating recommendations for clinical trial design. We
used publicly available data from clinicaltrials.gov for the study. Results
show that our recommendations approach achieves relevance scores of 70%-83%,
measured as the text similarity to actual clinical trial elements, and the most
relevant recommendation can be found near the top of list. Our study also
suggests potential improvement in training KGE using node semantics."
MCD: A Model-Agnostic Counterfactual Search Method For Multi-modal Design Modifications,0.141916,"Designers may often ask themselves how to adjust their design concepts to
achieve demanding functional goals. To answer such questions, designers must
often consider counterfactuals, weighing design alternatives and their
projected performance. This paper introduces Multi-objective Counterfactuals
for Design (MCD), a computational tool that automates and streamlines the
counterfactual search process and recommends targeted design modifications that
meet designers' unique requirements. MCD improves upon existing counterfactual
search methods by supporting multi-objective requirements, which are crucial in
design problems, and by decoupling the counterfactual search and sampling
processes, thus enhancing efficiency and facilitating objective trade-off
visualization. The paper showcases MCD's capabilities in complex engineering
tasks using three demonstrative bicycle design challenges. In the first, MCD
effectively identifies design modifications that quantifiably enhance
functional performance, strengthening the bike frame and saving weight. In the
second, MCD modifies parametric bike models in a cross-modal fashion to
resemble subjective text prompts or reference images. In a final
multidisciplinary case study, MCD tackles all the quantitative and subjective
design requirements introduced in the first two problems, while simultaneously
customizing a bike design to an individual rider's biomechanical attributes. By
exploring hypothetical design alterations and their impact on multiple design
objectives, MCD recommends effective design modifications for practitioners
seeking to make targeted enhancements to their designs. The code, test
problems, and datasets used in the paper are available to the public at
decode.mit.edu/projects/counterfactuals/."
pymdp: A Python library for active inference in discrete state spaces,0.480415,"Active inference is an account of cognition and behavior in complex systems
which brings together action, perception, and learning under the theoretical
mantle of Bayesian inference. Active inference has seen growing applications in
academic research, especially in fields that seek to model human or animal
behavior. While in recent years, some of the code arising from the active
inference literature has been written in open source languages like Python and
Julia, to-date, the most popular software for simulating active inference
agents is the DEM toolbox of SPM, a MATLAB library originally developed for the
statistical analysis and modelling of neuroimaging data. Increasing interest in
active inference, manifested both in terms of sheer number as well as
diversifying applications across scientific disciplines, has thus created a
need for generic, widely-available, and user-friendly code for simulating
active inference in open-source scientific computing languages like Python. The
Python package we present here, pymdp (see
https://github.com/infer-actively/pymdp), represents a significant step in this
direction: namely, we provide the first open-source package for simulating
active inference with partially-observable Markov Decision Processes or POMDPs.
We review the package's structure and explain its advantages like modular
design and customizability, while providing in-text code blocks along the way
to demonstrate how it can be used to build and run active inference processes
with ease. We developed pymdp to increase the accessibility and exposure of the
active inference framework to researchers, engineers, and developers with
diverse disciplinary backgrounds. In the spirit of open-source software, we
also hope that it spurs new innovation, development, and collaboration in the
growing active inference community."
A Quantitative and Qualitative Analysis of Suicide Ideation Detection using Deep Learning,0.159156,"For preventing youth suicide, social media platforms have received much
attention from researchers. A few researches apply machine learning, or deep
learning-based text classification approaches to classify social media posts
containing suicidality risk. This paper replicated competitive social
media-based suicidality detection/prediction models. We evaluated the
feasibility of detecting suicidal ideation using multiple datasets and
different state-of-the-art deep learning models, RNN-, CNN-, and
Attention-based models. Using two suicidality evaluation datasets, we evaluated
28 combinations of 7 input embeddings with 4 commonly used deep learning models
and 5 pretrained language models in quantitative and qualitative ways. Our
replication study confirms that deep learning works well for social media-based
suicidality detection in general, but it highly depends on the dataset's
quality."
Making Science Simple: Corpora for the Lay Summarisation of Scientific Literature,0.99772,"Lay summarisation aims to jointly summarise and simplify a given text, thus
making its content more comprehensible to non-experts. Automatic approaches for
lay summarisation can provide significant value in broadening access to
scientific literature, enabling a greater degree of both interdisciplinary
knowledge sharing and public understanding when it comes to research findings.
However, current corpora for this task are limited in their size and scope,
hindering the development of broadly applicable data-driven approaches. Aiming
to rectify these issues, we present two novel lay summarisation datasets, PLOS
(large-scale) and eLife (medium-scale), each of which contains biomedical
journal articles alongside expert-written lay summaries. We provide a thorough
characterisation of our lay summaries, highlighting differing levels of
readability and abstractiveness between datasets that can be leveraged to
support the needs of different applications. Finally, we benchmark our datasets
using mainstream summarisation approaches and perform a manual evaluation with
domain experts, demonstrating their utility and casting light on the key
challenges of this task."
ContraReg: Contrastive Learning of Multi-modality Unsupervised Deformable Image Registration,0.694703,"Establishing voxelwise semantic correspondence across distinct imaging
modalities is a foundational yet formidable computer vision task. Current
multi-modality registration techniques maximize hand-crafted inter-domain
similarity functions, are limited in modeling nonlinear intensity-relationships
and deformations, and may require significant re-engineering or underperform on
new tasks, datasets, and domain pairs. This work presents ContraReg, an
unsupervised contrastive representation learning approach to multi-modality
deformable registration. By projecting learned multi-scale local patch features
onto a jointly learned inter-domain embedding space, ContraReg obtains
representations useful for non-rigid multi-modality alignment. Experimentally,
ContraReg achieves accurate and robust results with smooth and invertible
deformations across a series of baselines and ablations on a neonatal T1-T2
brain MRI registration task with all methods validated over a wide range of
deformation regularization strengths."
"Opening up ChatGPT: Tracking openness, transparency, and accountability in instruction-tuned text generators",0.865335,"Large language models that exhibit instruction-following behaviour represent
one of the biggest recent upheavals in conversational interfaces, a trend in
large part fuelled by the release of OpenAI's ChatGPT, a proprietary large
language model for text generation fine-tuned through reinforcement learning
from human feedback (LLM+RLHF). We review the risks of relying on proprietary
software and survey the first crop of open-source projects of comparable
architecture and functionality. The main contribution of this paper is to show
that openness is differentiated, and to offer scientific documentation of
degrees of openness in this fast-moving field. We evaluate projects in terms of
openness of code, training data, model weights, RLHF data, licensing,
scientific documentation, and access methods. We find that while there is a
fast-growing list of projects billing themselves as 'open source', many inherit
undocumented data of dubious legality, few share the all-important
instruction-tuning (a key site where human annotation labour is involved), and
careful scientific documentation is exceedingly rare. Degrees of openness are
relevant to fairness and accountability at all points, from data collection and
curation to model architecture, and from training and fine-tuning to release
and deployment."
Causal Balancing for Domain Generalization,0.471673,"While machine learning models rapidly advance the state-of-the-art on various
real-world tasks, out-of-domain (OOD) generalization remains a challenging
problem given the vulnerability of these models to spurious correlations. We
propose a balanced mini-batch sampling strategy to transform a biased data
distribution into a spurious-free balanced distribution, based on the
invariance of the underlying causal mechanisms for the data generation process.
We argue that the Bayes optimal classifiers trained on such balanced
distribution are minimax optimal across a diverse enough environment space. We
also provide an identifiability guarantee of the latent variable model of the
proposed data generation process, when utilizing enough train environments.
Experiments are conducted on DomainBed, demonstrating empirically that our
method obtains the best performance across 20 baselines reported on the
benchmark."
Alignment-Uniformity aware Representation Learning for Zero-shot Video Classification,0.311788,"Most methods tackle zero-shot video classification by aligning
visual-semantic representations within seen classes, which limits
generalization to unseen classes. To enhance model generalizability, this paper
presents an end-to-end framework that preserves alignment and uniformity
properties for representations on both seen and unseen classes. Specifically,
we formulate a supervised contrastive loss to simultaneously align
visual-semantic features (i.e., alignment) and encourage the learned features
to distribute uniformly (i.e., uniformity). Unlike existing methods that only
consider the alignment, we propose uniformity to preserve maximal-info of
existing features, which improves the probability that unobserved features fall
around observed data. Further, we synthesize features of unseen classes by
proposing a class generator that interpolates and extrapolates the features of
seen classes. Besides, we introduce two metrics, closeness and dispersion, to
quantify the two properties and serve as new measurements of model
generalizability. Experiments show that our method significantly outperforms
SoTA by relative improvements of 28.1% on UCF101 and 27.0% on HMDB51. Code is
available."
M$^2$DAR: Multi-View Multi-Scale Driver Action Recognition with Vision Transformer,0.696786,"Ensuring traffic safety and preventing accidents is a critical goal in daily
driving, where the advancement of computer vision technologies can be leveraged
to achieve this goal. In this paper, we present a multi-view, multi-scale
framework for naturalistic driving action recognition and localization in
untrimmed videos, namely M$^2$DAR, with a particular focus on detecting
distracted driving behaviors. Our system features a weight-sharing, multi-scale
Transformer-based action recognition network that learns robust hierarchical
representations. Furthermore, we propose a new election algorithm consisting of
aggregation, filtering, merging, and selection processes to refine the
preliminary results from the action recognition module across multiple views.
Extensive experiments conducted on the 7th AI City Challenge Track 3 dataset
demonstrate the effectiveness of our approach, where we achieved an overlap
score of 0.5921 on the A2 test set. Our source code is available at
\url{https://github.com/PurdueDigitalTwin/M2DAR}."
One Explanation to Rule them All -- Ensemble Consistent Explanations,0.348832,"Transparency is a major requirement of modern AI based decision making
systems deployed in real world. A popular approach for achieving transparency
is by means of explanations. A wide variety of different explanations have been
proposed for single decision making systems. In practice it is often the case
to have a set (i.e. ensemble) of decisions that are used instead of a single
decision only, in particular in complex systems. Unfortunately, explanation
methods for single decision making systems are not easily applicable to
ensembles -- i.e. they would yield an ensemble of individual explanations which
are not necessarily consistent, hence less useful and more difficult to
understand than a single consistent explanation of all observed phenomena. We
propose a novel concept for consistently explaining an ensemble of decisions
locally with a single explanation -- we introduce a formal concept, as well as
a specific implementation using counterfactual explanations."
Revisiting and Advancing Chinese Natural Language Understanding with Accelerated Heterogeneous Knowledge Pre-training,0.799973,"Recently, knowledge-enhanced pre-trained language models (KEPLMs) improve
context-aware representations via learning from structured relations in
knowledge graphs, and/or linguistic knowledge from syntactic or dependency
analysis. Unlike English, there is a lack of high-performing open-source
Chinese KEPLMs in the natural language processing (NLP) community to support
various language understanding applications. In this paper, we revisit and
advance the development of Chinese natural language understanding with a series
of novel Chinese KEPLMs released in various parameter sizes, namely CKBERT
(Chinese knowledge-enhanced BERT).Specifically, both relational and linguistic
knowledge is effectively injected into CKBERT based on two novel pre-training
tasks, i.e., linguistic-aware masked language modeling and contrastive
multi-hop relation modeling. Based on the above two pre-training paradigms and
our in-house implemented TorchAccelerator, we have pre-trained base (110M),
large (345M) and huge (1.3B) versions of CKBERT efficiently on GPU clusters.
Experiments demonstrate that CKBERT outperforms strong baselines for Chinese
over various benchmark NLP tasks and in terms of different model sizes."
"Facilitating Fine-grained Detection of Chinese Toxic Language: Hierarchical Taxonomy, Resources, and Benchmarks",0.255544,"The widespread dissemination of toxic online posts is increasingly damaging
to society. However, research on detecting toxic language in Chinese has lagged
significantly. Existing datasets lack fine-grained annotation of toxic types
and expressions, and ignore the samples with indirect toxicity. In addition, it
is crucial to introduce lexical knowledge to detect the toxicity of posts,
which has been a challenge for researchers. In this paper, we facilitate the
fine-grained detection of Chinese toxic language. First, we built Monitor Toxic
Frame, a hierarchical taxonomy to analyze toxic types and expressions. Then, a
fine-grained dataset ToxiCN is presented, including both direct and indirect
toxic samples. We also build an insult lexicon containing implicit profanity
and propose Toxic Knowledge Enhancement (TKE) as a benchmark, incorporating the
lexical feature to detect toxic language. In the experimental stage, we
demonstrate the effectiveness of TKE. After that, a systematic quantitative and
qualitative analysis of the findings is given."
Gemini Pro Defeated by GPT-4V: Evidence from Education,0.893935,"This study compared the classification performance of Gemini Pro and GPT-4V
in educational settings. Employing visual question answering (VQA) techniques,
the study examined both models' abilities to read text-based rubrics and then
automatically score student-drawn models in science education. We employed both
quantitative and qualitative analyses using a dataset derived from
student-drawn scientific models and employing NERIF (Notation-Enhanced Rubrics
for Image Feedback) prompting methods. The findings reveal that GPT-4V
significantly outperforms Gemini Pro in terms of scoring accuracy and Quadratic
Weighted Kappa. The qualitative analysis reveals that the differences may be
due to the models' ability to process fine-grained texts in images and overall
image classification performance. Even adapting the NERIF approach by further
de-sizing the input images, Gemini Pro seems not able to perform as well as
GPT-4V. The findings suggest GPT-4V's superior capability in handling complex
multimodal educational tasks. The study concludes that while both models
represent advancements in AI, GPT-4V's higher performance makes it a more
suitable tool for educational applications involving multimodal data
interpretation."
Generative Plug and Play: Posterior Sampling for Inverse Problems,0.747906,"Over the past decade, Plug-and-Play (PnP) has become a popular method for
reconstructing images using a modular framework consisting of a forward and
prior model. The great strength of PnP is that an image denoiser can be used as
a prior model while the forward model can be implemented using more traditional
physics-based approaches. However, a limitation of PnP is that it reconstructs
only a single deterministic image.
  In this paper, we introduce Generative Plug-and-Play (GPnP), a generalization
of PnP to sample from the posterior distribution. As with PnP, GPnP has a
modular framework using a physics-based forward model and an image denoising
prior model. However, in GPnP these models are extended to become proximal
generators, which sample from associated distributions. GPnP applies these
proximal generators in alternation to produce samples from the posterior. We
present experimental simulations using the well-known BM3D denoiser. Our
results demonstrate that the GPnP method is robust, easy to implement, and
produces intuitively reasonable samples from the posterior for sparse
interpolation and tomographic reconstruction. Code to accompany this paper is
available at https://github.com/gbuzzard/generative-pnp-allerton ."
Skip-Attention: Improving Vision Transformers by Paying Less Attention,0.21812,"This work aims to improve the efficiency of vision transformers (ViT). While
ViTs use computationally expensive self-attention operations in every layer, we
identify that these operations are highly correlated across layers -- a key
redundancy that causes unnecessary computations. Based on this observation, we
propose SkipAt, a method to reuse self-attention computation from preceding
layers to approximate attention at one or more subsequent layers. To ensure
that reusing self-attention blocks across layers does not degrade the
performance, we introduce a simple parametric function, which outperforms the
baseline transformer's performance while running computationally faster. We
show the effectiveness of our method in image classification and
self-supervised learning on ImageNet-1K, semantic segmentation on ADE20K, image
denoising on SIDD, and video denoising on DAVIS. We achieve improved throughput
at the same-or-higher accuracy levels in all these tasks."
Novelty Detection in Network Traffic: Using Survival Analysis for Feature Identification,0.318184,"Intrusion Detection Systems are an important component of many organizations'
cyber defense and resiliency strategies. However, one downside of these systems
is their reliance on known attack signatures for detection of malicious network
events. When it comes to unknown attack types and zero-day exploits, modern
Intrusion Detection Systems often fall short. In this paper, we introduce an
unconventional approach to identifying network traffic features that influence
novelty detection based on survival analysis techniques. Specifically, we
combine several Cox proportional hazards models and implement Kaplan-Meier
estimates to predict the probability that a classifier identifies novelty after
the injection of an unknown network attack at any given time. The proposed
model is successful at pinpointing PSH Flag Count, ACK Flag Count, URG Flag
Count, and Down/Up Ratio as the main features to impact novelty detection via
Random Forest, Bayesian Ridge, and Linear Support Vector Regression
classifiers."
Regularizing a Model-based Policy Stationary Distribution to Stabilize Offline Reinforcement Learning,0.382382,"Offline reinforcement learning (RL) extends the paradigm of classical RL
algorithms to purely learning from static datasets, without interacting with
the underlying environment during the learning process. A key challenge of
offline RL is the instability of policy training, caused by the mismatch
between the distribution of the offline data and the undiscounted stationary
state-action distribution of the learned policy. To avoid the detrimental
impact of distribution mismatch, we regularize the undiscounted stationary
distribution of the current policy towards the offline data during the policy
optimization process. Further, we train a dynamics model to both implement this
regularization and better estimate the stationary distribution of the current
policy, reducing the error induced by distribution mismatch. On a wide range of
continuous-control offline RL datasets, our method indicates competitive
performance, which validates our algorithm. The code is publicly available."
Deep Learning-Enabled Sleep Staging From Vital Signs and Activity Measured Using a Near-Infrared Video Camera,0.713048,"Conventional sleep monitoring is time-consuming, expensive and uncomfortable,
requiring a large number of contact sensors to be attached to the patient.
Video data is commonly recorded as part of a sleep laboratory assessment. If
accurate sleep staging could be achieved solely from video, this would overcome
many of the problems of traditional methods. In this work we use heart rate,
breathing rate and activity measures, all derived from a near-infrared video
camera, to perform sleep stage classification. We use a deep transfer learning
approach to overcome data scarcity, by using an existing contact-sensor dataset
to learn effective representations from the heart and breathing rate time
series. Using a dataset of 50 healthy volunteers, we achieve an accuracy of
73.4\% and a Cohen's kappa of 0.61 in four-class sleep stage classification,
establishing a new state-of-the-art for video-based sleep staging."
Can Visual Dialogue Models Do Scorekeeping? Exploring How Dialogue Representations Incrementally Encode Shared Knowledge,0.864665,"Cognitively plausible visual dialogue models should keep a mental scoreboard
of shared established facts in the dialogue context. We propose a theory-based
evaluation method for investigating to what degree models pretrained on the
VisDial dataset incrementally build representations that appropriately do
scorekeeping. Our conclusion is that the ability to make the distinction
between shared and privately known statements along the dialogue is moderately
present in the analysed models, but not always incrementally consistent, which
may partially be due to the limited need for grounding interactions in the
original task."
Faking Fake News for Real Fake News Detection: Propaganda-loaded Training Data Generation,0.928404,"Despite recent advances in detecting fake news generated by neural models,
their results are not readily applicable to effective detection of
human-written disinformation. What limits the successful transfer between them
is the sizable gap between machine-generated fake news and human-authored ones,
including the notable differences in terms of style and underlying intent. With
this in mind, we propose a novel framework for generating training examples
that are informed by the known styles and strategies of human-authored
propaganda. Specifically, we perform self-critical sequence training guided by
natural language inference to ensure the validity of the generated articles,
while also incorporating propaganda techniques, such as appeal to authority and
loaded language. In particular, we create a new training dataset, PropaNews,
with 2,256 examples, which we release for future use. Our experimental results
show that fake news detectors trained on PropaNews are better at detecting
human-written disinformation by 3.62 - 7.69% F1 score on two public datasets."
LaCAM: Search-Based Algorithm for Quick Multi-Agent Pathfinding,0.839363,"We propose a novel complete algorithm for multi-agent pathfinding (MAPF)
called lazy constraints addition search for MAPF (LaCAM). MAPF is a problem of
finding collision-free paths for multiple agents on graphs and is the
foundation of multi-robot coordination. LaCAM uses a two-level search to find
solutions quickly, even with hundreds of agents or more. At the low-level, it
searches constraints about agents' locations. At the high-level, it searches a
sequence of all agents' locations, following the constraints specified by the
low-level. Our exhaustive experiments reveal that LaCAM is comparable to or
outperforms state-of-the-art sub-optimal MAPF algorithms in a variety of
scenarios, regarding success rate, planning time, and solution quality of
sum-of-costs."
Color Image Recovery Using Generalized Matrix Completion over Higher-Order Finite Dimensional Algebra,0.769243,"To improve the accuracy of color image completion with missing entries, we
present a recovery method based on generalized higher-order scalars. We extend
the traditional second-order matrix model to a more comprehensive higher-order
matrix equivalent, called the ""t-matrix"" model, which incorporates a pixel
neighborhood expansion strategy to characterize the local pixel constraints.
This ""t-matrix"" model is then used to extend some commonly used matrix and
tensor completion algorithms to their higher-order versions. We perform
extensive experiments on various algorithms using simulated data and algorithms
on simulated data and publicly available images and compare their performance.
The results show that our generalized matrix completion model and the
corresponding algorithm compare favorably with their lower-order tensor and
conventional matrix counterparts."
Learning to Adapt Domain Shifts of Moral Values via Instance Weighting,0.809831,"Classifying moral values in user-generated text from social media is critical
in understanding community cultures and interpreting user behaviors of social
movements. Moral values and language usage can change across the social
movements; however, text classifiers are usually trained in source domains of
existing social movements and tested in target domains of new social issues
without considering the variations. In this study, we examine domain shifts of
moral values and language usage, quantify the effects of domain shifts on the
morality classification task, and propose a neural adaptation framework via
instance weighting to improve cross-domain classification tasks. The
quantification analysis suggests a strong correlation between morality shifts,
language usage, and classification performance. We evaluate the neural
adaptation framework on a public Twitter data across 7 social movements and
gain classification improvements up to 12.1\%. Finally, we release a new data
of the COVID-19 vaccine labeled with moral values and evaluate our approach on
the new target domain. For the case study of the COVID-19 vaccine, our
adaptation framework achieves up to 5.26\% improvements over neural baselines."
Contextual Biasing with the Knuth-Morris-Pratt Matching Algorithm,0.619823,"Contextual biasing refers to the problem of biasing the automatic speech
recognition (ASR) systems towards rare entities that are relevant to the
specific user or application scenarios. We propose algorithms for contextual
biasing based on the Knuth-Morris-Pratt algorithm for pattern matching. During
beam search, we boost the score of a token extension if it extends matching
into a set of biasing phrases. Our method simulates the classical approaches
often implemented in the weighted finite state transducer (WFST) framework, but
avoids the FST language altogether, with careful considerations on memory
footprint and efficiency on tensor processing units (TPUs) by vectorization.
Without introducing additional model parameters, our method achieves
significant word error rate (WER) reductions on biasing test sets by itself,
and yields further performance gain when combined with a model-based biasing
method."
Embeddings as Epistemic States: Limitations on the Use of Pooling Operators for Accumulating Knowledge,0.154906,"Various neural network architectures rely on pooling operators to aggregate
information coming from different sources. It is often implicitly assumed in
such contexts that vectors encode epistemic states, i.e. that vectors capture
the evidence that has been obtained about some properties of interest, and that
pooling these vectors yields a vector that combines this evidence. We study,
for a number of standard pooling operators, under what conditions they are
compatible with this idea, which we call the epistemic pooling principle. While
we find that all the considered pooling operators can satisfy the epistemic
pooling principle, this only holds when embeddings are sufficiently
high-dimensional and, for most pooling operators, when the embeddings satisfy
particular constraints (e.g. having non-negative coordinates). We furthermore
show that these constraints have important implications on how the embeddings
can be used in practice. In particular, we find that when the epistemic pooling
principle is satisfied, in most cases it is impossible to verify the
satisfaction of propositional formulas using linear scoring functions, with two
exceptions: (i) max-pooling with embeddings that are upper-bounded and (ii)
Hadamard pooling with non-negative embeddings. This finding helps to clarify,
among others, why Graph Neural Networks sometimes under-perform in reasoning
tasks. Finally, we also study an extension of the epistemic pooling principle
to weighted epistemic states, which are important in the context of
non-monotonic reasoning, where max-pooling emerges as the most suitable
operator."
Collaborative Reasoning on Multi-Modal Semantic Graphs for Video-Grounded Dialogue Generation,0.136694,"We study video-grounded dialogue generation, where a response is generated
based on the dialogue context and the associated video. The primary challenges
of this task lie in (1) the difficulty of integrating video data into
pre-trained language models (PLMs) which presents obstacles to exploiting the
power of large-scale pre-training; and (2) the necessity of taking into account
the complementarity of various modalities throughout the reasoning process.
Although having made remarkable progress in video-grounded dialogue generation,
existing methods still fall short when it comes to integrating with PLMs in a
way that allows information from different modalities to complement each other.
To alleviate these issues, we first propose extracting pertinent information
from videos and turning it into reasoning paths that are acceptable to PLMs.
Additionally, we propose a multi-agent reinforcement learning method to
collaboratively perform reasoning on different modalities (i.e., video and
dialogue context). Empirical experiment results on two public datasets indicate
that the proposed model can significantly outperform state-of-the-art models by
large margins on both automatic and human evaluations."
OSFormer: One-Stage Camouflaged Instance Segmentation with Transformers,0.918396,"We present OSFormer, the first one-stage transformer framework for
camouflaged instance segmentation (CIS). OSFormer is based on two key designs.
First, we design a location-sensing transformer (LST) to obtain the location
label and instance-aware parameters by introducing the location-guided queries
and the blend-convolution feedforward network. Second, we develop a
coarse-to-fine fusion (CFF) to merge diverse context information from the LST
encoder and CNN backbone. Coupling these two components enables OSFormer to
efficiently blend local features and long-range context dependencies for
predicting camouflaged instances. Compared with two-stage frameworks, our
OSFormer reaches 41% AP and achieves good convergence efficiency without
requiring enormous training data, i.e., only 3,040 samples under 60 epochs.
Code link: https://github.com/PJLallen/OSFormer."
Causal Discovery of Dynamic Models for Predicting Human Spatial Interactions,0.295162,"Exploiting robots for activities in human-shared environments, whether
warehouses, shopping centres or hospitals, calls for such robots to understand
the underlying physical interactions between nearby agents and objects. In
particular, modelling cause-and-effect relations between the latter can help to
predict unobserved human behaviours and anticipate the outcome of specific
robot interventions. In this paper, we propose an application of causal
discovery methods to model human-robot spatial interactions, trying to
understand human behaviours from real-world sensor data in two possible
scenarios: humans interacting with the environment, and humans interacting with
obstacles. New methods and practical solutions are discussed to exploit, for
the first time, a state-of-the-art causal discovery algorithm in some
challenging human environments, with potential application in many service
robotics scenarios. To demonstrate the utility of the causal models obtained
from real-world datasets, we present a comparison between causal and non-causal
prediction approaches. Our results show that the causal model correctly
captures the underlying interactions of the considered scenarios and improves
its prediction accuracy."
Chinese Idiom Paraphrasing,0.77687,"Idioms, are a kind of idiomatic expression in Chinese, most of which consist
of four Chinese characters. Due to the properties of non-compositionality and
metaphorical meaning, Chinese Idioms are hard to be understood by children and
non-native speakers. This study proposes a novel task, denoted as Chinese Idiom
Paraphrasing (CIP). CIP aims to rephrase idioms-included sentences to
non-idiomatic ones under the premise of preserving the original sentence's
meaning. Since the sentences without idioms are easier handled by Chinese NLP
systems, CIP can be used to pre-process Chinese datasets, thereby facilitating
and improving the performance of Chinese NLP tasks, e.g., machine translation
system, Chinese idiom cloze, and Chinese idiom embeddings. In this study, CIP
task is treated as a special paraphrase generation task. To circumvent
difficulties in acquiring annotations, we first establish a large-scale CIP
dataset based on human and machine collaboration, which consists of 115,530
sentence pairs. We further deploy three baselines and two novel CIP approaches
to deal with CIP problems. The results show that the proposed methods have
better performances than the baselines based on the established CIP dataset."
False perspectives on human language: why statistics needs linguistics,0.046636,"A sharp tension exists about the nature of human language between two
opposite parties: those who believe that statistical surface distributions, in
particular using measures like surprisal, provide a better understanding of
language processing, vs. those who believe that discrete hierarchical
structures implementing linguistic information such as syntactic ones are a
better tool. In this paper, we show that this dichotomy is a false one. Relying
on the fact that statistical measures can be defined on the basis of either
structural or non-structural models, we provide empirical evidence that only
models of surprisal that reflect syntactic structure are able to account for
language regularities."
"Language Diversity: Visible to Humans, Exploitable by Machines",0.279868,"The Universal Knowledge Core (UKC) is a large multilingual lexical database
with a focus on language diversity and covering over a thousand languages. The
aim of the database, as well as its tools and data catalogue, is to make the
somewhat abstract notion of diversity visually understandable for humans and
formally exploitable by machines. The UKC website lets users explore millions
of individual words and their meanings, but also phenomena of cross-lingual
convergence and divergence, such as shared interlingual meanings, lexicon
similarities, cognate clusters, or lexical gaps. The UKC LiveLanguage
Catalogue, in turn, provides access to the underlying lexical data in a
computer-processable form, ready to be reused in cross-lingual applications."
Towards True Detail Restoration for Super-Resolution: A Benchmark and a Quality Metric,0.0809544,"Super-resolution (SR) has become a widely researched topic in recent years.
SR methods can improve overall image and video quality and create new
possibilities for further content analysis. But the SR mainstream focuses
primarily on increasing the naturalness of the resulting image despite
potentially losing context accuracy. Such methods may produce an incorrect
digit, character, face, or other structural object even though they otherwise
yield good visual quality. Incorrect detail restoration can cause errors when
detecting and identifying objects both manually and automatically. To analyze
the detail-restoration capabilities of image and video SR models, we developed
a benchmark based on our own video dataset, which contains complex patterns
that SR models generally fail to correctly restore. We assessed 32 recent SR
models using our benchmark and compared their ability to preserve scene
context. We also conducted a crowd-sourced comparison of restored details and
developed an objective assessment metric that outperforms other quality metrics
by correlation with subjective scores for this task. In conclusion, we provide
a deep analysis of benchmark results that yields insights for future SR-based
work."
Improving Prosody for Cross-Speaker Style Transfer by Semi-Supervised Style Extractor and Hierarchical Modeling in Speech Synthesis,0.542959,"Cross-speaker style transfer in speech synthesis aims at transferring a style
from source speaker to synthesized speech of a target speaker's timbre. In most
previous methods, the synthesized fine-grained prosody features often represent
the source speaker's average style, similar to the one-to-many problem(i.e.,
multiple prosody variations correspond to the same text). In response to this
problem, a strength-controlled semi-supervised style extractor is proposed to
disentangle the style from content and timbre, improving the representation and
interpretability of the global style embedding, which can alleviate the
one-to-many mapping and data imbalance problems in prosody prediction. A
hierarchical prosody predictor is proposed to improve prosody modeling. We find
that better style transfer can be achieved by using the source speaker's
prosody features that are easily predicted. Additionally, a
speaker-transfer-wise cycle consistency loss is proposed to assist the model in
learning unseen style-timbre combinations during the training phase.
Experimental results show that the method outperforms the baseline. We provide
a website with audio samples."
Natural Language Sentence Generation from API Specifications,0.0565936,"APIs are everywhere; they provide access to automation solutions that could
help businesses automate some of their tasks. Unfortunately, they may not be
accessible to the business users who need them but are not equipped with the
necessary technical skills to leverage them. Wrapping these APIs with chatbot
capabilities is one solution to make these automation solutions interactive. In
this work, we propose a system to generate sentences to train intent
recognition models, a crucial component within chatbots to understand natural
language utterances from users. Evaluation of our approach based on deep
learning models showed promising and inspiring results, and the
human-in-the-loop interaction will provide further improvement on the system."
Gradient Domain Diffusion Models for Image Synthesis,0.119047,"Diffusion models are getting popular in generative image and video synthesis.
However, due to the diffusion process, they require a large number of steps to
converge. To tackle this issue, in this paper, we propose to perform the
diffusion process in the gradient domain, where the convergence becomes faster.
There are two reasons. First, thanks to the Poisson equation, the gradient
domain is mathematically equivalent to the original image domain. Therefore,
each diffusion step in the image domain has a unique corresponding gradient
domain representation. Second, the gradient domain is much sparser than the
image domain. As a result, gradient domain diffusion models converge faster.
Several numerical experiments confirm that the gradient domain diffusion models
are more efficient than the original diffusion models. The proposed method can
be applied in a wide range of applications such as image processing, computer
vision and machine learning tasks."
Rank-N-Contrast: Learning Continuous Representations for Regression,0.708021,"Deep regression models typically learn in an end-to-end fashion without
explicitly emphasizing a regression-aware representation. Consequently, the
learned representations exhibit fragmentation and fail to capture the
continuous nature of sample orders, inducing suboptimal results across a wide
range of regression tasks. To fill the gap, we propose Rank-N-Contrast (RNC), a
framework that learns continuous representations for regression by contrasting
samples against each other based on their rankings in the target space. We
demonstrate, theoretically and empirically, that RNC guarantees the desired
order of learned representations in accordance with the target orders, enjoying
not only better performance but also significantly improved robustness,
efficiency, and generalization. Extensive experiments using five real-world
regression datasets that span computer vision, human-computer interaction, and
healthcare verify that RNC achieves state-of-the-art performance, highlighting
its intriguing properties including better data efficiency, robustness to
spurious targets and data corruptions, and generalization to distribution
shifts. Code is available at: https://github.com/kaiwenzha/Rank-N-Contrast."
Region-Conditioned Orthogonal 3D U-Net for Weather4Cast Competition,0.532397,"The Weather4Cast competition (hosted by NeurIPS 2022) required competitors to
predict super-resolution rain movies in various regions of Europe when
low-resolution satellite contexts covering wider regions are given. In this
paper, we show that a general baseline 3D U-Net can be significantly improved
with region-conditioned layers as well as orthogonality regularizations on
1x1x1 convolutional layers. Additionally, we facilitate the generalization with
a bag of training strategies: mixup data augmentation, self-distillation, and
feature-wise linear modulation (FiLM). Presented modifications outperform the
baseline algorithms (3D U-Net) by up to 19.54% with less than 1% additional
parameters, which won the 4th place in the core test leaderboard."
Explainable Slot Type Attentions to Improve Joint Intent Detection and Slot Filling,0.202654,"Joint intent detection and slot filling is a key research topic in natural
language understanding (NLU). Existing joint intent and slot filling systems
analyze and compute features collectively for all slot types, and importantly,
have no way to explain the slot filling model decisions. In this work, we
propose a novel approach that: (i) learns to generate additional slot type
specific features in order to improve accuracy and (ii) provides explanations
for slot filling decisions for the first time in a joint NLU model. We perform
an additional constrained supervision using a set of binary classifiers for the
slot type specific feature learning, thus ensuring appropriate attention
weights are learned in the process to explain slot filling decisions for
utterances. Our model is inherently explainable and does not need any post-hoc
processing. We evaluate our approach on two widely used datasets and show
accuracy improvements. Moreover, a detailed analysis is also provided for the
exclusive slot explainability."
"BiCo-Net: Regress Globally, Match Locally for Robust 6D Pose Estimation",0.368571,"The challenges of learning a robust 6D pose function lie in 1) severe
occlusion and 2) systematic noises in depth images. Inspired by the success of
point-pair features, the goal of this paper is to recover the 6D pose of an
object instance segmented from RGB-D images by locally matching pairs of
oriented points between the model and camera space. To this end, we propose a
novel Bi-directional Correspondence Mapping Network (BiCo-Net) to first
generate point clouds guided by a typical pose regression, which can thus
incorporate pose-sensitive information to optimize generation of local
coordinates and their normal vectors. As pose predictions via geometric
computation only rely on one single pair of local oriented points, our BiCo-Net
can achieve robustness against sparse and occluded point clouds. An ensemble of
redundant pose predictions from locally matching and direct pose regression
further refines final pose output against noisy observations. Experimental
results on three popularly benchmarking datasets can verify that our method can
achieve state-of-the-art performance, especially for the more challenging
severe occluded scenes. Source codes are available at
https://github.com/Gorilla-Lab-SCUT/BiCo-Net."
Knowledge-based Analogical Reasoning in Neuro-symbolic Latent Spaces,0.0886032,"Analogical Reasoning problems challenge both connectionist and symbolic AI
systems as these entail a combination of background knowledge, reasoning and
pattern recognition. While symbolic systems ingest explicit domain knowledge
and perform deductive reasoning, they are sensitive to noise and require inputs
be mapped to preset symbolic features. Connectionist systems on the other hand
can directly ingest rich input spaces such as images, text or speech and
recognize pattern even with noisy inputs. However, connectionist models
struggle to include explicit domain knowledge for deductive reasoning. In this
paper, we propose a framework that combines the pattern recognition abilities
of neural networks with symbolic reasoning and background knowledge for solving
a class of Analogical Reasoning problems where the set of attributes and
possible relations across them are known apriori. We take inspiration from the
'neural algorithmic reasoning' approach [DeepMind 2020] and use
problem-specific background knowledge by (i) learning a distributed
representation based on a symbolic model of the problem (ii) training
neural-network transformations reflective of the relations involved in the
problem and finally (iii) training a neural network encoder from images to the
distributed representation in (i). These three elements enable us to perform
search-based reasoning using neural networks as elementary functions
manipulating distributed representations. We test this on visual analogy
problems in RAVENs Progressive Matrices, and achieve accuracy competitive with
human performance and, in certain cases, superior to initial end-to-end
neural-network based approaches. While recent neural models trained at scale
yield SOTA, our novel neuro-symbolic reasoning approach is a promising
direction for this problem, and is arguably more general, especially for
problems where domain knowledge is available."
Experiencer-Specific Emotion and Appraisal Prediction,0.685414,"Emotion classification in NLP assigns emotions to texts, such as sentences or
paragraphs. With texts like ""I felt guilty when he cried"", focusing on the
sentence level disregards the standpoint of each participant in the situation:
the writer (""I"") and the other entity (""he"") could in fact have different
affective states. The emotions of different entities have been considered only
partially in emotion semantic role labeling, a task that relates semantic roles
to emotion cue words. Proposing a related task, we narrow the focus on the
experiencers of events, and assign an emotion (if any holds) to each of them.
To this end, we represent each emotion both categorically and with appraisal
variables, as a psychological access to explaining why a person develops a
particular emotion. On an event description corpus, our experiencer-aware
models of emotions and appraisals outperform the experiencer-agnostic
baselines, showing that disregarding event participants is an
oversimplification for the emotion detection task."
"Computational Inference in Cognitive Science: Operational, Societal and Ethical Considerations",0.388046,"Emerging research frontiers and computational advances have gradually
transformed cognitive science into a multidisciplinary and data-driven field.
As a result, there is a proliferation of cognitive theories investigated and
interpreted from different academic lens and in different levels of
abstraction. We formulate this applied aspect of this challenge as the
computational cognitive inference, and describe the major routes of
computational approaches. To balance the potential optimism alongside the speed
and scale of the data-driven era of cognitive science, we propose to inspect
this trend in more empirical terms by identifying the operational challenges,
societal impacts and ethical guidelines in conducting research and interpreting
results from the computational inference in cognitive science."
Who's the Expert? On Multi-source Belief Change,0.546985,"Consider the following belief change/merging scenario. A group of information
sources gives a sequence of reports about the state of the world at various
instances (e.g. different points in time). The true states at these instances
are unknown to us. The sources have varying levels of expertise, also unknown
to us, and may be knowledgeable on some topics but not others. This may cause
sources to report false statements in areas they lack expertise. What should we
believe on the basis of these reports? We provide a framework in which to
explore this problem, based on an extension of propositional logic with
expertise formulas. This extended language allows us to express beliefs about
the state of the world at each instance, as well as beliefs about the expertise
of each source. We propose several postulates, provide a couple of families of
concrete operators, and analyse these operators with respect to the postulates."
Guiding Online Reinforcement Learning with Action-Free Offline Pretraining,0.249292,"Offline RL methods have been shown to reduce the need for environment
interaction by training agents using offline collected episodes. However, these
methods typically require action information to be logged during data
collection, which can be difficult or even impossible in some practical cases.
In this paper, we investigate the potential of using action-free offline
datasets to improve online reinforcement learning, name this problem
Reinforcement Learning with Action-Free Offline Pretraining (AFP-RL). We
introduce Action-Free Guide (AF-Guide), a method that guides online training by
extracting knowledge from action-free offline datasets. AF-Guide consists of an
Action-Free Decision Transformer (AFDT) implementing a variant of Upside-Down
Reinforcement Learning. It learns to plan the next states from the offline
dataset, and a Guided Soft Actor-Critic (Guided SAC) that learns online with
guidance from AFDT. Experimental results show that AF-Guide can improve sample
efficiency and performance in online training thanks to the knowledge from the
action-free offline dataset. Code is available at
https://github.com/Vision-CAIR/AF-Guide."
IC3: Image Captioning by Committee Consensus,0.335542,"If you ask a human to describe an image, they might do so in a thousand
different ways. Traditionally, image captioning models are trained to generate
a single ""best"" (most like a reference) image caption. Unfortunately, doing so
encourages captions that are ""informationally impoverished,"" and focus on only
a subset of the possible details, while ignoring other potentially useful
information in the scene. In this work, we introduce a simple, yet novel,
method: ""Image Captioning by Committee Consensus"" (IC3), designed to generate a
single caption that captures high-level details from several annotator
viewpoints. Humans rate captions produced by IC3 at least as helpful as
baseline SOTA models more than two thirds of the time, and IC3 can improve the
performance of SOTA automated recall systems by up to 84%, outperforming single
human-generated reference captions, and indicating significant improvements
over SOTA approaches for visual description. Code is available at
https://davidmchan.github.io/caption-by-committee/"
A Classical-Quantum Convolutional Neural Network for Detecting Pneumonia from Chest Radiographs,0.221785,"While many quantum computing techniques for machine learning have been
proposed, their performance on real-world datasets remains to be studied. In
this paper, we explore how a variational quantum circuit could be integrated
into a classical neural network for the problem of detecting pneumonia from
chest radiographs. We substitute one layer of a classical convolutional neural
network with a variational quantum circuit to create a hybrid neural network.
We train both networks on an image dataset containing chest radiographs and
benchmark their performance. To mitigate the influence of different sources of
randomness in network training, we sample the results over multiple rounds. We
show that the hybrid network outperforms the classical network on different
performance measures, and that these improvements are statistically
significant. Our work serves as an experimental demonstration of the potential
of quantum computing to significantly improve neural network performance for
real-world, non-trivial problems relevant to society and industry."
Chain of Empathy: Enhancing Empathetic Response of Large Language Models Based on Psychotherapy Models,0.275378,"We present a novel method, the Chain of Empathy (CoE) prompting, that
utilizes insights from psychotherapy to induce Large Language Models (LLMs) to
reason about human emotional states. This method is inspired by various
psychotherapy approaches including Cognitive Behavioral Therapy (CBT),
Dialectical Behavior Therapy (DBT), Person Centered Therapy (PCT), and Reality
Therapy (RT), each leading to different patterns of interpreting clients'
mental states. LLMs without reasoning generated predominantly exploratory
responses. However, when LLMs used CoE reasoning, we found a more comprehensive
range of empathetic responses aligned with the different reasoning patterns of
each psychotherapy model. The CBT based CoE resulted in the most balanced
generation of empathetic responses. The findings underscore the importance of
understanding the emotional context and how it affects human and AI
communication. Our research contributes to understanding how psychotherapeutic
models can be incorporated into LLMs, facilitating the development of
context-specific, safer, and empathetic AI."
A Property Induction Framework for Neural Language Models,0.266125,"To what extent can experience from language contribute to our conceptual
knowledge? Computational explorations of this question have shed light on the
ability of powerful neural language models (LMs) -- informed solely through
text input -- to encode and elicit information about concepts and properties.
To extend this line of research, we present a framework that uses
neural-network language models (LMs) to perform property induction -- a task in
which humans generalize novel property knowledge (has sesamoid bones) from one
or more concepts (robins) to others (sparrows, canaries). Patterns of property
induction observed in humans have shed considerable light on the nature and
organization of human conceptual knowledge. Inspired by this insight, we use
our framework to explore the property inductions of LMs, and find that they
show an inductive preference to generalize novel properties on the basis of
category membership, suggesting the presence of a taxonomic bias in their
representations."
"Improving Human-AI Partnerships in Child Welfare: Understanding Worker Practices, Challenges, and Desires for Algorithmic Decision Support",0.980745,"AI-based decision support tools (ADS) are increasingly used to augment human
decision-making in high-stakes, social contexts. As public sector agencies
begin to adopt ADS, it is critical that we understand workers' experiences with
these systems in practice. In this paper, we present findings from a series of
interviews and contextual inquiries at a child welfare agency, to understand
how they currently make AI-assisted child maltreatment screening decisions.
Overall, we observe how workers' reliance upon the ADS is guided by (1) their
knowledge of rich, contextual information beyond what the AI model captures,
(2) their beliefs about the ADS's capabilities and limitations relative to
their own, (3) organizational pressures and incentives around the use of the
ADS, and (4) awareness of misalignments between algorithmic predictions and
their own decision-making objectives. Drawing upon these findings, we discuss
design implications towards supporting more effective human-AI decision-making."
Uncertainty-based Detection of Adversarial Attacks in Semantic Segmentation,0.11372,"State-of-the-art deep neural networks have proven to be highly powerful in a
broad range of tasks, including semantic image segmentation. However, these
networks are vulnerable against adversarial attacks, i.e., non-perceptible
perturbations added to the input image causing incorrect predictions, which is
hazardous in safety-critical applications like automated driving. Adversarial
examples and defense strategies are well studied for the image classification
task, while there has been limited research in the context of semantic
segmentation. First works however show that the segmentation outcome can be
severely distorted by adversarial attacks. In this work, we introduce an
uncertainty-based approach for the detection of adversarial attacks in semantic
segmentation. We observe that uncertainty as for example captured by the
entropy of the output distribution behaves differently on clean and perturbed
images and leverage this property to distinguish between the two cases. Our
method works in a light-weight and post-processing manner, i.e., we do not
modify the model or need knowledge of the process used for generating
adversarial examples. In a thorough empirical analysis, we demonstrate the
ability of our approach to detect perturbed images across multiple types of
adversarial attacks."
Spatial Feature Mapping for 6DoF Object Pose Estimation,0.46944,"This work aims to estimate 6Dof (6D) object pose in background clutter.
Considering the strong occlusion and background noise, we propose to utilize
the spatial structure for better tackling this challenging task. Observing that
the 3D mesh can be naturally abstracted by a graph, we build the graph using 3D
points as vertices and mesh connections as edges. We construct the
corresponding mapping from 2D image features to 3D points for filling the graph
and fusion of the 2D and 3D features. Afterward, a Graph Convolutional Network
(GCN) is applied to help the feature exchange among objects' points in 3D
space. To address the problem of rotation symmetry ambiguity for objects, a
spherical convolution is utilized and the spherical features are combined with
the convolutional features that are mapped to the graph. Predefined 3D
keypoints are voted and the 6DoF pose is obtained via the fitting optimization.
Two scenarios of inference, one with the depth information and the other
without it are discussed. Tested on the datasets of YCB-Video and LINEMOD, the
experiments demonstrate the effectiveness of our proposed method."
SemiRetro: Semi-template framework boosts deep retrosynthesis prediction,0.664889,"Recently, template-based (TB) and template-free (TF) molecule graph learning
methods have shown promising results to retrosynthesis. TB methods are more
accurate using pre-encoded reaction templates, and TF methods are more scalable
by decomposing retrosynthesis into subproblems, i.e., center identification and
synthon completion. To combine both advantages of TB and TF, we suggest
breaking a full-template into several semi-templates and embedding them into
the two-step TF framework. Since many semi-templates are reduplicative, the
template redundancy can be reduced while the essential chemical knowledge is
still preserved to facilitate synthon completion. We call our method SemiRetro,
introduce a new GNN layer (DRGAT) to enhance center identification, and propose
a novel self-correcting module to improve semi-template classification.
Experimental results show that SemiRetro significantly outperforms both
existing TB and TF methods. In scalability, SemiRetro covers 98.9\% data using
150 semi-templates, while previous template-based GLN requires 11,647 templates
to cover 93.3\% data. In top-1 accuracy, SemiRetro exceeds template-free G2G
4.8\% (class known) and 6.0\% (class unknown). Besides, SemiRetro has better
training efficiency than existing methods."
Detecting Emerging Technologies and their Evolution using Deep Learning and Weak Signal Analysis,0.506184,"Emerging technologies can have major economic impacts and affect strategic
stability. Yet, early identification of emerging technologies remains
challenging. In order to identify emerging technologies in a timely and
reliable manner, a comprehensive examination of relevant scientific and
technological (S&T) trends and their related references is required. This
examination is generally done by domain experts and requires significant
amounts of time and effort to gain insights. The use of domain experts to
identify emerging technologies from S&T trends may limit the capacity to
analyse large volumes of information and introduce subjectivity in the
assessments. Decision support systems are required to provide accurate and
reliable evidence-based indicators through constant and continuous monitoring
of the environment and help identify signals of emerging technologies that
could alter security and economic prosperity. For example, the research field
of hypersonics has recently witnessed several advancements having profound
technological, commercial, and national security implications. In this work, we
present a multi-layer quantitative approach able to identify future signs from
scientific publications on hypersonics by leveraging deep learning and weak
signal analysis. The proposed framework can help strategic planners and domain
experts better identify and monitor emerging technology trends."
Language Model-In-The-Loop: Data Optimal Approach to Learn-To-Recommend Actions in Text Games,0.407755,"Large Language Models (LLMs) have demonstrated superior performance in
language understanding benchmarks. CALM, a popular approach, leverages
linguistic priors of LLMs -- GPT-2 -- for action candidate recommendations to
improve the performance in text games in Jericho without environment-provided
actions. However, CALM adapts GPT-2 with annotated human gameplays and keeps
the LLM fixed during the learning of the text based games. In this work, we
explore and evaluate updating LLM used for candidate recommendation during the
learning of the text based game as well to mitigate the reliance on the human
annotated gameplays, which are costly to acquire. We observe that by updating
the LLM during learning using carefully selected in-game transitions, we can
reduce the dependency on using human annotated game plays for fine-tuning the
LLMs. We conducted further analysis to study the transferability of the updated
LLMs and observed that transferring in-game trained models to other games did
not result in a consistent transfer."
SpotEM: Efficient Video Search for Episodic Memory,0.796142,"The goal in episodic memory (EM) is to search a long egocentric video to
answer a natural language query (e.g., ""where did I leave my purse?""). Existing
EM methods exhaustively extract expensive fixed-length clip features to look
everywhere in the video for the answer, which is infeasible for long
wearable-camera videos that span hours or even days. We propose SpotEM, an
approach to achieve efficiency for a given EM method while maintaining good
accuracy. SpotEM consists of three key ideas: 1) a novel clip selector that
learns to identify promising video regions to search conditioned on the
language query; 2) a set of low-cost semantic indexing features that capture
the context of rooms, objects, and interactions that suggest where to look; and
3) distillation losses that address the optimization issues arising from
end-to-end joint training of the clip selector and EM model. Our experiments on
200+ hours of video from the Ego4D EM Natural Language Queries benchmark and
three different EM models demonstrate the effectiveness of our approach:
computing only 10% - 25% of the clip features, we preserve 84% - 97% of the
original EM model's accuracy. Project page:
https://vision.cs.utexas.edu/projects/spotem"
A Reference Model for Common Understanding of Capabilities and Skills in Manufacturing,0.944496,"In manufacturing, many use cases of Industry 4.0 require vendor-neutral and
machine-readable information models to describe, implement and execute resource
functions. Such models have been researched under the terms capabilities and
skills. Standardization of such models is required, but currently not
available. This paper presents a reference model developed jointly by members
of various organizations in a working group of the Plattform Industrie 4.0.
This model covers definitions of most important aspects of capabilities and
skills. It can be seen as a basis for further standardization efforts."
Designerly Understanding: Information Needs for Model Transparency to Support Design Ideation for AI-Powered User Experience,0.999809,"Despite the widespread use of artificial intelligence (AI), designing user
experiences (UX) for AI-powered systems remains challenging. UX designers face
hurdles understanding AI technologies, such as pre-trained language models, as
design materials. This limits their ability to ideate and make decisions about
whether, where, and how to use AI. To address this problem, we bridge the
literature on AI design and AI transparency to explore whether and how
frameworks for transparent model reporting can support design ideation with
pre-trained models. By interviewing 23 UX practitioners, we find that
practitioners frequently work with pre-trained models, but lack support for
UX-led ideation. Through a scenario-based design task, we identify common goals
that designers seek model understanding for and pinpoint their model
transparency information needs. Our study highlights the pivotal role that UX
designers can play in Responsible AI and calls for supporting their
understanding of AI limitations through model transparency and interrogation."
Reconstructing Action-Conditioned Human-Object Interactions Using Commonsense Knowledge Priors,0.778976,"We present a method for inferring diverse 3D models of human-object
interactions from images. Reasoning about how humans interact with objects in
complex scenes from a single 2D image is a challenging task given ambiguities
arising from the loss of information through projection. In addition, modeling
3D interactions requires the generalization ability towards diverse object
categories and interaction types. We propose an action-conditioned modeling of
interactions that allows us to infer diverse 3D arrangements of humans and
objects without supervision on contact regions or 3D scene geometry. Our method
extracts high-level commonsense knowledge from large language models (such as
GPT-3), and applies them to perform 3D reasoning of human-object interactions.
Our key insight is priors extracted from large language models can help in
reasoning about human-object contacts from textural prompts only. We
quantitatively evaluate the inferred 3D models on a large human-object
interaction dataset and show how our method leads to better 3D reconstructions.
We further qualitatively evaluate the effectiveness of our method on real
images and demonstrate its generalizability towards interaction types and
object categories."
Learnable Blur Kernel for Single-Image Defocus Deblurring in the Wild,0.166856,"Recent research showed that the dual-pixel sensor has made great progress in
defocus map estimation and image defocus deblurring. However, extracting
real-time dual-pixel views is troublesome and complex in algorithm deployment.
Moreover, the deblurred image generated by the defocus deblurring network lacks
high-frequency details, which is unsatisfactory in human perception. To
overcome this issue, we propose a novel defocus deblurring method that uses the
guidance of the defocus map to implement image deblurring. The proposed method
consists of a learnable blur kernel to estimate the defocus map, which is an
unsupervised method, and a single-image defocus deblurring generative
adversarial network (DefocusGAN) for the first time. The proposed network can
learn the deblurring of different regions and recover realistic details. We
propose a defocus adversarial loss to guide this training process. Competitive
experimental results confirm that with a learnable blur kernel, the generated
defocus map can achieve results comparable to supervised methods. In the
single-image defocus deblurring task, the proposed method achieves
state-of-the-art results, especially significant improvements in perceptual
quality, where PSNR reaches 25.56 dB and LPIPS reaches 0.111."
Cyberbullying detection across social media platforms via platform-aware adversarial encoding,0.808821,"Despite the increasing interest in cyberbullying detection, existing efforts
have largely been limited to experiments on a single platform and their
generalisability across different social media platforms have received less
attention. We propose XP-CB, a novel cross-platform framework based on
Transformers and adversarial learning. XP-CB can enhance a Transformer
leveraging unlabelled data from the source and target platforms to come up with
a common representation while preventing platform-specific training. To
validate our proposed framework, we experiment on cyberbullying datasets from
three different platforms through six cross-platform configurations, showing
its effectiveness with both BERT and RoBERTa as the underlying Transformer
models."
Do self-supervised speech models develop human-like perception biases?,0.403981,"Self-supervised models for speech processing form representational spaces
without using any external labels. Increasingly, they appear to be a feasible
way of at least partially eliminating costly manual annotations, a problem of
particular concern for low-resource languages. But what kind of
representational spaces do these models construct? Human perception specializes
to the sounds of listeners' native languages. Does the same thing happen in
self-supervised models? We examine the representational spaces of three kinds
of state-of-the-art self-supervised models: wav2vec 2.0, HuBERT and contrastive
predictive coding (CPC), and compare them with the perceptual spaces of
French-speaking and English-speaking human listeners, both globally and taking
account of the behavioural differences between the two language groups. We show
that the CPC model shows a small native language effect, but that wav2vec 2.0
and HuBERT seem to develop a universal speech perception space which is not
language specific. A comparison against the predictions of supervised phone
recognisers suggests that all three self-supervised models capture relatively
fine-grained perceptual phenomena, while supervised models are better at
capturing coarser, phone-level, effects of listeners' native language, on
perception."
Breaking BERT: Evaluating and Optimizing Sparsified Attention,0.026288,"Transformers allow attention between all pairs of tokens, but there is reason
to believe that most of these connections - and their quadratic time and memory
- may not be necessary. But which ones? We evaluate the impact of
sparsification patterns with a series of ablation experiments. First, we
compare masks based on syntax, lexical similarity, and token position to random
connections, and measure which patterns reduce performance the least. We find
that on three common finetuning tasks even using attention that is at least 78%
sparse can have little effect on performance if applied at later transformer
layers, but that applying sparsity throughout the network reduces performance
significantly. Second, we vary the degree of sparsity for three patterns
supported by previous work, and find that connections to neighbouring tokens
are the most significant. Finally, we treat sparsity as an optimizable
parameter, and present an algorithm to learn degrees of neighboring connections
that gives a fine-grained control over the accuracy-sparsity trade-off while
approaching the performance of existing methods."
DAE-Former: Dual Attention-guided Efficient Transformer for Medical Image Segmentation,0.878426,"Transformers have recently gained attention in the computer vision domain due
to their ability to model long-range dependencies. However, the self-attention
mechanism, which is the core part of the Transformer model, usually suffers
from quadratic computational complexity with respect to the number of tokens.
Many architectures attempt to reduce model complexity by limiting the
self-attention mechanism to local regions or by redesigning the tokenization
process. In this paper, we propose DAE-Former, a novel method that seeks to
provide an alternative perspective by efficiently designing the self-attention
mechanism. More specifically, we reformulate the self-attention mechanism to
capture both spatial and channel relations across the whole feature dimension
while staying computationally efficient. Furthermore, we redesign the skip
connection path by including the cross-attention module to ensure the feature
reusability and enhance the localization power. Our method outperforms
state-of-the-art methods on multi-organ cardiac and skin lesion segmentation
datasets without requiring pre-training weights. The code is publicly available
at https://github.com/mindflow-institue/DAEFormer."
SpA-Former: Transformer image shadow detection and removal via spatial attention,0.307232,"In this paper, we propose an end-to-end SpA-Former to recover a shadow-free
image from a single shaded image. Unlike traditional methods that require two
steps for shadow detection and then shadow removal, the SpA-Former unifies
these steps into one, which is a one-stage network capable of directly learning
the mapping function between shadows and no shadows, it does not require a
separate shadow detection. Thus, SpA-former is adaptable to real image
de-shadowing for shadows projected on different semantic regions. SpA-Former
consists of transformer layer and a series of joint Fourier transform residual
blocks and two-wheel joint spatial attention. The network in this paper is able
to handle the task while achieving a very fast processing efficiency.
  Our code is relased on
https://github.com/zhangbaijin/SpA-Former-shadow-removal"
Phenomenological Causality,0.338203,"Discussions on causal relations in real life often consider variables for
which the definition of causality is unclear since the notion of interventions
on the respective variables is obscure. Asking 'what qualifies an action for
being an intervention on the variable X' raises the question whether the action
impacted all other variables only through X or directly, which implicitly
refers to a causal model.
  To avoid this known circularity, we instead suggest a notion of
'phenomenological causality' whose basic concept is a set of elementary
actions. Then the causal structure is defined such that elementary actions
change only the causal mechanism at one node (e.g. one of the causal
conditionals in the Markov factorization). This way, the Principle of
Independent Mechanisms becomes the defining property of causal structure in
domains where causality is a more abstract phenomenon rather than being an
objective fact relying on hard-wired causal links between tangible objects. We
describe this phenomenological approach to causality for toy and hypothetical
real-world examples and argue that it is consistent with the causal Markov
condition when the system under consideration interacts with other variables
that control the elementary actions."
Data Splits and Metrics for Method Benchmarking on Surgical Action Triplet Datasets,0.846434,"In addition to generating data and annotations, devising sensible data
splitting strategies and evaluation metrics is essential for the creation of a
benchmark dataset. This practice ensures consensus on the usage of the data,
homogeneous assessment, and uniform comparison of research methods on the
dataset. This study focuses on CholecT50, which is a 50 video surgical dataset
that formalizes surgical activities as triplets of <instrument, verb, target>.
In this paper, we introduce the standard splits for the CholecT50 and CholecT45
datasets and show how they compare with existing use of the dataset. CholecT45
is the first public release of 45 videos of CholecT50 dataset. We also develop
a metrics library, ivtmetrics, for model evaluation on surgical triplets.
Furthermore, we conduct a benchmark study by reproducing baseline methods in
the most predominantly used deep learning frameworks (PyTorch and TensorFlow)
to evaluate them using the proposed data splits and metrics and release them
publicly to support future research. The proposed data splits and evaluation
metrics will enable global tracking of research progress on the dataset and
facilitate optimal model selection for further deployment."
"Milestones in Autonomous Driving and Intelligent Vehicles Part I: Control, Computing System Design, Communication, HD Map, Testing, and Human Behaviors",0.867843,"Interest in autonomous driving (AD) and intelligent vehicles (IVs) is growing
at a rapid pace due to the convenience, safety, and economic benefits. Although
a number of surveys have reviewed research achievements in this field, they are
still limited in specific tasks and lack systematic summaries and research
directions in the future. Our work is divided into 3 independent articles and
the first part is a Survey of Surveys (SoS) for total technologies of AD and
IVs that involves the history, summarizes the milestones, and provides the
perspectives, ethics, and future research directions. This is the second part
(Part I for this technical survey) to review the development of control,
computing system design, communication, High Definition map (HD map), testing,
and human behaviors in IVs. In addition, the third part (Part II for this
technical survey) is to review the perception and planning sections. The
objective of this paper is to involve all the sections of AD, summarize the
latest technical milestones, and guide abecedarians to quickly understand the
development of AD and IVs. Combining the SoS and Part II, we anticipate that
this work will bring novel and diverse insights to researchers and
abecedarians, and serve as a bridge between past and future."
Playing the Werewolf game with artificial intelligence for language understanding,0.932801,"The Werewolf game is a social deduction game based on free natural language
communication, in which players try to deceive others in order to survive. An
important feature of this game is that a large portion of the conversations are
false information, and the behavior of artificial intelligence (AI) in such a
situation has not been widely investigated. The purpose of this study is to
develop an AI agent that can play Werewolf through natural language
conversations. First, we collected game logs from 15 human players. Next, we
fine-tuned a Transformer-based pretrained language model to construct a value
network that can predict a posterior probability of winning a game at any given
phase of the game and given a candidate for the next action. We then developed
an AI agent that can interact with humans and choose the best voting target on
the basis of its probability from the value network. Lastly, we evaluated the
performance of the agent by having it actually play the game with human
players. We found that our AI agent, Deep Wolf, could play Werewolf as
competitively as average human players in a villager or a betrayer role,
whereas Deep Wolf was inferior to human players in a werewolf or a seer role.
These results suggest that current language models have the capability to
suspect what others are saying, tell a lie, or detect lies in conversations."
4D Unsupervised Object Discovery,0.665042,"Object discovery is a core task in computer vision. While fast progresses
have been made in supervised object detection, its unsupervised counterpart
remains largely unexplored. With the growth of data volume, the expensive cost
of annotations is the major limitation hindering further study. Therefore,
discovering objects without annotations has great significance. However, this
task seems impractical on still-image or point cloud alone due to the lack of
discriminative information. Previous studies underlook the crucial temporal
information and constraints naturally behind multi-modal inputs. In this paper,
we propose 4D unsupervised object discovery, jointly discovering objects from
4D data -- 3D point clouds and 2D RGB images with temporal information. We
present the first practical approach for this task by proposing a ClusterNet on
3D point clouds, which is jointly iteratively optimized with a 2D localization
network. Extensive experiments on the large-scale Waymo Open Dataset suggest
that the localization network and ClusterNet achieve competitive performance on
both class-agnostic 2D object detection and 3D instance segmentation, bridging
the gap between unsupervised methods and full supervised ones. Codes and models
will be made available at https://github.com/Robertwyq/LSMOL."
IMF: Interactive Multimodal Fusion Model for Link Prediction,0.8842,"Link prediction aims to identify potential missing triples in knowledge
graphs. To get better results, some recent studies have introduced multimodal
information to link prediction. However, these methods utilize multimodal
information separately and neglect the complicated interaction between
different modalities. In this paper, we aim at better modeling the
inter-modality information and thus introduce a novel Interactive Multimodal
Fusion (IMF) model to integrate knowledge from different modalities. To this
end, we propose a two-stage multimodal fusion framework to preserve
modality-specific knowledge as well as take advantage of the complementarity
between different modalities. Instead of directly projecting different
modalities into a unified space, our multimodal fusion module limits the
representations of different modalities independent while leverages bilinear
pooling for fusion and incorporates contrastive learning as additional
constraints. Furthermore, the decision fusion module delivers the learned
weighted average over the predictions of all modalities to better incorporate
the complementarity of different modalities. Our approach has been demonstrated
to be effective through empirical evaluations on several real-world datasets.
The implementation code is available online at
https://github.com/HestiaSky/IMF-Pytorch."
Mathematical Structure of Syntactic Merge,0.613637,"The syntactic Merge operation of the Minimalist Program in linguistics can be
described mathematically in terms of Hopf algebras, with a formalism similar to
the one arising in the physics of renormalization. This mathematical
formulation of Merge has good descriptive power, as phenomena empirically
observed in linguistics can be justified from simple mathematical arguments. It
also provides a possible mathematical model for externalization and for the
role of syntactic parameters."
Towards a Cleaner Document-Oriented Multilingual Crawled Corpus,0.99851,"The need for raw large raw corpora has dramatically increased in recent years
with the introduction of transfer learning and semi-supervised learning methods
to Natural Language Processing. And while there have been some recent attempts
to manually curate the amount of data necessary to train large language models,
the main way to obtain this data is still through automatic web crawling. In
this paper we take the existing multilingual web corpus OSCAR and its pipeline
Ungoliant that extracts and classifies data from Common Crawl at the line
level, and propose a set of improvements and automatic annotations in order to
produce a new document-oriented version of OSCAR that could prove more suitable
to pre-train large generative language models as well as hopefully other
applications in Natural Language Processing and Digital Humanities."
HARP: Autoregressive Latent Video Prediction with High-Fidelity Image Generator,0.819026,"Video prediction is an important yet challenging problem; burdened with the
tasks of generating future frames and learning environment dynamics. Recently,
autoregressive latent video models have proved to be a powerful video
prediction tool, by separating the video prediction into two sub-problems:
pre-training an image generator model, followed by learning an autoregressive
prediction model in the latent space of the image generator. However,
successfully generating high-fidelity and high-resolution videos has yet to be
seen. In this work, we investigate how to train an autoregressive latent video
prediction model capable of predicting high-fidelity future frames with minimal
modification to existing models, and produce high-resolution (256x256) videos.
Specifically, we scale up prior models by employing a high-fidelity image
generator (VQ-GAN) with a causal transformer model, and introduce additional
techniques of top-k sampling and data augmentation to further improve video
prediction quality. Despite the simplicity, the proposed method achieves
competitive performance to state-of-the-art approaches on standard video
prediction benchmarks with fewer parameters, and enables high-resolution video
prediction on complex and large-scale datasets. Videos are available at
https://sites.google.com/view/harp-videos/home."
Temporal Inductive Path Neural Network for Temporal Knowledge Graph Reasoning,0.577294,"Temporal Knowledge Graph (TKG) is an extension of traditional Knowledge Graph
(KG) that incorporates the dimension of time. Reasoning on TKGs is a crucial
task that aims to predict future facts based on historical occurrences. The key
challenge lies in uncovering structural dependencies within historical
subgraphs and temporal patterns. Most existing approaches model TKGs relying on
entity modeling, as nodes in the graph play a crucial role in knowledge
representation. However, the real-world scenario often involves an extensive
number of entities, with new entities emerging over time. This makes it
challenging for entity-dependent methods to cope with extensive volumes of
entities, and effectively handling newly emerging entities also becomes a
significant challenge. Therefore, we propose Temporal Inductive Path Neural
Network (TiPNN), which models historical information in an entity-independent
perspective. Specifically, TiPNN adopts a unified graph, namely history
temporal graph, to comprehensively capture and encapsulate information from
history. Subsequently, we utilize the defined query-aware temporal paths on a
history temporal graph to model historical path information related to queries
for reasoning. Extensive experiments illustrate that the proposed model not
only attains significant performance enhancements but also handles inductive
settings, while additionally facilitating the provision of reasoning evidence
through history temporal graphs."
Fair NLP Models with Differentially Private Text Encoders,0.332056,"Encoded text representations often capture sensitive attributes about
individuals (e.g., race or gender), which raise privacy concerns and can make
downstream models unfair to certain groups. In this work, we propose FEDERATE,
an approach that combines ideas from differential privacy and adversarial
training to learn private text representations which also induces fairer
models. We empirically evaluate the trade-off between the privacy of the
representations and the fairness and accuracy of the downstream model on four
NLP datasets. Our results show that FEDERATE consistently improves upon
previous methods, and thus suggest that privacy and fairness can positively
reinforce each other."
Enhancing Emergency Decision-making with Knowledge Graphs and Large Language Models,0.218649,"Emergency management urgently requires comprehensive knowledge while having a
high possibility to go beyond individuals' cognitive scope. Therefore,
artificial intelligence(AI) supported decision-making under that circumstance
is of vital importance. Recent emerging large language models (LLM) provide a
new direction for enhancing targeted machine intelligence. However, the
utilization of LLM directly would inevitably introduce unreliable output for
its inherent issue of hallucination and poor reasoning skills. In this work, we
develop a system called Enhancing Emergency decision-making with Knowledge
Graph and LLM (E-KELL), which provides evidence-based decision-making in
various emergency stages. The study constructs a structured emergency knowledge
graph and guides LLMs to reason over it via a prompt chain. In real-world
evaluations, E-KELL receives scores of 9.06, 9.09, 9.03, and 9.09 in
comprehensibility, accuracy, conciseness, and instructiveness from a group of
emergency commanders and firefighters, demonstrating a significant improvement
across various situations compared to baseline models. This work introduces a
novel approach to providing reliable emergency decision support."
A Simple and Strong Baseline for End-to-End Neural RST-style Discourse Parsing,0.76708,"To promote and further develop RST-style discourse parsing models, we need a
strong baseline that can be regarded as a reference for reporting reliable
experimental results. This paper explores a strong baseline by integrating
existing simple parsing strategies, top-down and bottom-up, with various
transformer-based pre-trained language models. The experimental results
obtained from two benchmark datasets demonstrate that the parsing performance
strongly relies on the pretrained language models rather than the parsing
strategies. In particular, the bottom-up parser achieves large performance
gains compared to the current best parser when employing DeBERTa. We further
reveal that language models with a span-masking scheme especially boost the
parsing performance through our analysis within intra- and multi-sentential
parsing, and nuclearity prediction."
Measuring Inconsistency in Declarative Process Specifications,0.342388,"We address the problem of measuring inconsistency in declarative process
specifications, with an emphasis on linear temporal logic on fixed traces
(LTLff). As we will show, existing inconsistency measures for classical logic
cannot provide a meaningful assessment of inconsistency in LTL in general, as
they cannot adequately handle the temporal operators. We therefore propose a
novel paraconsistent semantics as a framework for inconsistency measurement. We
then present two new inconsistency measures based on these semantics and show
that they satisfy important desirable properties. We show how these measures
can be applied to declarative process models and investigate the computational
complexity of the introduced approach."
Realistic Defocus Blur for Multiplane Computer-Generated Holography,0.778965,"This paper introduces a new multiplane CGH computation method to reconstruct
artefact-free high-quality holograms with natural-looking defocus blur. Our
method introduces a new targeting scheme and a new loss function. While the
targeting scheme accounts for defocused parts of the scene at each depth plane,
the new loss function analyzes focused and defocused parts separately in
reconstructed images. Our method support phase-only CGH calculations using
various iterative (e.g., Gerchberg-Saxton, Gradient Descent) and non-iterative
(e.g., Double Phase) CGH techniques. We achieve our best image quality using a
modified gradient descent-based optimization recipe where we introduce a
constraint inspired by the double phase method. We validate our method
experimentally using our proof-of-concept holographic display, comparing
various algorithms, including multi-depth scenes with sparse and dense
contents."
Make It So: Steering StyleGAN for Any Image Inversion and Editing,0.229636,"StyleGAN's disentangled style representation enables powerful image editing
by manipulating the latent variables, but accurately mapping real-world images
to their latent variables (GAN inversion) remains a challenge. Existing GAN
inversion methods struggle to maintain editing directions and produce realistic
results.
  To address these limitations, we propose Make It So, a novel GAN inversion
method that operates in the $\mathcal{Z}$ (noise) space rather than the typical
$\mathcal{W}$ (latent style) space. Make It So preserves editing capabilities,
even for out-of-domain images. This is a crucial property that was overlooked
in prior methods. Our quantitative evaluations demonstrate that Make It So
outperforms the state-of-the-art method PTI~\cite{roich2021pivotal} by a factor
of five in inversion accuracy and achieves ten times better edit quality for
complex indoor scenes."
Improving Mass Detection in Mammography Images: A Study of Weakly Supervised Learning and Class Activation Map Methods,0.399239,"In recent years, weakly supervised models have aided in mass detection using
mammography images, decreasing the need for pixel-level annotations. However,
most existing models in the literature rely on Class Activation Maps (CAM) as
the activation method, overlooking the potential benefits of exploring other
activation techniques. This work presents a study that explores and compares
different activation maps in conjunction with state-of-the-art methods for
weakly supervised training in mammography images. Specifically, we investigate
CAM, GradCAM, GradCAM++, XGradCAM, and LayerCAM methods within the framework of
the GMIC model for mass detection in mammography images. The evaluation is
conducted on the VinDr-Mammo dataset, utilizing the metrics Accuracy, True
Positive Rate (TPR), False Negative Rate (FNR), and False Positive Per Image
(FPPI). Results show that using different strategies of activation maps during
training and test stages leads to an improvement of the model. With this
strategy, we improve the results of the GMIC method, decreasing the FPPI value
and increasing TPR."
BeAts: Bengali Speech Acts Recognition using Multimodal Attention Fusion,0.327973,"Spoken languages often utilise intonation, rhythm, intensity, and structure,
to communicate intention, which can be interpreted differently depending on the
rhythm of speech of their utterance. These speech acts provide the foundation
of communication and are unique in expression to the language. Recent
advancements in attention-based models, demonstrating their ability to learn
powerful representations from multilingual datasets, have performed well in
speech tasks and are ideal to model specific tasks in low resource languages.
Here, we develop a novel multimodal approach combining two models, wav2vec2.0
for audio and MarianMT for text translation, by using multimodal attention
fusion to predict speech acts in our prepared Bengali speech corpus. We also
show that our model BeAts ($\underline{\textbf{Be}}$ngali speech acts
recognition using Multimodal $\underline{\textbf{At}}$tention
Fu$\underline{\textbf{s}}$ion) significantly outperforms both the unimodal
baseline using only speech data and a simpler bimodal fusion using both speech
and text data. Project page: https://soumitri2001.github.io/BeAts"
LVRNet: Lightweight Image Restoration for Aerial Images under Low Visibility,0.267459,"Learning to recover clear images from images having a combination of
degrading factors is a challenging task. That being said, autonomous
surveillance in low visibility conditions caused by high pollution/smoke, poor
air quality index, low light, atmospheric scattering, and haze during a
blizzard becomes even more important to prevent accidents. It is thus crucial
to form a solution that can result in a high-quality image and is efficient
enough to be deployed for everyday use. However, the lack of proper datasets
available to tackle this task limits the performance of the previous methods
proposed. To this end, we generate the LowVis-AFO dataset, containing 3647
paired dark-hazy and clear images. We also introduce a lightweight deep
learning model called Low-Visibility Restoration Network (LVRNet). It
outperforms previous image restoration methods with low latency, achieving a
PSNR value of 25.744 and an SSIM of 0.905, making our approach scalable and
ready for practical use. The code and data can be found at
https://github.com/Achleshwar/LVRNet."
VIINTER: View Interpolation with Implicit Neural Representations of Images,0.245201,"We present VIINTER, a method for view interpolation by interpolating the
implicit neural representation (INR) of the captured images. We leverage the
learned code vector associated with each image and interpolate between these
codes to achieve viewpoint transitions. We propose several techniques that
significantly enhance the interpolation quality. VIINTER signifies a new way to
achieve view interpolation without constructing 3D structure, estimating camera
poses, or computing pixel correspondence. We validate the effectiveness of
VIINTER on several multi-view scenes with different types of camera layout and
scene composition. As the development of INR of images (as opposed to surface
or volume) has centered around tasks like image fitting and super-resolution,
with VIINTER, we show its capability for view interpolation and offer a
promising outlook on using INR for image manipulation tasks."
Discovering Variable Binding Circuitry with Desiderata,0.975562,"Recent work has shown that computation in language models may be
human-understandable, with successful efforts to localize and intervene on both
single-unit features and input-output circuits. Here, we introduce an approach
which extends causal mediation experiments to automatically identify model
components responsible for performing a specific subtask by solely specifying a
set of \textit{desiderata}, or causal attributes of the model components
executing that subtask. As a proof of concept, we apply our method to
automatically discover shared \textit{variable binding circuitry} in LLaMA-13B,
which retrieves variable values for multiple arithmetic tasks. Our method
successfully localizes variable binding to only 9 attention heads (of the 1.6k)
and one MLP in the final token's residual stream."
Fuse to Forget: Bias Reduction and Selective Memorization through Model Fusion,0.367241,"Model fusion research aims to aggregate the knowledge of multiple models to
enhance performance by combining their weights. In this work, we study the
inverse, investigating whether and how can model fusion interfere and reduce
unwanted knowledge. We delve into the effects of model fusion on the evolution
of learned shortcuts, social biases, and memorization capabilities in
fine-tuned language models. Through several experiments covering text
classification and generation tasks, our analysis highlights that shared
knowledge among models is usually enhanced during model fusion, while unshared
knowledge is usually lost or forgotten. Based on this observation, we
demonstrate the potential of model fusion as a debiasing tool and showcase its
efficacy in addressing privacy concerns associated with language models."
Colo-SCRL: Self-Supervised Contrastive Representation Learning for Colonoscopic Video Retrieval,0.608015,"Colonoscopic video retrieval, which is a critical part of polyp treatment,
has great clinical significance for the prevention and treatment of colorectal
cancer. However, retrieval models trained on action recognition datasets
usually produce unsatisfactory retrieval results on colonoscopic datasets due
to the large domain gap between them. To seek a solution to this problem, we
construct a large-scale colonoscopic dataset named Colo-Pair for medical
practice. Based on this dataset, a simple yet effective training method called
Colo-SCRL is proposed for more robust representation learning. It aims to
refine general knowledge from colonoscopies through masked autoencoder-based
reconstruction and momentum contrast to improve retrieval performance. To the
best of our knowledge, this is the first attempt to employ the contrastive
learning paradigm for medical video retrieval. Empirical results show that our
method significantly outperforms current state-of-the-art methods in the
colonoscopic video retrieval task."
Interactively Learning Preference Constraints in Linear Bandits,0.26955,"We study sequential decision-making with known rewards and unknown
constraints, motivated by situations where the constraints represent
expensive-to-evaluate human preferences, such as safe and comfortable driving
behavior. We formalize the challenge of interactively learning about these
constraints as a novel linear bandit problem which we call constrained linear
best-arm identification. To solve this problem, we propose the Adaptive
Constraint Learning (ACOL) algorithm. We provide an instance-dependent lower
bound for constrained linear best-arm identification and show that ACOL's
sample complexity matches the lower bound in the worst-case. In the average
case, ACOL's sample complexity bound is still significantly tighter than bounds
of simpler approaches. In synthetic experiments, ACOL performs on par with an
oracle solution and outperforms a range of baselines. As an application, we
consider learning constraints to represent human preferences in a driving
simulation. ACOL is significantly more sample efficient than alternatives for
this application. Further, we find that learning preferences as constraints is
more robust to changes in the driving scenario than encoding the preferences
directly in the reward function."
Asymptotic Soft Cluster Pruning for Deep Neural Networks,0.0864377,"Filter pruning method introduces structural sparsity by removing selected
filters and is thus particularly effective for reducing complexity. Previous
works empirically prune networks from the point of view that filter with
smaller norm contributes less to the final results. However, such criteria has
been proven sensitive to the distribution of filters, and the accuracy may hard
to recover since the capacity gap is fixed once pruned. In this paper, we
propose a novel filter pruning method called Asymptotic Soft Cluster Pruning
(ASCP), to identify the redundancy of network based on the similarity of
filters. Each filter from over-parameterized network is first distinguished by
clustering, and then reconstructed to manually introduce redundancy into it.
Several guidelines of clustering are proposed to better preserve feature
extraction ability. After reconstruction, filters are allowed to be updated to
eliminate the effect caused by mistakenly selected. Besides, various decaying
strategies of the pruning rate are adopted to stabilize the pruning process and
improve the final performance as well. By gradually generating more identical
filters within each cluster, ASCP can remove them through channel addition
operation with almost no accuracy drop. Extensive experiments on CIFAR-10 and
ImageNet datasets show that our method can achieve competitive results compared
with many state-of-the-art algorithms."
Panini-Net: GAN Prior Based Degradation-Aware Feature Interpolation for Face Restoration,0.380888,"Emerging high-quality face restoration (FR) methods often utilize pre-trained
GAN models (\textit{i.e.}, StyleGAN2) as GAN Prior. However, these methods
usually struggle to balance realness and fidelity when facing various
degradation levels. Besides, there is still a noticeable visual quality gap
compared with pre-trained GAN models. In this paper, we propose a novel GAN
Prior based degradation-aware feature interpolation network, dubbed Panini-Net,
for FR tasks by explicitly learning the abstract representations to distinguish
various degradations. Specifically, an unsupervised degradation representation
learning (UDRL) strategy is first developed to extract degradation
representations (DR) of the input degraded images. Then, a degradation-aware
feature interpolation (DAFI) module is proposed to dynamically fuse the two
types of informative features (\textit{i.e.}, features from input images and
features from GAN Prior) with flexible adaption to various degradations based
on DR. Ablation studies reveal the working mechanism of DAFI and its potential
for editable FR. Extensive experiments demonstrate that our Panini-Net achieves
state-of-the-art performance for multi-degradation face restoration and face
super-resolution. The source code is available at
https://github.com/jianzhangcs/panini."
Understanding Why ViT Trains Badly on Small Datasets: An Intuitive Perspective,0.285661,"Vision transformer (ViT) is an attention neural network architecture that is
shown to be effective for computer vision tasks. However, compared to ResNet-18
with a similar number of parameters, ViT has a significantly lower evaluation
accuracy when trained on small datasets. To facilitate studies in related
fields, we provide a visual intuition to help understand why it is the case. We
first compare the performance of the two models and confirm that ViT has less
accuracy than ResNet-18 when trained on small datasets. We then interpret the
results by showing attention map visualization for ViT and feature map
visualization for ResNet-18. The difference is further analyzed through a
representation similarity perspective. We conclude that the representation of
ViT trained on small datasets is hugely different from ViT trained on large
datasets, which may be the reason why the performance drops a lot on small
datasets."
EDTER: Edge Detection with Transformer,0.972592,"Convolutional neural networks have made significant progresses in edge
detection by progressively exploring the context and semantic features.
However, local details are gradually suppressed with the enlarging of receptive
fields. Recently, vision transformer has shown excellent capability in
capturing long-range dependencies. Inspired by this, we propose a novel
transformer-based edge detector, \emph{Edge Detection TransformER (EDTER)}, to
extract clear and crisp object boundaries and meaningful edges by exploiting
the full image context information and detailed local cues simultaneously.
EDTER works in two stages. In Stage I, a global transformer encoder is used to
capture long-range global context on coarse-grained image patches. Then in
Stage II, a local transformer encoder works on fine-grained patches to excavate
the short-range local cues. Each transformer encoder is followed by an
elaborately designed Bi-directional Multi-Level Aggregation decoder to achieve
high-resolution features. Finally, the global context and local cues are
combined by a Feature Fusion Module and fed into a decision head for edge
prediction. Extensive experiments on BSDS500, NYUDv2, and Multicue demonstrate
the superiority of EDTER in comparison with state-of-the-arts."
Target-aware Abstractive Related Work Generation with Contrastive Learning,0.926192,"The related work section is an important component of a scientific paper,
which highlights the contribution of the target paper in the context of the
reference papers. Authors can save their time and effort by using the
automatically generated related work section as a draft to complete the final
related work. Most of the existing related work section generation methods rely
on extracting off-the-shelf sentences to make a comparative discussion about
the target work and the reference papers. However, such sentences need to be
written in advance and are hard to obtain in practice. Hence, in this paper, we
propose an abstractive target-aware related work generator (TAG), which can
generate related work sections consisting of new sentences. Concretely, we
first propose a target-aware graph encoder, which models the relationships
between reference papers and the target paper with target-centered attention
mechanisms. In the decoding process, we propose a hierarchical decoder that
attends to the nodes of different levels in the graph with keyphrases as
semantic indicators. Finally, to generate a more informative related work, we
propose multi-level contrastive optimization objectives, which aim to maximize
the mutual information between the generated related work with the references
and minimize that with non-references. Extensive experiments on two public
scholar datasets show that the proposed model brings substantial improvements
over several strong baselines in terms of automatic and tailored human
evaluations."
STRUDEL: Structured Dialogue Summarization for Dialogue Comprehension,0.0552586,"Abstractive dialogue summarization has long been viewed as an important
standalone task in natural language processing, but no previous work has
explored the possibility of whether abstractive dialogue summarization can also
be used as a means to boost an NLP system's performance on other important
dialogue comprehension tasks. In this paper, we propose a novel type of
dialogue summarization task - STRUctured DiaLoguE Summarization - that can help
pre-trained language models to better understand dialogues and improve their
performance on important dialogue comprehension tasks. We further collect human
annotations of STRUDEL summaries over 400 dialogues and introduce a new STRUDEL
dialogue comprehension modeling framework that integrates STRUDEL into a
graph-neural-network-based dialogue reasoning module over transformer encoder
language models to improve their dialogue comprehension abilities. In our
empirical experiments on two important downstream dialogue comprehension tasks
- dialogue question answering and dialogue response prediction - we show that
our STRUDEL dialogue comprehension model can significantly improve the dialogue
comprehension performance of transformer encoder language models."
Training Robots without Robots: Deep Imitation Learning for Master-to-Robot Policy Transfer,0.750612,"Deep imitation learning is promising for robot manipulation because it only
requires demonstration samples. In this study, deep imitation learning is
applied to tasks that require force feedback. However, existing demonstration
methods have deficiencies; bilateral teleoperation requires a complex control
scheme and is expensive, and kinesthetic teaching suffers from visual
distractions from human intervention. This research proposes a new
master-to-robot (M2R) policy transfer system that does not require robots for
teaching force feedback-based manipulation tasks. The human directly
demonstrates a task using a controller. This controller resembles the kinematic
parameters of the robot arm and uses the same end-effector with force/torque
(F/T) sensors to measure the force feedback. Using this controller, the
operator can feel force feedback without a bilateral system. The proposed
method can overcome domain gaps between the master and robot using gaze-based
imitation learning and a simple calibration method. Furthermore, a Transformer
is applied to infer policy from F/T sensory input. The proposed system was
evaluated on a bottle-cap-opening task that requires force feedback."
Deep Learning with Logical Constraints,0.699618,"In recent years, there has been an increasing interest in exploiting
logically specified background knowledge in order to obtain neural models (i)
with a better performance, (ii) able to learn from less data, and/or (iii)
guaranteed to be compliant with the background knowledge itself, e.g., for
safety-critical applications. In this survey, we retrace such works and
categorize them based on (i) the logical language that they use to express the
background knowledge and (ii) the goals that they achieve."
A Pathway Towards Responsible AI Generated Content,0.947196,"AI Generated Content (AIGC) has received tremendous attention within the past
few years, with content generated in the format of image, text, audio, video,
etc. Meanwhile, AIGC has become a double-edged sword and recently received much
criticism regarding its responsible usage. In this article, we focus on 8 main
concerns that may hinder the healthy development and deployment of AIGC in
practice, including risks from (1) privacy; (2) bias, toxicity, misinformation;
(3) intellectual property (IP); (4) robustness; (5) open source and
explanation; (6) technology abuse; (7) consent, credit, and compensation; (8)
environment. Additionally, we provide insights into the promising directions
for tackling these risks while constructing generative models, enabling AIGC to
be used more responsibly to truly benefit society."
Transformer Memory as a Differentiable Search Index,0.999907,"In this paper, we demonstrate that information retrieval can be accomplished
with a single Transformer, in which all information about the corpus is encoded
in the parameters of the model. To this end, we introduce the Differentiable
Search Index (DSI), a new paradigm that learns a text-to-text model that maps
string queries directly to relevant docids; in other words, a DSI model answers
queries directly using only its parameters, dramatically simplifying the whole
retrieval process. We study variations in how documents and their identifiers
are represented, variations in training procedures, and the interplay between
models and corpus sizes. Experiments demonstrate that given appropriate design
choices, DSI significantly outperforms strong baselines such as dual encoder
models. Moreover, DSI demonstrates strong generalization capabilities,
outperforming a BM25 baseline in a zero-shot setup."
Plug-and-Play Adaptation for Continuously-updated QA,0.70371,"Language models (LMs) have shown great potential as implicit knowledge bases
(KBs). And for their practical use, knowledge in LMs need to be updated
periodically. However, existing tasks to assess LMs' efficacy as KBs do not
adequately consider multiple large-scale updates. To this end, we first propose
a novel task--Continuously-updated QA (CuQA)--in which multiple large-scale
updates are made to LMs, and the performance is measured with respect to the
success in adding and updating knowledge while retaining existing knowledge. We
then present LMs with plug-in modules that effectively handle the updates.
Experiments conducted on zsRE QA and NQ datasets show that our method
outperforms existing approaches. We find that our method is 4x more effective
in terms of updates/forgets ratio, compared to a fine-tuning baseline."
Extractive is not Faithful: An Investigation of Broad Unfaithfulness Problems in Extractive Summarization,0.912676,"The problems of unfaithful summaries have been widely discussed under the
context of abstractive summarization. Though extractive summarization is less
prone to the common unfaithfulness issues of abstractive summaries, does that
mean extractive is equal to faithful? Turns out that the answer is no. In this
work, we define a typology with five types of broad unfaithfulness problems
(including and beyond not-entailment) that can appear in extractive summaries,
including incorrect coreference, incomplete coreference, incorrect discourse,
incomplete discourse, as well as other misleading information. We ask humans to
label these problems out of 1600 English summaries produced by 16 diverse
extractive systems. We find that 30% of the summaries have at least one of the
five issues. To automatically detect these problems, we find that 5 existing
faithfulness evaluation metrics for summarization have poor correlations with
human judgment. To remedy this, we propose a new metric, ExtEval, that is
designed for detecting unfaithful extractive summaries and is shown to have the
best performance. We hope our work can increase the awareness of unfaithfulness
problems in extractive summarization and help future work to evaluate and
resolve these issues. Our data and code are publicly available at
https://github.com/ZhangShiyue/extractive_is_not_faithful"
Concentration Network for Reinforcement Learning of Large-Scale Multi-Agent Systems,0.468815,"When dealing with a series of imminent issues, humans can naturally
concentrate on a subset of these concerning issues by prioritizing them
according to their contributions to motivational indices, e.g., the probability
of winning a game. This idea of concentration offers insights into
reinforcement learning of sophisticated Large-scale Multi-Agent Systems (LMAS)
participated by hundreds of agents. In such an LMAS, each agent receives a long
series of entity observations at each step, which can overwhelm existing
aggregation networks such as graph attention networks and cause inefficiency.
In this paper, we propose a concentration network called ConcNet. First,
ConcNet scores the observed entities considering several motivational indices,
e.g., expected survival time and state value of the agents, and then ranks,
prunes, and aggregates the encodings of observed entities to extract features.
Second, distinct from the well-known attention mechanism, ConcNet has a unique
motivational subnetwork to explicitly consider the motivational indices when
scoring the observed entities. Furthermore, we present a concentration policy
gradient architecture that can learn effective policies in LMAS from scratch.
Extensive experiments demonstrate that the presented architecture has excellent
scalability and flexibility, and significantly outperforms existing methods on
LMAS benchmarks."
Counterfactual reasoning: Do language models need world knowledge for causal understanding?,0.0283709,"Current pre-trained language models have enabled remarkable improvements in
downstream tasks, but it remains difficult to distinguish effects of
statistical correlation from more systematic logical reasoning grounded on
understanding of the real world. In this paper we tease these factors apart by
leveraging counterfactual conditionals, which force language models to predict
unusual consequences based on hypothetical propositions. We introduce a set of
tests drawn from psycholinguistic experiments, as well as larger-scale
controlled datasets, to probe counterfactual predictions from a variety of
popular pre-trained language models. We find that models are consistently able
to override real-world knowledge in counterfactual scenarios, and that this
effect is more robust in case of stronger baseline world knowledge -- however,
we also find that for most models this effect appears largely to be driven by
simple lexical cues. When we mitigate effects of both world knowledge and
lexical cues to test knowledge of linguistic nuances of counterfactuals, we
find that only GPT-3 shows sensitivity to these nuances, though this
sensitivity is also non-trivially impacted by lexical associative factors."
Improving Fake News Detection of Influential Domain via Domain- and Instance-Level Transfer,0.903514,"Both real and fake news in various domains, such as politics, health, and
entertainment are spread via online social media every day, necessitating fake
news detection for multiple domains. Among them, fake news in specific domains
like politics and health has more serious potential negative impacts on the
real world (e.g., the infodemic led by COVID-19 misinformation). Previous
studies focus on multi-domain fake news detection, by equally mining and
modeling the correlation between domains. However, these multi-domain methods
suffer from a seesaw problem: the performance of some domains is often improved
at the cost of hurting the performance of other domains, which could lead to an
unsatisfying performance in specific domains. To address this issue, we propose
a Domain- and Instance-level Transfer Framework for Fake News Detection
(DITFEND), which could improve the performance of specific target domains. To
transfer coarse-grained domain-level knowledge, we train a general model with
data of all domains from the meta-learning perspective. To transfer
fine-grained instance-level knowledge and adapt the general model to a target
domain, we train a language model on the target domain to evaluate the
transferability of each data instance in source domains and re-weigh each
instance's contribution. Offline experiments on two datasets demonstrate the
effectiveness of DITFEND. Online experiments show that DITFEND brings
additional improvements over the base models in a real-world scenario."
Robust Trajectory Prediction against Adversarial Attacks,0.790037,"Trajectory prediction using deep neural networks (DNNs) is an essential
component of autonomous driving (AD) systems. However, these methods are
vulnerable to adversarial attacks, leading to serious consequences such as
collisions. In this work, we identify two key ingredients to defend trajectory
prediction models against adversarial attacks including (1) designing effective
adversarial training methods and (2) adding domain-specific data augmentation
to mitigate the performance degradation on clean data. We demonstrate that our
method is able to improve the performance by 46% on adversarial data and at the
cost of only 3% performance degradation on clean data, compared to the model
trained with clean data. Additionally, compared to existing robust methods, our
method can improve performance by 21% on adversarial examples and 9% on clean
data. Our robust model is evaluated with a planner to study its downstream
impacts. We demonstrate that our model can significantly reduce the severe
accident rates (e.g., collisions and off-road driving)."
ORCA: A Challenging Benchmark for Arabic Language Understanding,0.507601,"Due to their crucial role in all NLP, several benchmarks have been proposed
to evaluate pretrained language models. In spite of these efforts, no public
benchmark of diverse nature currently exists for evaluation of Arabic. This
makes it challenging to measure progress for both Arabic and multilingual
language models. This challenge is compounded by the fact that any benchmark
targeting Arabic needs to take into account the fact that Arabic is not a
single language but rather a collection of languages and varieties. In this
work, we introduce ORCA, a publicly available benchmark for Arabic language
understanding evaluation. ORCA is carefully constructed to cover diverse Arabic
varieties and a wide range of challenging Arabic understanding tasks exploiting
60 different datasets across seven NLU task clusters. To measure current
progress in Arabic NLU, we use ORCA to offer a comprehensive comparison between
18 multilingual and Arabic language models. We also provide a public
leaderboard with a unified single-number evaluation metric (ORCA score) to
facilitate future research."
JSRNN: Joint Sampling and Reconstruction Neural Networks for High Quality Image Compressed Sensing,0.107452,"Most Deep Learning (DL) based Compressed Sensing (DCS) algorithms adopt a
single neural network for signal reconstruction, and fail to jointly consider
the influences of the sampling operation for reconstruction. In this paper, we
propose unified framework, which jointly considers the sampling and
reconstruction process for image compressive sensing based on well-designed
cascade neural networks. Two sub-networks, which are the sampling sub-network
and the reconstruction sub-network, are included in the proposed framework. In
the sampling sub-network, an adaptive full connected layer instead of the
traditional random matrix is used to mimic the sampling operator. In the
reconstruction sub-network, a cascade network combining stacked denoising
autoencoder (SDA) and convolutional neural network (CNN) is designed to
reconstruct signals. The SDA is used to solve the signal mapping problem and
the signals are initially reconstructed. Furthermore, CNN is used to fully
recover the structure and texture features of the image to obtain better
reconstruction performance. Extensive experiments show that this framework
outperforms many other state-of-the-art methods, especially at low sampling
rates."
Matching Writers to Content Writing Tasks,0.0400634,"Businesses need content. In various forms and formats and for varied
purposes. In fact, the content marketing industry is set to be worth $412.88
billion by the end of 2021. However, according to the Content Marketing
Institute, creating engaging content is the #1 challenge that marketers face
today. We under-stand that producing great content requires great writers who
understand the business and can weave their message into reader (and search
engine) friendly content. In this project, the team has attempted to bridge the
gap between writers and projects by using AI and ML tools. We used NLP
techniques to analyze thou-sands of publicly available business articles
(corpora) to extract various defining factors for each writing sample. Through
this project we aim to automate the highly time-consuming, and often biased
task of manually shortlisting the most suitable writer for a given content
writing requirement. We believe that a tool like this will have far reaching
positive implications for both parties - businesses looking for suitable talent
for niche writing jobs as well as experienced writers and Subject Matter
Experts (SMEs) wanting to lend their services to content marketing projects.
The business gets the content they need, the content writer/ SME gets a chance
to leverage his or her talent, while the reader gets authentic content that
adds real value."
Improving Stability of Fine-Tuning Pretrained Language Models via Component-Wise Gradient Norm Clipping,0.0829001,"Fine-tuning over large pretrained language models (PLMs) has established many
state-of-the-art results. Despite its superior performance, such fine-tuning
can be unstable, resulting in significant variance in performance and potential
risks for practical applications. Previous works have attributed such
instability to the catastrophic forgetting problem in the top layers of PLMs,
which indicates iteratively that fine-tuning layers in a top-down manner is a
promising solution. In this paper, we first point out that this method does not
always work out due to the different convergence speeds of different
layers/modules. Inspired by this observation, we propose a simple
component-wise gradient norm clipping method to adjust the convergence speed
for different components. Experiment results demonstrate that our method
achieves consistent improvements in terms of generalization performance,
convergence speed, and training stability. The codebase can be found at
https://github.com/yangalan123/FineTuningStability."
Enhanced Multimodal Representation Learning with Cross-modal KD,0.242593,"This paper explores the tasks of leveraging auxiliary modalities which are
only available at training to enhance multimodal representation learning
through cross-modal Knowledge Distillation (KD). The widely adopted mutual
information maximization-based objective leads to a short-cut solution of the
weak teacher, i.e., achieving the maximum mutual information by simply making
the teacher model as weak as the student model. To prevent such a weak
solution, we introduce an additional objective term, i.e., the mutual
information between the teacher and the auxiliary modality model. Besides, to
narrow down the information gap between the student and teacher, we further
propose to minimize the conditional entropy of the teacher given the student.
Novel training schemes based on contrastive learning and adversarial learning
are designed to optimize the mutual information and the conditional entropy,
respectively. Experimental results on three popular multimodal benchmark
datasets have shown that the proposed method outperforms a range of
state-of-the-art approaches for video recognition, video retrieval and emotion
classification."
Adaptive Transformers for Robust Few-shot Cross-domain Face Anti-spoofing,0.681298,"While recent face anti-spoofing methods perform well under the intra-domain
setups, an effective approach needs to account for much larger appearance
variations of images acquired in complex scenes with different sensors for
robust performance. In this paper, we present adaptive vision transformers
(ViT) for robust cross-domain face antispoofing. Specifically, we adopt ViT as
a backbone to exploit its strength to account for long-range dependencies among
pixels. We further introduce the ensemble adapters module and feature-wise
transformation layers in the ViT to adapt to different domains for robust
performance with a few samples. Experiments on several benchmark datasets show
that the proposed models achieve both robust and competitive performance
against the state-of-the-art methods for cross-domain face anti-spoofing using
a few samples."
2-D SSM: A General Spatial Layer for Visual Transformers,0.622787,"A central objective in computer vision is to design models with appropriate
2-D inductive bias. Desiderata for 2D inductive bias include two-dimensional
position awareness, dynamic spatial locality, and translation and permutation
invariance. To address these goals, we leverage an expressive variation of the
multidimensional State Space Model (SSM). Our approach introduces efficient
parameterization, accelerated computation, and a suitable normalization scheme.
Empirically, we observe that incorporating our layer at the beginning of each
transformer block of Vision Transformers (ViT) significantly enhances
performance for multiple ViT backbones and across datasets. The new layer is
effective even with a negligible amount of additional parameters and inference
time. Ablation studies and visualizations demonstrate that the layer has a
strong 2-D inductive bias. For example, vision transformers equipped with our
layer exhibit effective performance even without positional encoding"
Accelerating System-Level Debug Using Rule Learning and Subgroup Discovery Techniques,0.0467749,"We propose a root-causing procedure for accelerating system-level debug using
rule-based techniques. We describe the procedure and how it provides high
quality debug hints for reducing the debug effort. This includes the heuristics
for engineering features from logs of many tests, and the data analytics
techniques for generating powerful debug hints. As a case study, we used these
techniques for root-causing failures of the Power Management (PM) design
feature Package-C8 and showed their effectiveness. Furthermore, we propose an
approach for mining the root-causing experience and results for reuse, to
accelerate future debug activities and reduce dependency on validation experts.
We believe that these techniques are beneficial also for other validation
activities at different levels of abstraction, for complex hardware, software
and firmware systems, both pre-silicon and post-silicon."
Certified Robust Neural Networks: Generalization and Corruption Resistance,0.345281,"Recent work have demonstrated that robustness (to ""corruption"") can be at
odds with generalization. Adversarial training, for instance, aims to reduce
the problematic susceptibility of modern neural networks to small data
perturbations. Surprisingly, overfitting is a major concern in adversarial
training despite being mostly absent in standard training. We provide here
theoretical evidence for this peculiar ""robust overfitting"" phenomenon.
Subsequently, we advance a novel distributionally robust loss function bridging
robustness and generalization. We demonstrate both theoretically as well as
empirically the loss to enjoy a certified level of robustness against two
common types of corruption--data evasion and poisoning attacks--while ensuring
guaranteed generalization. We show through careful numerical experiments that
our resulting holistic robust (HR) training procedure yields SOTA performance.
Finally, we indicate that HR training can be interpreted as a direct extension
of adversarial training and comes with a negligible additional computational
burden. A ready-to-use python library implementing our algorithm is available
at https://github.com/RyanLucas3/HR_Neural_Networks."
Towards Continuous Consistency Axiom,0.127448,"Development of new algorithms in the area of machine learning, especially
clustering, comparative studies of such algorithms as well as testing according
to software engineering principles requires availability of labeled data sets.
While standard benchmarks are made available, a broader range of such data sets
is necessary in order to avoid the problem of overfitting. In this context,
theoretical works on axiomatization of clustering algorithms, especially axioms
on clustering preserving transformations are quite a cheap way to produce
labeled data sets from existing ones. However, the frequently cited axiomatic
system of Kleinberg:2002, as we show in this paper, is not applicable for
finite dimensional Euclidean spaces, in which many algorithms like $k$-means,
operate. In particular, the so-called outer-consistency axiom fails upon making
small changes in datapoint positions and inner-consistency axiom is valid only
for identity transformation in general settings.
  Hence we propose an alternative axiomatic system, in which Kleinberg's inner
consistency axiom is replaced by a centric consistency axiom and outer
consistency axiom is replaced by motion consistency axiom. We demonstrate that
the new system is satisfiable for a hierarchical version of $k$-means with
auto-adjusted $k$, hence it is not contradictory. Additionally, as $k$-means
creates convex clusters only, we demonstrate that it is possible to create a
version detecting concave clusters and still the axiomatic system can be
satisfied. The practical application area of such an axiomatic system may be
the generation of new labeled test data from existent ones for clustering
algorithm testing. %We propose the gravitational consistency as a replacement
which does not have this deficiency."
Navigating to Objects Specified by Images,0.968765,"Images are a convenient way to specify which particular object instance an
embodied agent should navigate to. Solving this task requires semantic visual
reasoning and exploration of unknown environments. We present a system that can
perform this task in both simulation and the real world. Our modular method
solves sub-tasks of exploration, goal instance re-identification, goal
localization, and local navigation. We re-identify the goal instance in
egocentric vision using feature-matching and localize the goal instance by
projecting matched features to a map. Each sub-task is solved using
off-the-shelf components requiring zero fine-tuning. On the HM3D
InstanceImageNav benchmark, this system outperforms a baseline end-to-end RL
policy 7x and a state-of-the-art ImageNav model 2.3x (56% vs 25% success). We
deploy this system to a mobile robot platform and demonstrate effective
real-world performance, achieving an 88% success rate across a home and an
office environment."
DDXPlus: A New Dataset For Automatic Medical Diagnosis,0.537403,"There has been a rapidly growing interest in Automatic Symptom Detection
(ASD) and Automatic Diagnosis (AD) systems in the machine learning research
literature, aiming to assist doctors in telemedicine services. These systems
are designed to interact with patients, collect evidence about their symptoms
and relevant antecedents, and possibly make predictions about the underlying
diseases. Doctors would review the interactions, including the evidence and the
predictions, collect if necessary additional information from patients, before
deciding on next steps. Despite recent progress in this area, an important
piece of doctors' interactions with patients is missing in the design of these
systems, namely the differential diagnosis. Its absence is largely due to the
lack of datasets that include such information for models to train on. In this
work, we present a large-scale synthetic dataset of roughly 1.3 million
patients that includes a differential diagnosis, along with the ground truth
pathology, symptoms and antecedents for each patient. Unlike existing datasets
which only contain binary symptoms and antecedents, this dataset also contains
categorical and multi-choice symptoms and antecedents useful for efficient data
collection. Moreover, some symptoms are organized in a hierarchy, making it
possible to design systems able to interact with patients in a logical way. As
a proof-of-concept, we extend two existing AD and ASD systems to incorporate
the differential diagnosis, and provide empirical evidence that using
differentials as training signals is essential for the efficiency of such
systems or for helping doctors better understand the reasoning of those
systems."
Deep Image Fingerprint: Towards Low Budget Synthetic Image Detection and Model Lineage Analysis,0.721556,"The generation of high-quality images has become widely accessible and is a
rapidly evolving process. As a result, anyone can generate images that are
indistinguishable from real ones. This leads to a wide range of applications,
including malicious usage with deceptive intentions. Despite advances in
detection techniques for generated images, a robust detection method still
eludes us. Furthermore, model personalization techniques might affect the
detection capabilities of existing methods. In this work, we utilize the
architectural properties of convolutional neural networks (CNNs) to develop a
new detection method. Our method can detect images from a known generative
model and enable us to establish relationships between fine-tuned generative
models. We tested the method on images produced by both Generative Adversarial
Networks (GANs) and recent large text-to-image models (LTIMs) that rely on
Diffusion Models. Our approach outperforms others trained under identical
conditions and achieves comparable performance to state-of-the-art pre-trained
detection methods on images generated by Stable Diffusion and MidJourney, with
significantly fewer required train samples."
Unified Semantic Typing with Meaningful Label Inference,0.864046,"Semantic typing aims at classifying tokens or spans of interest in a textual
context into semantic categories such as relations, entity types, and event
types. The inferred labels of semantic categories meaningfully interpret how
machines understand components of text. In this paper, we present UniST, a
unified framework for semantic typing that captures label semantics by
projecting both inputs and labels into a joint semantic embedding space. To
formulate different lexical and relational semantic typing tasks as a unified
task, we incorporate task descriptions to be jointly encoded with the input,
allowing UniST to be adapted to different tasks without introducing
task-specific model components. UniST optimizes a margin ranking loss such that
the semantic relatedness of the input and labels is reflected from their
embedding similarity. Our experiments demonstrate that UniST achieves strong
performance across three semantic typing tasks: entity typing, relation
classification and event typing. Meanwhile, UniST effectively transfers
semantic knowledge of labels and substantially improves generalizability on
inferring rarely seen and unseen types. In addition, multiple semantic typing
tasks can be jointly trained within the unified framework, leading to a single
compact multi-tasking model that performs comparably to dedicated single-task
models, while offering even better transferability."
Continual Learning by Modeling Intra-Class Variation,0.195651,"It has been observed that neural networks perform poorly when the data or
tasks are presented sequentially. Unlike humans, neural networks suffer greatly
from catastrophic forgetting, making it impossible to perform life-long
learning. To address this issue, memory-based continual learning has been
actively studied and stands out as one of the best-performing methods. We
examine memory-based continual learning and identify that large variation in
the representation space is crucial for avoiding catastrophic forgetting.
Motivated by this, we propose to diversify representations by using two types
of perturbations: model-agnostic variation (i.e., the variation is generated
without the knowledge of the learned neural network) and model-based variation
(i.e., the variation is conditioned on the learned neural network). We
demonstrate that enlarging representational variation serves as a general
principle to improve continual learning. Finally, we perform empirical studies
which demonstrate that our method, as a simple plug-and-play component, can
consistently improve a number of memory-based continual learning methods by a
large margin."
Choose your Data Wisely: A Framework for Semantic Counterfactuals,0.313124,"Counterfactual explanations have been argued to be one of the most intuitive
forms of explanation. They are typically defined as a minimal set of edits on a
given data sample that, when applied, changes the output of a model on that
sample. However, a minimal set of edits is not always clear and understandable
to an end-user, as it could, for instance, constitute an adversarial example
(which is indistinguishable from the original data sample to an end-user).
Instead, there are recent ideas that the notion of minimality in the context of
counterfactuals should refer to the semantics of the data sample, and not to
the feature space. In this work, we build on these ideas, and propose a
framework that provides counterfactual explanations in terms of knowledge
graphs. We provide an algorithm for computing such explanations (given some
assumptions about the underlying knowledge), and quantitatively evaluate the
framework with a user study."
DeciWatch: A Simple Baseline for 10x Efficient 2D and 3D Pose Estimation,0.802446,"This paper proposes a simple baseline framework for video-based 2D/3D human
pose estimation that can achieve 10 times efficiency improvement over existing
works without any performance degradation, named DeciWatch. Unlike current
solutions that estimate each frame in a video, DeciWatch introduces a simple
yet effective sample-denoise-recover framework that only watches sparsely
sampled frames, taking advantage of the continuity of human motions and the
lightweight pose representation. Specifically, DeciWatch uniformly samples less
than 10% video frames for detailed estimation, denoises the estimated 2D/3D
poses with an efficient Transformer architecture, and then accurately recovers
the rest of the frames using another Transformer-based network. Comprehensive
experimental results on three video-based human pose estimation and body mesh
recovery tasks with four datasets validate the efficiency and effectiveness of
DeciWatch. Code is available at https://github.com/cure-lab/DeciWatch."
Likelihood-Based Generative Radiance Field with Latent Space Energy-Based Model for 3D-Aware Disentangled Image Representation,0.216564,"We propose the NeRF-LEBM, a likelihood-based top-down 3D-aware 2D image
generative model that incorporates 3D representation via Neural Radiance Fields
(NeRF) and 2D imaging process via differentiable volume rendering. The model
represents an image as a rendering process from 3D object to 2D image and is
conditioned on some latent variables that account for object characteristics
and are assumed to follow informative trainable energy-based prior models. We
propose two likelihood-based learning frameworks to train the NeRF-LEBM: (i)
maximum likelihood estimation with Markov chain Monte Carlo-based inference and
(ii) variational inference with the reparameterization trick. We study our
models in the scenarios with both known and unknown camera poses. Experiments
on several benchmark datasets demonstrate that the NeRF-LEBM can infer 3D
object structures from 2D images, generate 2D images with novel views and
objects, learn from incomplete 2D images, and learn from 2D images with known
or unknown camera poses."
A Context-Sensitive Word Embedding Approach for The Detection of Troll Tweets,0.167417,"In this study, we aimed to address the growing concern of trolling behavior
on social media by developing and evaluating a set of model architectures for
the automatic detection of troll tweets. Utilizing deep learning techniques and
pre-trained word embedding methods such as BERT, ELMo, and GloVe, we evaluated
the performance of each architecture using metrics such as classification
accuracy, F1 score, AUC, and precision. Our results indicate that BERT and ELMo
embedding methods performed better than the GloVe method, likely due to their
ability to provide contextualized word embeddings that better capture the
nuances and subtleties of language use in online social media. Additionally, we
found that CNN and GRU encoders performed similarly in terms of F1 score and
AUC, suggesting their effectiveness in extracting relevant information from
input text. The best-performing method was found to be an ELMo-based
architecture that employed a GRU classifier, with an AUC score of 0.929. This
research highlights the importance of utilizing contextualized word embeddings
and appropriate encoder methods in the task of troll tweet detection, which can
assist social-based systems in improving their performance in identifying and
addressing trolling behavior on their platforms."
DisPositioNet: Disentangled Pose and Identity in Semantic Image Manipulation,0.0735788,"Graph representation of objects and their relations in a scene, known as a
scene graph, provides a precise and discernible interface to manipulate a scene
by modifying the nodes or the edges in the graph. Although existing works have
shown promising results in modifying the placement and pose of objects, scene
manipulation often leads to losing some visual characteristics like the
appearance or identity of objects. In this work, we propose DisPositioNet, a
model that learns a disentangled representation for each object for the task of
image manipulation using scene graphs in a self-supervised manner. Our
framework enables the disentanglement of the variational latent embeddings as
well as the feature representation in the graph. In addition to producing more
realistic images due to the decomposition of features like pose and identity,
our method takes advantage of the probabilistic sampling in the intermediate
features to generate more diverse images in object replacement or addition
tasks. The results of our experiments show that disentangling the feature
representations in the latent manifold of the model outperforms the previous
works qualitatively and quantitatively on two public benchmarks. Project Page:
https://scenegenie.github.io/DispositioNet/"
Few-shot Learning with Noisy Labels,0.898638,"Few-shot learning (FSL) methods typically assume clean support sets with
accurately labeled samples when training on novel classes. This assumption can
often be unrealistic: support sets, no matter how small, can still include
mislabeled samples. Robustness to label noise is therefore essential for FSL
methods to be practical, but this problem surprisingly remains largely
unexplored. To address mislabeled samples in FSL settings, we make several
technical contributions. (1) We offer simple, yet effective, feature
aggregation methods, improving the prototypes used by ProtoNet, a popular FSL
technique. (2) We describe a novel Transformer model for Noisy Few-Shot
Learning (TraNFS). TraNFS leverages a transformer's attention mechanism to
weigh mislabeled versus correct samples. (3) Finally, we extensively test these
methods on noisy versions of MiniImageNet and TieredImageNet. Our results show
that TraNFS is on-par with leading FSL methods on clean support sets, yet
outperforms them, by far, in the presence of label noise."
Event Detection Explorer: An Interactive Tool for Event Detection Exploration,0.0925276,"Event Detection (ED) is an important task in natural language processing. In
the past few years, many datasets have been introduced for advancing ED machine
learning models. However, most of these datasets are under-explored because not
many tools are available for people to study events, trigger words, and event
mention instances systematically and efficiently. In this paper, we present an
interactive and easy-to-use tool, namely ED Explorer, for ED dataset and model
exploration. ED Explorer consists of an interactive web application, an API,
and an NLP toolkit, which can help both domain experts and non-experts to
better understand the ED task. We use ED Explorer to analyze a recent proposed
large-scale ED datasets (referred to as MAVEN), and discover several underlying
problems, including sparsity, label bias, label imbalance, and debatable
annotations, which provide us with directions to improve the MAVEN dataset. The
ED Explorer can be publicly accessed through http://edx.leafnlp.org/. The
demonstration video is available here
https://www.youtube.com/watch?v=6QPnxPwxg50."
Fast Inference and Update of Probabilistic Density Estimation on Trajectory Prediction,0.7577,"Safety-critical applications such as autonomous vehicles and social robots
require fast computation and accurate probability density estimation on
trajectory prediction. To address both requirements, this paper presents a new
normalizing flow-based trajectory prediction model named FlowChain. FlowChain
is a stack of conditional continuously-indexed flows (CIFs) that are expressive
and allow analytical probability density computation. This analytical
computation is faster than the generative models that need additional
approximations such as kernel density estimation. Moreover, FlowChain is more
accurate than the Gaussian mixture-based models due to fewer assumptions on the
estimated density. FlowChain also allows a rapid update of estimated
probability densities. This update is achieved by adopting the \textit{newest
observed position} and reusing the flow transformations and its
log-det-jacobians that represent the \textit{motion trend}. This update is
completed in less than one millisecond because this reuse greatly omits the
computational cost. Experimental results showed our FlowChain achieved
state-of-the-art trajectory prediction accuracy compared to previous methods.
Furthermore, our FlowChain demonstrated superiority in the accuracy and speed
of density estimation. Our code is available at
\url{https://github.com/meaten/FlowChain-ICCV2023}"
Pruning Large Language Models via Accuracy Predictor,0.121618,"Large language models(LLMs) containing tens of billions of parameters (or
even more) have demonstrated impressive capabilities in various NLP tasks.
However, substantial model size poses challenges to training, inference, and
deployment so that it is necessary to compress the model. At present, most
model compression for LLMs requires manual design of pruning features, which
has problems such as complex optimization pipeline and difficulty in retaining
the capabilities of certain parts of the model.Therefore, we propose a novel
pruning approach: firstly, a training set of a certain number of
architecture-accuracy pairs is established, and then a non-neural model is
trained as an accuracy predictor. Using the accuracy predictor to further
optimize the search space and search, the optimal model can be automatically
selected. Experiments show that our proposed approach is effective and
efficient. Compared with the baseline, the perplexity(PPL) on Wikitext2 and PTB
dropped by 9.48% and 5,76% respectively, and the average accuracy of MMLU
increased by 6.28%."
Unsupervised Non-transferable Text Classification,0.185904,"Training a good deep learning model requires substantial data and computing
resources, which makes the resulting neural model a valuable intellectual
property. To prevent the neural network from being undesirably exploited,
non-transferable learning has been proposed to reduce the model generalization
ability in specific target domains. However, existing approaches require
labeled data for the target domain which can be difficult to obtain.
Furthermore, they do not have the mechanism to still recover the model's
ability to access the target domain. In this paper, we propose a novel
unsupervised non-transferable learning method for the text classification task
that does not require annotated target domain data. We further introduce a
secret key component in our approach for recovering the access to the target
domain, where we design both an explicit and an implicit method for doing so.
Extensive experiments demonstrate the effectiveness of our approach."
Efficient CNN Architecture Design Guided by Visualization,0.200466,"Modern efficient Convolutional Neural Networks(CNNs) always use Depthwise
Separable Convolutions(DSCs) and Neural Architecture Search(NAS) to reduce the
number of parameters and the computational complexity. But some inherent
characteristics of networks are overlooked. Inspired by visualizing feature
maps and N$\times$N(N$>$1) convolution kernels, several guidelines are
introduced in this paper to further improve parameter efficiency and inference
speed. Based on these guidelines, our parameter-efficient CNN architecture,
called \textit{VGNetG}, achieves better accuracy and lower latency than
previous networks with about 30%$\thicksim$50% parameters reduction. Our
VGNetG-1.0MP achieves 67.7% top-1 accuracy with 0.99M parameters and 69.2%
top-1 accuracy with 1.14M parameters on ImageNet classification dataset.
  Furthermore, we demonstrate that edge detectors can replace learnable
depthwise convolution layers to mix features by replacing the N$\times$N
kernels with fixed edge detection kernels. And our VGNetF-1.5MP archives
64.4%(-3.2%) top-1 accuracy and 66.2%(-1.4%) top-1 accuracy with additional
Gaussian kernels."
NeRFMeshing: Distilling Neural Radiance Fields into Geometrically-Accurate 3D Meshes,0.857539,"With the introduction of Neural Radiance Fields (NeRFs), novel view synthesis
has recently made a big leap forward. At the core, NeRF proposes that each 3D
point can emit radiance, allowing to conduct view synthesis using
differentiable volumetric rendering. While neural radiance fields can
accurately represent 3D scenes for computing the image rendering, 3D meshes are
still the main scene representation supported by most computer graphics and
simulation pipelines, enabling tasks such as real time rendering and
physics-based simulations. Obtaining 3D meshes from neural radiance fields
still remains an open challenge since NeRFs are optimized for view synthesis,
not enforcing an accurate underlying geometry on the radiance field. We thus
propose a novel compact and flexible architecture that enables easy 3D surface
reconstruction from any NeRF-driven approach. Upon having trained the radiance
field, we distill the volumetric 3D representation into a Signed Surface
Approximation Network, allowing easy extraction of the 3D mesh and appearance.
Our final 3D mesh is physically accurate and can be rendered in real time on an
array of devices."
Span-based joint entity and relation extraction augmented with sequence tagging mechanism,0.186819,"Span-based joint extraction simultaneously conducts named entity recognition
(NER) and relation extraction (RE) in text span form. However, since previous
span-based models rely on span-level classifications, they cannot benefit from
token-level label information, which has been proven advantageous for the task.
In this paper, we propose a Sequence Tagging augmented Span-based Network
(STSN), a span-based joint model that can make use of token-level label
information. In STSN, we construct a core neural architecture by deep stacking
multiple attention layers, each of which consists of three basic attention
units. On the one hand, the core architecture enables our model to learn
token-level label information via the sequence tagging mechanism and then uses
the information in the span-based joint extraction; on the other hand, it
establishes a bi-directional information interaction between NER and RE.
Experimental results on three benchmark datasets show that STSN consistently
outperforms the strongest baselines in terms of F1, creating new
state-of-the-art results."
Task-specific Pre-training and Prompt Decomposition for Knowledge Graph Population with Language Models,0.517771,"We present a system for knowledge graph population with Language Models,
evaluated on the Knowledge Base Construction from Pre-trained Language Models
(LM-KBC) challenge at ISWC 2022. Our system involves task-specific pre-training
to improve LM representation of the masked object tokens, prompt decomposition
for progressive generation of candidate objects, among other methods for
higher-quality retrieval. Our system is the winner of track 1 of the LM-KBC
challenge, based on BERT LM; it achieves 55.0% F-1 score on the hidden test set
of the challenge."
Neural Compositional Rule Learning for Knowledge Graph Reasoning,0.498224,"Learning logical rules is critical to improving reasoning in KGs. This is due
to their ability to provide logical and interpretable explanations when used
for predictions, as well as their ability to generalize to other tasks,
domains, and data. While recent methods have been proposed to learn logical
rules, the majority of these methods are either restricted by their
computational complexity and can not handle the large search space of
large-scale KGs, or show poor generalization when exposed to data outside the
training set. In this paper, we propose an end-to-end neural model for learning
compositional logical rules called NCRL. NCRL detects the best compositional
structure of a rule body, and breaks it into small compositions in order to
infer the rule head. By recurrently merging compositions in the rule body with
a recurrent attention unit, NCRL finally predicts a single rule head.
Experimental results show that NCRL learns high-quality rules, as well as being
generalizable. Specifically, we show that NCRL is scalable, efficient, and
yields state-of-the-art results for knowledge graph completion on large-scale
KGs. Moreover, we test NCRL for systematic generalization by learning to reason
on small-scale observed graphs and evaluating on larger unseen ones."
Benchmarking Zero-Shot Recognition with Vision-Language Models: Challenges on Granularity and Specificity,0.02051,"This paper presents novel benchmarks for evaluating vision-language models
(VLMs) in zero-shot recognition, focusing on granularity and specificity.
Although VLMs excel in tasks like image captioning, they face challenges in
open-world settings. Our benchmarks test VLMs' consistency in understanding
concepts across semantic granularity levels and their response to varying text
specificity. Findings show that VLMs favor moderately fine-grained concepts and
struggle with specificity, often misjudging texts that differ from their
training data. Extensive evaluations reveal limitations in current VLMs,
particularly in distinguishing between correct and subtly incorrect
descriptions. While fine-tuning offers some improvements, it doesn't fully
address these issues, highlighting the need for VLMs with enhanced
generalization capabilities for real-world applications. This study provides
insights into VLM limitations and suggests directions for developing more
robust models."
"Zoom-VQA: Patches, Frames and Clips Integration for Video Quality Assessment",0.470407,"Video quality assessment (VQA) aims to simulate the human perception of video
quality, which is influenced by factors ranging from low-level color and
texture details to high-level semantic content. To effectively model these
complicated quality-related factors, in this paper, we decompose video into
three levels (\ie, patch level, frame level, and clip level), and propose a
novel Zoom-VQA architecture to perceive spatio-temporal features at different
levels. It integrates three components: patch attention module, frame pyramid
alignment, and clip ensemble strategy, respectively for capturing
region-of-interest in the spatial dimension, multi-level information at
different feature levels, and distortions distributed over the temporal
dimension. Owing to the comprehensive design, Zoom-VQA obtains state-of-the-art
results on four VQA benchmarks and achieves 2nd place in the NTIRE 2023 VQA
challenge. Notably, Zoom-VQA has outperformed the previous best results on two
subsets of LSVQ, achieving 0.8860 (+1.0%) and 0.7985 (+1.9%) of SRCC on the
respective subsets. Adequate ablation studies further verify the effectiveness
of each component. Codes and models are released in
https://github.com/k-zha14/Zoom-VQA."
Fine-tuned vs. Prompt-tuned Supervised Representations: Which Better Account for Brain Language Representations?,0.487268,"To decipher the algorithm underlying the human brain's language
representation, previous work probed brain responses to language input with
pre-trained artificial neural network (ANN) models fine-tuned on NLU tasks.
However, full fine-tuning generally updates the entire parametric space and
distorts pre-trained features, cognitively inconsistent with the brain's robust
multi-task learning ability. Prompt-tuning, in contrast, protects pre-trained
weights and learns task-specific embeddings to fit a task. Could prompt-tuning
generate representations that better account for the brain's language
representations than fine-tuning? If so, what kind of NLU task leads a
pre-trained model to better decode the information represented in the human
brain? We investigate these questions by comparing prompt-tuned and fine-tuned
representations in neural decoding, that is predicting the linguistic stimulus
from the brain activities evoked by the stimulus. We find that on none of the
10 NLU tasks, full fine-tuning significantly outperforms prompt-tuning in
neural decoding, implicating that a more brain-consistent tuning method yields
representations that better correlate with brain data. Moreover, we identify
that tasks dealing with fine-grained concept meaning yield representations that
better decode brain activation patterns than other tasks, especially the
syntactic chunking task. This indicates that our brain encodes more
fine-grained concept information than shallow syntactic information when
representing languages."
Compositional preference models for aligning LMs,0.227535,"As language models (LMs) become more capable, it is increasingly important to
align them with human preferences. However, the dominant paradigm for training
Preference Models (PMs) for that purpose suffers from fundamental limitations,
such as lack of transparency and scalability, along with susceptibility to
overfitting the preference dataset. We propose Compositional Preference Models
(CPMs), a novel PM framework that decomposes one global preference assessment
into several interpretable features, obtains scalar scores for these features
from a prompted LM, and aggregates these scores using a logistic regression
classifier. Through these simple steps, CPMs allow to control which properties
of the preference data are used to train the preference model and to build it
based on features that are believed to underlie the human preference judgment.
Our experiments show that CPMs not only improve generalization and are more
robust to overoptimization than standard PMs, but also that best-of-n samples
obtained using CPMs tend to be preferred over samples obtained using
conventional PMs. Overall, our approach demonstrates the benefits of endowing
PMs with priors about which features determine human preferences while relying
on LM capabilities to extract those features in a scalable and robust way."
Look to the Right: Mitigating Relative Position Bias in Extractive Question Answering,0.19095,"Extractive question answering (QA) models tend to exploit spurious
correlations to make predictions when a training set has unintended biases.
This tendency results in models not being generalizable to examples where the
correlations do not hold. Determining the spurious correlations QA models can
exploit is crucial in building generalizable QA models in real-world
applications; moreover, a method needs to be developed that prevents these
models from learning the spurious correlations even when a training set is
biased. In this study, we discovered that the relative position of an answer,
which is defined as the relative distance from an answer span to the closest
question-context overlap word, can be exploited by QA models as superficial
cues for making predictions. Specifically, we find that when the relative
positions in a training set are biased, the performance on examples with
relative positions unseen during training is significantly degraded. To
mitigate the performance degradation for unseen relative positions, we propose
an ensemble-based debiasing method that does not require prior knowledge about
the distribution of relative positions. We demonstrate that the proposed method
mitigates the models' reliance on relative positions using the biased and full
SQuAD dataset. We hope that this study can help enhance the generalization
ability of QA models in real-world applications."
SpaBERT: A Pretrained Language Model from Geographic Data for Geo-Entity Representation,0.925303,"Named geographic entities (geo-entities for short) are the building blocks of
many geographic datasets. Characterizing geo-entities is integral to various
application domains, such as geo-intelligence and map comprehension, while a
key challenge is to capture the spatial-varying context of an entity. We
hypothesize that we shall know the characteristics of a geo-entity by its
surrounding entities, similar to knowing word meanings by their linguistic
context. Accordingly, we propose a novel spatial language model, SpaBERT, which
provides a general-purpose geo-entity representation based on neighboring
entities in geospatial data. SpaBERT extends BERT to capture linearized spatial
context, while incorporating a spatial coordinate embedding mechanism to
preserve spatial relations of entities in the 2-dimensional space. SpaBERT is
pretrained with masked language modeling and masked entity prediction tasks to
learn spatial dependencies. We apply SpaBERT to two downstream tasks:
geo-entity typing and geo-entity linking. Compared with the existing language
models that do not use spatial context, SpaBERT shows significant performance
improvement on both tasks. We also analyze the entity representation from
SpaBERT in various settings and the effect of spatial coordinate embedding."
(Psycho-)Linguistic Features Meet Transformer Models for Improved Explainable and Controllable Text Simplification,0.0217657,"State-of-the-art text simplification (TS) systems adopt end-to-end neural
network models to directly generate the simplified version of the input text,
and usually function as a blackbox. Moreover, TS is usually treated as an
all-purpose generic task under the assumption of homogeneity, where the same
simplification is suitable for all. In recent years, however, there has been
increasing recognition of the need to adapt the simplification techniques to
the specific needs of different target groups. In this work, we aim to advance
current research on explainable and controllable TS in two ways: First,
building on recently proposed work to increase the transparency of TS systems,
we use a large set of (psycho-)linguistic features in combination with
pre-trained language models to improve explainable complexity prediction.
Second, based on the results of this preliminary task, we extend a
state-of-the-art Seq2Seq TS model, ACCESS, to enable explicit control of ten
attributes. The results of experiments show (1) that our approach improves the
performance of state-of-the-art models for predicting explainable complexity
and (2) that explicitly conditioning the Seq2Seq model on ten attributes leads
to a significant improvement in performance in both within-domain and
out-of-domain settings."
Towards Weakly-Supervised Text Spotting using a Multi-Task Transformer,0.948658,"Text spotting end-to-end methods have recently gained attention in the
literature due to the benefits of jointly optimizing the text detection and
recognition components. Existing methods usually have a distinct separation
between the detection and recognition branches, requiring exact annotations for
the two tasks. We introduce TextTranSpotter (TTS), a transformer-based approach
for text spotting and the first text spotting framework which may be trained
with both fully- and weakly-supervised settings. By learning a single latent
representation per word detection, and using a novel loss function based on the
Hungarian loss, our method alleviates the need for expensive localization
annotations. Trained with only text transcription annotations on real data, our
weakly-supervised method achieves competitive performance with previous
state-of-the-art fully-supervised methods. When trained in a fully-supervised
manner, TextTranSpotter shows state-of-the-art results on multiple benchmarks."
Towards Afrocentric NLP for African Languages: Where We Are and Where We Can Go,0.489895,"Aligning with ACL 2022 special Theme on ""Language Diversity: from Low
Resource to Endangered Languages"", we discuss the major linguistic and
sociopolitical challenges facing development of NLP technologies for African
languages. Situating African languages in a typological framework, we discuss
how the particulars of these languages can be harnessed. To facilitate future
research, we also highlight current efforts, communities, venues, datasets, and
tools. Our main objective is to motivate and advocate for an Afrocentric
approach to technology development. With this in mind, we recommend
\textit{what} technologies to build and \textit{how} to build, evaluate, and
deploy them based on the needs of local African communities."
BOLAA: Benchmarking and Orchestrating LLM-augmented Autonomous Agents,0.9684,"The massive successes of large language models (LLMs) encourage the emerging
exploration of LLM-augmented Autonomous Agents (LAAs). An LAA is able to
generate actions with its core LLM and interact with environments, which
facilitates the ability to resolve complex tasks by conditioning on past
interactions such as observations and actions. Since the investigation of LAA
is still very recent, limited explorations are available. Therefore, we provide
a comprehensive comparison of LAA in terms of both agent architectures and LLM
backbones. Additionally, we propose a new strategy to orchestrate multiple LAAs
such that each labor LAA focuses on one type of action, \textit{i.e.} BOLAA,
where a controller manages the communication among multiple agents. We conduct
simulations on both decision-making and multi-step reasoning environments,
which comprehensively justify the capacity of LAAs. Our performance results
provide quantitative suggestions for designing LAA architectures and the
optimal choice of LLMs, as well as the compatibility of both. We release our
implementation code of LAAs to the public at
\url{https://github.com/salesforce/BOLAA}."
Dual-Scale Single Image Dehazing Via Neural Augmentation,0.927653,"Model-based single image dehazing algorithms restore haze-free images with
sharp edges and rich details for real-world hazy images at the expense of low
PSNR and SSIM values for synthetic hazy images. Data-driven ones restore
haze-free images with high PSNR and SSIM values for synthetic hazy images but
with low contrast, and even some remaining haze for real world hazy images. In
this paper, a novel single image dehazing algorithm is introduced by combining
model-based and data-driven approaches. Both transmission map and atmospheric
light are first estimated by the model-based methods, and then refined by
dual-scale generative adversarial networks (GANs) based approaches. The
resultant algorithm forms a neural augmentation which converges very fast while
the corresponding data-driven approach might not converge. Haze-free images are
restored by using the estimated transmission map and atmospheric light as well
as the Koschmiederlaw. Experimental results indicate that the proposed
algorithm can remove haze well from real-world and synthetic hazy images."
"Layout-Aware Information Extraction for Document-Grounded Dialogue: Dataset, Method and Demonstration",0.562066,"Building document-grounded dialogue systems have received growing interest as
documents convey a wealth of human knowledge and commonly exist in enterprises.
Wherein, how to comprehend and retrieve information from documents is a
challenging research problem. Previous work ignores the visual property of
documents and treats them as plain text, resulting in incomplete modality. In
this paper, we propose a Layout-aware document-level Information Extraction
dataset, LIE, to facilitate the study of extracting both structural and
semantic knowledge from visually rich documents (VRDs), so as to generate
accurate responses in dialogue systems. LIE contains 62k annotations of three
extraction tasks from 4,061 pages in product and official documents, becoming
the largest VRD-based information extraction dataset to the best of our
knowledge. We also develop benchmark methods that extend the token-based
language model to consider layout features like humans. Empirical results show
that layout is critical for VRD-based extraction, and system demonstration also
verifies that the extracted knowledge can help locate the answers that users
care about."
Explainability in reinforcement learning: perspective and position,0.467401,"Artificial intelligence (AI) has been embedded into many aspects of people's
daily lives and it has become normal for people to have AI make decisions for
them. Reinforcement learning (RL) models increase the space of solvable
problems with respect to other machine learning paradigms. Some of the most
interesting applications are in situations with non-differentiable expected
reward function, operating in unknown or underdefined environment, as well as
for algorithmic discovery that surpasses performance of any teacher, whereby
agent learns from experimental experience through simple feedback. The range of
applications and their social impact is vast, just to name a few: genomics,
game-playing (chess, Go, etc.), general optimization, financial investment,
governmental policies, self-driving cars, recommendation systems, etc. It is
therefore essential to improve the trust and transparency of RL-based systems
through explanations. Most articles dealing with explainability in artificial
intelligence provide methods that concern supervised learning and there are
very few articles dealing with this in the area of RL. The reasons for this are
the credit assignment problem, delayed rewards, and the inability to assume
that data is independently and identically distributed (i.i.d.). This position
paper attempts to give a systematic overview of existing methods in the
explainable RL area and propose a novel unified taxonomy, building and
expanding on the existing ones. The position section describes pragmatic
aspects of how explainability can be observed. The gap between the parties
receiving and generating the explanation is especially emphasized. To reduce
the gap and achieve honesty and truthfulness of explanations, we set up three
pillars: proactivity, risk attitudes, and epistemological constraints. To this
end, we illustrate our proposal on simple variants of the shortest path
problem."
MDQE: Mining Discriminative Query Embeddings to Segment Occluded Instances on Challenging Videos,0.493433,"While impressive progress has been achieved, video instance segmentation
(VIS) methods with per-clip input often fail on challenging videos with
occluded objects and crowded scenes. This is mainly because instance queries in
these methods cannot encode well the discriminative embeddings of instances,
making the query-based segmenter difficult to distinguish those `hard'
instances. To address these issues, we propose to mine discriminative query
embeddings (MDQE) to segment occluded instances on challenging videos. First,
we initialize the positional embeddings and content features of object queries
by considering their spatial contextual information and the inter-frame object
motion. Second, we propose an inter-instance mask repulsion loss to distance
each instance from its nearby non-target instances. The proposed MDQE is the
first VIS method with per-clip input that achieves state-of-the-art results on
challenging videos and competitive performance on simple videos. In specific,
MDQE with ResNet50 achieves 33.0\% and 44.5\% mask AP on OVIS and YouTube-VIS
2021, respectively. Code of MDQE can be found at
\url{https://github.com/MinghanLi/MDQE_CVPR2023}."
Sanity checks for patch visualisation in prototype-based image classification,0.160223,"In this work, we perform an analysis of the visualisation methods implemented
in ProtoPNet and ProtoTree, two self-explaining visual classifiers based on
prototypes. We show that such methods do not correctly identify the regions of
interest inside of the images, and therefore do not reflect the model
behaviour, which can create a false sense of bias in the model. We also
demonstrate quantitatively that this issue can be mitigated by using other
saliency methods that provide more faithful image patches."
V2X-ViT: Vehicle-to-Everything Cooperative Perception with Vision Transformer,0.997489,"In this paper, we investigate the application of Vehicle-to-Everything (V2X)
communication to improve the perception performance of autonomous vehicles. We
present a robust cooperative perception framework with V2X communication using
a novel vision Transformer. Specifically, we build a holistic attention model,
namely V2X-ViT, to effectively fuse information across on-road agents (i.e.,
vehicles and infrastructure). V2X-ViT consists of alternating layers of
heterogeneous multi-agent self-attention and multi-scale window self-attention,
which captures inter-agent interaction and per-agent spatial relationships.
These key modules are designed in a unified Transformer architecture to handle
common V2X challenges, including asynchronous information sharing, pose errors,
and heterogeneity of V2X components. To validate our approach, we create a
large-scale V2X perception dataset using CARLA and OpenCDA. Extensive
experimental results demonstrate that V2X-ViT sets new state-of-the-art
performance for 3D object detection and achieves robust performance even under
harsh, noisy environments. The code is available at
https://github.com/DerrickXuNu/v2x-vit."
Artificial Intelligence Nomenclature Identified From Delphi Study on Key Issues Related to Trust and Barriers to Adoption for Autonomous Systems,0.114716,"The rapid integration of artificial intelligence across traditional research
domains has generated an amalgamation of nomenclature. As cross-discipline
teams work together on complex machine learning challenges, finding a consensus
of basic definitions in the literature is a more fundamental problem. As a step
in the Delphi process to define issues with trust and barriers to the adoption
of autonomous systems, our study first collected and ranked the top concerns
from a panel of international experts from the fields of engineering, computer
science, medicine, aerospace, and defence, with experience working with
artificial intelligence. This document presents a summary of the literature
definitions for nomenclature derived from expert feedback."
Adapting the Exploration Rate for Value-of-Information-Based Reinforcement Learning,0.413733,"In this paper, we consider the problem of adjusting the exploration rate when
using value-of-information-based exploration. We do this by converting the
value-of-information optimization into a problem of finding equilibria of a
flow for a changing exploration rate. We then develop an efficient
path-following scheme for converging to these equilibria and hence uncovering
optimal action-selection policies. Under this scheme, the exploration rate is
automatically adapted according to the agent's experiences. Global convergence
is theoretically assured.
  We first evaluate our exploration-rate adaptation on the Nintendo GameBoy
games Centipede and Millipede. We demonstrate aspects of the search process,
like that it yields a hierarchy of state abstractions. We also show that our
approach returns better policies in fewer episodes than conventional search
strategies relying on heuristic, annealing-based exploration-rate adjustments.
We then illustrate that these trends hold for deep, value-of-information-based
agents that learn to play ten simple games and over forty more complicated
games for the Nintendo GameBoy system. Performance either near or well above
the level of human play is observed."
Robust $Q$-learning Algorithm for Markov Decision Processes under Wasserstein Uncertainty,0.885303,"We present a novel $Q$-learning algorithm to solve distributionally robust
Markov decision problems, where the corresponding ambiguity set of transition
probabilities for the underlying Markov decision process is a Wasserstein ball
around a (possibly estimated) reference measure. We prove convergence of the
presented algorithm and provide several examples also using real data to
illustrate both the tractability of our algorithm as well as the benefits of
considering distributional robustness when solving stochastic optimal control
problems, in particular when the estimated distributions turn out to be
misspecified in practice."
DaliID: Distortion-Adaptive Learned Invariance for Identification Models,0.221516,"In unconstrained scenarios, face recognition and person re-identification are
subject to distortions such as motion blur, atmospheric turbulence, or
upsampling artifacts. To improve robustness in these scenarios, we propose a
methodology called Distortion-Adaptive Learned Invariance for Identification
(DaliID) models. We contend that distortion augmentations, which degrade image
quality, can be successfully leveraged to a greater degree than has been shown
in the literature. Aided by an adaptive weighting schedule, a novel distortion
augmentation is applied at severe levels during training. This training
strategy increases feature-level invariance to distortions and decreases domain
shift to unconstrained scenarios. At inference, we use a magnitude-weighted
fusion of features from parallel models to retain robustness across the range
of images. DaliID models achieve state-of-the-art (SOTA) for both face
recognition and person re-identification on seven benchmark datasets, including
IJB-S, TinyFace, DeepChange, and MSMT17. Additionally, we provide recaptured
evaluation data at a distance of 750+ meters and further validate on real
long-distance face imagery."
Efficient Knowledge Distillation from Model Checkpoints,0.716099,"Knowledge distillation is an effective approach to learn compact models
(students) with the supervision of large and strong models (teachers). As
empirically there exists a strong correlation between the performance of
teacher and student models, it is commonly believed that a high performing
teacher is preferred. Consequently, practitioners tend to use a well trained
network or an ensemble of them as the teacher. In this paper, we make an
intriguing observation that an intermediate model, i.e., a checkpoint in the
middle of the training procedure, often serves as a better teacher compared to
the fully converged model, although the former has much lower accuracy. More
surprisingly, a weak snapshot ensemble of several intermediate models from a
same training trajectory can outperform a strong ensemble of independently
trained and fully converged models, when they are used as teachers. We show
that this phenomenon can be partially explained by the information bottleneck
principle: the feature representations of intermediate models can have higher
mutual information regarding the input, and thus contain more ""dark knowledge""
for effective distillation. We further propose an optimal intermediate teacher
selection algorithm based on maximizing the total task-related mutual
information. Experiments verify its effectiveness and applicability."
Two-person Graph Convolutional Network for Skeleton-based Human Interaction Recognition,0.642567,"Graph convolutional networks (GCNs) have been the predominant methods in
skeleton-based human action recognition, including human-human interaction
recognition. However, when dealing with interaction sequences, current
GCN-based methods simply split the two-person skeleton into two discrete graphs
and perform graph convolution separately as done for single-person action
classification. Such operations ignore rich interactive information and hinder
effective spatial inter-body relationship modeling. To overcome the above
shortcoming, we introduce a novel unified two-person graph to represent
inter-body and intra-body correlations between joints. Experiments show
accuracy improvements in recognizing both interactions and individual actions
when utilizing the proposed two-person graph topology. In addition, We design
several graph labeling strategies to supervise the model to learn discriminant
spatial-temporal interactive features. Finally, we propose a two-person graph
convolutional network (2P-GCN). Our model achieves state-of-the-art results on
four benchmarks of three interaction datasets: SBU, interaction subsets of
NTU-RGB+D and NTU-RGB+D 120."
Adversarially-Aware Robust Object Detector,0.641784,"Object detection, as a fundamental computer vision task, has achieved a
remarkable progress with the emergence of deep neural networks. Nevertheless,
few works explore the adversarial robustness of object detectors to resist
adversarial attacks for practical applications in various real-world scenarios.
Detectors have been greatly challenged by unnoticeable perturbation, with sharp
performance drop on clean images and extremely poor performance on adversarial
images. In this work, we empirically explore the model training for adversarial
robustness in object detection, which greatly attributes to the conflict
between learning clean images and adversarial images. To mitigate this issue,
we propose a Robust Detector (RobustDet) based on adversarially-aware
convolution to disentangle gradients for model learning on clean and
adversarial images. RobustDet also employs the Adversarial Image Discriminator
(AID) and Consistent Features with Reconstruction (CFR) to ensure a reliable
robustness. Extensive experiments on PASCAL VOC and MS-COCO demonstrate that
our model effectively disentangles gradients and significantly enhances the
detection robustness with maintaining the detection ability on clean images."
SVBR-NET: A Non-Blind Spatially Varying Defocus Blur Removal Network,0.354552,"Defocus blur is a physical consequence of the optical sensors used in most
cameras. Although it can be used as a photographic style, it is commonly viewed
as an image degradation modeled as the convolution of a sharp image with a
spatially-varying blur kernel. Motivated by the advance of blur estimation
methods in the past years, we propose a non-blind approach for image deblurring
that can deal with spatially-varying kernels. We introduce two encoder-decoder
sub-networks that are fed with the blurry image and the estimated blur map,
respectively, and produce as output the deblurred (deconvolved) image. Each
sub-network presents several skip connections that allow data propagation from
layers spread apart, and also inter-subnetwork skip connections that ease the
communication between the modules. The network is trained with synthetically
blur kernels that are augmented to emulate blur maps produced by existing blur
estimation methods, and our experimental results show that our method works
well when combined with a variety of blur estimation methods."
V$^2$L: Leveraging Vision and Vision-language Models into Large-scale Product Retrieval,0.119061,"Product retrieval is of great importance in the ecommerce domain. This paper
introduces our 1st-place solution in eBay eProduct Visual Search Challenge
(FGVC9), which is featured for an ensemble of about 20 models from vision
models and vision-language models. While model ensemble is common, we show that
combining the vision models and vision-language models brings particular
benefits from their complementarity and is a key factor to our superiority.
Specifically, for the vision models, we use a two-stage training pipeline which
first learns from the coarse labels provided in the training set and then
conducts fine-grained self-supervised training, yielding a coarse-to-fine
metric learning manner. For the vision-language models, we use the textual
description of the training image as the supervision signals for fine-tuning
the image-encoder (feature extractor). With these designs, our solution
achieves 0.7623 MAR@10, ranking the first place among all the competitors. The
code is available at: \href{https://github.com/WangWenhao0716/V2L}{V$^2$L}."
Formal concept analysis for evaluating intrinsic dimension of a natural language,0.357809,"Some results of a computational experiment for determining the intrinsic
dimension of linguistic varieties for the Bengali and Russian languages are
presented. At the same time, both sets of words and sets of bigrams in these
languages were considered separately. The method used to solve this problem was
based on formal concept analysis algorithms. It was found that the intrinsic
dimensions of these languages are significantly less than the dimensions used
in popular neural network models in natural language processing."
Joint Optimization of Class-Specific Training- and Test-Time Data Augmentation in Segmentation,0.327231,"This paper presents an effective and general data augmentation framework for
medical image segmentation. We adopt a computationally efficient and
data-efficient gradient-based meta-learning scheme to explicitly align the
distribution of training and validation data which is used as a proxy for
unseen test data. We improve the current data augmentation strategies with two
core designs. First, we learn class-specific training-time data augmentation
(TRA) effectively increasing the heterogeneity within the training subsets and
tackling the class imbalance common in segmentation. Second, we jointly
optimize TRA and test-time data augmentation (TEA), which are closely connected
as both aim to align the training and test data distribution but were so far
considered separately in previous works. We demonstrate the effectiveness of
our method on four medical image segmentation tasks across different scenarios
with two state-of-the-art segmentation models, DeepMedic and nnU-Net. Extensive
experimentation shows that the proposed data augmentation framework can
significantly and consistently improve the segmentation performance when
compared to existing solutions. Code is publicly available."
Causal Explanation for Reinforcement Learning: Quantifying State and Temporal Importance,0.149147,"Explainability plays an increasingly important role in machine learning.
Furthermore, humans view the world through a causal lens and thus prefer causal
explanations over associational ones. Therefore, in this paper, we develop a
causal explanation mechanism that quantifies the causal importance of states on
actions and such importance over time. We also demonstrate the advantages of
our mechanism over state-of-the-art associational methods in terms of RL policy
explanation through a series of simulation studies, including crop irrigation,
Blackjack, collision avoidance, and lunar lander."
EAutoDet: Efficient Architecture Search for Object Detection,0.58587,"Training CNN for detection is time-consuming due to the large dataset and
complex network modules, making it hard to search architectures on detection
datasets directly, which usually requires vast search costs (usually tens and
even hundreds of GPU-days). In contrast, this paper introduces an efficient
framework, named EAutoDet, that can discover practical backbone and FPN
architectures for object detection in 1.4 GPU-days. Specifically, we construct
a supernet for both backbone and FPN modules and adopt the differentiable
method. To reduce the GPU memory requirement and computational cost, we propose
a kernel reusing technique by sharing the weights of candidate operations on
one edge and consolidating them into one convolution. A dynamic channel
refinement strategy is also introduced to search channel numbers. Extensive
experiments show significant efficacy and efficiency of our method. In
particular, the discovered architectures surpass state-of-the-art object
detection NAS methods and achieve 40.1 mAP with 120 FPS and 49.2 mAP with 41.3
FPS on COCO test-dev set. We also transfer the discovered architectures to
rotation detection task, which achieve 77.05 mAP$_{\text{50}}$ on DOTA-v1.0
test set with 21.1M parameters."
Sensible AI: Re-imagining Interpretability and Explainability using Sensemaking Theory,0.660138,"Understanding how ML models work is a prerequisite for responsibly designing,
deploying, and using ML-based systems. With interpretability approaches, ML can
now offer explanations for its outputs to aid human understanding. Though these
approaches rely on guidelines for how humans explain things to each other, they
ultimately solve for improving the artifact -- an explanation. In this paper,
we propose an alternate framework for interpretability grounded in Weick's
sensemaking theory, which focuses on who the explanation is intended for.
Recent work has advocated for the importance of understanding stakeholders'
needs -- we build on this by providing concrete properties (e.g., identity,
social context, environmental cues, etc.) that shape human understanding. We
use an application of sensemaking in organizations as a template for discussing
design guidelines for Sensible AI, AI that factors in the nuances of human
cognition when trying to explain itself."
Focus for Free in Density-Based Counting,0.207346,"This work considers supervised learning to count from images and their
corresponding point annotations. Where density-based counting methods typically
use the point annotations only to create Gaussian-density maps, which act as
the supervision signal, the starting point of this work is that point
annotations have counting potential beyond density map generation. We introduce
two methods that repurpose the available point annotations to enhance counting
performance. The first is a counting-specific augmentation that leverages point
annotations to simulate occluded objects in both input and density images to
enhance the network's robustness to occlusions. The second method, foreground
distillation, generates foreground masks from the point annotations, from which
we train an auxiliary network on images with blacked-out backgrounds. By doing
so, it learns to extract foreground counting knowledge without interference
from the background. These methods can be seamlessly integrated with existing
counting advances and are adaptable to different loss functions. We demonstrate
complementary effects of the approaches, allowing us to achieve robust counting
results even in challenging scenarios such as background clutter, occlusion,
and varying crowd densities. Our proposed approach achieves strong counting
results on multiple datasets, including ShanghaiTech Part\_A and Part\_B,
UCF\_QNRF, JHU-Crowd++, and NWPU-Crowd."
Multiverse Transformer: 1st Place Solution for Waymo Open Sim Agents Challenge 2023,0.944255,"This technical report presents our 1st place solution for the Waymo Open Sim
Agents Challenge (WOSAC) 2023. Our proposed MultiVerse Transformer for Agent
simulation (MVTA) effectively leverages transformer-based motion prediction
approaches, and is tailored for closed-loop simulation of agents. In order to
produce simulations with a high degree of realism, we design novel training and
sampling methods, and implement a receding horizon prediction mechanism. In
addition, we introduce a variable-length history aggregation method to mitigate
the compounding error that can arise during closed-loop autoregressive
execution. On the WOSAC, our MVTA and its enhanced version MVTE reach a realism
meta-metric of 0.5091 and 0.5168, respectively, outperforming all the other
methods on the leaderboard."
Saving Dense Retriever from Shortcut Dependency in Conversational Search,0.499543,"Conversational search (CS) needs a holistic understanding of conversational
inputs to retrieve relevant passages. In this paper, we demonstrate the
existence of a retrieval shortcut in CS, which causes models to retrieve
passages solely relying on partial history while disregarding the latest
question. With in-depth analysis, we first show that naively trained dense
retrievers heavily exploit the shortcut and hence perform poorly when asked to
answer history-independent questions. To build more robust models against
shortcut dependency, we explore various hard negative mining strategies.
Experimental results show that training with the model-based hard negatives
effectively mitigates the dependency on the shortcut, significantly improving
dense retrievers on recent CS benchmarks. In particular, our retriever
outperforms the previous state-of-the-art model by 11.0 in Recall@10 on QReCC."
Bridging the Gap between Local Semantic Concepts and Bag of Visual Words for Natural Scene Image Retrieval,0.0160266,"This paper addresses the problem of semantic-based image retrieval of natural
scenes. A typical content-based image retrieval system deals with the query
image and images in the dataset as a collection of low-level features and
retrieves a ranked list of images based on the similarities between features of
the query image and features of images in the image dataset. However, top
ranked images in the retrieved list, which have high similarities to the query
image, may be different from the query image in terms of the semantic
interpretation of the user which is known as the semantic gap. In order to
reduce the semantic gap, this paper investigates how natural scene retrieval
can be performed using the bag of visual word model and the distribution of
local semantic concepts. The paper studies the efficiency of using different
approaches for representing the semantic information, depicted in natural scene
images, for image retrieval. An extensive experimental work has been conducted
to study the efficiency of using semantic information as well as the bag of
visual words model for natural and urban scene image retrieval."
QuoteR: A Benchmark of Quote Recommendation for Writing,0.252211,"It is very common to use quotations (quotes) to make our writings more
elegant or convincing. To help people find appropriate quotes efficiently, the
task of quote recommendation is presented, aiming to recommend quotes that fit
the current context of writing. There have been various quote recommendation
approaches, but they are evaluated on different unpublished datasets. To
facilitate the research on this task, we build a large and fully open quote
recommendation dataset called QuoteR, which comprises three parts including
English, standard Chinese and classical Chinese. Any part of it is larger than
previous unpublished counterparts. We conduct an extensive evaluation of
existing quote recommendation methods on QuoteR. Furthermore, we propose a new
quote recommendation model that significantly outperforms previous methods on
all three parts of QuoteR. All the code and data of this paper are available at
https://github.com/thunlp/QuoteR."
Multi-Query Video Retrieval,0.625027,"Retrieving target videos based on text descriptions is a task of great
practical value and has received increasing attention over the past few years.
Despite recent progress, imperfect annotations in existing video retrieval
datasets have posed significant challenges on model evaluation and development.
In this paper, we tackle this issue by focusing on the less-studied setting of
multi-query video retrieval, where multiple descriptions are provided to the
model for searching over the video archive. We first show that multi-query
retrieval task effectively mitigates the dataset noise introduced by imperfect
annotations and better correlates with human judgement on evaluating retrieval
abilities of current models. We then investigate several methods which leverage
multiple queries at training time, and demonstrate that the multi-query
inspired training can lead to superior performance and better generalization.
We hope further investigation in this direction can bring new insights on
building systems that perform better in real-world video retrieval
applications."
Image Super-Resolution using Efficient Striped Window Transformer,0.306799,"Transformers have achieved remarkable results in single-image
super-resolution (SR). However, the challenge of balancing model performance
and complexity has hindered their application in lightweight SR (LSR). To
tackle this challenge, we propose an efficient striped window transformer
(ESWT). We revisit the normalization layer in the transformer and design a
concise and efficient transformer structure to build the ESWT. Furthermore, we
introduce a striped window mechanism to model long-term dependencies more
efficiently. To fully exploit the potential of the ESWT, we propose a novel
flexible window training strategy that can improve the performance of the ESWT
without additional cost. Extensive experiments show that ESWT outperforms
state-of-the-art LSR transformers, and achieves a better trade-off between
model performance and complexity. The ESWT requires fewer parameters, incurs
faster inference, smaller FLOPs, and less memory consumption, making it a
promising solution for LSR."
Efficient Parametric Approximations of Neural Network Function Space Distance,0.314159,"It is often useful to compactly summarize important properties of model
parameters and training data so that they can be used later without storing
and/or iterating over the entire dataset. As a specific case, we consider
estimating the Function Space Distance (FSD) over a training set, i.e. the
average discrepancy between the outputs of two neural networks. We propose a
Linearized Activation Function TRick (LAFTR) and derive an efficient
approximation to FSD for ReLU neural networks. The key idea is to approximate
the architecture as a linear network with stochastic gating. Despite requiring
only one parameter per unit of the network, our approach outcompetes other
parametric approximations with larger memory requirements. Applied to continual
learning, our parametric approximation is competitive with state-of-the-art
nonparametric approximations, which require storing many training examples.
Furthermore, we show its efficacy in estimating influence functions accurately
and detecting mislabeled examples without expensive iterations over the entire
dataset."
AMT: All-Pairs Multi-Field Transforms for Efficient Frame Interpolation,0.851422,"We present All-Pairs Multi-Field Transforms (AMT), a new network architecture
for video frame interpolation. It is based on two essential designs. First, we
build bidirectional correlation volumes for all pairs of pixels, and use the
predicted bilateral flows to retrieve correlations for updating both flows and
the interpolated content feature. Second, we derive multiple groups of
fine-grained flow fields from one pair of updated coarse flows for performing
backward warping on the input frames separately. Combining these two designs
enables us to generate promising task-oriented flows and reduce the
difficulties in modeling large motions and handling occluded areas during frame
interpolation. These qualities promote our model to achieve state-of-the-art
performance on various benchmarks with high efficiency. Moreover, our
convolution-based model competes favorably compared to Transformer-based models
in terms of accuracy and efficiency. Our code is available at
https://github.com/MCG-NKU/AMT."
DocBed: A Multi-Stage OCR Solution for Documents with Complex Layouts,0.716781,"Digitization of newspapers is of interest for many reasons including
preservation of history, accessibility and search ability, etc. While
digitization of documents such as scientific articles and magazines is
prevalent in literature, one of the main challenges for digitization of
newspaper lies in its complex layout (e.g. articles spanning multiple columns,
text interrupted by images) analysis, which is necessary to preserve human
read-order. This work provides a major breakthrough in the digitization of
newspapers on three fronts: first, releasing a dataset of 3000 fully-annotated,
real-world newspaper images from 21 different U.S. states representing an
extensive variety of complex layouts for document layout analysis; second,
proposing layout segmentation as a precursor to existing optical character
recognition (OCR) engines, where multiple state-of-the-art image segmentation
models and several post-processing methods are explored for document layout
segmentation; third, providing a thorough and structured evaluation protocol
for isolated layout segmentation and end-to-end OCR."
Giraffe: Adventures in Expanding Context Lengths in LLMs,0.785381,"Modern large language models (LLMs) that rely on attention mechanisms are
typically trained with fixed context lengths which enforce upper limits on the
length of input sequences that they can handle at evaluation time. To use these
models on sequences longer than the train-time context length, one might employ
techniques from the growing family of context length extrapolation methods --
most of which focus on modifying the system of positional encodings used in the
attention mechanism to indicate where tokens or activations are located in the
input sequence. We conduct a wide survey of existing methods of context length
extrapolation on a base LLaMA or LLaMA 2 model, and introduce some of our own
design as well -- in particular, a new truncation strategy for modifying the
basis for the position encoding.
  We test these methods using three new evaluation tasks (FreeFormQA,
AlteredNumericQA, and LongChat-Lines) as well as perplexity, which we find to
be less fine-grained as a measure of long context performance of LLMs. We
release the three tasks publicly as datasets on HuggingFace. We discover that
linear scaling is the best method for extending context length, and show that
further gains can be achieved by using longer scales at evaluation time. We
also discover promising extrapolation capabilities in the truncated basis. To
support further research in this area, we release three new 13B parameter
long-context models which we call Giraffe: 4k and 16k context models trained
from base LLaMA-13B, and a 32k context model trained from base LLaMA2-13B. We
also release the code to replicate our results."
SFD2: Semantic-guided Feature Detection and Description,0.90005,"Visual localization is a fundamental task for various applications including
autonomous driving and robotics. Prior methods focus on extracting large
amounts of often redundant locally reliable features, resulting in limited
efficiency and accuracy, especially in large-scale environments under
challenging conditions. Instead, we propose to extract globally reliable
features by implicitly embedding high-level semantics into both the detection
and description processes. Specifically, our semantic-aware detector is able to
detect keypoints from reliable regions (e.g. building, traffic lane) and
suppress unreliable areas (e.g. sky, car) implicitly instead of relying on
explicit semantic labels. This boosts the accuracy of keypoint matching by
reducing the number of features sensitive to appearance changes and avoiding
the need of additional segmentation networks at test time. Moreover, our
descriptors are augmented with semantics and have stronger discriminative
ability, providing more inliers at test time. Particularly, experiments on
long-term large-scale visual localization Aachen Day-Night and RobotCar-Seasons
datasets demonstrate that our model outperforms previous local features and
gives competitive accuracy to advanced matchers but is about 2 and 3 times
faster when using 2k and 4k keypoints, respectively."
Privacy-friendly Synthetic Data for the Development of Face Morphing Attack Detectors,0.997949,"The main question this work aims at answering is: ""can morphing attack
detection (MAD) solutions be successfully developed based on synthetic data?"".
Towards that, this work introduces the first synthetic-based MAD development
dataset, namely the Synthetic Morphing Attack Detection Development dataset
(SMDD). This dataset is utilized successfully to train three MAD backbones
where it proved to lead to high MAD performance, even on completely unknown
attack types. Additionally, an essential aspect of this work is the detailed
legal analyses of the challenges of using and sharing real biometric data,
rendering our proposed SMDD dataset extremely essential. The SMDD dataset,
consisting of 30,000 attack and 50,000 bona fide samples, is publicly available
for research purposes."
Memory-Based Model Editing at Scale,0.999571,"Even the largest neural networks make errors, and once-correct predictions
can become invalid as the world changes. Model editors make local updates to
the behavior of base (pre-trained) models to inject updated knowledge or
correct undesirable behaviors. Existing model editors have shown promise, but
also suffer from insufficient expressiveness: they struggle to accurately model
an edit's intended scope (examples affected by the edit), leading to inaccurate
predictions for test inputs loosely related to the edit, and they often fail
altogether after many edits. As a higher-capacity alternative, we propose
Semi-Parametric Editing with a Retrieval-Augmented Counterfactual Model
(SERAC), which stores edits in an explicit memory and learns to reason over
them to modulate the base model's predictions as needed. To enable more
rigorous evaluation of model editors, we introduce three challenging language
model editing problems based on question answering, fact-checking, and dialogue
generation. We find that only SERAC achieves high performance on all three
problems, consistently outperforming existing approaches to model editing by a
significant margin. Code, data, and additional project information will be made
available at https://sites.google.com/view/serac-editing."
Unsupervised detection of ash dieback disease (Hymenoscyphus fraxineus) using diffusion-based hyperspectral image clustering,0.293011,"Ash dieback (Hymenoscyphus fraxineus) is an introduced fungal disease that is
causing the widespread death of ash trees across Europe. Remote sensing
hyperspectral images encode rich structure that has been exploited for the
detection of dieback disease in ash trees using supervised machine learning
techniques. However, to understand the state of forest health at
landscape-scale, accurate unsupervised approaches are needed. This article
investigates the use of the unsupervised Diffusion and VCA-Assisted Image
Segmentation (D-VIS) clustering algorithm for the detection of ash dieback
disease in a forest site near Cambridge, United Kingdom. The unsupervised
clustering presented in this work has high overlap with the supervised
classification of previous work on this scene (overall accuracy = 71%). Thus,
unsupervised learning may be used for the remote detection of ash dieback
disease without the need for expert labeling."
From Natural Language to Simulations: Applying GPT-3 Codex to Automate Simulation Modeling of Logistics Systems,0.155158,"Our work is the first attempt to apply Natural Language Processing to
automate the development of simulation models of systems vitally important for
logistics. We demonstrated that the framework built on top of the fine-tuned
GPT-3 Codex, a Transformer-based language model, could produce functionally
valid simulations of queuing and inventory control systems given the verbal
description. In conducted experiments, GPT-3 Codex demonstrated convincing
expertise in Python as well as an understanding of the domain-specific
vocabulary. As a result, the language model could produce simulations of a
single-product inventory-control system and single-server queuing system given
the domain-specific context, a detailed description of the process, and a list
of variables with the corresponding values. The demonstrated results, along
with the rapid improvement of language models, open the door for significant
simplification of the workflow behind the simulation model development, which
will allow experts to focus on the high-level consideration of the problem and
holistic thinking."
On the Impact of Temporal Concept Drift on Model Explanations,0.868386,"Explanation faithfulness of model predictions in natural language processing
is typically evaluated on held-out data from the same temporal distribution as
the training data (i.e. synchronous settings). While model performance often
deteriorates due to temporal variation (i.e. temporal concept drift), it is
currently unknown how explanation faithfulness is impacted when the time span
of the target data is different from the data used to train the model (i.e.
asynchronous settings). For this purpose, we examine the impact of temporal
variation on model explanations extracted by eight feature attribution methods
and three select-then-predict models across six text classification tasks. Our
experiments show that (i)faithfulness is not consistent under temporal
variations across feature attribution methods (e.g. it decreases or increases
depending on the method), with an attention-based method demonstrating the most
robust faithfulness scores across datasets; and (ii) select-then-predict models
are mostly robust in asynchronous settings with only small degradation in
predictive performance. Finally, feature attribution methods show conflicting
behavior when used in FRESH (i.e. a select-and-predict model) and for measuring
sufficiency/comprehensiveness (i.e. as post-hoc methods), suggesting that we
need more robust metrics to evaluate post-hoc explanation faithfulness."
"Mapping the Multilingual Margins: Intersectional Biases of Sentiment Analysis Systems in English, Spanish, and Arabic",0.672362,"As natural language processing systems become more widespread, it is
necessary to address fairness issues in their implementation and deployment to
ensure that their negative impacts on society are understood and minimized.
However, there is limited work that studies fairness using a multilingual and
intersectional framework or on downstream tasks. In this paper, we introduce
four multilingual Equity Evaluation Corpora, supplementary test sets designed
to measure social biases, and a novel statistical framework for studying
unisectional and intersectional social biases in natural language processing.
We use these tools to measure gender, racial, ethnic, and intersectional social
biases across five models trained on emotion regression tasks in English,
Spanish, and Arabic. We find that many systems demonstrate statistically
significant unisectional and intersectional social biases."
Overview of Abusive and Threatening Language Detection in Urdu at FIRE 2021,0.637737,"With the growth of social media platform influence, the effect of their
misuse becomes more and more impactful. The importance of automatic detection
of threatening and abusive language can not be overestimated. However, most of
the existing studies and state-of-the-art methods focus on English as the
target language, with limited work on low- and medium-resource languages. In
this paper, we present two shared tasks of abusive and threatening language
detection for the Urdu language which has more than 170 million speakers
worldwide. Both are posed as binary classification tasks where participating
systems are required to classify tweets in Urdu into two classes, namely: (i)
Abusive and Non-Abusive for the first task, and (ii) Threatening and
Non-Threatening for the second. We present two manually annotated datasets
containing tweets labelled as (i) Abusive and Non-Abusive, and (ii) Threatening
and Non-Threatening. The abusive dataset contains 2400 annotated tweets in the
train part and 1100 annotated tweets in the test part. The threatening dataset
contains 6000 annotated tweets in the train part and 3950 annotated tweets in
the test part. We also provide logistic regression and BERT-based baseline
classifiers for both tasks. In this shared task, 21 teams from six countries
registered for participation (India, Pakistan, China, Malaysia, United Arab
Emirates, and Taiwan), 10 teams submitted their runs for Subtask A, which is
Abusive Language Detection and 9 teams submitted their runs for Subtask B,
which is Threatening Language detection, and seven teams submitted their
technical reports. The best performing system achieved an F1-score value of
0.880 for Subtask A and 0.545 for Subtask B. For both subtasks, m-Bert based
transformer model showed the best performance."
GANHead: Towards Generative Animatable Neural Head Avatars,0.180686,"To bring digital avatars into people's lives, it is highly demanded to
efficiently generate complete, realistic, and animatable head avatars. This
task is challenging, and it is difficult for existing methods to satisfy all
the requirements at once. To achieve these goals, we propose GANHead
(Generative Animatable Neural Head Avatar), a novel generative head model that
takes advantages of both the fine-grained control over the explicit expression
parameters and the realistic rendering results of implicit representations.
Specifically, GANHead represents coarse geometry, fine-gained details and
texture via three networks in canonical space to obtain the ability to generate
complete and realistic head avatars. To achieve flexible animation, we define
the deformation filed by standard linear blend skinning (LBS), with the learned
continuous pose and expression bases and LBS weights. This allows the avatars
to be directly animated by FLAME parameters and generalize well to unseen poses
and expressions. Compared to state-of-the-art (SOTA) methods, GANHead achieves
superior performance on head avatar generation and raw scan fitting."
ADVISER: AI-Driven Vaccination Intervention Optimiser for Increasing Vaccine Uptake in Nigeria,0.57696,"More than 5 million children under five years die from largely preventable or
treatable medical conditions every year, with an overwhelmingly large
proportion of deaths occurring in under-developed countries with low
vaccination uptake. One of the United Nations' sustainable development goals
(SDG 3) aims to end preventable deaths of newborns and children under five
years of age. We focus on Nigeria, where the rate of infant mortality is
appalling. We collaborate with HelpMum, a large non-profit organization in
Nigeria to design and optimize the allocation of heterogeneous health
interventions under uncertainty to increase vaccination uptake, the first such
collaboration in Nigeria. Our framework, ADVISER: AI-Driven Vaccination
Intervention Optimiser, is based on an integer linear program that seeks to
maximize the cumulative probability of successful vaccination. Our optimization
formulation is intractable in practice. We present a heuristic approach that
enables us to solve the problem for real-world use-cases. We also present
theoretical bounds for the heuristic method. Finally, we show that the proposed
approach outperforms baseline methods in terms of vaccination uptake through
experimental evaluation. HelpMum is currently planning a pilot program based on
our approach to be deployed in the largest city of Nigeria, which would be the
first deployment of an AI-driven vaccination uptake program in the country and
hopefully, pave the way for other data-driven programs to improve health
outcomes in Nigeria."
Evaluating Explainable AI on a Multi-Modal Medical Imaging Task: Can Existing Algorithms Fulfill Clinical Requirements?,0.891394,"Being able to explain the prediction to clinical end-users is a necessity to
leverage the power of artificial intelligence (AI) models for clinical decision
support. For medical images, a feature attribution map, or heatmap, is the most
common form of explanation that highlights important features for AI models'
prediction. However, it is unknown how well heatmaps perform on explaining
decisions on multi-modal medical images, where each image modality or channel
visualizes distinct clinical information of the same underlying biomedical
phenomenon. Understanding such modality-dependent features is essential for
clinical users' interpretation of AI decisions. To tackle this clinically
important but technically ignored problem, we propose the modality-specific
feature importance (MSFI) metric. It encodes clinical image and explanation
interpretation patterns of modality prioritization and modality-specific
feature localization. We conduct a clinical requirement-grounded, systematic
evaluation using computational methods and a clinician user study. Results show
that the examined 16 heatmap algorithms failed to fulfill clinical requirements
to correctly indicate AI model decision process or decision quality. The
evaluation and MSFI metric can guide the design and selection of XAI algorithms
to meet clinical requirements on multi-modal explanation."
HPT: Hierarchy-aware Prompt Tuning for Hierarchical Text Classification,0.761262,"Hierarchical text classification (HTC) is a challenging subtask of
multi-label classification due to its complex label hierarchy. Recently, the
pretrained language models (PLM)have been widely adopted in HTC through a
fine-tuning paradigm. However, in this paradigm, there exists a huge gap
between the classification tasks with sophisticated label hierarchy and the
masked language model (MLM) pretraining tasks of PLMs and thus the potentials
of PLMs can not be fully tapped. To bridge the gap, in this paper, we propose
HPT, a Hierarchy-aware Prompt Tuning method to handle HTC from a multi-label
MLM perspective. Specifically, we construct a dynamic virtual template and
label words that take the form of soft prompts to fuse the label hierarchy
knowledge and introduce a zero-bounded multi-label cross entropy loss to
harmonize the objectives of HTC and MLM. Extensive experiments show HPT
achieves state-of-the-art performances on 3 popular HTC datasets and is adept
at handling the imbalance and low resource situations. Our code is available at
https://github.com/wzh9969/HPT."
Mix and Localize: Localizing Sound Sources in Mixtures,0.753976,"We present a method for simultaneously localizing multiple sound sources
within a visual scene. This task requires a model to both group a sound mixture
into individual sources, and to associate them with a visual signal. Our method
jointly solves both tasks at once, using a formulation inspired by the
contrastive random walk of Jabri et al. We create a graph in which images and
separated sounds correspond to nodes, and train a random walker to transition
between nodes from different modalities with high return probability. The
transition probabilities for this walk are determined by an audio-visual
similarity metric that is learned by our model. We show through experiments
with musical instruments and human speech that our model can successfully
localize multiple sounds, outperforming other self-supervised methods. Project
site: https://hxixixh.github.io/mix-and-localize"
EOD: The IEEE GRSS Earth Observation Database,0.821673,"In the era of deep learning, annotated datasets have become a crucial asset
to the remote sensing community. In the last decade, a plethora of different
datasets was published, each designed for a specific data type and with a
specific task or application in mind. In the jungle of remote sensing datasets,
it can be hard to keep track of what is available already. With this paper, we
introduce EOD - the IEEE GRSS Earth Observation Database (EOD) - an interactive
online platform for cataloguing different types of datasets leveraging remote
sensing imagery."
A Transformer-based Framework for POI-level Social Post Geolocation,0.960356,"POI-level geo-information of social posts is critical to many location-based
applications and services. However, the multi-modality, complexity and diverse
nature of social media data and their platforms limit the performance of
inferring such fine-grained locations and their subsequent applications. To
address this issue, we present a transformer-based general framework, which
builds upon pre-trained language models and considers non-textual data, for
social post geolocation at the POI level. To this end, inputs are categorized
to handle different social data, and an optimal combination strategy is
provided for feature representations. Moreover, a uniform representation of
hierarchy is proposed to learn temporal information, and a concatenated version
of encodings is employed to capture feature-wise positions better. Experimental
results on various social datasets demonstrate that three variants of our
proposed framework outperform multiple state-of-art baselines by a large margin
in terms of accuracy and distance error metrics."
AlphaZero Gomoku,0.0407192,"In the past few years, AlphaZero's exceptional capability in mastering
intricate board games has garnered considerable interest. Initially designed
for the game of Go, this revolutionary algorithm merges deep learning
techniques with the Monte Carlo tree search (MCTS) to surpass earlier top-tier
methods. In our study, we broaden the use of AlphaZero to Gomoku, an age-old
tactical board game also referred to as ""Five in a Row."" Intriguingly, Gomoku
has innate challenges due to a bias towards the initial player, who has a
theoretical advantage. To add value, we strive for a balanced game-play. Our
tests demonstrate AlphaZero's versatility in adapting to games other than Go.
MCTS has become a predominant algorithm for decision processes in intricate
scenarios, especially board games. MCTS creates a search tree by examining
potential future actions and uses random sampling to predict possible results.
By leveraging the best of both worlds, the AlphaZero technique fuses deep
learning from Reinforcement Learning with the balancing act of MCTS,
establishing a fresh standard in game-playing AI. Its triumph is notably
evident in board games such as Go, chess, and shogi."
CoNSoLe: Convex Neural Symbolic Learning,0.517945,"Learning the underlying equation from data is a fundamental problem in many
disciplines. Recent advances rely on Neural Networks (NNs) but do not provide
theoretical guarantees in obtaining the exact equations owing to the
non-convexity of NNs. In this paper, we propose Convex Neural Symbolic Learning
(CoNSoLe) to seek convexity under mild conditions. The main idea is to
decompose the recovering process into two steps and convexify each step. In the
first step of searching for right symbols, we convexify the deep Q-learning.
The key is to maintain double convexity for both the negative Q-function and
the negative reward function in each iteration, leading to provable convexity
of the negative optimal Q function to learn the true symbol connections.
Conditioned on the exact searching result, we construct a Locally Convex
equation Learner (LoCaL) neural network to convexify the estimation of symbol
coefficients. With such a design, we quantify a large region with strict
convexity in the loss surface of LoCaL for commonly used physical functions.
Finally, we demonstrate the superior performance of the CoNSoLe framework over
the state-of-the-art on a diverse set of datasets."
ObjectMix: Data Augmentation by Copy-Pasting Objects in Videos for Action Recognition,0.472264,"In this paper, we propose a data augmentation method for action recognition
using instance segmentation. Although many data augmentation methods have been
proposed for image recognition, few of them are tailored for action
recognition. Our proposed method, ObjectMix, extracts each object region from
two videos using instance segmentation and combines them to create new videos.
Experiments on two action recognition datasets, UCF101 and HMDB51, demonstrate
the effectiveness of the proposed method and show its superiority over
VideoMix, a prior work."
Multimodal Chain-of-Thought Reasoning in Language Models,0.964243,"Large language models (LLMs) have shown impressive performance on complex
reasoning by leveraging chain-of-thought (CoT) prompting to generate
intermediate reasoning chains as the rationale to infer the answer. However,
existing CoT studies have primarily focused on the language modality. We
propose Multimodal-CoT that incorporates language (text) and vision (images)
modalities into a two-stage framework that separates rationale generation and
answer inference. In this way, answer inference can leverage better generated
rationales that are based on multimodal information. Experimental results on
ScienceQA and A-OKVQA benchmark datasets show the effectiveness of our proposed
approach. With Multimodal-CoT, our model under 1 billion parameters achieves
state-of-the-art performance on the ScienceQA benchmark. Our analysis indicates
that Multimodal-CoT offers the advantages of mitigating hallucination and
enhancing convergence speed. Code is publicly available at
https://github.com/amazon-science/mm-cot."
Towards Using Data-Influence Methods to Detect Noisy Samples in Source Code Corpora,0.22515,"Despite the recent trend of developing and applying neural source code models
to software engineering tasks, the quality of such models is insufficient for
real-world use. This is because there could be noise in the source code corpora
used to train such models. We adapt data-influence methods to detect such
noises in this paper. Data-influence methods are used in machine learning to
evaluate the similarity of a target sample to the correct samples in order to
determine whether or not the target sample is noisy. Our evaluation results
show that data-influence methods can identify noisy samples from neural code
models in classification-based tasks. This approach will contribute to the
larger vision of developing better neural source code models from a
data-centric perspective, which is a key driver for developing useful source
code models in practice."
Stain-invariant self supervised learning for histopathology image analysis,0.107394,"We present a self-supervised algorithm for several classification tasks
within hematoxylin and eosin (H&E) stained images of breast cancer. Our method
is robust to stain variations inherent to the histology images acquisition
process, which has limited the applicability of automated analysis tools. We
address this problem by imposing constraints a learnt latent space which
leverages stain normalization techniques during training. At every iteration,
we select an image as a normalization target and generate a version of every
image in the batch normalized to that target. We minimize the distance between
the embeddings that correspond to the same image under different staining
variations while maximizing the distance between other samples. We show that
our method not only improves robustness to stain variations across multi-center
data, but also classification performance through extensive experiments on
various normalization targets and methods. Our method achieves the
state-of-the-art performance on several publicly available breast cancer
datasets ranging from tumor classification (CAMELYON17) and subtyping (BRACS)
to HER2 status classification and treatment response prediction."
Avalon's Game of Thoughts: Battle Against Deception through Recursive Contemplation,0.789349,"Recent breakthroughs in large language models (LLMs) have brought remarkable
success in the field of LLM-as-Agent. Nevertheless, a prevalent assumption is
that the information processed by LLMs is consistently honest, neglecting the
pervasive deceptive or misleading information in human society and AI-generated
content. This oversight makes LLMs susceptible to malicious manipulations,
potentially resulting in detrimental outcomes. This study utilizes the
intricate Avalon game as a testbed to explore LLMs' potential in deceptive
environments. Avalon, full of misinformation and requiring sophisticated logic,
manifests as a ""Game-of-Thoughts"". Inspired by the efficacy of humans'
recursive thinking and perspective-taking in the Avalon game, we introduce a
novel framework, Recursive Contemplation (ReCon), to enhance LLMs' ability to
identify and counteract deceptive information. ReCon combines formulation and
refinement contemplation processes; formulation contemplation produces initial
thoughts and speech, while refinement contemplation further polishes them.
Additionally, we incorporate first-order and second-order perspective
transitions into these processes respectively. Specifically, the first-order
allows an LLM agent to infer others' mental states, and the second-order
involves understanding how others perceive the agent's mental state. After
integrating ReCon with different LLMs, extensive experiment results from the
Avalon game indicate its efficacy in aiding LLMs to discern and maneuver around
deceptive information without extra fine-tuning and data. Finally, we offer a
possible explanation for the efficacy of ReCon and explore the current
limitations of LLMs in terms of safety, reasoning, speaking style, and format,
potentially furnishing insights for subsequent research."
MagicEdit: High-Fidelity and Temporally Coherent Video Editing,0.810554,"In this report, we present MagicEdit, a surprisingly simple yet effective
solution to the text-guided video editing task. We found that high-fidelity and
temporally coherent video-to-video translation can be achieved by explicitly
disentangling the learning of content, structure and motion signals during
training. This is in contradict to most existing methods which attempt to
jointly model both the appearance and temporal representation within a single
framework, which we argue, would lead to degradation in per-frame quality.
Despite its simplicity, we show that MagicEdit supports various downstream
video editing tasks, including video stylization, local editing, video-MagicMix
and video outpainting."
Clustering-Based Approaches for Symbolic Knowledge Extraction,0.0819932,"Opaque models belonging to the machine learning world are ever more exploited
in the most different application areas. These models, acting as black boxes
(BB) from the human perspective, cannot be entirely trusted if the application
is critical unless there exists a method to extract symbolic and human-readable
knowledge out of them. In this paper we analyse a recurrent design adopted by
symbolic knowledge extractors for BB regressors - that is, the creation of
rules associated with hypercubic input space regions. We argue that this kind
of partitioning may lead to suboptimal solutions when the data set at hand is
high-dimensional or does not satisfy symmetric constraints. We then propose a
(deep) clustering-based approach to be performed before symbolic knowledge
extraction to achieve better performance with data sets of any kind."
GPS: Genetic Prompt Search for Efficient Few-shot Learning,0.481796,"Prompt-based techniques have demostrated great potential for improving the
few-shot generalization of pretrained language models. However, their
performance heavily relies on the manual design of prompts and thus requires a
lot of human efforts. In this paper, we introduce Genetic Prompt Search (GPS)
to improve few-shot learning with prompts, which utilizes a genetic algorithm
to automatically search for high-performing prompts. GPS is gradient-free and
requires no update of model parameters but only a small validation set.
Experiments on diverse datasets proved the effectiveness of GPS, which
outperforms manual prompts by a large margin of 2.6 points. Our method is also
better than other parameter-efficient tuning methods such as prompt tuning."
An Analysis of Abstractive Text Summarization Using Pre-trained Models,0.352864,"People nowadays use search engines like Google, Yahoo, and Bing to find
information on the Internet. Due to explosion in data, it is helpful for users
if they are provided relevant summaries of the search results rather than just
links to webpages. Text summarization has become a vital approach to help
consumers swiftly grasp vast amounts of information.In this paper, different
pre-trained models for text summarization are evaluated on different datasets.
Specifically, we have used three different pre-trained models, namely,
google/pegasus-cnn-dailymail, T5-base, facebook/bart-large-cnn. We have
considered three different datasets, namely, CNN-dailymail, SAMSum and BillSum
to get the output from the above three models. The pre-trained models are
compared over these different datasets, each of 2000 examples, through ROUGH
and BLEU metrics."
ArgRewrite V.2: an Annotated Argumentative Revisions Corpus,0.764063,"Analyzing how humans revise their writings is an interesting research
question, not only from an educational perspective but also in terms of
artificial intelligence. Better understanding of this process could facilitate
many NLP applications, from intelligent tutoring systems to supportive and
collaborative writing environments. Developing these applications, however,
requires revision corpora, which are not widely available. In this work, we
present ArgRewrite V.2, a corpus of annotated argumentative revisions,
collected from two cycles of revisions to argumentative essays about
self-driving cars. Annotations are provided at different levels of purpose
granularity (coarse and fine) and scope (sentential and subsentential). In
addition, the corpus includes the revision goal given to each writer, essay
scores, annotation verification, pre- and post-study surveys collected from
participants as meta-data. The variety of revision unit scope and purpose
granularity levels in ArgRewrite, along with the inclusion of new types of
meta-data, can make it a useful resource for research and applications that
involve revision analysis. We demonstrate some potential applications of
ArgRewrite V.2 in the development of automatic revision purpose predictors, as
a training source and benchmark."
Building an Efficiency Pipeline: Commutativity and Cumulativeness of Efficiency Operators for Transformers,0.165917,"There exists a wide variety of efficiency methods for natural language
processing (NLP) tasks, such as pruning, distillation, dynamic inference,
quantization, etc. We can consider an efficiency method as an operator applied
on a model. Naturally, we may construct a pipeline of multiple efficiency
methods, i.e., to apply multiple operators on the model sequentially. In this
paper, we study the plausibility of this idea, and more importantly, the
commutativity and cumulativeness of efficiency operators. We make two
interesting observations: (1) Efficiency operators are commutative -- the order
of efficiency methods within the pipeline has little impact on the final
results; (2) Efficiency operators are also cumulative -- the final results of
combining several efficiency methods can be estimated by combining the results
of individual methods. These observations deepen our understanding of
efficiency operators and provide useful guidelines for their real-world
applications."
Event Collapse in Contrast Maximization Frameworks,0.560296,"Contrast maximization (CMax) is a framework that provides state-of-the-art
results on several event-based computer vision tasks, such as ego-motion or
optical flow estimation. However, it may suffer from a problem called event
collapse, which is an undesired solution where events are warped into too few
pixels. As prior works have largely ignored the issue or proposed workarounds,
it is imperative to analyze this phenomenon in detail. Our work demonstrates
event collapse in its simplest form and proposes collapse metrics by using
first principles of space-time deformation based on differential geometry and
physics. We experimentally show on publicly available datasets that the
proposed metrics mitigate event collapse and do not harm well-posed warps. To
the best of our knowledge, regularizers based on the proposed metrics are the
only effective solution against event collapse in the experimental settings
considered, compared with other methods. We hope that this work inspires
further research to tackle more complex warp models."
A Holistic Framework for Analyzing the COVID-19 Vaccine Debate,0.821673,"The Covid-19 pandemic has led to infodemic of low quality information leading
to poor health decisions. Combating the outcomes of this infodemic is not only
a question of identifying false claims, but also reasoning about the decisions
individuals make. In this work we propose a holistic analysis framework
connecting stance and reason analysis, and fine-grained entity level moral
sentiment analysis. We study how to model the dependencies between the
different level of analysis and incorporate human insights into the learning
process. Experiments show that our framework provides reliable predictions even
in the low-supervision settings."
Pushing the Efficiency Limit Using Structured Sparse Convolutions,0.125902,"Weight pruning is among the most popular approaches for compressing deep
convolutional neural networks. Recent work suggests that in a randomly
initialized deep neural network, there exist sparse subnetworks that achieve
performance comparable to the original network. Unfortunately, finding these
subnetworks involves iterative stages of training and pruning, which can be
computationally expensive. We propose Structured Sparse Convolution (SSC),
which leverages the inherent structure in images to reduce the parameters in
the convolutional filter. This leads to improved efficiency of convolutional
architectures compared to existing methods that perform pruning at
initialization. We show that SSC is a generalization of commonly used layers
(depthwise, groupwise and pointwise convolution) in ``efficient
architectures.'' Extensive experiments on well-known CNN models and datasets
show the effectiveness of the proposed method. Architectures based on SSC
achieve state-of-the-art performance compared to baselines on CIFAR-10,
CIFAR-100, Tiny-ImageNet, and ImageNet classification benchmarks."
Prediction of User Request and Complaint in Spoken Customer-Agent Conversations,0.632121,"We present the corpus called HealthCall. This was recorded in real-life
conditions in the call center of Malakoff Humanis. It includes two separate
audio channels, the first one for the customer and the second one for the
agent. Each conversation was anonymized respecting the General Data Protection
Regulation. This corpus includes a transcription of the spoken conversations
and was divided into two sets: Train and Devel sets. Two important customer
relationship management tasks were assessed on the HealthCall corpus: Automatic
prediction of type of user requests and complaints detection. For this purpose,
we have investigated 14 feature sets: 6 linguistic feature sets, 6 audio
feature sets and 2 vocal interaction feature sets. We have used Bidirectional
Encoder Representation from Transformers models for the linguistic features,
openSMILE and Wav2Vec 2.0 for the audio features. The vocal interaction feature
sets were designed and developed from Turn Takings. The results show that the
linguistic features always give the best results (91.2% for the Request task
and 70.3% for the Complaint task). The Wav2Vec 2.0 features seem more suitable
for these two tasks than the ComPaRe16 features. Vocal interaction features
outperformed ComPaRe16 features on Complaint task with a 57% rate achieved with
only six features."
TeachAugment: Data Augmentation Optimization Using Teacher Knowledge,0.664912,"Optimization of image transformation functions for the purpose of data
augmentation has been intensively studied. In particular, adversarial data
augmentation strategies, which search augmentation maximizing task loss, show
significant improvement in the model generalization for many tasks. However,
the existing methods require careful parameter tuning to avoid excessively
strong deformations that take away image features critical for acquiring
generalization. In this paper, we propose a data augmentation optimization
method based on the adversarial strategy called TeachAugment, which can produce
informative transformed images to the model without requiring careful tuning by
leveraging a teacher model. Specifically, the augmentation is searched so that
augmented images are adversarial for the target model and recognizable for the
teacher model. We also propose data augmentation using neural networks, which
simplifies the search space design and allows for updating of the data
augmentation using the gradient method. We show that TeachAugment outperforms
existing methods in experiments of image classification, semantic segmentation,
and unsupervised representation learning tasks."
Learning Explicit Object-Centric Representations with Vision Transformers,0.094213,"With the recent successful adaptation of transformers to the vision domain,
particularly when trained in a self-supervised fashion, it has been shown that
vision transformers can learn impressive object-reasoning-like behaviour and
features expressive for the task of object segmentation in images. In this
paper, we build on the self-supervision task of masked autoencoding and explore
its effectiveness for explicitly learning object-centric representations with
transformers. To this end, we design an object-centric autoencoder using
transformers only and train it end-to-end to reconstruct full images from
unmasked patches. We show that the model efficiently learns to decompose simple
scenes as measured by segmentation metrics on several multi-object benchmarks."
Collateral facilitation in humans and language models,0.265666,"Are the predictions of humans and language models affected by similar things?
Research suggests that while comprehending language, humans make predictions
about upcoming words, with more predictable words being processed more easily.
However, evidence also shows that humans display a similar processing advantage
for highly anomalous words when these words are semantically related to the
preceding context or to the most probable continuation. Using stimuli from 3
psycholinguistic experiments, we find that this is also almost always also the
case for 8 contemporary transformer language models (BERT, ALBERT, RoBERTa,
XLM-R, GPT-2, GPT-Neo, GPT-J, and XGLM). We then discuss the implications of
this phenomenon for our understanding of both human language comprehension and
the predictions made by language models."
A Neural Pairwise Ranking Model for Readability Assessment,0.590482,"Automatic Readability Assessment (ARA), the task of assigning a reading level
to a text, is traditionally treated as a classification problem in NLP
research. In this paper, we propose the first neural, pairwise ranking approach
to ARA and compare it with existing classification, regression, and
(non-neural) ranking methods. We establish the performance of our model by
conducting experiments with three English, one French and one Spanish datasets.
We demonstrate that our approach performs well in monolingual single/cross
corpus testing scenarios and achieves a zero-shot cross-lingual ranking
accuracy of over 80% for both French and Spanish when trained on English data.
Additionally, we also release a new parallel bilingual readability dataset in
English and French. To our knowledge, this paper proposes the first neural
pairwise ranking model for ARA, and shows the first results of cross-lingual,
zero-shot evaluation of ARA with neural models."
Toward Next-Generation Artificial Intelligence: Catalyzing the NeuroAI Revolution,0.801186,"Neuroscience has long been an essential driver of progress in artificial
intelligence (AI). We propose that to accelerate progress in AI, we must invest
in fundamental research in NeuroAI. A core component of this is the embodied
Turing test, which challenges AI animal models to interact with the
sensorimotor world at skill levels akin to their living counterparts. The
embodied Turing test shifts the focus from those capabilities like game playing
and language that are especially well-developed or uniquely human to those
capabilities, inherited from over 500 million years of evolution, that are
shared with all animals. Building models that can pass the embodied Turing test
will provide a roadmap for the next generation of AI."
Egocentric Video Task Translation @ Ego4D Challenge 2022,0.221516,"This technical report describes the EgoTask Translation approach that
explores relations among a set of egocentric video tasks in the Ego4D
challenge. To improve the primary task of interest, we propose to leverage
existing models developed for other related tasks and design a task translator
that learns to ''translate'' auxiliary task features to the primary task. With
no modification to the baseline architectures, our proposed approach achieves
competitive performance on two Ego4D challenges, ranking the 1st in the talking
to me challenge and the 3rd in the PNR keyframe localization challenge."
Scaling Novel Object Detection with Weakly Supervised Detection Transformers,0.183871,"A critical object detection task is finetuning an existing model to detect
novel objects, but the standard workflow requires bounding box annotations
which are time-consuming and expensive to collect. Weakly supervised object
detection (WSOD) offers an appealing alternative, where object detectors can be
trained using image-level labels. However, the practical application of current
WSOD models is limited, as they only operate at small data scales and require
multiple rounds of training and refinement. To address this, we propose the
Weakly Supervised Detection Transformer, which enables efficient knowledge
transfer from a large-scale pretraining dataset to WSOD finetuning on hundreds
of novel objects. Additionally, we leverage pretrained knowledge to improve the
multiple instance learning (MIL) framework often used in WSOD methods. Our
experiments show that our approach outperforms previous state-of-the-art models
on large-scale novel object detection datasets, and our scaling study reveals
that class quantity is more important than image quantity for WSOD pretraining.
The code is available at https://github.com/tmlabonte/weakly-supervised-DETR."
FreGAN: Exploiting Frequency Components for Training GANs under Limited Data,0.862824,"Training GANs under limited data often leads to discriminator overfitting and
memorization issues, causing divergent training. Existing approaches mitigate
the overfitting by employing data augmentations, model regularization, or
attention mechanisms. However, they ignore the frequency bias of GANs and take
poor consideration towards frequency information, especially high-frequency
signals that contain rich details. To fully utilize the frequency information
of limited data, this paper proposes FreGAN, which raises the model's frequency
awareness and draws more attention to producing high-frequency signals,
facilitating high-quality generation. In addition to exploiting both real and
generated images' frequency information, we also involve the frequency signals
of real images as a self-supervised constraint, which alleviates the GAN
disequilibrium and encourages the generator to synthesize adequate rather than
arbitrary frequency signals. Extensive results demonstrate the superiority and
effectiveness of our FreGAN in ameliorating generation quality in the low-data
regime (especially when training data is less than 100). Besides, FreGAN can be
seamlessly applied to existing regularization and attention mechanism models to
further boost the performance."
AFPN: Asymptotic Feature Pyramid Network for Object Detection,0.829378,"Multi-scale features are of great importance in encoding objects with scale
variance in object detection tasks. A common strategy for multi-scale feature
extraction is adopting the classic top-down and bottom-up feature pyramid
networks. However, these approaches suffer from the loss or degradation of
feature information, impairing the fusion effect of non-adjacent levels. This
paper proposes an asymptotic feature pyramid network (AFPN) to support direct
interaction at non-adjacent levels. AFPN is initiated by fusing two adjacent
low-level features and asymptotically incorporates higher-level features into
the fusion process. In this way, the larger semantic gap between non-adjacent
levels can be avoided. Given the potential for multi-object information
conflicts to arise during feature fusion at each spatial location, adaptive
spatial fusion operation is further utilized to mitigate these inconsistencies.
We incorporate the proposed AFPN into both two-stage and one-stage object
detection frameworks and evaluate with the MS-COCO 2017 validation and test
datasets. Experimental evaluation shows that our method achieves more
competitive results than other state-of-the-art feature pyramid networks. The
code is available at
\href{https://github.com/gyyang23/AFPN}{https://github.com/gyyang23/AFPN}."
Self-Sufficient Framework for Continuous Sign Language Recognition,0.908278,"The goal of this work is to develop self-sufficient framework for Continuous
Sign Language Recognition (CSLR) that addresses key issues of sign language
recognition. These include the need for complex multi-scale features such as
hands, face, and mouth for understanding, and absence of frame-level
annotations. To this end, we propose (1) Divide and Focus Convolution (DFConv)
which extracts both manual and non-manual features without the need for
additional networks or annotations, and (2) Dense Pseudo-Label Refinement
(DPLR) which propagates non-spiky frame-level pseudo-labels by combining the
ground truth gloss sequence labels with the predicted sequence. We demonstrate
that our model achieves state-of-the-art performance among RGB-based methods on
large-scale CSLR benchmarks, PHOENIX-2014 and PHOENIX-2014-T, while showing
comparable results with better efficiency when compared to other approaches
that use multi-modality or extra annotations."
Non-Linear Coordination Graphs,0.478289,"Value decomposition multi-agent reinforcement learning methods learn the
global value function as a mixing of each agent's individual utility functions.
Coordination graphs (CGs) represent a higher-order decomposition by
incorporating pairwise payoff functions and thus is supposed to have a more
powerful representational capacity. However, CGs decompose the global value
function linearly over local value functions, severely limiting the complexity
of the value function class that can be represented. In this paper, we propose
the first non-linear coordination graph by extending CG value decomposition
beyond the linear case. One major challenge is to conduct greedy action
selections in this new function class to which commonly adopted DCOP algorithms
are no longer applicable. We study how to solve this problem when mixing
networks with LeakyReLU activation are used. An enumeration method with a
global optimality guarantee is proposed and motivates an efficient iterative
optimization method with a local optimality guarantee. We find that our method
can achieve superior performance on challenging multi-agent coordination tasks
like MACO."
VPAIR -- Aerial Visual Place Recognition and Localization in Large-scale Outdoor Environments,0.624076,"Visual Place Recognition and Visual Localization are essential components in
navigation and mapping for autonomous vehicles especially in GNSS-denied
navigation scenarios. Recent work has focused on ground or close to ground
applications such as self-driving cars or indoor-scenarios and low-altitude
drone flights. However, applications such as Urban Air Mobility require
operations in large-scale outdoor environments at medium to high altitudes. We
present a new dataset named VPAIR. The dataset was recorded on board a light
aircraft flying at an altitude of more than 300 meters above ground capturing
images with a downwardfacing camera. Each image is paired with a high
resolution reference render including dense depth information and 6-DoF
reference poses. The dataset covers a more than one hundred kilometers long
trajectory over various types of challenging landscapes, e.g. urban, farmland
and forests. Experiments on this dataset illustrate the challenges introduced
by the change in perspective to a bird's eye view such as in-plane rotations."
Reinforcement Learning with Human Feedback for Realistic Traffic Simulation,0.50789,"In light of the challenges and costs of real-world testing, autonomous
vehicle developers often rely on testing in simulation for the creation of
reliable systems. A key element of effective simulation is the incorporation of
realistic traffic models that align with human knowledge, an aspect that has
proven challenging due to the need to balance realism and diversity. This works
aims to address this by developing a framework that employs reinforcement
learning with human preference (RLHF) to enhance the realism of existing
traffic models. This study also identifies two main challenges: capturing the
nuances of human preferences on realism and the unification of diverse traffic
simulation models. To tackle these issues, we propose using human feedback for
alignment and employ RLHF due to its sample efficiency. We also introduce the
first dataset for realism alignment in traffic modeling to support such
research. Our framework, named TrafficRLHF, demonstrates its proficiency in
generating realistic traffic scenarios that are well-aligned with human
preferences, as corroborated by comprehensive evaluations on the nuScenes
dataset."
CrossKD: Cross-Head Knowledge Distillation for Object Detection,0.174006,"Knowledge Distillation (KD) has been validated as an effective model
compression technique for learning compact object detectors. Existing
state-of-the-art KD methods for object detection are mostly based on feature
imitation. In this paper, we present a general and effective prediction
mimicking distillation scheme, called CrossKD, which delivers the intermediate
features of the student's detection head to the teacher's detection head. The
resulting cross-head predictions are then forced to mimic the teacher's
predictions. This manner relieves the student's head from receiving
contradictory supervision signals from the annotations and the teacher's
predictions, greatly improving the student's detection performance. Moreover,
as mimicking the teacher's predictions is the target of KD, CrossKD offers more
task-oriented information in contrast with feature imitation. On MS COCO, with
only prediction mimicking losses applied, our CrossKD boosts the average
precision of GFL ResNet-50 with 1x training schedule from 40.2 to 43.7,
outperforming all existing KD methods. In addition, our method also works well
when distilling detectors with heterogeneous backbones. Code is available at
https://github.com/jbwang1997/CrossKD."
Test-Time Style Shifting: Handling Arbitrary Styles in Domain Generalization,0.321263,"In domain generalization (DG), the target domain is unknown when the model is
being trained, and the trained model should successfully work on an arbitrary
(and possibly unseen) target domain during inference. This is a difficult
problem, and despite active studies in recent years, it remains a great
challenge. In this paper, we take a simple yet effective approach to tackle
this issue. We propose test-time style shifting, which shifts the style of the
test sample (that has a large style gap with the source domains) to the nearest
source domain that the model is already familiar with, before making the
prediction. This strategy enables the model to handle any target domains with
arbitrary style statistics, without additional model update at test-time.
Additionally, we propose style balancing, which provides a great platform for
maximizing the advantage of test-time style shifting by handling the
DG-specific imbalance issues. The proposed ideas are easy to implement and
successfully work in conjunction with various other DG schemes. Experimental
results on different datasets show the effectiveness of our methods."
Where did you tweet from? Inferring the origin locations of tweets based on contextual information,0.617902,"Public conversations on Twitter comprise many pertinent topics including
disasters, protests, politics, propaganda, sports, climate change,
epidemics/pandemic outbreaks, etc., that can have both regional and global
aspects. Spatial discourse analysis rely on geographical data. However, today
less than 1% of tweets are geotagged; in both cases--point location or bounding
place information. A major issue with tweets is that Twitter users can be at
location A and exchange conversations specific to location B, which we call the
Location A/B problem. The problem is considered solved if location entities can
be classified as either origin locations (Location As) or non-origin locations
(Location Bs). In this work, we propose a simple yet effective framework--the
True Origin Model--to address the problem that uses machine-level natural
language understanding to identify tweets that conceivably contain their origin
location information. The model achieves promising accuracy at country (80%),
state (67%), city (58%), county (56%) and district (64%) levels with support
from a Location Extraction Model as basic as the CoNLL-2003-based RoBERTa. We
employ a tweet contexualizer (locBERT) which is one of the core components of
the proposed model, to investigate multiple tweets' distributions for
understanding Twitter users' tweeting behavior in terms of mentioning origin
and non-origin locations. We also highlight a major concern with the currently
regarded gold standard test set (ground truth) methodology, introduce a new
data set, and identify further research avenues for advancing the area."
RotoGBML: Towards Out-of-Distribution Generalization for Gradient-Based Meta-Learning,0.355581,"Gradient-based meta-learning (GBML) algorithms are able to fast adapt to new
tasks by transferring the learned meta-knowledge, while assuming that all tasks
come from the same distribution (in-distribution, ID). However, in the real
world, they often suffer from an out-of-distribution (OOD) generalization
problem, where tasks come from different distributions. OOD exacerbates
inconsistencies in magnitudes and directions of task gradients, which brings
challenges for GBML to optimize the meta-knowledge by minimizing the sum of
task gradients in each minibatch. To address this problem, we propose RotoGBML,
a novel approach to homogenize OOD task gradients. RotoGBML uses reweighted
vectors to dynamically balance diverse magnitudes to a common scale and uses
rotation matrixes to rotate conflicting directions close to each other. To
reduce overhead, we homogenize gradients with the features rather than the
network parameters. On this basis, to avoid the intervention of non-causal
features (e.g., backgrounds), we also propose an invariant self-information
(ISI) module to extract invariant causal features (e.g., the outlines of
objects). Finally, task gradients are homogenized based on these invariant
causal features. Experiments show that RotoGBML outperforms other
state-of-the-art methods on various few-shot image classification benchmarks."
MonoPGC: Monocular 3D Object Detection with Pixel Geometry Contexts,0.667286,"Monocular 3D object detection reveals an economical but challenging task in
autonomous driving. Recently center-based monocular methods have developed
rapidly with a great trade-off between speed and accuracy, where they usually
depend on the object center's depth estimation via 2D features. However, the
visual semantic features without sufficient pixel geometry information, may
affect the performance of clues for spatial 3D detection tasks. To alleviate
this, we propose MonoPGC, a novel end-to-end Monocular 3D object detection
framework with rich Pixel Geometry Contexts. We introduce the pixel depth
estimation as our auxiliary task and design depth cross-attention pyramid
module (DCPM) to inject local and global depth geometry knowledge into visual
features. In addition, we present the depth-space-aware transformer (DSAT) to
integrate 3D space position and depth-aware features efficiently. Besides, we
design a novel depth-gradient positional encoding (DGPE) to bring more distinct
pixel geometry contexts into the transformer for better object detection.
Extensive experiments demonstrate that our method achieves the state-of-the-art
performance on the KITTI dataset."
Do Differentiable Simulators Give Better Policy Gradients?,0.937542,"Differentiable simulators promise faster computation time for reinforcement
learning by replacing zeroth-order gradient estimates of a stochastic objective
with an estimate based on first-order gradients. However, it is yet unclear
what factors decide the performance of the two estimators on complex landscapes
that involve long-horizon planning and control on physical systems, despite the
crucial relevance of this question for the utility of differentiable
simulators. We show that characteristics of certain physical systems, such as
stiffness or discontinuities, may compromise the efficacy of the first-order
estimator, and analyze this phenomenon through the lens of bias and variance.
We additionally propose an $\alpha$-order gradient estimator, with $\alpha \in
[0,1]$, which correctly utilizes exact gradients to combine the efficiency of
first-order estimates with the robustness of zero-order methods. We demonstrate
the pitfalls of traditional estimators and the advantages of the $\alpha$-order
estimator on some numerical examples."
Revisiting Non-Autoregressive Translation at Scale,0.285918,"In real-world systems, scaling has been critical for improving the
translation quality in autoregressive translation (AT), which however has not
been well studied for non-autoregressive translation (NAT). In this work, we
bridge the gap by systematically studying the impact of scaling on NAT
behaviors. Extensive experiments on six WMT benchmarks over two advanced NAT
models show that scaling can alleviate the commonly-cited weaknesses of NAT
models, resulting in better translation performance. To reduce the side-effect
of scaling on decoding speed, we empirically investigate the impact of NAT
encoder and decoder on the translation performance. Experimental results on the
large-scale WMT20 En-De show that the asymmetric architecture (e.g. bigger
encoder and smaller decoder) can achieve comparable performance with the
scaling model, while maintaining the superiority of decoding speed with
standard NAT models. To this end, we establish a new benchmark by validating
scaled NAT models on the scaled dataset, which can be regarded as a strong
baseline for future works. We release code and system outputs at
https://github.com/DeepLearnXMU/Scaling4NAT."
MMANet: Margin-aware Distillation and Modality-aware Regularization for Incomplete Multimodal Learning,0.33423,"Multimodal learning has shown great potentials in numerous scenes and
attracts increasing interest recently. However, it often encounters the problem
of missing modality data and thus suffers severe performance degradation in
practice. To this end, we propose a general framework called MMANet to assist
incomplete multimodal learning. It consists of three components: the deployment
network used for inference, the teacher network transferring comprehensive
multimodal information to the deployment network, and the regularization
network guiding the deployment network to balance weak modality combinations.
Specifically, we propose a novel margin-aware distillation (MAD) to assist the
information transfer by weighing the sample contribution with the
classification uncertainty. This encourages the deployment network to focus on
the samples near decision boundaries and acquire the refined inter-class
margin. Besides, we design a modality-aware regularization (MAR) algorithm to
mine the weak modality combinations and guide the regularization network to
calculate prediction loss for them. This forces the deployment network to
improve its representation ability for the weak modality combinations
adaptively. Finally, extensive experiments on multimodal classification and
segmentation tasks demonstrate that our MMANet outperforms the state-of-the-art
significantly. Code is available at: https://github.com/shicaiwei123/MMANet"
Equivariant Self-Supervision for Musical Tempo Estimation,0.905989,"Self-supervised methods have emerged as a promising avenue for representation
learning in the recent years since they alleviate the need for labeled
datasets, which are scarce and expensive to acquire. Contrastive methods are a
popular choice for self-supervision in the audio domain, and typically provide
a learning signal by forcing the model to be invariant to some transformations
of the input. These methods, however, require measures such as negative
sampling or some form of regularisation to be taken to prevent the model from
collapsing on trivial solutions. In this work, instead of invariance, we
propose to use equivariance as a self-supervision signal to learn audio tempo
representations from unlabelled data. We derive a simple loss function that
prevents the network from collapsing on a trivial solution during training,
without requiring any form of regularisation or negative sampling. Our
experiments show that it is possible to learn meaningful representations for
tempo estimation by solely relying on equivariant self-supervision, achieving
performance comparable with supervised methods on several benchmarks. As an
added benefit, our method only requires moderate compute resources and
therefore remains accessible to a wide research community."
Adaptive multilingual speech recognition with pretrained models,0.73623,"Multilingual speech recognition with supervised learning has achieved great
results as reflected in recent research. With the development of pretraining
methods on audio and text data, it is imperative to transfer the knowledge from
unsupervised multilingual models to facilitate recognition, especially in many
languages with limited data. Our work investigated the effectiveness of using
two pretrained models for two modalities: wav2vec 2.0 for audio and MBART50 for
text, together with the adaptive weight techniques to massively improve the
recognition quality on the public datasets containing CommonVoice and Europarl.
Overall, we noticed an 44% improvement over purely supervised learning, and
more importantly, each technique provides a different reinforcement in
different languages. We also explore other possibilities to potentially obtain
the best model by slightly adding either depth or relative attention to the
architecture."
Treeformer: Dense Gradient Trees for Efficient Attention Computation,0.155163,"Standard inference and training with transformer based architectures scale
quadratically with input sequence length. This is prohibitively large for a
variety of applications especially in web-page translation, query-answering
etc. Consequently, several approaches have been developed recently to speedup
attention computation by enforcing different attention structures such as
sparsity, low-rank, approximating attention using kernels. In this work, we
view attention computation as that of nearest neighbor retrieval, and use
decision tree based hierarchical navigation to reduce the retrieval cost per
query token from linear in sequence length to nearly logarithmic. Based on such
hierarchical navigation, we design Treeformer which can use one of two
efficient attention layers -- TF-Attention and TC-Attention. TF-Attention
computes the attention in a fine-grained style, while TC-Attention is a coarse
attention layer which also ensures that the gradients are ""dense"". To optimize
such challenging discrete layers, we propose a two-level bootstrapped training
method. Using extensive experiments on standard NLP benchmarks, especially for
long-sequences, we demonstrate that our Treeformer architecture can be almost
as accurate as baseline Transformer while using 30x lesser FLOPs in the
attention layer. Compared to Linformer, the accuracy can be as much as 12%
higher while using similar FLOPs in the attention layer."
About optimal loss function for training physics-informed neural networks under respecting causality,0.469596,"A method is presented that allows to reduce a problem described by
differential equations with initial and boundary conditions to the problem
described only by differential equations. The advantage of using the modified
problem for physics-informed neural networks (PINNs) methodology is that it
becomes possible to represent the loss function in the form of a single term
associated with differential equations, thus eliminating the need to tune the
scaling coefficients for the terms related to boundary and initial conditions.
The weighted loss functions respecting causality were modified and new weighted
loss functions based on generalized functions are derived. Numerical
experiments have been carried out for a number of problems, demonstrating the
accuracy of the proposed methods."
A Comparative Analysis of Techniques and Algorithms for Recognising Sign Language,0.414441,"Sign language is a visual language that enhances communication between people
and is frequently used as the primary form of communication by people with
hearing loss. Even so, not many people with hearing loss use sign language, and
they frequently experience social isolation. Therefore, it is necessary to
create human-computer interface systems that can offer hearing-impaired people
a social platform. Most commercial sign language translation systems now on the
market are sensor-based, pricey, and challenging to use. Although vision-based
systems are desperately needed, they must first overcome several challenges.
Earlier continuous sign language recognition techniques used hidden Markov
models, which have a limited ability to include temporal information. To get
over these restrictions, several machine learning approaches are being applied
to transform hand and sign language motions into spoken or written language. In
this study, we compare various deep learning techniques for recognising sign
language. Our survey aims to provide a comprehensive overview of the most
recent approaches and challenges in this field."
SkillGPT: a RESTful API service for skill extraction and standardization using a Large Language Model,0.209392,"We present SkillGPT, a tool for skill extraction and standardization (SES)
from free-style job descriptions and user profiles with an open-source Large
Language Model (LLM) as backbone. Most previous methods for similar tasks
either need supervision or rely on heavy data-preprocessing and feature
engineering. Directly prompting the latest conversational LLM for standard
skills, however, is slow, costly and inaccurate. In contrast, SkillGPT utilizes
a LLM to perform its tasks in steps via summarization and vector similarity
search, to balance speed with precision. The backbone LLM of SkillGPT is based
on Llama, free for academic use and thus useful for exploratory research and
prototype development. Hence, our cost-free SkillGPT gives users the
convenience of conversational SES, efficiently and reliably."
Image-free Domain Generalization via CLIP for 3D Hand Pose Estimation,0.275158,"RGB-based 3D hand pose estimation has been successful for decades thanks to
large-scale databases and deep learning. However, the hand pose estimation
network does not operate well for hand pose images whose characteristics are
far different from the training data. This is caused by various factors such as
illuminations, camera angles, diverse backgrounds in the input images, etc.
Many existing methods tried to solve it by supplying additional large-scale
unconstrained/target domain images to augment data space; however collecting
such large-scale images takes a lot of labors. In this paper, we present a
simple image-free domain generalization approach for the hand pose estimation
framework that uses only source domain data. We try to manipulate the image
features of the hand pose estimation network by adding the features from text
descriptions using the CLIP (Contrastive Language-Image Pre-training) model.
The manipulated image features are then exploited to train the hand pose
estimation network via the contrastive learning framework. In experiments with
STB and RHD datasets, our algorithm shows improved performance over the
state-of-the-art domain generalization approaches."
InBiaseD: Inductive Bias Distillation to Improve Generalization and Robustness through Shape-awareness,0.159579,"Humans rely less on spurious correlations and trivial cues, such as texture,
compared to deep neural networks which lead to better generalization and
robustness. It can be attributed to the prior knowledge or the high-level
cognitive inductive bias present in the brain. Therefore, introducing
meaningful inductive bias to neural networks can help learn more generic and
high-level representations and alleviate some of the shortcomings. We propose
InBiaseD to distill inductive bias and bring shape-awareness to the neural
networks. Our method includes a bias alignment objective that enforces the
networks to learn more generic representations that are less vulnerable to
unintended cues in the data which results in improved generalization
performance. InBiaseD is less susceptible to shortcut learning and also
exhibits lower texture bias. The better representations also aid in improving
robustness to adversarial attacks and we hence plugin InBiaseD seamlessly into
the existing adversarial training schemes to show a better trade-off between
generalization and robustness."
Learning from Multi-Perception Features for Real-Word Image Super-resolution,0.397103,"Currently, there are two popular approaches for addressing real-world image
super-resolution problems: degradation-estimation-based and blind-based
methods. However, degradation-estimation-based methods may be inaccurate in
estimating the degradation, making them less applicable to real-world LR
images. On the other hand, blind-based methods are often limited by their fixed
single perception information, which hinders their ability to handle diverse
perceptual characteristics. To overcome this limitation, we propose a novel SR
method called MPF-Net that leverages multiple perceptual features of input
images. Our method incorporates a Multi-Perception Feature Extraction (MPFE)
module to extract diverse perceptual information and a series of newly-designed
Cross-Perception Blocks (CPB) to combine this information for effective
super-resolution reconstruction. Additionally, we introduce a contrastive
regularization term (CR) that improves the model's learning capability by using
newly generated HR and LR images as positive and negative samples for ground
truth HR. Experimental results on challenging real-world SR datasets
demonstrate that our approach significantly outperforms existing
state-of-the-art methods in both qualitative and quantitative measures."
Hearing voices at the National Library -- a speech corpus and acoustic model for the Swedish language,0.357872,"This paper explains our work in developing new acoustic models for automated
speech recognition (ASR) at KBLab, the infrastructure for data-driven research
at the National Library of Sweden (KB). We evaluate different approaches for a
viable speech-to-text pipeline for audiovisual resources in Swedish, using the
wav2vec 2.0 architecture in combination with speech corpuses created from KB's
collections. These approaches include pretraining an acoustic model for Swedish
from the ground up, and fine-tuning existing monolingual and multilingual
models. The collections-based corpuses we use have been sampled from millions
of hours of speech, with a conscious attempt to balance regional dialects to
produce a more representative, and thus more democratic, model. The acoustic
model this enabled, ""VoxRex"", outperforms existing models for Swedish ASR. We
also evaluate combining this model with various pretrained language models,
which further enhanced performance. We conclude by highlighting the potential
of such technology for cultural heritage institutions with vast collections of
previously unlabelled audiovisual data. Our models are released for further
exploration and research here: https://huggingface.co/KBLab."
ArtWhisperer: A Dataset for Characterizing Human-AI Interactions in Artistic Creations,0.39776,"As generative AI becomes more prevalent, it is important to study how human
users interact with such models. In this work, we investigate how people use
text-to-image models to generate desired target images. To study this
interaction, we created ArtWhisperer, an online game where users are given a
target image and are tasked with iteratively finding a prompt that creates a
similar-looking image as the target. Through this game, we recorded over 50,000
human-AI interactions; each interaction corresponds to one text prompt created
by a user and the corresponding generated image. The majority of these are
repeated interactions where a user iterates to find the best prompt for their
target image, making this a unique sequential dataset for studying human-AI
collaborations. In an initial analysis of this dataset, we identify several
characteristics of prompt interactions and user strategies. People submit
diverse prompts and are able to discover a variety of text descriptions that
generate similar images. Interestingly, prompt diversity does not decrease as
users find better prompts. We further propose a new metric to quantify the
steerability of AI using our dataset. We define steerability as the expected
number of interactions required to adequately complete a task. We estimate this
value by fitting a Markov chain for each target task and calculating the
expected time to reach an adequate score in the Markov chain. We quantify and
compare AI steerability across different types of target images and two
different models, finding that images of cities and natural world images are
more steerable than artistic and fantasy images. These findings provide
insights into human-AI interaction behavior, present a concrete method of
assessing AI steerability, and demonstrate the general utility of the
ArtWhisperer dataset."
Semi-Supervised Single-View 3D Reconstruction via Prototype Shape Priors,0.722299,"The performance of existing single-view 3D reconstruction methods heavily
relies on large-scale 3D annotations. However, such annotations are tedious and
expensive to collect. Semi-supervised learning serves as an alternative way to
mitigate the need for manual labels, but remains unexplored in 3D
reconstruction. Inspired by the recent success of semi-supervised image
classification tasks, we propose SSP3D, a semi-supervised framework for 3D
reconstruction. In particular, we introduce an attention-guided prototype shape
prior module for guiding realistic object reconstruction. We further introduce
a discriminator-guided module to incentivize better shape generation, as well
as a regularizer to tolerate noisy training samples. On the ShapeNet benchmark,
the proposed approach outperforms previous supervised methods by clear margins
under various labeling ratios, (i.e., 1%, 5% , 10% and 20%). Moreover, our
approach also performs well when transferring to real-world Pix3D datasets
under labeling ratios of 10%. We also demonstrate our method could transfer to
novel categories with few novel supervised data. Experiments on the popular
ShapeNet dataset show that our method outperforms the zero-shot baseline by
over 12% and we also perform rigorous ablations and analysis to validate our
approach."
Additive MIL: Intrinsically Interpretable Multiple Instance Learning for Pathology,0.887723,"Multiple Instance Learning (MIL) has been widely applied in pathology towards
solving critical problems such as automating cancer diagnosis and grading,
predicting patient prognosis, and therapy response. Deploying these models in a
clinical setting requires careful inspection of these black boxes during
development and deployment to identify failures and maintain physician trust.
In this work, we propose a simple formulation of MIL models, which enables
interpretability while maintaining similar predictive performance. Our Additive
MIL models enable spatial credit assignment such that the contribution of each
region in the image can be exactly computed and visualized. We show that our
spatial credit assignment coincides with regions used by pathologists during
diagnosis and improves upon classical attention heatmaps from attention MIL
models. We show that any existing MIL model can be made additive with a simple
change in function composition. We also show how these models can debug model
failures, identify spurious features, and highlight class-wise regions of
interest, enabling their use in high-stakes environments such as clinical
decision-making."
Rotation Synchronization via Deep Matrix Factorization,0.159376,"In this paper we address the rotation synchronization problem, where the
objective is to recover absolute rotations starting from pairwise ones, where
the unknowns and the measures are represented as nodes and edges of a graph,
respectively. This problem is an essential task for structure from motion and
simultaneous localization and mapping. We focus on the formulation of
synchronization via neural networks, which has only recently begun to be
explored in the literature. Inspired by deep matrix completion, we express
rotation synchronization in terms of matrix factorization with a deep neural
network. Our formulation exhibits implicit regularization properties and, more
importantly, is unsupervised, whereas previous deep approaches are supervised.
Our experiments show that we achieve comparable accuracy to the closest
competitors in most scenes, while working under weaker assumptions."
Semantic Embedded Deep Neural Network: A Generic Approach to Boost Multi-Label Image Classification Performance,0.586783,"Fine-grained multi-label classification models have broad applications in
e-commerce, such as visual based label predictions ranging from fashion
attribute detection to brand recognition. One challenge to achieve satisfactory
performance for those classification tasks in real world is the wild visual
background signal that contains irrelevant pixels which confuses model to focus
onto the region of interest and make prediction upon the specific region. In
this paper, we introduce a generic semantic-embedding deep neural network to
apply the spatial awareness semantic feature incorporating a channel-wise
attention based model to leverage the localization guidance to boost model
performance for multi-label prediction. We observed an Avg.relative improvement
of 15.27% in terms of AUC score across all labels compared to the baseline
approach. Core experiment and ablation studies involve multi-label fashion
attribute classification performed on Instagram fashion apparels' image. We
compared the model performances among our approach, baseline approach, and 3
alternative approaches to leverage semantic features. Results show favorable
performance for our approach."
Deep Whole-Body Control: Learning a Unified Policy for Manipulation and Locomotion,0.998048,"An attached arm can significantly increase the applicability of legged robots
to several mobile manipulation tasks that are not possible for the wheeled or
tracked counterparts. The standard hierarchical control pipeline for such
legged manipulators is to decouple the controller into that of manipulation and
locomotion. However, this is ineffective. It requires immense engineering to
support coordination between the arm and legs, and error can propagate across
modules causing non-smooth unnatural motions. It is also biological implausible
given evidence for strong motor synergies across limbs. In this work, we
propose to learn a unified policy for whole-body control of a legged
manipulator using reinforcement learning. We propose Regularized Online
Adaptation to bridge the Sim2Real gap for high-DoF control, and Advantage
Mixing exploiting the causal dependency in the action space to overcome local
minima during training the whole-body system. We also present a simple design
for a low-cost legged manipulator, and find that our unified policy can
demonstrate dynamic and agile behaviors across several task setups. Videos are
at https://maniploco.github.io"
A lightweight multi-scale context network for salient object detection in optical remote sensing images,0.22395,"Due to the more dramatic multi-scale variations and more complicated
foregrounds and backgrounds in optical remote sensing images (RSIs), the
salient object detection (SOD) for optical RSIs becomes a huge challenge.
However, different from natural scene images (NSIs), the discussion on the
optical RSI SOD task still remains scarce. In this paper, we propose a
multi-scale context network, namely MSCNet, for SOD in optical RSIs.
Specifically, a multi-scale context extraction module is adopted to address the
scale variation of salient objects by effectively learning multi-scale
contextual information. Meanwhile, in order to accurately detect complete
salient objects in complex backgrounds, we design an attention-based pyramid
feature aggregation mechanism for gradually aggregating and refining the
salient regions from the multi-scale context extraction module. Extensive
experiments on two benchmarks demonstrate that MSCNet achieves competitive
performance with only 3.26M parameters. The code will be available at
https://github.com/NuaaYH/MSCNet."
CalibNet: Dual-branch Cross-modal Calibration for RGB-D Salient Instance Segmentation,0.454504,"We propose a novel approach for RGB-D salient instance segmentation using a
dual-branch cross-modal feature calibration architecture called CalibNet. Our
method simultaneously calibrates depth and RGB features in the kernel and mask
branches to generate instance-aware kernels and mask features. CalibNet
consists of three simple modules, a dynamic interactive kernel (DIK) and a
weight-sharing fusion (WSF), which work together to generate effective
instance-aware kernels and integrate cross-modal features. To improve the
quality of depth features, we incorporate a depth similarity assessment (DSA)
module prior to DIK and WSF. In addition, we further contribute a new DSIS
dataset, which contains 1,940 images with elaborate instance-level annotations.
Extensive experiments on three challenging benchmarks show that CalibNet yields
a promising result, i.e., 58.0% AP with 320*480 input size on the COME15K-N
test set, which significantly surpasses the alternative frameworks. Our code
and dataset are available at: https://github.com/PJLallen/CalibNet."
Large language models in medicine: the potentials and pitfalls,0.505043,"Large language models (LLMs) have been applied to tasks in healthcare,
ranging from medical exam questions to responding to patient questions. With
increasing institutional partnerships between companies producing LLMs and
healthcare systems, real world clinical application is coming closer to
reality. As these models gain traction, it is essential for healthcare
practitioners to understand what LLMs are, their development, their current and
potential applications, and the associated pitfalls when utilized in medicine.
This review and accompanying tutorial aim to give an overview of these topics
to aid healthcare practitioners in understanding the rapidly changing landscape
of LLMs as applied to medicine."
4DenoiseNet: Adverse Weather Denoising from Adjacent Point Clouds,0.902202,"Reliable point cloud data is essential for perception tasks \textit{e.g.} in
robotics and autonomous driving applications. Adverse weather causes a specific
type of noise to light detection and ranging (LiDAR) sensor data, which
degrades the quality of the point clouds significantly. To address this issue,
this letter presents a novel point cloud adverse weather denoising deep
learning algorithm (4DenoiseNet). Our algorithm takes advantage of the time
dimension unlike deep learning adverse weather denoising methods in the
literature. It performs about 10\% better in terms of intersection over union
metric compared to the previous work and is more computationally efficient.
These results are achieved on our novel SnowyKITTI dataset, which has over
40000 adverse weather annotated point clouds. Moreover, strong qualitative
results on the Canadian Adverse Driving Conditions dataset indicate good
generalizability to domain shifts and to different sensor intrinsics."
CrudeOilNews: An Annotated Crude Oil News Corpus for Event Extraction,0.348051,"In this paper, we present CrudeOilNews, a corpus of English Crude Oil news
for event extraction. It is the first of its kind for Commodity News and serve
to contribute towards resource building for economic and financial text mining.
This paper describes the data collection process, the annotation methodology
and the event typology used in producing the corpus. Firstly, a seed set of 175
news articles were manually annotated, of which a subset of 25 news were used
as the adjudicated reference test set for inter-annotator and system
evaluation. Agreement was generally substantial and annotator performance was
adequate, indicating that the annotation scheme produces consistent event
annotations of high quality. Subsequently the dataset is expanded through (1)
data augmentation and (2) Human-in-the-loop active learning. The resulting
corpus has 425 news articles with approximately 11k events annotated. As part
of active learning process, the corpus was used to train basic event extraction
models for machine labeling, the resulting models also serve as a validation or
as a pilot study demonstrating the use of the corpus in machine learning
purposes. The annotated corpus is made available for academic research purpose
at https://github.com/meisin/CrudeOilNews-Corpus."
Detector-Free Weakly Supervised Group Activity Recognition,0.814712,"Group activity recognition is the task of understanding the activity
conducted by a group of people as a whole in a multi-person video. Existing
models for this task are often impractical in that they demand ground-truth
bounding box labels of actors even in testing or rely on off-the-shelf object
detectors. Motivated by this, we propose a novel model for group activity
recognition that depends neither on bounding box labels nor on object detector.
Our model based on Transformer localizes and encodes partial contexts of a
group activity by leveraging the attention mechanism, and represents a video
clip as a set of partial context embeddings. The embedding vectors are then
aggregated to form a single group representation that reflects the entire
context of an activity while capturing temporal evolution of each partial
context. Our method achieves outstanding performance on two benchmarks,
Volleyball and NBA datasets, surpassing not only the state of the art trained
with the same level of supervision, but also some of existing models relying on
stronger supervision."
Target-oriented Proactive Dialogue Systems with Personalization: Problem Formulation and Dataset Curation,0.804045,"Target-oriented dialogue systems, designed to proactively steer conversations
toward predefined targets or accomplish specific system-side goals, are an
exciting area in conversational AI. In this work, by formulating a <dialogue
act, topic> pair as the conversation target, we explore a novel problem of
personalized target-oriented dialogue by considering personalization during the
target accomplishment process. However, there remains an emergent need for
high-quality datasets, and building one from scratch requires tremendous human
effort. To address this, we propose an automatic dataset curation framework
using a role-playing approach. Based on this framework, we construct a
large-scale personalized target-oriented dialogue dataset, TopDial, which
comprises about 18K multi-turn dialogues. The experimental results show that
this dataset is of high quality and could contribute to exploring personalized
target-oriented dialogue."
Fantastic Questions and Where to Find Them: FairytaleQA -- An Authentic Dataset for Narrative Comprehension,0.995902,"Question answering (QA) is a fundamental means to facilitate assessment and
training of narrative comprehension skills for both machines and young
children, yet there is scarcity of high-quality QA datasets carefully designed
to serve this purpose. In particular, existing datasets rarely distinguish
fine-grained reading skills, such as the understanding of varying narrative
elements. Drawing on the reading education research, we introduce FairytaleQA,
a dataset focusing on narrative comprehension of kindergarten to eighth-grade
students. Generated by educational experts based on an evidence-based
theoretical framework, FairytaleQA consists of 10,580 explicit and implicit
questions derived from 278 children-friendly stories, covering seven types of
narrative elements or relations. Our dataset is valuable in two folds: First,
we ran existing QA models on our dataset and confirmed that this annotation
helps assess models' fine-grained learning skills. Second, the dataset supports
question generation (QG) task in the education domain. Through benchmarking
with QG models, we show that the QG model trained on FairytaleQA is capable of
asking high-quality and more diverse questions."
Motron: Multimodal Probabilistic Human Motion Forecasting,0.693447,"Autonomous systems and humans are increasingly sharing the same space. Robots
work side by side or even hand in hand with humans to balance each other's
limitations. Such cooperative interactions are ever more sophisticated. Thus,
the ability to reason not just about a human's center of gravity position, but
also its granular motion is an important prerequisite for human-robot
interaction. Though, many algorithms ignore the multimodal nature of humans or
neglect uncertainty in their motion forecasts. We present Motron, a multimodal,
probabilistic, graph-structured model, that captures human's multimodality
using probabilistic methods while being able to output deterministic
maximum-likelihood motions and corresponding confidence values for each mode.
Our model aims to be tightly integrated with the robotic
planning-control-interaction loop; outputting physically feasible human motions
and being computationally efficient. We demonstrate the performance of our
model on several challenging real-world motion forecasting datasets,
outperforming a wide array of generative/variational methods while providing
state-of-the-art single-output motions if required. Both using significantly
less computational power than state-of-the art algorithms."
MonoViT: Self-Supervised Monocular Depth Estimation with a Vision Transformer,0.998943,"Self-supervised monocular depth estimation is an attractive solution that
does not require hard-to-source depth labels for training. Convolutional neural
networks (CNNs) have recently achieved great success in this task. However,
their limited receptive field constrains existing network architectures to
reason only locally, dampening the effectiveness of the self-supervised
paradigm. In the light of the recent successes achieved by Vision Transformers
(ViTs), we propose MonoViT, a brand-new framework combining the global
reasoning enabled by ViT models with the flexibility of self-supervised
monocular depth estimation. By combining plain convolutions with Transformer
blocks, our model can reason locally and globally, yielding depth prediction at
a higher level of detail and accuracy, allowing MonoViT to achieve
state-of-the-art performance on the established KITTI dataset. Moreover,
MonoViT proves its superior generalization capacities on other datasets such as
Make3D and DrivingStereo."
QAGAN: Adversarial Approach To Learning Domain Invariant Language Features,0.212678,"Training models that are robust to data domain shift has gained an increasing
interest both in academia and industry. Question-Answering language models,
being one of the typical problem in Natural Language Processing (NLP) research,
has received much success with the advent of large transformer models. However,
existing approaches mostly work under the assumption that data is drawn from
same distribution during training and testing which is unrealistic and
non-scalable in the wild.
  In this paper, we explore adversarial training approach towards learning
domain-invariant features so that language models can generalize well to
out-of-domain datasets. We also inspect various other ways to boost our model
performance including data augmentation by paraphrasing sentences, conditioning
end of answer span prediction on the start word, and carefully designed
annealing function. Our initial results show that in combination with these
methods, we are able to achieve $15.2\%$ improvement in EM score and $5.6\%$
boost in F1 score on out-of-domain validation dataset over the baseline. We
also dissect our model outputs and visualize the model hidden-states by
projecting them onto a lower-dimensional space, and discover that our specific
adversarial training approach indeed encourages the model to learn domain
invariant embedding and bring them closer in the multi-dimensional space."
EASE: Entity-Aware Contrastive Learning of Sentence Embedding,0.981417,"We present EASE, a novel method for learning sentence embeddings via
contrastive learning between sentences and their related entities. The
advantage of using entity supervision is twofold: (1) entities have been shown
to be a strong indicator of text semantics and thus should provide rich
training signals for sentence embeddings; (2) entities are defined
independently of languages and thus offer useful cross-lingual alignment
supervision. We evaluate EASE against other unsupervised models both in
monolingual and multilingual settings. We show that EASE exhibits competitive
or better performance in English semantic textual similarity (STS) and short
text clustering (STC) tasks and it significantly outperforms baseline methods
in multilingual settings on a variety of tasks. Our source code, pre-trained
models, and newly constructed multilingual STC dataset are available at
https://github.com/studio-ousia/ease."
Quantifying the perceptual value of lexical and non-lexical channels in speech,0.202477,"Speech is a fundamental means of communication that can be seen to provide
two channels for transmitting information: the lexical channel of which words
are said, and the non-lexical channel of how they are spoken. Both channels
shape listener expectations of upcoming communication; however, directly
quantifying their relative effect on expectations is challenging. Previous
attempts require spoken variations of lexically-equivalent dialogue turns or
conspicuous acoustic manipulations. This paper introduces a generalised
paradigm to study the value of non-lexical information in dialogue across
unconstrained lexical content. By quantifying the perceptual value of the
non-lexical channel with both accuracy and entropy reduction, we show that
non-lexical information produces a consistent effect on expectations of
upcoming dialogue: even when it leads to poorer discriminative turn judgements
than lexical content alone, it yields higher consensus among participants."
SAMSNeRF: Segment Anything Model (SAM) Guides Dynamic Surgical Scene Reconstruction by Neural Radiance Field (NeRF),0.151706,"The accurate reconstruction of surgical scenes from surgical videos is
critical for various applications, including intraoperative navigation and
image-guided robotic surgery automation. However, previous approaches, mainly
relying on depth estimation, have limited effectiveness in reconstructing
surgical scenes with moving surgical tools. To address this limitation and
provide accurate 3D position prediction for surgical tools in all frames, we
propose a novel approach called SAMSNeRF that combines Segment Anything Model
(SAM) and Neural Radiance Field (NeRF) techniques. Our approach generates
accurate segmentation masks of surgical tools using SAM, which guides the
refinement of the dynamic surgical scene reconstruction by NeRF. Our
experimental results on public endoscopy surgical videos demonstrate that our
approach successfully reconstructs high-fidelity dynamic surgical scenes and
accurately reflects the spatial information of surgical tools. Our proposed
approach can significantly enhance surgical navigation and automation by
providing surgeons with accurate 3D position information of surgical tools
during surgery.The source code will be released soon."
CitySpec with Shield: A Secure Intelligent Assistant for Requirement Formalization,0.168808,"An increasing number of monitoring systems have been developed in smart
cities to ensure that the real-time operations of a city satisfy safety and
performance requirements. However, many existing city requirements are written
in English with missing, inaccurate, or ambiguous information. There is a high
demand for assisting city policymakers in converting human-specified
requirements to machine-understandable formal specifications for monitoring
systems. To tackle this limitation, we build CitySpec, the first intelligent
assistant system for requirement specification in smart cities. To create
CitySpec, we first collect over 1,500 real-world city requirements across
different domains (e.g., transportation and energy) from over 100 cities and
extract city-specific knowledge to generate a dataset of city vocabulary with
3,061 words. We also build a translation model and enhance it through
requirement synthesis and develop a novel online learning framework with
shielded validation. The evaluation results on real-world city requirements
show that CitySpec increases the sentence-level accuracy of requirement
specification from 59.02% to 86.64%, and has strong adaptability to a new city
and a new domain (e.g., the F1 score for requirements in Seattle increases from
77.6% to 93.75% with online learning). After the enhancement from the shield
function, CitySpec is now immune to most known textual adversarial inputs
(e.g., the attack success rate of DeepWordBug after the shield function is
reduced to 0% from 82.73%). We test the CitySpec with 18 participants from
different domains. CitySpec shows its strong usability and adaptability to
different domains, and also its robustness to malicious inputs."
Computing Rule-Based Explanations of Machine Learning Classifiers using Knowledge Graphs,0.157478,"The use of symbolic knowledge representation and reasoning as a way to
resolve the lack of transparency of machine learning classifiers is a research
area that lately attracts many researchers. In this work, we use knowledge
graphs as the underlying framework providing the terminology for representing
explanations for the operation of a machine learning classifier. In particular,
given a description of the application domain of the classifier in the form of
a knowledge graph, we introduce a novel method for extracting and representing
black-box explanations of its operation, in the form of first-order logic rules
expressed in the terminology of the knowledge graph."
Human-Machine Collaboration Approaches to Build a Dialogue Dataset for Hate Speech Countering,0.34201,"Fighting online hate speech is a challenge that is usually addressed using
Natural Language Processing via automatic detection and removal of hate
content. Besides this approach, counter narratives have emerged as an effective
tool employed by NGOs to respond to online hate on social media platforms. For
this reason, Natural Language Generation is currently being studied as a way to
automatize counter narrative writing. However, the existing resources necessary
to train NLG models are limited to 2-turn interactions (a hate speech and a
counter narrative as response), while in real life, interactions can consist of
multiple turns. In this paper, we present a hybrid approach for dialogical data
collection, which combines the intervention of human expert annotators over
machine generated dialogues obtained using 19 different configurations. The
result of this work is DIALOCONAN, the first dataset comprising over 3000
fictitious multi-turn dialogues between a hater and an NGO operator, covering 6
targets of hate."
Asynchronous Execution of Heterogeneous Tasks in ML-driven HPC Workflows,0.0677835,"Heterogeneous scientific workflows consist of numerous types of tasks that
require executing on heterogeneous resources. Asynchronous execution of those
tasks is crucial to improve resource utilization, task throughput and reduce
workflows' makespan. Therefore, middleware capable of scheduling and executing
different task types across heterogeneous resources must enable asynchronous
execution of tasks. In this paper, we investigate the requirements and
properties of the asynchronous task execution of machine learning (ML)-driven
high performance computing (HPC) workflows. We model the degree of
asynchronicity permitted for arbitrary workflows and propose key metrics that
can be used to determine qualitative benefits when employing asynchronous
execution. Our experiments represent relevant scientific drivers, we perform
them at scale on Summit, and we show that the performance enhancements due to
asynchronous execution are consistent with our model."
Motion Policy Networks,0.754901,"Collision-free motion generation in unknown environments is a core building
block for robot manipulation. Generating such motions is challenging due to
multiple objectives; not only should the solutions be optimal, the motion
generator itself must be fast enough for real-time performance and reliable
enough for practical deployment. A wide variety of methods have been proposed
ranging from local controllers to global planners, often being combined to
offset their shortcomings. We present an end-to-end neural model called Motion
Policy Networks (M$\pi$Nets) to generate collision-free, smooth motion from
just a single depth camera observation. M$\pi$Nets are trained on over 3
million motion planning problems in over 500,000 environments. Our experiments
show that M$\pi$Nets are significantly faster than global planners while
exhibiting the reactivity needed to deal with dynamic scenes. They are 46%
better than prior neural planners and more robust than local control policies.
Despite being only trained in simulation, M$\pi$Nets transfer well to the real
robot with noisy partial point clouds. Code and data are publicly available at
https://mpinets.github.io."
TherapyView: Visualizing Therapy Sessions with Temporal Topic Modeling and AI-Generated Arts,0.76477,"We present the TherapyView, a demonstration system to help therapists
visualize the dynamic contents of past treatment sessions, enabled by the
state-of-the-art neural topic modeling techniques to analyze the topical
tendencies of various psychiatric conditions and deep learning-based image
generation engine to provide a visual summary. The system incorporates temporal
modeling to provide a time-series representation of topic similarities at a
turn-level resolution and AI-generated artworks given the dialogue segments to
provide a concise representations of the contents covered in the session,
offering interpretable insights for therapists to optimize their strategies and
enhance the effectiveness of psychotherapy. This system provides a proof of
concept of AI-augmented therapy tools with e in-depth understanding of the
patient's mental state and enabling more effective treatment."
Low-Resource Multilingual and Zero-Shot Multispeaker TTS,0.304947,"While neural methods for text-to-speech (TTS) have shown great advances in
modeling multiple speakers, even in zero-shot settings, the amount of data
needed for those approaches is generally not feasible for the vast majority of
the world's over 6,000 spoken languages. In this work, we bring together the
tasks of zero-shot voice cloning and multilingual low-resource TTS. Using the
language agnostic meta learning (LAML) procedure and modifications to a TTS
encoder, we show that it is possible for a system to learn speaking a new
language using just 5 minutes of training data while retaining the ability to
infer the voice of even unseen speakers in the newly learned language. We show
the success of our proposed approach in terms of intelligibility, naturalness
and similarity to target speaker using objective metrics as well as human
studies and provide our code and trained models open source."
Joint ANN-SNN Co-training for Object Localization and Image Segmentation,0.119011,"The field of machine learning has been greatly transformed with the
advancement of deep artificial neural networks (ANNs) and the increased
availability of annotated data. Spiking neural networks (SNNs) have recently
emerged as a low-power alternative to ANNs due to their sparsity nature. In
this work, we propose a novel hybrid ANN-SNN co-training framework to improve
the performance of converted SNNs. Our approach is a fine-tuning scheme,
conducted through an alternating, forward-backward training procedure. We apply
our framework to object detection and image segmentation tasks. Experiments
demonstrate the effectiveness of our approach in achieving the design goals."
MoEC: Mixture of Expert Clusters,0.610312,"Sparsely Mixture of Experts (MoE) has received great interest due to its
promising scaling capability with affordable computational overhead. MoE
converts dense layers into sparse experts, and utilizes a gated routing network
to make experts conditionally activated. However, as the number of experts
grows, MoE with outrageous parameters suffers from overfitting and sparse data
allocation. Such problems are especially severe on tasks with limited data,
thus hindering the progress for MoE models to improve performance by scaling
up. In this work, we propose Mixture of Expert Clusters - a general approach to
enable expert layers to learn more diverse and appropriate knowledge by
imposing variance-based constraints on the routing stage. We further propose a
cluster-level expert dropout strategy specifically designed for the expert
cluster structure. Our experiments reveal that MoEC could improve performance
on machine translation and natural language understanding tasks, and raise the
performance upper bound for scaling up experts under limited data. We also
verify that MoEC plays a positive role in mitigating overfitting and sparse
data allocation."
Sentence-Select: Large-Scale Language Model Data Selection for Rare-Word Speech Recognition,0.389096,"Language model fusion helps smart assistants recognize words which are rare
in acoustic data but abundant in text-only corpora (typed search logs).
However, such corpora have properties that hinder downstream performance,
including being (1) too large, (2) beset with domain-mismatched content, and
(3) heavy-headed rather than heavy-tailed (excessively many duplicate search
queries such as ""weather""). We show that three simple strategies for selecting
language modeling data can dramatically improve rare-word recognition without
harming overall performance. First, to address the heavy-headedness, we
downsample the data according to a soft log function, which tunably reduces
high frequency (head) sentences. Second, to encourage rare-word exposure, we
explicitly filter for words rare in the acoustic data. Finally, we tackle
domain-mismatch via perplexity-based contrastive selection, filtering for
examples matched to the target domain. We down-select a large corpus of web
search queries by a factor of 53x and achieve better LM perplexities than
without down-selection. When shallow-fused with a state-of-the-art, production
speech engine, our LM achieves WER reductions of up to 24% relative on
rare-word sentences (without changing overall WER) compared to a baseline LM
trained on the raw corpus. These gains are further validated through favorable
side-by-side evaluations on live voice search traffic."
Bias of AI-Generated Content: An Examination of News Produced by Large Language Models,0.254325,"Large language models (LLMs) have the potential to transform our lives and
work through the content they generate, known as AI-Generated Content (AIGC).
To harness this transformation, we need to understand the limitations of LLMs.
Here, we investigate the bias of AIGC produced by seven representative LLMs,
including ChatGPT and LLaMA. We collect news articles from The New York Times
and Reuters, both known for their dedication to provide unbiased news. We then
apply each examined LLM to generate news content with headlines of these news
articles as prompts, and evaluate the gender and racial biases of the AIGC
produced by the LLM by comparing the AIGC and the original news articles. We
further analyze the gender bias of each LLM under biased prompts by adding
gender-biased messages to prompts constructed from these news headlines. Our
study reveals that the AIGC produced by each examined LLM demonstrates
substantial gender and racial biases. Moreover, the AIGC generated by each LLM
exhibits notable discrimination against females and individuals of the Black
race. Among the LLMs, the AIGC generated by ChatGPT demonstrates the lowest
level of bias, and ChatGPT is the sole model capable of declining content
generation when provided with biased prompts."
Named Entity and Relation Extraction with Multi-Modal Retrieval,0.638602,"Multi-modal named entity recognition (NER) and relation extraction (RE) aim
to leverage relevant image information to improve the performance of NER and
RE. Most existing efforts largely focused on directly extracting potentially
useful information from images (such as pixel-level features, identified
objects, and associated captions). However, such extraction processes may not
be knowledge aware, resulting in information that may not be highly relevant.
In this paper, we propose a novel Multi-modal Retrieval based framework (MoRe).
MoRe contains a text retrieval module and an image-based retrieval module,
which retrieve related knowledge of the input text and image in the knowledge
corpus respectively. Next, the retrieval results are sent to the textual and
visual models respectively for predictions. Finally, a Mixture of Experts (MoE)
module combines the predictions from the two models to make the final decision.
Our experiments show that both our textual model and visual model can achieve
state-of-the-art performance on four multi-modal NER datasets and one
multi-modal RE dataset. With MoE, the model performance can be further improved
and our analysis demonstrates the benefits of integrating both textual and
visual cues for such tasks."
A Hierarchical Interactive Network for Joint Span-based Aspect-Sentiment Analysis,0.408954,"Recently, some span-based methods have achieved encouraging performances for
joint aspect-sentiment analysis, which first extract aspects (aspect
extraction) by detecting aspect boundaries and then classify the span-level
sentiments (sentiment classification). However, most existing approaches either
sequentially extract task-specific features, leading to insufficient feature
interactions, or they encode aspect features and sentiment features in a
parallel manner, implying that feature representation in each task is largely
independent of each other except for input sharing. Both of them ignore the
internal correlations between the aspect extraction and sentiment
classification. To solve this problem, we novelly propose a hierarchical
interactive network (HI-ASA) to model two-way interactions between two tasks
appropriately, where the hierarchical interactions involve two steps:
shallow-level interaction and deep-level interaction. First, we utilize
cross-stitch mechanism to combine the different task-specific features
selectively as the input to ensure proper two-way interactions. Second, the
mutual information technique is applied to mutually constrain learning between
two tasks in the output layer, thus the aspect input and the sentiment input
are capable of encoding features of the other task via backpropagation.
Extensive experiments on three real-world datasets demonstrate HI-ASA's
superiority over baselines."
Reflective Linguistic Programming (RLP): A Stepping Stone in Socially-Aware AGI (SocialAGI),0.529254,"This paper presents Reflective Linguistic Programming (RLP), a unique
approach to conversational AI that emphasizes self-awareness and strategic
planning. RLP encourages models to introspect on their own predefined
personality traits, emotional responses to incoming messages, and planned
strategies, enabling contextually rich, coherent, and engaging interactions. A
striking illustration of RLP's potential involves a toy example, an AI persona
with an adversarial orientation, a demon named `Bogus' inspired by the
children's fairy tale Hansel & Gretel. Bogus exhibits sophisticated behaviors,
such as strategic deception and sensitivity to user discomfort, that
spontaneously arise from the model's introspection and strategic planning.
These behaviors are not pre-programmed or prompted, but emerge as a result of
the model's advanced cognitive modeling. The potential applications of RLP in
socially-aware AGI (Social AGI) are vast, from nuanced negotiations and mental
health support systems to the creation of diverse and dynamic AI personas. Our
exploration of deception serves as a stepping stone towards a new frontier in
AGI, one filled with opportunities for advanced cognitive modeling and the
creation of truly human `digital souls'."
Danish Airs and Grounds: A Dataset for Aerial-to-Street-Level Place Recognition and Localization,0.736403,"Place recognition and visual localization are particularly challenging in
wide baseline configurations. In this paper, we contribute with the
\emph{Danish Airs and Grounds} (DAG) dataset, a large collection of
street-level and aerial images targeting such cases. Its main challenge lies in
the extreme viewing-angle difference between query and reference images with
consequent changes in illumination and perspective. The dataset is larger and
more diverse than current publicly available data, including more than 50 km of
road in urban, suburban and rural areas. All images are associated with
accurate 6-DoF metadata that allows the benchmarking of visual localization
methods.
  We also propose a map-to-image re-localization pipeline, that first estimates
a dense 3D reconstruction from the aerial images and then matches query
street-level images to street-level renderings of the 3D model. The dataset can
be downloaded at: https://frederikwarburg.github.io/DAG"
Multi-Agent Deep Reinforcement Learning for Cost- and Delay-Sensitive Virtual Network Function Placement and Routing,0.6559,"This paper proposes an effective and novel multiagent deep reinforcement
learning (MADRL)-based method for solving the joint virtual network function
(VNF) placement and routing (P&R), where multiple service requests with
differentiated demands are delivered at the same time. The differentiated
demands of the service requests are reflected by their delay- and
cost-sensitive factors. We first construct a VNF P&R problem to jointly
minimize a weighted sum of service delay and resource consumption cost, which
is NP-complete. Then, the joint VNF P&R problem is decoupled into two iterative
subtasks: placement subtask and routing subtask. Each subtask consists of
multiple concurrent parallel sequential decision processes. By invoking the
deep deterministic policy gradient method and multi-agent technique, an
MADRL-P&R framework is designed to perform the two subtasks. The new joint
reward and internal rewards mechanism is proposed to match the goals and
constraints of the placement and routing subtasks. We also propose the
parameter migration-based model-retraining method to deal with changing network
topologies. Corroborated by experiments, the proposed MADRL-P&R framework is
superior to its alternatives in terms of service cost and delay, and offers
higher flexibility for personalized service demands. The parameter
migration-based model-retraining method can efficiently accelerate convergence
under moderate network topology changes."
Large-scale multi-objective influence maximisation with network downscaling,0.305298,"Finding the most influential nodes in a network is a computationally hard
problem with several possible applications in various kinds of network-based
problems. While several methods have been proposed for tackling the influence
maximisation (IM) problem, their runtime typically scales poorly when the
network size increases. Here, we propose an original method, based on network
downscaling, that allows a multi-objective evolutionary algorithm (MOEA) to
solve the IM problem on a reduced scale network, while preserving the relevant
properties of the original network. The downscaled solution is then upscaled to
the original network, using a mechanism based on centrality metrics such as
PageRank. Our results on eight large networks (including two with $\sim$50k
nodes) demonstrate the effectiveness of the proposed method with a more than
10-fold runtime gain compared to the time needed on the original network, and
an up to $82\%$ time reduction compared to CELF."
"Q-Ensemble for Offline RL: Don't Scale the Ensemble, Scale the Batch Size",0.525486,"Training large neural networks is known to be time-consuming, with the
learning duration taking days or even weeks. To address this problem,
large-batch optimization was introduced. This approach demonstrated that
scaling mini-batch sizes with appropriate learning rate adjustments can speed
up the training process by orders of magnitude. While long training time was
not typically a major issue for model-free deep offline RL algorithms, recently
introduced Q-ensemble methods achieving state-of-the-art performance made this
issue more relevant, notably extending the training duration. In this work, we
demonstrate how this class of methods can benefit from large-batch
optimization, which is commonly overlooked by the deep offline RL community. We
show that scaling the mini-batch size and naively adjusting the learning rate
allows for (1) a reduced size of the Q-ensemble, (2) stronger penalization of
out-of-distribution actions, and (3) improved convergence time, effectively
shortening training duration by 3-4x times on average."
A lightweight Transformer-based model for fish landmark detection,0.249792,"Transformer-based models, such as the Vision Transformer (ViT), can
outperform onvolutional Neural Networks (CNNs) in some vision tasks when there
is sufficient training data. However, (CNNs) have a strong and useful inductive
bias for vision tasks (i.e. translation equivariance and locality). In this
work, we developed a novel model architecture that we call a Mobile fish
landmark detection network (MFLD-net). We have made this model using
convolution operations based on ViT (i.e. Patch embeddings, Multi-Layer
Perceptrons). MFLD-net can achieve competitive or better results in low data
regimes while being lightweight and therefore suitable for embedded and mobile
devices. Furthermore, we show that MFLD-net can achieve keypoint (landmark)
estimation accuracies on-par or even better than some of the state-of-the-art
(CNNs) on a fish image dataset. Additionally, unlike ViT, MFLD-net does not
need a pre-trained model and can generalise well when trained on a small
dataset. We provide quantitative and qualitative results that demonstrate the
model's generalisation capabilities. This work will provide a foundation for
future efforts in developing mobile, but efficient fish monitoring systems and
devices."
Point Transformer V2: Grouped Vector Attention and Partition-based Pooling,0.999776,"As a pioneering work exploring transformer architecture for 3D point cloud
understanding, Point Transformer achieves impressive results on multiple highly
competitive benchmarks. In this work, we analyze the limitations of the Point
Transformer and propose our powerful and efficient Point Transformer V2 model
with novel designs that overcome the limitations of previous work. In
particular, we first propose group vector attention, which is more effective
than the previous version of vector attention. Inheriting the advantages of
both learnable weight encoding and multi-head attention, we present a highly
effective implementation of grouped vector attention with a novel grouped
weight encoding layer. We also strengthen the position information for
attention by an additional position encoding multiplier. Furthermore, we design
novel and lightweight partition-based pooling methods which enable better
spatial alignment and more efficient sampling. Extensive experiments show that
our model achieves better performance than its predecessor and achieves
state-of-the-art on several challenging 3D point cloud understanding
benchmarks, including 3D point cloud segmentation on ScanNet v2 and S3DIS and
3D point cloud classification on ModelNet40. Our code will be available at
https://github.com/Gofinge/PointTransformerV2."
Point RCNN: An Angle-Free Framework for Rotated Object Detection,0.242656,"Rotated object detection in aerial images is still challenging due to
arbitrary orientations, large scale and aspect ratio variations, and extreme
density of objects. Existing state-of-the-art rotated object detection methods
mainly rely on angle-based detectors. However, angle regression can easily
suffer from the long-standing boundary problem. To tackle this problem, we
propose a purely angle-free framework for rotated object detection, called
Point RCNN, which mainly consists of PointRPN and PointReg. In particular,
PointRPN generates accurate rotated RoIs (RRoIs) by converting the learned
representative points with a coarse-to-fine manner, which is motivated by
RepPoints. Based on the learned RRoIs, PointReg performs corner points
refinement for more accurate detection. In addition, aerial images are often
severely unbalanced in categories, and existing methods almost ignore this
issue. In this paper, we also experimentally verify that re-sampling the images
of the rare categories will stabilize training and further improve the
detection performance. Experiments demonstrate that our Point RCNN achieves the
new state-of-the-art detection performance on commonly used aerial datasets,
including DOTA-v1.0, DOTA-v1.5, and HRSC2016."
ProPaLL: Probabilistic Partial Label Learning,0.140387,"Partial label learning is a type of weakly supervised learning, where each
training instance corresponds to a set of candidate labels, among which only
one is true. In this paper, we introduce ProPaLL, a novel probabilistic
approach to this problem, which has at least three advantages compared to the
existing approaches: it simplifies the training process, improves performance,
and can be applied to any deep architecture. Experiments conducted on
artificial and real-world datasets indicate that ProPaLL outperforms the
existing approaches."
CKG: Dynamic Representation Based on Context and Knowledge Graph,0.0613054,"Recently, neural language representation models pre-trained on large corpus
can capture rich co-occurrence information and be fine-tuned in downstream
tasks to improve the performance. As a result, they have achieved
state-of-the-art results in a large range of language tasks. However, there
exists other valuable semantic information such as similar, opposite, or other
possible meanings in external knowledge graphs (KGs). We argue that entities in
KGs could be used to enhance the correct semantic meaning of language
sentences. In this paper, we propose a new method CKG: Dynamic Representation
Based on \textbf{C}ontext and \textbf{K}nowledge \textbf{G}raph. On the one
side, CKG can extract rich semantic information of large corpus. On the other
side, it can make full use of inside information such as co-occurrence in large
corpus and outside information such as similar entities in KGs. We conduct
extensive experiments on a wide range of tasks, including QQP, MRPC, SST-5,
SQuAD, CoNLL 2003, and SNLI. The experiment results show that CKG achieves SOTA
89.2 on SQuAD compared with SAN (84.4), ELMo (85.8), and BERT$_{Base}$ (88.5)."
The Neural Race Reduction: Dynamics of Abstraction in Gated Networks,0.761019,"Our theoretical understanding of deep learning has not kept pace with its
empirical success. While network architecture is known to be critical, we do
not yet understand its effect on learned representations and network behavior,
or how this architecture should reflect task structure.In this work, we begin
to address this gap by introducing the Gated Deep Linear Network framework that
schematizes how pathways of information flow impact learning dynamics within an
architecture. Crucially, because of the gating, these networks can compute
nonlinear functions of their input. We derive an exact reduction and, for
certain cases, exact solutions to the dynamics of learning. Our analysis
demonstrates that the learning dynamics in structured networks can be
conceptualized as a neural race with an implicit bias towards shared
representations, which then govern the model's ability to systematically
generalize, multi-task, and transfer. We validate our key insights on
naturalistic datasets and with relaxed assumptions. Taken together, our work
gives rise to general hypotheses relating neural architecture to learning and
provides a mathematical approach towards understanding the design of more
complex architectures and the role of modularity and compositionality in
solving real-world problems. The code and results are available at
https://www.saxelab.org/gated-dln ."
Line Graphics Digitization: A Step Towards Full Automation,0.36625,"The digitization of documents allows for wider accessibility and
reproducibility. While automatic digitization of document layout and text
content has been a long-standing focus of research, this problem in regard to
graphical elements, such as statistical plots, has been under-explored. In this
paper, we introduce the task of fine-grained visual understanding of
mathematical graphics and present the Line Graphics (LG) dataset, which
includes pixel-wise annotations of 5 coarse and 10 fine-grained categories. Our
dataset covers 520 images of mathematical graphics collected from 450 documents
from different disciplines. Our proposed dataset can support two different
computer vision tasks, i.e., semantic segmentation and object detection. To
benchmark our LG dataset, we explore 7 state-of-the-art models. To foster
further research on the digitization of statistical graphs, we will make the
dataset, code, and models publicly available to the community."
Argumentative Reward Learning: Reasoning About Human Preferences,0.129768,"We define a novel neuro-symbolic framework, argumentative reward learning,
which combines preference-based argumentation with existing approaches to
reinforcement learning from human feedback. Our method improves prior work by
generalising human preferences, reducing the burden on the user and increasing
the robustness of the reward model. We demonstrate this with a number of
experiments."
Truth Set Algebra: A New Way to Prove Undefinability,0.872864,"The article proposes a new technique for proving the undefinability of
logical connectives through each other and illustrates the technique with
several examples. Some of the obtained results are new proofs of the existing
theorems, others are original to this work."
LR-CSNet: Low-Rank Deep Unfolding Network for Image Compressive Sensing,0.584738,"Deep unfolding networks (DUNs) have proven to be a viable approach to
compressive sensing (CS). In this work, we propose a DUN called low-rank CS
network (LR-CSNet) for natural image CS. Real-world image patches are often
well-represented by low-rank approximations. LR-CSNet exploits this property by
adding a low-rank prior to the CS optimization task. We derive a corresponding
iterative optimization procedure using variable splitting, which is then
translated to a new DUN architecture. The architecture uses low-rank generation
modules (LRGMs), which learn low-rank matrix factorizations, as well as
gradient descent and proximal mappings (GDPMs), which are proposed to extract
high-frequency features to refine image details. In addition, the deep features
generated at each reconstruction stage in the DUN are transferred between
stages to boost the performance. Our extensive experiments on three widely
considered datasets demonstrate the promising performance of LR-CSNet compared
to state-of-the-art methods in natural image CS."
SELC: Self-Ensemble Label Correction Improves Learning with Noisy Labels,0.833861,"Deep neural networks are prone to overfitting noisy labels, resulting in poor
generalization performance. To overcome this problem, we present a simple and
effective method self-ensemble label correction (SELC) to progressively correct
noisy labels and refine the model. We look deeper into the memorization
behavior in training with noisy labels and observe that the network outputs are
reliable in the early stage. To retain this reliable knowledge, SELC uses
ensemble predictions formed by an exponential moving average of network outputs
to update the original noisy labels. We show that training with SELC refines
the model by gradually reducing supervision from noisy labels and increasing
supervision from ensemble predictions. Despite its simplicity, compared with
many state-of-the-art methods, SELC obtains more promising and stable results
in the presence of class-conditional, instance-dependent, and real-world label
noise. The code is available at https://github.com/MacLLL/SELC."
MINER: Multiscale Implicit Neural Representations,0.412058,"We introduce a new neural signal model designed for efficient high-resolution
representation of large-scale signals. The key innovation in our multiscale
implicit neural representation (MINER) is an internal representation via a
Laplacian pyramid, which provides a sparse multiscale decomposition of the
signal that captures orthogonal parts of the signal across scales. We leverage
the advantages of the Laplacian pyramid by representing small disjoint patches
of the pyramid at each scale with a small MLP. This enables the capacity of the
network to adaptively increase from coarse to fine scales, and only represent
parts of the signal with strong signal energy. The parameters of each MLP are
optimized from coarse-to-fine scale which results in faster approximations at
coarser scales, thereby ultimately an extremely fast training process. We apply
MINER to a range of large-scale signal representation tasks, including
gigapixel images and very large point clouds, and demonstrate that it requires
fewer than 25% of the parameters, 33% of the memory footprint, and 10% of the
computation time of competing techniques such as ACORN to reach the same
representation accuracy."
Context-Gloss Augmentation for Improving Arabic Target Sense Verification,0.770509,"Arabic language lacks semantic datasets and sense inventories. The most
common semantically-labeled dataset for Arabic is the ArabGlossBERT, a
relatively small dataset that consists of 167K context-gloss pairs (about 60K
positive and 107K negative pairs), collected from Arabic dictionaries. This
paper presents an enrichment to the ArabGlossBERT dataset, by augmenting it
using (Arabic-English-Arabic) machine back-translation. Augmentation increased
the dataset size to 352K pairs (149K positive and 203K negative pairs). We
measure the impact of augmentation using different data configurations to
fine-tune BERT on target sense verification (TSV) task. Overall, the accuracy
ranges between 78% to 84% for different data configurations. Although our
approach performed at par with the baseline, we did observe some improvements
for some POS tags in some experiments. Furthermore, our fine-tuned models are
trained on a larger dataset covering larger vocabulary and contexts. We provide
an in-depth analysis of the accuracy for each part-of-speech (POS)."
DecoupleNet: Decoupled Network for Domain Adaptive Semantic Segmentation,0.892623,"Unsupervised domain adaptation in semantic segmentation has been raised to
alleviate the reliance on expensive pixel-wise annotations. It leverages a
labeled source domain dataset as well as unlabeled target domain images to
learn a segmentation network. In this paper, we observe two main issues of the
existing domain-invariant learning framework. (1) Being distracted by the
feature distribution alignment, the network cannot focus on the segmentation
task. (2) Fitting source domain data well would compromise the target domain
performance. To address these issues, we propose DecoupleNet that alleviates
source domain overfitting and enables the final model to focus more on the
segmentation task. Furthermore, we put forward Self-Discrimination (SD) and
introduce an auxiliary classifier to learn more discriminative target domain
features with pseudo labels. Finally, we propose Online Enhanced Self-Training
(OEST) to contextually enhance the quality of pseudo labels in an online
manner. Experiments show our method outperforms existing state-of-the-art
methods, and extensive ablation studies verify the effectiveness of each
component. Code is available at https://github.com/dvlab-research/DecoupleNet."
NTIRE 2022 Challenge on Stereo Image Super-Resolution: Methods and Results,0.68648,"In this paper, we summarize the 1st NTIRE challenge on stereo image
super-resolution (restoration of rich details in a pair of low-resolution
stereo images) with a focus on new solutions and results. This challenge has 1
track aiming at the stereo image super-resolution problem under a standard
bicubic degradation. In total, 238 participants were successfully registered,
and 21 teams competed in the final testing phase. Among those participants, 20
teams successfully submitted results with PSNR (RGB) scores better than the
baseline. This challenge establishes a new benchmark for stereo image SR."
End-to-end video instance segmentation via spatial-temporal graph neural networks,0.416227,"Video instance segmentation is a challenging task that extends image instance
segmentation to the video domain. Existing methods either rely only on
single-frame information for the detection and segmentation subproblems or
handle tracking as a separate post-processing step, which limit their
capability to fully leverage and share useful spatial-temporal information for
all the subproblems. In this paper, we propose a novel graph-neural-network
(GNN) based method to handle the aforementioned limitation. Specifically, graph
nodes representing instance features are used for detection and segmentation
while graph edges representing instance relations are used for tracking. Both
inter and intra-frame information is effectively propagated and shared via
graph updates and all the subproblems (i.e. detection, segmentation and
tracking) are jointly optimized in an unified framework. The performance of our
method shows great improvement on the YoutubeVIS validation dataset compared to
existing methods and achieves 35.2% AP with a ResNet-50 backbone, operating at
22 FPS. Code is available at http://github.com/lucaswithai/visgraph.git ."
Recovering Patient Journeys: A Corpus of Biomedical Entities and Relations on Twitter (BEAR),0.272249,"Text mining and information extraction for the medical domain has focused on
scientific text generated by researchers. However, their direct access to
individual patient experiences or patient-doctor interactions can be limited.
Information provided on social media, e.g., by patients and their relatives,
complements the knowledge in scientific text. It reflects the patient's journey
and their subjective perspective on the process of developing symptoms, being
diagnosed and offered a treatment, being cured or learning to live with a
medical condition. The value of this type of data is therefore twofold:
Firstly, it offers direct access to people's perspectives. Secondly, it might
cover information that is not available elsewhere, including self-treatment or
self-diagnoses. Named entity recognition and relation extraction are methods to
structure information that is available in unstructured text. However, existing
medical social media corpora focused on a comparably small set of entities and
relations and particular domains, rather than putting the patient into the
center of analyses. With this paper we contribute a corpus with a rich set of
annotation layers following the motivation to uncover and model patients'
journeys and experiences in more detail. We label 14 entity classes (incl.
environmental factors, diagnostics, biochemical processes, patients'
quality-of-life descriptions, pathogens, medical conditions, and treatments)
and 20 relation classes (e.g., prevents, influences, interactions, causes) most
of which have not been considered before for social media data. The publicly
available dataset consists of 2,100 tweets with approx. 6,000 entity and 3,000
relation annotations. In a corpus analysis we find that over 80 % of documents
contain relevant entities. Over 50 % of tweets express relations which we
consider essential for uncovering patients' narratives about their journeys."
Improving Chinese Named Entity Recognition by Search Engine Augmentation,0.15872,"Compared with English, Chinese suffers from more grammatical ambiguities,
like fuzzy word boundaries and polysemous words. In this case, contextual
information is not sufficient to support Chinese named entity recognition
(NER), especially for rare and emerging named entities. Semantic augmentation
using external knowledge is a potential way to alleviate this problem, while
how to obtain and leverage external knowledge for the NER task remains a
challenge. In this paper, we propose a neural-based approach to perform
semantic augmentation using external knowledge from search engine for Chinese
NER. In particular, a multi-channel semantic fusion model is adopted to
generate the augmented input representations, which aggregates external related
texts retrieved from the search engine. Experiments have shown the superiority
of our model across 4 NER datasets, including formal and social media language
contexts, which further prove the effectiveness of our approach."
Convolutional Simultaneous Sparse Approximation with Applications to RGB-NIR Image Fusion,0.521377,"Simultaneous sparse approximation (SSA) seeks to represent a set of dependent
signals using sparse vectors with identical supports. The SSA model has been
used in various signal and image processing applications involving multiple
correlated input signals. In this paper, we propose algorithms for
convolutional SSA (CSSA) based on the alternating direction method of
multipliers. Specifically, we address the CSSA problem with different sparsity
structures and the convolutional feature learning problem in multimodal
data/signals based on the SSA model. We evaluate the proposed algorithms by
applying them to multimodal and multifocus image fusion problems."
BEVDepth: Acquisition of Reliable Depth for Multi-view 3D Object Detection,1.0,"In this research, we propose a new 3D object detector with a trustworthy
depth estimation, dubbed BEVDepth, for camera-based Bird's-Eye-View (BEV) 3D
object detection. Our work is based on a key observation -- depth estimation in
recent approaches is surprisingly inadequate given the fact that depth is
essential to camera 3D detection. Our BEVDepth resolves this by leveraging
explicit depth supervision. A camera-awareness depth estimation module is also
introduced to facilitate the depth predicting capability. Besides, we design a
novel Depth Refinement Module to counter the side effects carried by imprecise
feature unprojection. Aided by customized Efficient Voxel Pooling and
multi-frame mechanism, BEVDepth achieves the new state-of-the-art 60.9% NDS on
the challenging nuScenes test set while maintaining high efficiency. For the
first time, the NDS score of a camera model reaches 60%."
Sionna: An Open-Source Library for Next-Generation Physical Layer Research,1.0,"Sionna is a GPU-accelerated open-source library for link-level simulations
based on TensorFlow. It enables the rapid prototyping of complex communication
system architectures and provides native support for the integration of neural
networks. Sionna implements a wide breadth of carefully tested state-of-the-art
algorithms that can be used for benchmarking and end-to-end performance
evaluation. This allows researchers to focus on their research, making it more
impactful and reproducible, while saving time implementing components outside
their area of expertise. This white paper provides a brief introduction to
Sionna, explains its design principles and features, as well as future
extensions, such as integrated ray tracing and custom CUDA kernels. We believe
that Sionna is a valuable tool for research on next-generation communication
systems, such as 6G, and we welcome contributions from our community."
Irreducible Curriculum for Language Model Pretraining,0.0722687,"Automatic data selection and curriculum design for training large language
models is challenging, with only a few existing methods showing improvements
over standard training. Furthermore, current schemes focus on domain-level
selection, overlooking the more fine-grained contributions of each individual
training point. It is difficult to apply traditional datapoint selection
methods on large language models: most online batch selection methods perform
two-times forward or backward passes, which introduces considerable extra costs
with large-scale models. To mitigate these obstacles, we propose irreducible
curriculum as a curriculum learning algorithm for language model pretraining,
which prioritizes samples with higher learnability. Specifically, to avoid
prohibitive extra computation overhead, we simulate the sample loss along the
main model's training trajectory using a small-scale proxy model. Our
experiments on the RedPajama-1B dataset demonstrate a consistent improvement on
validation perplexity across all 7 domains compared to random uniform baseline
and the anti-curriculum strategy. Our method also reduces the sharpness of the
network and illustrates a better 5-shot accuracy on MMLU benchmarks."
Data Contamination: From Memorization to Exploitation,0.955182,"Pretrained language models are typically trained on massive web-based
datasets, which are often ""contaminated"" with downstream test sets. It is not
clear to what extent models exploit the contaminated data for downstream tasks.
We present a principled method to study this question. We pretrain BERT models
on joint corpora of Wikipedia and labeled downstream datasets, and fine-tune
them on the relevant task. Comparing performance between samples seen and
unseen during pretraining enables us to define and quantify levels of
memorization and exploitation. Experiments with two models and three downstream
tasks show that exploitation exists in some cases, but in others the models
memorize the contaminated data, but do not exploit it. We show that these two
measures are affected by different factors such as the number of duplications
of the contaminated data and the model size. Our results highlight the
importance of analyzing massive web-scale datasets to verify that progress in
NLP is obtained by better language understanding and not better data
exploitation."
An adaptive large neighborhood search heuristic for the multi-port continuous berth allocation problem,0.0772219,"In this paper, we study a problem that integrates the vessel scheduling
problem with the berth allocation into a collaborative problem denoted as the
multi-port continuous berth allocation problem (MCBAP). This problem optimizes
the berth allocation of a set of ships simultaneously in multiple ports while
also considering the sailing speed of ships between ports. Due to the highly
combinatorial character of the problem, exact methods struggle to scale to
large-size instances, which points to exploring heuristic methods. We present a
mixed-integer problem formulation for the MCBAP and introduce an adaptive large
neighborhood search (ALNS) algorithm enhanced with a local search procedure to
solve it. The computational results highlight the method's suitability for
larger instances by providing high-quality solutions in short computational
times. Practical insights indicate that the carriers' and terminal operators'
operational costs are impacted in different ways by fuel prices, external ships
at port, and the modeling of a continuous quay."
MIX-MAB: Reinforcement Learning-based Resource Allocation Algorithm for LoRaWAN,0.428163,"This paper focuses on improving the resource allocation algorithm in terms of
packet delivery ratio (PDR), i.e., the number of successfully received packets
sent by end devices (EDs) in a long-range wide-area network (LoRaWAN). Setting
the transmission parameters significantly affects the PDR. Employing
reinforcement learning (RL), we propose a resource allocation algorithm that
enables the EDs to configure their transmission parameters in a distributed
manner. We model the resource allocation problem as a multi-armed bandit (MAB)
and then address it by proposing a two-phase algorithm named MIX-MAB, which
consists of the exponential weights for exploration and exploitation (EXP3) and
successive elimination (SE) algorithms. We evaluate the MIX-MAB performance
through simulation results and compare it with other existing approaches.
Numerical results show that the proposed solution performs better than the
existing schemes in terms of convergence time and PDR."
Domain-Specific Fine-Tuning of Large Language Models for Interactive Robot Programming,0.219173,"Industrial robots are applied in a widening range of industries, but robot
programming mostly remains a task limited to programming experts. We propose a
natural language-based assistant for programming of advanced, industrial
robotic applications and investigate strategies for domain-specific fine-tuning
of foundation models with limited data and compute."
FisheyeHDK: Hyperbolic Deformable Kernel Learning for Ultra-Wide Field-of-View Image Recognition,0.793149,"Conventional convolution neural networks (CNNs) trained on narrow
Field-of-View (FoV) images are the state-of-the-art approaches for object
recognition tasks. Some methods proposed the adaptation of CNNs to ultra-wide
FoV images by learning deformable kernels. However, they are limited by the
Euclidean geometry and their accuracy degrades under strong distortions caused
by fisheye projections. In this work, we demonstrate that learning the shape of
convolution kernels in non-Euclidean spaces is better than existing deformable
kernel methods. In particular, we propose a new approach that learns deformable
kernel parameters (positions) in hyperbolic space. FisheyeHDK is a hybrid CNN
architecture combining hyperbolic and Euclidean convolution layers for
positions and features learning. First, we provide an intuition of hyperbolic
space for wide FoV images. Using synthetic distortion profiles, we demonstrate
the effectiveness of our approach. We select two datasets - Cityscapes and
BDD100K 2020 - of perspective images which we transform to fisheye equivalents
at different scaling factors (analog to focal lengths). Finally, we provide an
experiment on data collected by a real fisheye camera. Validations and
experiments show that our approach improves existing deformable kernel methods
for CNN adaptation on fisheye images."
More Interpretable Graph Similarity Computation via Maximum Common Subgraph Inference,0.675987,"Graph similarity measurement, which computes the distance/similarity between
two graphs, arises in various graph-related tasks. Recent learning-based
methods lack interpretability, as they directly transform interaction
information between two graphs into one hidden vector and then map it to
similarity. To cope with this problem, this study proposes a more interpretable
end-to-end paradigm for graph similarity learning, named Similarity Computation
via Maximum Common Subgraph Inference (INFMCS). Our critical insight into
INFMCS is the strong correlation between similarity score and Maximum Common
Subgraph (MCS). We implicitly infer MCS to obtain the normalized MCS size, with
the supervision information being only the similarity score during training. To
capture more global information, we also stack some vanilla transformer encoder
layers with graph convolution layers and propose a novel permutation-invariant
node Positional Encoding. The entire model is quite simple yet effective.
Comprehensive experiments demonstrate that INFMCS consistently outperforms
state-of-the-art baselines for graph-graph classification and regression tasks.
Ablation experiments verify the effectiveness of the proposed computation
paradigm and other components. Also, visualization and statistics of results
reveal the interpretability of INFMCS."
A Quantum Computing-based System for Portfolio Optimization using Future Asset Values and Automatic Reduction of the Investment Universe,0.431541,"One of the problems in quantitative finance that has received the most
attention is the portfolio optimization problem. Regarding its solving, this
problem has been approached using different techniques, with those related to
quantum computing being especially prolific in recent years. In this study, we
present a system called Quantum Computing-based System for Portfolio
Optimization with Future Asset Values and Automatic Universe Reduction
(Q4FuturePOP), which deals with the Portfolio Optimization Problem considering
the following innovations: i) the developed tool is modeled for working with
future prediction of assets, instead of historical values; and ii) Q4FuturePOP
includes an automatic universe reduction module, which is conceived to
intelligently reduce the complexity of the problem. We also introduce a brief
discussion about the preliminary performance of the different modules that
compose the prototypical version of Q4FuturePOP."
Measuring Harmful Representations in Scandinavian Language Models,0.327672,"Scandinavian countries are perceived as role-models when it comes to gender
equality. With the advent of pre-trained language models and their widespread
usage, we investigate to what extent gender-based harmful and toxic content
exist in selected Scandinavian language models. We examine nine models,
covering Danish, Swedish, and Norwegian, by manually creating template-based
sentences and probing the models for completion. We evaluate the completions
using two methods for measuring harmful and toxic completions and provide a
thorough analysis of the results. We show that Scandinavian pre-trained
language models contain harmful and gender-based stereotypes with similar
values across all languages. This finding goes against the general expectations
related to gender equality in Scandinavian countries and shows the possible
problematic outcomes of using such models in real-world settings."
Neuromorphic Event-based Facial Expression Recognition,0.949129,"Recently, event cameras have shown large applicability in several computer
vision fields especially concerning tasks that require high temporal
resolution. In this work, we investigate the usage of such kind of data for
emotion recognition by presenting NEFER, a dataset for Neuromorphic Event-based
Facial Expression Recognition. NEFER is composed of paired RGB and event videos
representing human faces labeled with the respective emotions and also
annotated with face bounding boxes and facial landmarks. We detail the data
acquisition process as well as providing a baseline method for RGB and event
data. The collected data captures subtle micro-expressions, which are hard to
spot with RGB data, yet emerge in the event domain. We report a double
recognition accuracy for the event-based approach, proving the effectiveness of
a neuromorphic approach for analyzing fast and hardly detectable expressions
and the emotions they conceal."
UniDistill: A Universal Cross-Modality Knowledge Distillation Framework for 3D Object Detection in Bird's-Eye View,0.894304,"In the field of 3D object detection for autonomous driving, the sensor
portfolio including multi-modality and single-modality is diverse and complex.
Since the multi-modal methods have system complexity while the accuracy of
single-modal ones is relatively low, how to make a tradeoff between them is
difficult. In this work, we propose a universal cross-modality knowledge
distillation framework (UniDistill) to improve the performance of
single-modality detectors. Specifically, during training, UniDistill projects
the features of both the teacher and the student detector into Bird's-Eye-View
(BEV), which is a friendly representation for different modalities. Then, three
distillation losses are calculated to sparsely align the foreground features,
helping the student learn from the teacher without introducing additional cost
during inference. Taking advantage of the similar detection paradigm of
different detectors in BEV, UniDistill easily supports LiDAR-to-camera,
camera-to-LiDAR, fusion-to-LiDAR and fusion-to-camera distillation paths.
Furthermore, the three distillation losses can filter the effect of misaligned
background information and balance between objects of different sizes,
improving the distillation effectiveness. Extensive experiments on nuScenes
demonstrate that UniDistill effectively improves the mAP and NDS of student
detectors by 2.0%~3.2%."
RetroMAE: Pre-Training Retrieval-oriented Language Models Via Masked Auto-Encoder,0.836364,"Despite pre-training's progress in many important NLP tasks, it remains to
explore effective pre-training strategies for dense retrieval. In this paper,
we propose RetroMAE, a new retrieval oriented pre-training paradigm based on
Masked Auto-Encoder (MAE). RetroMAE is highlighted by three critical designs.
1) A novel MAE workflow, where the input sentence is polluted for encoder and
decoder with different masks. The sentence embedding is generated from the
encoder's masked input; then, the original sentence is recovered based on the
sentence embedding and the decoder's masked input via masked language modeling.
2) Asymmetric model structure, with a full-scale BERT like transformer as
encoder, and a one-layer transformer as decoder. 3) Asymmetric masking ratios,
with a moderate ratio for encoder: 15~30%, and an aggressive ratio for decoder:
50~70%. Our framework is simple to realize and empirically competitive: the
pre-trained models dramatically improve the SOTA performances on a wide range
of dense retrieval benchmarks, like BEIR and MS MARCO. The source code and
pre-trained models are made publicly available at
https://github.com/staoxiao/RetroMAE so as to inspire more interesting
research."
Counterfactual Plans under Distributional Ambiguity,0.535598,"Counterfactual explanations are attracting significant attention due to the
flourishing applications of machine learning models in consequential domains. A
counterfactual plan consists of multiple possibilities to modify a given
instance so that the model's prediction will be altered. As the predictive
model can be updated subject to the future arrival of new data, a
counterfactual plan may become ineffective or infeasible with respect to the
future values of the model parameters. In this work, we study the
counterfactual plans under model uncertainty, in which the distribution of the
model parameters is partially prescribed using only the first- and
second-moment information. First, we propose an uncertainty quantification tool
to compute the lower and upper bounds of the probability of validity for any
given counterfactual plan. We then provide corrective methods to adjust the
counterfactual plan to improve the validity measure. The numerical experiments
validate our bounds and demonstrate that our correction increases the
robustness of the counterfactual plans in different real-world datasets."
Learning Fine-grained View-Invariant Representations from Unpaired Ego-Exo Videos via Temporal Alignment,0.789691,"The egocentric and exocentric viewpoints of a human activity look
dramatically different, yet invariant representations to link them are
essential for many potential applications in robotics and augmented reality.
Prior work is limited to learning view-invariant features from paired
synchronized viewpoints. We relax that strong data assumption and propose to
learn fine-grained action features that are invariant to the viewpoints by
aligning egocentric and exocentric videos in time, even when not captured
simultaneously or in the same environment. To this end, we propose AE2, a
self-supervised embedding approach with two key designs: (1) an object-centric
encoder that explicitly focuses on regions corresponding to hands and active
objects; and (2) a contrastive-based alignment objective that leverages
temporally reversed frames as negative samples. For evaluation, we establish a
benchmark for fine-grained video understanding in the ego-exo context,
comprising four datasets -- including an ego tennis forehand dataset we
collected, along with dense per-frame labels we annotated for each dataset. On
the four datasets, our AE2 method strongly outperforms prior work in a variety
of fine-grained downstream tasks, both in regular and cross-view settings."
Watch Where You Head: A View-biased Domain Gap in Gait Recognition and Unsupervised Adaptation,0.178401,"Gait Recognition is a computer vision task aiming to identify people by their
walking patterns. Although existing methods often show high performance on
specific datasets, they lack the ability to generalize to unseen scenarios.
Unsupervised Domain Adaptation (UDA) tries to adapt a model, pre-trained in a
supervised manner on a source domain, to an unlabelled target domain. There are
only a few works on UDA for gait recognition proposing solutions to limited
scenarios. In this paper, we reveal a fundamental phenomenon in adaptation of
gait recognition models, caused by the bias in the target domain to viewing
angle or walking direction. We then suggest a remedy to reduce this bias with a
novel triplet selection strategy combined with curriculum learning. To this
end, we present Gait Orientation-based method for Unsupervised Domain
Adaptation (GOUDA). We provide extensive experiments on four widely-used gait
datasets, CASIA-B, OU-MVLP, GREW, and Gait3D, and on three backbones, GaitSet,
GaitPart, and GaitGL, justifying the view bias and showing the superiority of
our proposed method over prior UDA works."
CTRAN: CNN-Transformer-based Network for Natural Language Understanding,0.30737,"Intent-detection and slot-filling are the two main tasks in natural language
understanding. In this study, we propose CTRAN, a novel encoder-decoder
CNN-Transformer-based architecture for intent-detection and slot-filling. In
the encoder, we use BERT, followed by several convolutional layers, and
rearrange the output using window feature sequence. We use stacked Transformer
encoders after the window feature sequence. For the intent-detection decoder,
we utilize self-attention followed by a linear layer. In the slot-filling
decoder, we introduce the aligned Transformer decoder, which utilizes a zero
diagonal mask, aligning output tags with input tokens. We apply our network on
ATIS and SNIPS, and surpass the current state-of-the-art in slot-filling on
both datasets. Furthermore, we incorporate the language model as word
embeddings, and show that this strategy yields a better result when compared to
the language model as an encoder."
Word Order Does Matter (And Shuffled Language Models Know It),0.847521,"Recent studies have shown that language models pretrained and/or fine-tuned
on randomly permuted sentences exhibit competitive performance on GLUE, putting
into question the importance of word order information. Somewhat
counter-intuitively, some of these studies also report that position embeddings
appear to be crucial for models' good performance with shuffled text. We probe
these language models for word order information and investigate what position
embeddings learned from shuffled text encode, showing that these models retain
information pertaining to the original, naturalistic word order. We show this
is in part due to a subtlety in how shuffling is implemented in previous work
-- before rather than after subword segmentation. Surprisingly, we find even
Language models trained on text shuffled after subword segmentation retain some
semblance of information about word order because of the statistical
dependencies between sentence length and unigram probabilities. Finally, we
show that beyond GLUE, a variety of language understanding tasks do require
word order information, often to an extent that cannot be learned through
fine-tuning."
RuSentNE-2023: Evaluating Entity-Oriented Sentiment Analysis on Russian News Texts,0.507972,"The paper describes the RuSentNE-2023 evaluation devoted to targeted
sentiment analysis in Russian news texts. The task is to predict sentiment
towards a named entity in a single sentence. The dataset for RuSentNE-2023
evaluation is based on the Russian news corpus RuSentNE having rich
sentiment-related annotation. The corpus is annotated with named entities and
sentiments towards these entities, along with related effects and emotional
states. The evaluation was organized using the CodaLab competition framework.
The main evaluation measure was macro-averaged measure of positive and negative
classes. The best results achieved were of 66% Macro F-measure
(Positive+Negative classes). We also tested ChatGPT on the test set from our
evaluation and found that the zero-shot answers provided by ChatGPT reached 60%
of the F-measure, which corresponds to 4th place in the evaluation. ChatGPT
also provided detailed explanations of its conclusion. This can be considered
as quite high for zero-shot application."
Out of Thin Air: Is Zero-Shot Cross-Lingual Keyword Detection Better Than Unsupervised?,0.280162,"Keyword extraction is the task of retrieving words that are essential to the
content of a given document. Researchers proposed various approaches to tackle
this problem. At the top-most level, approaches are divided into ones that
require training - supervised and ones that do not - unsupervised. In this
study, we are interested in settings, where for a language under investigation,
no training data is available. More specifically, we explore whether pretrained
multilingual language models can be employed for zero-shot cross-lingual
keyword extraction on low-resource languages with limited or no available
labeled training data and whether they outperform state-of-the-art unsupervised
keyword extractors. The comparison is conducted on six news article datasets
covering two high-resource languages, English and Russian, and four
low-resource languages, Croatian, Estonian, Latvian, and Slovenian. We find
that the pretrained models fine-tuned on a multilingual corpus covering
languages that do not appear in the test set (i.e. in a zero-shot setting),
consistently outscore unsupervised models in all six languages."
SimpleMind adds thinking to deep neural networks,0.294149,"Deep neural networks (DNNs) detect patterns in data and have shown
versatility and strong performance in many computer vision applications.
However, DNNs alone are susceptible to obvious mistakes that violate simple,
common sense concepts and are limited in their ability to use explicit
knowledge to guide their search and decision making. While overall DNN
performance metrics may be good, these obvious errors, coupled with a lack of
explainability, have prevented widespread adoption for crucial tasks such as
medical image analysis. The purpose of this paper is to introduce SimpleMind,
an open-source software framework for Cognitive AI focused on medical image
understanding. It allows creation of a knowledge base that describes expected
characteristics and relationships between image objects in an intuitive
human-readable form. The SimpleMind framework brings thinking to DNNs by: (1)
providing methods for reasoning with the knowledge base about image content,
such as spatial inferencing and conditional reasoning to check DNN outputs; (2)
applying process knowledge, in the form of general-purpose software agents,
that are chained together to accomplish image preprocessing, DNN prediction,
and result post-processing, and (3) performing automatic co-optimization of all
knowledge base parameters to adapt agents to specific problems. SimpleMind
enables reasoning on multiple detected objects to ensure consistency, providing
cross checking between DNN outputs. This machine reasoning improves the
reliability and trustworthiness of DNNs through an interpretable model and
explainable decisions. Example applications are provided that demonstrate how
SimpleMind supports and improves deep neural networks by embedding them within
a Cognitive AI framework."
GC-GRU-N for Traffic Prediction using Loop Detector Data,0.0998227,"Because traffic characteristics display stochastic nonlinear spatiotemporal
dependencies, traffic prediction is a challenging task. In this paper develop a
graph convolution gated recurrent unit (GC GRU N) network to extract the
essential Spatio temporal features. we use Seattle loop detector data
aggregated over 15 minutes and reframe the problem through space and time. The
model performance is compared o benchmark models; Historical Average, Long
Short Term Memory (LSTM), and Transformers. The proposed model ranked second
with the fastest inference time and a very close performance to first place
(Transformers). Our model also achieves a running time that is six times faster
than transformers. Finally, we present a comparative study of our model and the
available benchmarks using metrics such as training time, inference time, MAPE,
MAE and RMSE. Spatial and temporal aspects are also analyzed for each of the
trained models."
REFinD: Relation Extraction Financial Dataset,0.722532,"A number of datasets for Relation Extraction (RE) have been created to aide
downstream tasks such as information retrieval, semantic search, question
answering and textual entailment. However, these datasets fail to capture
financial-domain specific challenges since most of these datasets are compiled
using general knowledge sources such as Wikipedia, web-based text and news
articles, hindering real-life progress and adoption within the financial world.
To address this limitation, we propose REFinD, the first large-scale annotated
dataset of relations, with $\sim$29K instances and 22 relations amongst 8 types
of entity pairs, generated entirely over financial documents. We also provide
an empirical evaluation with various state-of-the-art models as benchmarks for
the RE task and highlight the challenges posed by our dataset. We observed that
various state-of-the-art deep learning models struggle with numeric inference,
relational and directional ambiguity."
Content-based Unrestricted Adversarial Attack,0.859301,"Unrestricted adversarial attacks typically manipulate the semantic content of
an image (e.g., color or texture) to create adversarial examples that are both
effective and photorealistic, demonstrating their ability to deceive human
perception and deep neural networks with stealth and success. However, current
works usually sacrifice unrestricted degrees and subjectively select some image
content to guarantee the photorealism of unrestricted adversarial examples,
which limits its attack performance. To ensure the photorealism of adversarial
examples and boost attack performance, we propose a novel unrestricted attack
framework called Content-based Unrestricted Adversarial Attack. By leveraging a
low-dimensional manifold that represents natural images, we map the images onto
the manifold and optimize them along its adversarial direction. Therefore,
within this framework, we implement Adversarial Content Attack based on Stable
Diffusion and can generate high transferable unrestricted adversarial examples
with various adversarial contents. Extensive experimentation and visualization
demonstrate the efficacy of ACA, particularly in surpassing state-of-the-art
attacks by an average of 13.3-50.4% and 16.8-48.0% in normally trained models
and defense methods, respectively."
T-STAR: Truthful Style Transfer using AMR Graph as Intermediate Representation,0.15166,"Unavailability of parallel corpora for training text style transfer (TST)
models is a very challenging yet common scenario. Also, TST models implicitly
need to preserve the content while transforming a source sentence into the
target style. To tackle these problems, an intermediate representation is often
constructed that is devoid of style while still preserving the meaning of the
source sentence. In this work, we study the usefulness of Abstract Meaning
Representation (AMR) graph as the intermediate style agnostic representation.
We posit that semantic notations like AMR are a natural choice for an
intermediate representation. Hence, we propose T-STAR: a model comprising of
two components, text-to-AMR encoder and a AMR-to-text decoder. We propose
several modeling improvements to enhance the style agnosticity of the generated
AMR. To the best of our knowledge, T-STAR is the first work that uses AMR as an
intermediate representation for TST. With thorough experimental evaluation we
show T-STAR significantly outperforms state of the art techniques by achieving
on an average 15.2% higher content preservation with negligible loss (3%
approx.) in style accuracy. Through detailed human evaluation with 90,000
ratings, we also show that T-STAR has up to 50% lesser hallucinations compared
to state of the art TST models."
Event-based Monocular Dense Depth Estimation with Recurrent Transformers,0.701452,"Event cameras, offering high temporal resolutions and high dynamic ranges,
have brought a new perspective to address common challenges (e.g., motion blur
and low light) in monocular depth estimation. However, how to effectively
exploit the sparse spatial information and rich temporal cues from asynchronous
events remains a challenging endeavor. To this end, we propose a novel
event-based monocular depth estimator with recurrent transformers, namely
EReFormer, which is the first pure transformer with a recursive mechanism to
process continuous event streams. Technically, for spatial modeling, a novel
transformer-based encoder-decoder with a spatial transformer fusion module is
presented, having better global context information modeling capabilities than
CNN-based methods. For temporal modeling, we design a gate recurrent vision
transformer unit that introduces a recursive mechanism into transformers,
improving temporal modeling capabilities while alleviating the expensive GPU
memory cost. The experimental results show that our EReFormer outperforms
state-of-the-art methods by a margin on both synthetic and real-world datasets.
We hope that our work will attract further research to develop stunning
transformers in the event-based vision community. Our open-source code can be
found in the supplemental material."
Few Shot Generative Model Adaption via Relaxed Spatial Structural Alignment,0.872701,"Training a generative adversarial network (GAN) with limited data has been a
challenging task. A feasible solution is to start with a GAN well-trained on a
large scale source domain and adapt it to the target domain with a few samples,
termed as few shot generative model adaption. However, existing methods are
prone to model overfitting and collapse in extremely few shot setting (less
than 10). To solve this problem, we propose a relaxed spatial structural
alignment method to calibrate the target generative models during the adaption.
We design a cross-domain spatial structural consistency loss comprising the
self-correlation and disturbance correlation consistency loss. It helps align
the spatial structural information between the synthesis image pairs of the
source and target domains. To relax the cross-domain alignment, we compress the
original latent space of generative models to a subspace. Image pairs generated
from the subspace are pulled closer. Qualitative and quantitative experiments
show that our method consistently surpasses the state-of-the-art methods in few
shot setting."
Learnable Heterogeneous Convolution: Learning both topology and strength,0.0172791,"Existing convolution techniques in artificial neural networks suffer from
huge computation complexity, while the biological neural network works in a
much more powerful yet efficient way. Inspired by the biological plasticity of
dendritic topology and synaptic strength, our method, Learnable Heterogeneous
Convolution, realizes joint learning of kernel shape and weights, which unifies
existing handcrafted convolution techniques in a data-driven way. A model based
on our method can converge with structural sparse weights and then be
accelerated by devices of high parallelism. In the experiments, our method
either reduces VGG16/19 and ResNet34/50 computation by nearly 5x on CIFAR10 and
2x on ImageNet without harming the performance, where the weights are
compressed by 10x and 4x respectively; or improves the accuracy by up to 1.0%
on CIFAR10 and 0.5% on ImageNet with slightly higher efficiency. The code will
be available on www.github.com/Genera1Z/LearnableHeterogeneousConvolution."
PSP-HDRI$+$: A Synthetic Dataset Generator for Pre-Training of Human-Centric Computer Vision Models,0.733332,"We introduce a new synthetic data generator PSP-HDRI$+$ that proves to be a
superior pre-training alternative to ImageNet and other large-scale synthetic
data counterparts. We demonstrate that pre-training with our synthetic data
will yield a more general model that performs better than alternatives even
when tested on out-of-distribution (OOD) sets. Furthermore, using ablation
studies guided by person keypoint estimation metrics with an off-the-shelf
model architecture, we show how to manipulate our synthetic data generator to
further improve model performance."
LMCap: Few-shot Multilingual Image Captioning by Retrieval Augmented Language Model Prompting,0.273535,"Multilingual image captioning has recently been tackled by training with
large-scale machine translated data, which is an expensive, noisy, and
time-consuming process. Without requiring any multilingual caption data, we
propose LMCap, an image-blind few-shot multilingual captioning model that works
by prompting a language model with retrieved captions. Specifically, instead of
following the standard encoder-decoder paradigm, given an image, LMCap first
retrieves the captions of similar images using a multilingual CLIP encoder.
These captions are then combined into a prompt for an XGLM decoder, in order to
generate captions in the desired language. In other words, the generation model
does not directly process the image, instead processing retrieved captions.
Experiments on the XM3600 dataset of geographically diverse images show that
our model is competitive with fully-supervised multilingual captioning models,
without requiring any supervised training on any captioning data."
Automatic Generation of Socratic Subquestions for Teaching Math Word Problems,0.772118,"Socratic questioning is an educational method that allows students to
discover answers to complex problems by asking them a series of thoughtful
questions. Generation of didactically sound questions is challenging, requiring
understanding of the reasoning process involved in the problem. We hypothesize
that such questioning strategy can not only enhance the human performance, but
also assist the math word problem (MWP) solvers. In this work, we explore the
ability of large language models (LMs) in generating sequential questions for
guiding math word problem-solving. We propose various guided question
generation schemes based on input conditioning and reinforcement learning. On
both automatic and human quality evaluations, we find that LMs constrained with
desirable question properties generate superior questions and improve the
overall performance of a math word problem solver. We conduct a preliminary
user study to examine the potential value of such question generation models in
the education domain. Results suggest that the difficulty level of problems
plays an important role in determining whether questioning improves or hinders
human performance. We discuss the future of using such questioning strategies
in education."
Evaluating Hallucinations in Chinese Large Language Models,0.35762,"In this paper, we establish a benchmark named HalluQA (Chinese Hallucination
Question-Answering) to measure the hallucination phenomenon in Chinese large
language models. HalluQA contains 450 meticulously designed adversarial
questions, spanning multiple domains, and takes into account Chinese historical
culture, customs, and social phenomena. During the construction of HalluQA, we
consider two types of hallucinations: imitative falsehoods and factual errors,
and we construct adversarial samples based on GLM-130B and ChatGPT. For
evaluation, we design an automated evaluation method using GPT-4 to judge
whether a model output is hallucinated. We conduct extensive experiments on 24
large language models, including ERNIE-Bot, Baichuan2, ChatGLM, Qwen, SparkDesk
and etc. Out of the 24 models, 18 achieved non-hallucination rates lower than
50%. This indicates that HalluQA is highly challenging. We analyze the primary
types of hallucinations in different types of models and their causes.
Additionally, we discuss which types of hallucinations should be prioritized
for different types of models."
DICE: Data-Efficient Clinical Event Extraction with Generative Models,0.784135,"Event extraction for the clinical domain is an under-explored research area.
The lack of training data along with the high volume of domain-specific
terminologies with vague entity boundaries makes the task especially
challenging. In this paper, we introduce DICE, a robust and data-efficient
generative model for clinical event extraction. DICE frames event extraction as
a conditional generation problem and introduces a contrastive learning
objective to accurately decide the boundaries of biomedical mentions. DICE also
trains an auxiliary mention identification task jointly with event extraction
tasks to better identify entity mention boundaries, and further introduces
special markers to incorporate identified entity mentions as trigger and
argument candidates for their respective tasks. To benchmark clinical event
extraction, we compose MACCROBAT-EE, the first clinical event extraction
dataset with argument annotation, based on an existing clinical information
extraction dataset MACCROBAT. Our experiments demonstrate state-of-the-art
performances of DICE for clinical and news domain event extraction, especially
under low data settings."
Transformer-based Approaches for Legal Text Processing,0.234913,"In this paper, we introduce our approaches using Transformer-based models for
different problems of the COLIEE 2021 automatic legal text processing
competition. Automated processing of legal documents is a challenging task
because of the characteristics of legal documents as well as the limitation of
the amount of data. With our detailed experiments, we found that
Transformer-based pretrained language models can perform well with automated
legal text processing problems with appropriate approaches. We describe in
detail the processing steps for each task such as problem formulation, data
processing and augmentation, pretraining, finetuning. In addition, we introduce
to the community two pretrained models that take advantage of parallel
translations in legal domain, NFSP and NMSP. In which, NFSP achieves the
state-of-the-art result in Task 5 of the competition. Although the paper
focuses on technical reporting, the novelty of its approaches can also be an
useful reference in automated legal document processing using Transformer-based
models."
Leveraging Off-the-shelf Diffusion Model for Multi-attribute Fashion Image Manipulation,0.80541,"Fashion attribute editing is a task that aims to convert the semantic
attributes of a given fashion image while preserving the irrelevant regions.
Previous works typically employ conditional GANs where the generator explicitly
learns the target attributes and directly execute the conversion. These
approaches, however, are neither scalable nor generic as they operate only with
few limited attributes and a separate generator is required for each dataset or
attribute set. Inspired by the recent advancement of diffusion models, we
explore the classifier-guided diffusion that leverages the off-the-shelf
diffusion model pretrained on general visual semantics such as Imagenet. In
order to achieve a generic editing pipeline, we pose this as multi-attribute
image manipulation task, where the attribute ranges from item category, fabric,
pattern to collar and neckline. We empirically show that conventional methods
fail in our challenging setting, and study efficient adaptation scheme that
involves recently introduced attention-pooling technique to obtain a
multi-attribute classifier guidance. Based on this, we present a mask-free
fashion attribute editing framework that leverages the classifier logits and
the cross-attention map for manipulation. We empirically demonstrate that our
framework achieves convincing sample quality and attribute alignments."
SMATCH++: Standardized and Extended Evaluation of Semantic Graphs,0.741204,"The Smatch metric is a popular method for evaluating graph distances, as is
necessary, for instance, to assess the performance of semantic graph parsing
systems. However, we observe some issues in the metric that jeopardize
meaningful evaluation. E.g., opaque pre-processing choices can affect results,
and current graph-alignment solvers do not provide us with upper-bounds.
Without upper-bounds, however, fair evaluation is not guaranteed. Furthermore,
adaptions of Smatch for extended tasks (e.g., fine-grained semantic similarity)
are spread out, and lack a unifying framework.
  For better inspection, we divide the metric into three modules:
pre-processing, alignment, and scoring. Examining each module, we specify its
goals and diagnose potential issues, for which we discuss and test mitigation
strategies. For pre-processing, we show how to fully conform to annotation
guidelines that allow structurally deviating but valid graphs. For safer and
enhanced alignment, we show the feasibility of optimal alignment in a standard
evaluation setup, and develop a lossless graph compression method that shrinks
the search space and significantly increases efficiency. For improved scoring,
we propose standardized and extended metric calculation of fine-grained
sub-graph meaning aspects. Our code is available at
https://github.com/flipz357/smatchpp"
Integrating Lattice-Free MMI into End-to-End Speech Recognition,0.522198,"In automatic speech recognition (ASR) research, discriminative criteria have
achieved superior performance in DNN-HMM systems. Given this success, the
adoption of discriminative criteria is promising to boost the performance of
end-to-end (E2E) ASR systems. With this motivation, previous works have
introduced the minimum Bayesian risk (MBR, one of the discriminative criteria)
into E2E ASR systems. However, the effectiveness and efficiency of the
MBR-based methods are compromised: the MBR criterion is only used in system
training, which creates a mismatch between training and decoding; the
on-the-fly decoding process in MBR-based methods results in the need for
pre-trained models and slow training speeds. To this end, novel algorithms are
proposed in this work to integrate another widely used discriminative
criterion, lattice-free maximum mutual information (LF-MMI), into E2E ASR
systems not only in the training stage but also in the decoding process. The
proposed LF-MMI training and decoding methods show their effectiveness on two
widely used E2E frameworks: Attention-Based Encoder-Decoders (AEDs) and Neural
Transducers (NTs). Compared with MBR-based methods, the proposed LF-MMI method:
maintains the consistency between training and decoding; eschews the on-the-fly
decoding process; trains from randomly initialized models with superior
training efficiency. Experiments suggest that the LF-MMI method outperforms its
MBR counterparts and consistently leads to statistically significant
performance improvements on various frameworks and datasets from 30 hours to
14.3k hours. The proposed method achieves state-of-the-art (SOTA) results on
Aishell-1 (CER 4.10%) and Aishell-2 (CER 5.02%) datasets. Code is released."
AutoTrial: Prompting Language Models for Clinical Trial Design,0.627051,"Clinical trials are critical for drug development. Constructing the
appropriate eligibility criteria (i.e., the inclusion/exclusion criteria for
patient recruitment) is essential for the trial's success. Proper design of
clinical trial protocols should consider similar precedent trials and their
eligibility criteria to ensure sufficient patient coverage. In this paper, we
present a method named AutoTrial to aid the design of clinical eligibility
criteria using language models. It allows (1) controllable generation under
instructions via a hybrid of discrete and neural prompting, (2) scalable
knowledge incorporation via in-context learning, and (3) explicit reasoning
chains to provide rationales for understanding the outputs. Experiments on over
70K clinical trials verify that AutoTrial generates high-quality criteria texts
that are fluent and coherent and with high accuracy in capturing the relevant
clinical concepts to the target trial. It is noteworthy that our method, with a
much smaller parameter size, gains around 60% winning rate against the GPT-3.5
baselines via human evaluations."
AraBART: a Pretrained Arabic Sequence-to-Sequence Model for Abstractive Summarization,0.658515,"Like most natural language understanding and generation tasks,
state-of-the-art models for summarization are transformer-based
sequence-to-sequence architectures that are pretrained on large corpora. While
most existing models focused on English, Arabic remained understudied. In this
paper we propose AraBART, the first Arabic model in which the encoder and the
decoder are pretrained end-to-end, based on BART. We show that AraBART achieves
the best performance on multiple abstractive summarization datasets,
outperforming strong baselines including a pretrained Arabic BERT-based model
and multilingual mBART and mT5 models."
Zero-shot Approach to Overcome Perturbation Sensitivity of Prompts,0.50325,"Recent studies have demonstrated that natural-language prompts can help to
leverage the knowledge learned by pre-trained language models for the binary
sentence-level sentiment classification task. Specifically, these methods
utilize few-shot learning settings to fine-tune the sentiment classification
model using manual or automatically generated prompts. However, the performance
of these methods is sensitive to the perturbations of the utilized prompts.
Furthermore, these methods depend on a few labeled instances for automatic
prompt generation and prompt ranking. This study aims to find high-quality
prompts for the given task in a zero-shot setting. Given a base prompt, our
proposed approach automatically generates multiple prompts similar to the base
prompt employing positional, reasoning, and paraphrasing techniques and then
ranks the prompts using a novel metric. We empirically demonstrate that the
top-ranked prompts are high-quality and significantly outperform the base
prompt and the prompts generated using few-shot learning for the binary
sentence-level sentiment classification task."
UAlberta at SemEval-2023 Task 1: Context Augmentation and Translation for Multilingual Visual Word Sense Disambiguation,0.550671,"We describe the systems of the University of Alberta team for the
SemEval-2023 Visual Word Sense Disambiguation (V-WSD) Task. We present a novel
algorithm that leverages glosses retrieved from BabelNet, in combination with
text and image encoders. Furthermore, we compare language-specific encoders
against the application of English encoders to translated texts. As the
contexts given in the task datasets are extremely short, we also experiment
with augmenting these contexts with descriptions generated by a language model.
This yields substantial improvements in accuracy. We describe and evaluate
additional V-WSD methods which use image generation and text-conditioned image
segmentation. Overall, the results of our official submission rank us 18 out of
56 teams. Some of our unofficial results are even better than the official
ones. Our code is publicly available at https://github.com/UAlberta-NLP/v-wsd."
Planning Assembly Sequence with Graph Transformer,0.597554,"Assembly sequence planning (ASP) is the essential process for modern
manufacturing, proven to be NP-complete thus its effective and efficient
solution has been a challenge for researchers in the field. In this paper, we
present a graph-transformer based framework for the ASP problem which is
trained and demonstrated on a self-collected ASP database. The ASP database
contains a self-collected set of LEGO models. The LEGO model is abstracted to a
heterogeneous graph structure after a thorough analysis of the original
structure and feature extraction. The ground truth assembly sequence is first
generated by brute-force search and then adjusted manually to in line with
human rational habits. Based on this self-collected ASP dataset, we propose a
heterogeneous graph-transformer framework to learn the latent rules for
assembly planning. We evaluated the proposed framework in a series of
experiment. The results show that the similarity of the predicted and ground
truth sequences can reach 0.44, a medium correlation measured by Kendall's
$\tau$. Meanwhile, we compared the different effects of node features and edge
features and generated a feasible and reasonable assembly sequence as a
benchmark for further research. Our data set and code is available on
https://github.com/AIR-DISCOVER/ICRA\_ASP."
The purpose of qualia: What if human thinking is not (only) information processing?,0.60015,"Despite recent breakthroughs in the field of artificial intelligence (AI) -
or more specifically machine learning (ML) algorithms for object recognition
and natural language processing - it seems to be the majority view that current
AI approaches are still no real match for natural intelligence (NI). More
importantly, philosophers have collected a long catalogue of features which
imply that NI works differently from current AI not only in a gradual sense,
but in a more substantial way: NI is closely related to consciousness,
intentionality and experiential features like qualia (the subjective contents
of mental states) and allows for understanding (e.g., taking insight into
causal relationships instead of 'blindly' relying on correlations), as well as
aesthetical and ethical judgement beyond what we can put into (explicit or
data-induced implicit) rules to program machines with. Additionally,
Psychologists find NI to range from unconscious psychological processes to
focused information processing, and from embodied and implicit cognition to
'true' agency and creativity. NI thus seems to transcend any neurobiological
functionalism by operating on 'bits of meaning' instead of information in the
sense of data, quite unlike both the 'good old fashioned', symbolic AI of the
past, as well as the current wave of deep neural network based, 'sub-symbolic'
AI, which both share the idea of thinking as (only) information processing. In
the following I propose an alternative view of NI as information processing
plus 'bundle pushing', discuss an example which illustrates how bundle pushing
can cut information processing short, and suggest first ideas for scientific
experiments in neuro-biology and information theory as further investigations."
Aligning Language Models with Offline Learning from Human Feedback,0.0226404,"Learning from human preferences is crucial for language models (LMs) to
effectively cater to human needs and societal values. Previous research has
made notable progress by leveraging human feedback to follow instructions.
However, these approaches rely primarily on online learning techniques like
Proximal Policy Optimization (PPO), which have been proven unstable and
challenging to tune for language models. Moreover, PPO requires complex
distributed system implementation, hindering the efficiency of large-scale
distributed training. In this study, we propose an offline learning from human
feedback framework to align LMs without interacting with environments.
Specifically, we explore filtering alignment (FA), reward-weighted regression
(RWR), and conditional alignment (CA) to align language models to human
preferences. By employing a loss function similar to supervised fine-tuning,
our methods ensure more stable model training than PPO with a simple machine
learning system~(MLSys) and much fewer (around 9\%) computing resources.
Experimental results demonstrate that conditional alignment outperforms other
offline alignment methods and is comparable to PPO."
Position Regression for Unsupervised Anomaly Detection,0.0777741,"In recent years, anomaly detection has become an essential field in medical
image analysis. Most current anomaly detection methods for medical images are
based on image reconstruction. In this work, we propose a novel anomaly
detection approach based on coordinate regression. Our method estimates the
position of patches within a volume, and is trained only on data of healthy
subjects. During inference, we can detect and localize anomalies by considering
the error of the position estimate of a given patch. We apply our method to 3D
CT volumes and evaluate it on patients with intracranial haemorrhages and
cranial fractures. The results show that our method performs well in detecting
these anomalies. Furthermore, we show that our method requires less memory than
comparable approaches that involve image reconstruction. This is highly
relevant for processing large 3D volumes, for instance, CT or MRI scans."
Collaborative Propagation on Multiple Instance Graphs for 3D Instance Segmentation with Single-point Supervision,0.0461746,"Instance segmentation on 3D point clouds has been attracting increasing
attention due to its wide applications, especially in scene understanding
areas. However, most existing methods operate on fully annotated data while
manually preparing ground-truth labels at point-level is very cumbersome and
labor-intensive. To address this issue, we propose a novel weakly supervised
method RWSeg that only requires labeling one object with one point. With these
sparse weak labels, we introduce a unified framework with two branches to
propagate semantic and instance information respectively to unknown regions
using self-attention and a cross-graph random walk method. Specifically, we
propose a Cross-graph Competing Random Walks (CRW) algorithm that encourages
competition among different instance graphs to resolve ambiguities in closely
placed objects, improving instance assignment accuracy. RWSeg generates
high-quality instance-level pseudo labels. Experimental results on ScanNet-v2
and S3DIS datasets show that our approach achieves comparable performance with
fully-supervised methods and outperforms previous weakly-supervised methods by
a substantial margin."
Confidence Based Bidirectional Global Context Aware Training Framework for Neural Machine Translation,0.644137,"Most dominant neural machine translation (NMT) models are restricted to make
predictions only according to the local context of preceding words in a
left-to-right manner. Although many previous studies try to incorporate global
information into NMT models, there still exist limitations on how to
effectively exploit bidirectional global context. In this paper, we propose a
Confidence Based Bidirectional Global Context Aware (CBBGCA) training framework
for NMT, where the NMT model is jointly trained with an auxiliary conditional
masked language model (CMLM). The training consists of two stages: (1)
multi-task joint training; (2) confidence based knowledge distillation. At the
first stage, by sharing encoder parameters, the NMT model is additionally
supervised by the signal from the CMLM decoder that contains bidirectional
global contexts. Moreover, at the second stage, using the CMLM as teacher, we
further pertinently incorporate bidirectional global context to the NMT model
on its unconfidently-predicted target words via knowledge distillation.
Experimental results show that our proposed CBBGCA training framework
significantly improves the NMT model by +1.02, +1.30 and +0.57 BLEU scores on
three large-scale translation datasets, namely WMT'14 English-to-German, WMT'19
Chinese-to-English and WMT'14 English-to-French, respectively."
Towards Responsible AI: A Design Space Exploration of Human-Centered Artificial Intelligence User Interfaces to Investigate Fairness,0.56065,"With Artificial intelligence (AI) to aid or automate decision-making
advancing rapidly, a particular concern is its fairness. In order to create
reliable, safe and trustworthy systems through human-centred artificial
intelligence (HCAI) design, recent efforts have produced user interfaces (UIs)
for AI experts to investigate the fairness of AI models. In this work, we
provide a design space exploration that supports not only data scientists but
also domain experts to investigate AI fairness. Using loan applications as an
example, we held a series of workshops with loan officers and data scientists
to elicit their requirements. We instantiated these requirements into FairHIL,
a UI to support human-in-the-loop fairness investigations, and describe how
this UI could be generalized to other use cases. We evaluated FairHIL through a
think-aloud user study. Our work contributes better designs to investigate an
AI model's fairness-and move closer towards responsible AI."
"Match the Script, Adapt if Multilingual: Analyzing the Effect of Multilingual Pretraining on Cross-lingual Transferability",0.214947,"Pretrained multilingual models enable zero-shot learning even for unseen
languages, and that performance can be further improved via adaptation prior to
finetuning. However, it is unclear how the number of pretraining languages
influences a model's zero-shot learning for languages unseen during
pretraining. To fill this gap, we ask the following research questions: (1) How
does the number of pretraining languages influence zero-shot performance on
unseen target languages? (2) Does the answer to that question change with model
adaptation? (3) Do the findings for our first question change if the languages
used for pretraining are all related? Our experiments on pretraining with
related languages indicate that choosing a diverse set of languages is crucial.
Without model adaptation, surprisingly, increasing the number of pretraining
languages yields better results up to adding related languages, after which
performance plateaus. In contrast, with model adaptation via continued
pretraining, pretraining on a larger number of languages often gives further
improvement, suggesting that model adaptation is crucial to exploit additional
pretraining languages."
Improving robustness of language models from a geometry-aware perspective,0.412737,"Recent studies have found that removing the norm-bounded projection and
increasing search steps in adversarial training can significantly improve
robustness. However, we observe that a too large number of search steps can
hurt accuracy. We aim to obtain strong robustness efficiently using fewer
steps. Through a toy experiment, we find that perturbing the clean data to the
decision boundary but not crossing it does not degrade the test accuracy.
Inspired by this, we propose friendly adversarial data augmentation (FADA) to
generate friendly adversarial data. On top of FADA, we propose geometry-aware
adversarial training (GAT) to perform adversarial training on friendly
adversarial data so that we can save a large number of search steps.
Comprehensive experiments across two widely used datasets and three pre-trained
language models demonstrate that GAT can obtain stronger robustness via fewer
steps. In addition, we provide extensive empirical results and in-depth
analyses on robustness to facilitate future studies."
ModelScope Text-to-Video Technical Report,0.996967,"This paper introduces ModelScopeT2V, a text-to-video synthesis model that
evolves from a text-to-image synthesis model (i.e., Stable Diffusion).
ModelScopeT2V incorporates spatio-temporal blocks to ensure consistent frame
generation and smooth movement transitions. The model could adapt to varying
frame numbers during training and inference, rendering it suitable for both
image-text and video-text datasets. ModelScopeT2V brings together three
components (i.e., VQGAN, a text encoder, and a denoising UNet), totally
comprising 1.7 billion parameters, in which 0.5 billion parameters are
dedicated to temporal capabilities. The model demonstrates superior performance
over state-of-the-art methods across three evaluation metrics. The code and an
online demo are available at
\url{https://modelscope.cn/models/damo/text-to-video-synthesis/summary}."
RbA: Segmenting Unknown Regions Rejected by All,0.97515,"Standard semantic segmentation models owe their success to curated datasets
with a fixed set of semantic categories, without contemplating the possibility
of identifying unknown objects from novel categories. Existing methods in
outlier detection suffer from a lack of smoothness and objectness in their
predictions, due to limitations of the per-pixel classification paradigm.
Furthermore, additional training for detecting outliers harms the performance
of known classes. In this paper, we explore another paradigm with region-level
classification to better segment unknown objects. We show that the object
queries in mask classification tend to behave like one \vs all classifiers.
Based on this finding, we propose a novel outlier scoring function called RbA
by defining the event of being an outlier as being rejected by all known
classes. Our extensive experiments show that mask classification improves the
performance of the existing outlier detection methods, and the best results are
achieved with the proposed RbA. We also propose an objective to optimize RbA
using minimal outlier supervision. Further fine-tuning with outliers improves
the unknown performance, and unlike previous methods, it does not degrade the
inlier performance."
Open Relation and Event Type Discovery with Type Abstraction,0.864665,"Conventional closed-world information extraction (IE) approaches rely on
human ontologies to define the scope for extraction. As a result, such
approaches fall short when applied to new domains. This calls for systems that
can automatically infer new types from given corpora, a task which we refer to
as type discovery. To tackle this problem, we introduce the idea of type
abstraction, where the model is prompted to generalize and name the type. Then
we use the similarity between inferred names to induce clusters. Observing that
this abstraction-based representation is often complementary to the
entity/trigger token representation, we set up these two representations as two
views and design our model as a co-training framework. Our experiments on
multiple relation extraction and event extraction datasets consistently show
the advantage of our type abstraction approach. Code available at
https://github.com/raspberryice/type-discovery-abs."
HOB-CNN: Hallucination of Occluded Branches with a Convolutional Neural Network for 2D Fruit Trees,0.452656,"Orchard automation has attracted the attention of researchers recently due to
the shortage of global labor force. To automate tasks in orchards such as
pruning, thinning, and harvesting, a detailed understanding of the tree
structure is required. However, occlusions from foliage and fruits can make it
challenging to predict the position of occluded trunks and branches. This work
proposes a regression-based deep learning model, Hallucination of Occluded
Branch Convolutional Neural Network (HOB-CNN), for tree branch position
prediction in varying occluded conditions. We formulate tree branch position
prediction as a regression problem towards the horizontal locations of the
branch along the vertical direction or vice versa. We present comparative
experiments on Y-shaped trees with two state-of-the-art baselines, representing
common approaches to the problem. Experiments show that HOB-CNN outperform the
baselines at predicting branch position and shows robustness against varying
levels of occlusion. We further validated HOB-CNN against two different types
of 2D trees, and HOB-CNN shows generalization across different trees and
robustness under different occluded conditions."
AdvFAS: A robust face anti-spoofing framework against adversarial examples,0.7578,"Ensuring the reliability of face recognition systems against presentation
attacks necessitates the deployment of face anti-spoofing techniques. Despite
considerable advancements in this domain, the ability of even the most
state-of-the-art methods to defend against adversarial examples remains
elusive. While several adversarial defense strategies have been proposed, they
typically suffer from constrained practicability due to inevitable trade-offs
between universality, effectiveness, and efficiency. To overcome these
challenges, we thoroughly delve into the coupled relationship between
adversarial detection and face anti-spoofing. Based on this, we propose a
robust face anti-spoofing framework, namely AdvFAS, that leverages two coupled
scores to accurately distinguish between correctly detected and wrongly
detected face images. Extensive experiments demonstrate the effectiveness of
our framework in a variety of settings, including different attacks, datasets,
and backbones, meanwhile enjoying high accuracy on clean examples. Moreover, we
successfully apply the proposed method to detect real-world adversarial
examples."
ESMC: Entire Space Multi-Task Model for Post-Click Conversion Rate via Parameter Constraint,0.534718,"Large-scale online recommender system spreads all over the Internet being in
charge of two basic tasks: Click-Through Rate (CTR) and Post-Click Conversion
Rate (CVR) estimations. However, traditional CVR estimators suffer from
well-known Sample Selection Bias and Data Sparsity issues. Entire space models
were proposed to address the two issues via tracing the decision-making path of
""exposure_click_purchase"". Further, some researchers observed that there are
purchase-related behaviors between click and purchase, which can better draw
the user's decision-making intention and improve the recommendation
performance. Thus, the decision-making path has been extended to
""exposure_click_in-shop action_purchase"" and can be modeled with conditional
probability approach. Nevertheless, we observe that the chain rule of
conditional probability does not always hold. We report Probability Space
Confusion (PSC) issue and give a derivation of difference between ground-truth
and estimation mathematically. We propose a novel Entire Space Multi-Task Model
for Post-Click Conversion Rate via Parameter Constraint (ESMC) and two
alternatives: Entire Space Multi-Task Model with Siamese Network (ESMS) and
Entire Space Multi-Task Model in Global Domain (ESMG) to address the PSC issue.
Specifically, we handle ""exposure_click_in-shop action"" and ""in-shop
action_purchase"" separately in the light of characteristics of in-shop action.
The first path is still treated with conditional probability while the second
one is treated with parameter constraint strategy. Experiments on both offline
and online environments in a large-scale recommendation system illustrate the
superiority of our proposed methods over state-of-the-art models. The
real-world datasets will be released."
Event Transformer. A sparse-aware solution for efficient event data processing,0.917554,"Event cameras are sensors of great interest for many applications that run in
low-resource and challenging environments. They log sparse illumination changes
with high temporal resolution and high dynamic range, while they present
minimal power consumption. However, top-performing methods often ignore
specific event-data properties, leading to the development of generic but
computationally expensive algorithms. Efforts toward efficient solutions
usually do not achieve top-accuracy results for complex tasks. This work
proposes a novel framework, Event Transformer (EvT), that effectively takes
advantage of event-data properties to be highly efficient and accurate. We
introduce a new patch-based event representation and a compact transformer-like
architecture to process it. EvT is evaluated on different event-based
benchmarks for action and gesture recognition. Evaluation results show better
or comparable accuracy to the state-of-the-art while requiring significantly
less computation resources, which makes EvT able to work with minimal latency
both on GPU and CPU."
Unlabeled Imperfect Demonstrations in Adversarial Imitation Learning,0.214062,"Adversarial imitation learning has become a widely used imitation learning
framework. The discriminator is often trained by taking expert demonstrations
and policy trajectories as examples respectively from two categories (positive
vs. negative) and the policy is then expected to produce trajectories that are
indistinguishable from the expert demonstrations. But in the real world, the
collected expert demonstrations are more likely to be imperfect, where only an
unknown fraction of the demonstrations are optimal. Instead of treating
imperfect expert demonstrations as absolutely positive or negative, we
investigate unlabeled imperfect expert demonstrations as they are. A
positive-unlabeled adversarial imitation learning algorithm is developed to
dynamically sample expert demonstrations that can well match the trajectories
from the constantly optimized agent policy. The trajectories of an initial
agent policy could be closer to those non-optimal expert demonstrations, but
within the framework of adversarial imitation learning, agent policy will be
optimized to cheat the discriminator and produce trajectories that are similar
to those optimal expert demonstrations. Theoretical analysis shows that our
method learns from the imperfect demonstrations via a self-paced way.
Experimental results on MuJoCo and RoboSuite platforms demonstrate the
effectiveness of our method from different aspects."
Underwater Object Classification and Detection: first results and open challenges,0.117216,"This work reviews the problem of object detection in underwater environments.
We analyse and quantify the shortcomings of conventional state-of-the-art
(SOTA) algorithms in the computer vision community when applied to this
challenging environment, as well as providing insights and general guidelines
for future research efforts. First, we assessed if pretraining with the
conventional ImageNet is beneficial when the object detector needs to be
applied to environments that may be characterised by a different feature
distribution. We then investigate whether two-stage detectors yields to better
performance with respect to single-stage detectors, in terms of accuracy,
intersection of union (IoU), floating operation per second (FLOPS), and
inference time. Finally, we assessed the generalisation capability of each
model to a lower quality dataset to simulate performance on a real scenario, in
which harsher conditions ought to be expected. Our experimental results provide
evidence that underwater object detection requires searching for ""ad-hoc""
architectures than merely training SOTA architectures on new data, and that
pretraining is not beneficial."
Debiased Large Language Models Still Associate Muslims with Uniquely Violent Acts,0.046778,"Recent work demonstrates a bias in the GPT-3 model towards generating violent
text completions when prompted about Muslims, compared with Christians and
Hindus. Two pre-registered replication attempts, one exact and one approximate,
found only the weakest bias in the more recent Instruct Series version of
GPT-3, fine-tuned to eliminate biased and toxic outputs. Few violent
completions were observed. Additional pre-registered experiments, however,
showed that using common names associated with the religions in prompts yields
a highly significant increase in violent completions, also revealing a stronger
second-order bias against Muslims. Names of Muslim celebrities from non-violent
domains resulted in relatively fewer violent completions, suggesting that
access to individualized information can steer the model away from using
stereotypes. Nonetheless, content analysis revealed religion-specific violent
themes containing highly offensive ideas regardless of prompt format. Our
results show the need for additional debiasing of large language models to
address higher-order schemas and associations."
Addressing Resource and Privacy Constraints in Semantic Parsing Through Data Augmentation,0.246956,"We introduce a novel setup for low-resource task-oriented semantic parsing
which incorporates several constraints that may arise in real-world scenarios:
(1) lack of similar datasets/models from a related domain, (2) inability to
sample useful logical forms directly from a grammar, and (3) privacy
requirements for unlabeled natural utterances. Our goal is to improve a
low-resource semantic parser using utterances collected through user
interactions. In this highly challenging but realistic setting, we investigate
data augmentation approaches involving generating a set of structured canonical
utterances corresponding to logical forms, before simulating corresponding
natural language and filtering the resulting pairs. We find that such
approaches are effective despite our restrictive setup: in a low-resource
setting on the complex SMCalFlow calendaring dataset (Andreas et al., 2020), we
observe 33% relative improvement over a non-data-augmented baseline in top-1
match."
SAOR: Single-View Articulated Object Reconstruction,0.457083,"We introduce SAOR, a novel approach for estimating the 3D shape, texture, and
viewpoint of an articulated object from a single image captured in the wild.
Unlike prior approaches that rely on pre-defined category-specific 3D templates
or tailored 3D skeletons, SAOR learns to articulate shapes from single-view
image collections with a skeleton-free part-based model without requiring any
3D object shape priors. To prevent ill-posed solutions, we propose a
cross-instance consistency loss that exploits disentangled object shape
deformation and articulation. This is helped by a new silhouette-based sampling
mechanism to enhance viewpoint diversity during training. Our method only
requires estimated object silhouettes and relative depth maps from
off-the-shelf pre-trained networks during training. At inference time, given a
single-view image, it efficiently outputs an explicit mesh representation. We
obtain improved qualitative and quantitative results on challenging quadruped
animals compared to relevant existing work."
Generative AI-empowered Effective Physical-Virtual Synchronization in the Vehicular Metaverse,0.505611,"Metaverse seamlessly blends the physical world and virtual space via
ubiquitous communication and computing infrastructure. In transportation
systems, the vehicular Metaverse can provide a fully-immersive and hyperreal
traveling experience (e.g., via augmented reality head-up displays, AR-HUDs) to
drivers and users in autonomous vehicles (AVs) via roadside units (RSUs).
However, provisioning real-time and immersive services necessitates effective
physical-virtual synchronization between physical and virtual entities, i.e.,
AVs and Metaverse AR recommenders (MARs). In this paper, we propose a
generative AI-empowered physical-virtual synchronization framework for the
vehicular Metaverse. In physical-to-virtual synchronization, digital twin (DT)
tasks generated by AVs are offloaded for execution in RSU with future route
generation. In virtual-to-physical synchronization, MARs customize diverse and
personal AR recommendations via generative AI models based on user preferences.
Furthermore, we propose a multi-task enhanced auction-based mechanism to match
and price AVs and MARs for RSUs to provision real-time and effective services.
Finally, property analysis and experimental results demonstrate that the
proposed mechanism is strategy-proof and adverse-selection free while
increasing social surplus by 50%."
TUVF: Learning Generalizable Texture UV Radiance Fields,0.0632253,"Textures are a vital aspect of creating visually appealing and realistic 3D
models. In this paper, we study the problem of generating high-fidelity texture
given shapes of 3D assets, which has been relatively less explored compared
with generic 3D shape modeling. Our goal is to facilitate a controllable
texture generation process, such that one texture code can correspond to a
particular appearance style independent of any input shapes from a category. We
introduce Texture UV Radiance Fields (TUVF) that generate textures in a
learnable UV sphere space rather than directly on the 3D shape. This allows the
texture to be disentangled from the underlying shape and transferable to other
shapes that share the same UV space, i.e., from the same category. We integrate
the UV sphere space with the radiance field, which provides a more efficient
and accurate representation of textures than traditional texture maps. We
perform our experiments on synthetic and real-world object datasets where we
achieve not only realistic synthesis but also substantial improvements over
state-of-the-arts on texture controlling and editing. Project Page:
https://www.anjiecheng.me/TUVF"
Better Sampling of Negatives for Distantly Supervised Named Entity Recognition,0.21054,"Distantly supervised named entity recognition (DS-NER) has been proposed to
exploit the automatically labeled training data instead of human annotations.
The distantly annotated datasets are often noisy and contain a considerable
number of false negatives. The recent approach uses a weighted sampling
approach to select a subset of negative samples for training. However, it
requires a good classifier to assign weights to the negative samples. In this
paper, we propose a simple and straightforward approach for selecting the top
negative samples that have high similarities with all the positive samples for
training. Our method achieves consistent performance improvements on four
distantly supervised NER datasets. Our analysis also shows that it is critical
to differentiate the true negatives from the false negatives."
SD-HuBERT: Sentence-Level Self-Distillation Induces Syllabic Organization in HuBERT,0.101349,"Data-driven unit discovery in self-supervised learning (SSL) of speech has
embarked on a new era of spoken language processing. Yet, the discovered units
often remain in phonetic space and the units beyond phonemes are largely
underexplored. Here, we demonstrate that a syllabic organization emerges in
learning sentence-level representation of speech. In particular, we adopt
""self-distillation"" objective to fine-tune the pretrained HuBERT with an
aggregator token that summarizes the entire sentence. Without any supervision,
the resulting model draws definite boundaries in speech, and the
representations across frames exhibit salient syllabic structures. We
demonstrate that this emergent structure largely corresponds to the ground
truth syllables. Furthermore, we propose a new benchmark task, Spoken Speech
ABX, for evaluating sentence-level representation of speech. When compared to
previous models, our model outperforms in both unsupervised syllable discovery
and learning sentence-level representation. Together, we demonstrate that the
self-distillation of HuBERT gives rise to syllabic organization without relying
on external labels or modalities, and potentially provides novel data-driven
units for spoken language modeling."
Learning Efficient Abstract Planning Models that Choose What to Predict,0.729652,"An effective approach to solving long-horizon tasks in robotics domains with
continuous state and action spaces is bilevel planning, wherein a high-level
search over an abstraction of an environment is used to guide low-level
decision-making. Recent work has shown how to enable such bilevel planning by
learning abstract models in the form of symbolic operators and neural samplers.
In this work, we show that existing symbolic operator learning approaches fall
short in many robotics domains where a robot's actions tend to cause a large
number of irrelevant changes in the abstract state. This is primarily because
they attempt to learn operators that exactly predict all observed changes in
the abstract state. To overcome this issue, we propose to learn operators that
'choose what to predict' by only modelling changes necessary for abstract
planning to achieve specified goals. Experimentally, we show that our approach
learns operators that lead to efficient planning across 10 different hybrid
robotics domains, including 4 from the challenging BEHAVIOR-100 benchmark,
while generalizing to novel initial states, goals, and objects."
Evaluating Inter-Bilingual Semantic Parsing for Indian Languages,0.178496,"Despite significant progress in Natural Language Generation for Indian
languages (IndicNLP), there is a lack of datasets around complex structured
tasks such as semantic parsing. One reason for this imminent gap is the
complexity of the logical form, which makes English to multilingual translation
difficult. The process involves alignment of logical forms, intents and slots
with translated unstructured utterance. To address this, we propose an
Inter-bilingual Seq2seq Semantic parsing dataset IE-SEMPARSE for 11 distinct
Indian languages. We highlight the proposed task's practicality, and evaluate
existing multilingual seq2seq models across several train-test strategies. Our
experiment reveals a high correlation across performance of original
multilingual semantic parsing datasets (such as mTOP, multilingual TOP and
multiATIS++) and our proposed IE-SEMPARSE suite."
Learning Clothing and Pose Invariant 3D Shape Representation for Long-Term Person Re-Identification,0.98365,"Long-Term Person Re-Identification (LT-ReID) has become increasingly crucial
in computer vision and biometrics. In this work, we aim to extend LT-ReID
beyond pedestrian recognition to include a wider range of real-world human
activities while still accounting for cloth-changing scenarios over large time
gaps. This setting poses additional challenges due to the geometric
misalignment and appearance ambiguity caused by the diversity of human pose and
clothing. To address these challenges, we propose a new approach 3DInvarReID
for (i) disentangling identity from non-identity components (pose, clothing
shape, and texture) of 3D clothed humans, and (ii) reconstructing accurate 3D
clothed body shapes and learning discriminative features of naked body shapes
for person ReID in a joint manner. To better evaluate our study of LT-ReID, we
collect a real-world dataset called CCDA, which contains a wide variety of
human activities and clothing changes. Experimentally, we show the superior
performance of our approach for person ReID."
USCORE: An Effective Approach to Fully Unsupervised Evaluation Metrics for Machine Translation,0.776268,"The vast majority of evaluation metrics for machine translation are
supervised, i.e., (i) are trained on human scores, (ii) assume the existence of
reference translations, or (iii) leverage parallel data. This hinders their
applicability to cases where such supervision signals are not available. In
this work, we develop fully unsupervised evaluation metrics. To do so, we
leverage similarities and synergies between evaluation metric induction,
parallel corpus mining, and MT systems. In particular, we use an unsupervised
evaluation metric to mine pseudo-parallel data, which we use to remap deficient
underlying vector spaces (in an iterative manner) and to induce an unsupervised
MT system, which then provides pseudo-references as an additional component in
the metric. Finally, we also induce unsupervised multilingual sentence
embeddings from pseudo-parallel data. We show that our fully unsupervised
metrics are effective, i.e., they beat supervised competitors on 4 out of our 5
evaluation datasets. We make our code publicly available."
An Efficient COarse-to-fiNE Alignment Framework @ Ego4D Natural Language Queries Challenge 2022,0.410338,"This technical report describes the CONE approach for Ego4D Natural Language
Queries (NLQ) Challenge in ECCV 2022. We leverage our model CONE, an efficient
window-centric COarse-to-fiNE alignment framework. Specifically, CONE
dynamically slices the long video into candidate windows via a sliding window
approach. Centering at windows, CONE (1) learns the inter-window
(coarse-grained) semantic variance through contrastive learning and speeds up
inference by pre-filtering the candidate windows relevant to the NL query, and
(2) conducts intra-window (fine-grained) candidate moments ranking utilizing
the powerful multi-modal alignment ability of the contrastive vision-text
pre-trained model EgoVLP. On the blind test set, CONE achieves 15.26 and 9.24
for R1@IoU=0.3 and R1@IoU=0.5, respectively."
Understanding Domain Learning in Language Models Through Subpopulation Analysis,0.0699527,"We investigate how different domains are encoded in modern neural network
architectures. We analyze the relationship between natural language domains,
model size, and the amount of training data used. The primary analysis tool we
develop is based on subpopulation analysis with Singular Vector Canonical
Correlation Analysis (SVCCA), which we apply to Transformer-based language
models (LMs). We compare the latent representations of such a language model at
its different layers from a pair of models: a model trained on multiple domains
(an experimental model) and a model trained on a single domain (a control
model). Through our method, we find that increasing the model capacity impacts
how domain information is stored in upper and lower layers differently. In
addition, we show that larger experimental models simultaneously embed
domain-specific information as if they were conjoined control models. These
findings are confirmed qualitatively, demonstrating the validity of our method."
ArabGend: Gender Analysis and Inference on Arabic Twitter,0.361216,"Gender analysis of Twitter can reveal important socio-cultural differences
between male and female users. There has been a significant effort to analyze
and automatically infer gender in the past for most widely spoken languages'
content, however, to our knowledge very limited work has been done for Arabic.
In this paper, we perform an extensive analysis of differences between male and
female users on the Arabic Twitter-sphere. We study differences in user
engagement, topics of interest, and the gender gap in professions. Along with
gender analysis, we also propose a method to infer gender by utilizing
usernames, profile pictures, tweets, and networks of friends. In order to do
so, we manually annotated gender and locations for ~166K Twitter accounts
associated with ~92K user location, which we plan to make publicly available at
http://anonymous.com. Our proposed gender inference method achieve an F1 score
of 82.1%, which is 47.3% higher than majority baseline. In addition, we also
developed a demo and made it publicly available."
Unsupervised Chunking with Hierarchical RNN,0.1506,"In Natural Language Processing (NLP), predicting linguistic structures, such
as parsing and chunking, has mostly relied on manual annotations of syntactic
structures. This paper introduces an unsupervised approach to chunking, a
syntactic task that involves grouping words in a non-hierarchical manner. We
present a two-layer Hierarchical Recurrent Neural Network (HRNN) designed to
model word-to-chunk and chunk-to-sentence compositions. Our approach involves a
two-stage training process: pretraining with an unsupervised parser and
finetuning on downstream NLP tasks. Experiments on the CoNLL-2000 dataset
reveal a notable improvement over existing unsupervised methods, enhancing
phrase F1 score by up to 6 percentage points. Further, finetuning with
downstream tasks results in an additional performance improvement.
Interestingly, we observe that the emergence of the chunking structure is
transient during the neural model's downstream-task training. This study
contributes to the advancement of unsupervised syntactic structure discovery
and opens avenues for further research in linguistic theory."
IR-GAN: Image Manipulation with Linguistic Instruction by Increment Reasoning,0.226538,"Conditional image generation is an active research topic including text2image
and image translation.
  Recently image manipulation with linguistic instruction brings new challenges
of multimodal conditional generation.
  However, traditional conditional image generation models mainly focus on
generating high-quality and visually realistic images, and lack resolving the
partial consistency between image and instruction.
  To address this issue, we propose an Increment Reasoning Generative
Adversarial Network (IR-GAN), which aims to reason the consistency between
visual increment in images and semantic increment in instructions.
  First, we introduce the word-level and instruction-level instruction encoders
to learn user's intention from history-correlated instructions as semantic
increment.
  Second, we embed the representation of semantic increment into that of source
image for generating target image, where source image plays the role of
referring auxiliary.
  Finally, we propose a reasoning discriminator to measure the consistency
between visual increment and semantic increment, which purifies user's
intention and guarantees the good logic of generated target image.
  Extensive experiments and visualization conducted on two datasets show the
effectiveness of IR-GAN."
Human-in-the-Loop through Chain-of-Thought,0.998006,"While the emergence of powerful language models along with Chain-of-thought
prompting has made automation more and more omnipresent, it sometimes
demonstrates its weakness in long-term or multi-step logical reasoning. For
example, users don't always get desirable answers for complex mathematical
problems without human involvement. Against this background, we present the
Manual Correction System (MCS) -- a human-in-the-loop system enhanced by
Chain-of-Thought prompting, which explores how manual correction of sub-logics
in rationales can improve LLM's reasoning performance. Moving one step forward,
considering a system with human-in-the-loop involves more than having humans
improve performance but also controlling the cost. Therefore, we post a
Cost-utility Analysis Model for Human-in-the-Loop systems (CAMLOP) based on
classical economics theory to analyze, quantify and balance the utility and the
corresponding cost. We conduct experiments of MCS and CAMLOP with twelve
datasets. A significant advantage w.r.t cost and utility proves its superiority
over strong baselines."
Detection of Fake Generated Scientific Abstracts,0.0521636,"The widespread adoption of Large Language Models and publicly available
ChatGPT has marked a significant turning point in the integration of Artificial
Intelligence into people's everyday lives. The academic community has taken
notice of these technological advancements and has expressed concerns regarding
the difficulty of discriminating between what is real and what is artificially
generated. Thus, researchers have been working on developing effective systems
to identify machine-generated text. In this study, we utilize the GPT-3 model
to generate scientific paper abstracts through Artificial Intelligence and
explore various text representation methods when combined with Machine Learning
models with the aim of identifying machine-written text. We analyze the models'
performance and address several research questions that rise during the
analysis of the results. By conducting this research, we shed light on the
capabilities and limitations of Artificial Intelligence generated text."
Instruction-driven history-aware policies for robotic manipulations,0.995861,"In human environments, robots are expected to accomplish a variety of
manipulation tasks given simple natural language instructions. Yet, robotic
manipulation is extremely challenging as it requires fine-grained motor
control, long-term memory as well as generalization to previously unseen tasks
and environments. To address these challenges, we propose a unified
transformer-based approach that takes into account multiple inputs. In
particular, our transformer architecture integrates (i) natural language
instructions and (ii) multi-view scene observations while (iii) keeping track
of the full history of observations and actions. Such an approach enables
learning dependencies between history and instructions and improves
manipulation precision using multiple views. We evaluate our method on the
challenging RLBench benchmark and on a real-world robot. Notably, our approach
scales to 74 diverse RLBench tasks and outperforms the state of the art. We
also address instruction-conditioned tasks and demonstrate excellent
generalization to previously unseen variations."
Sensemaking About Contraceptive Methods Across Online Platforms,0.0754004,"Selecting a birth control method is a complex healthcare decision. While
birth control methods provide important benefits, they can also cause
unpredictable side effects and be stigmatized, leading many people to seek
additional information online, where they can find reviews, advice, hypotheses,
and experiences of other birth control users. However, the relationships
between their healthcare concerns, sensemaking activities, and online settings
are not well understood. We gather texts about birth control shared on Twitter,
Reddit, and WebMD -- platforms with different affordances, moderation, and
audiences -- to study where and how birth control is discussed online. Using a
combination of topic modeling and hand annotation, we identify and characterize
the dominant sensemaking practices across these platforms, and we create
lexicons to draw comparisons across birth control methods and side effects. We
use these to measure variations from survey reports of side effect experiences
and method usage. Our findings characterize how online platforms are used to
make sense of difficult healthcare choices and highlight unmet needs of birth
control users."
A Simple Temporal Information Matching Mechanism for Entity Alignment Between Temporal Knowledge Graphs,0.420242,"Entity alignment (EA) aims to find entities in different knowledge graphs
(KGs) that refer to the same object in the real world. Recent studies
incorporate temporal information to augment the representations of KGs. The
existing methods for EA between temporal KGs (TKGs) utilize a time-aware
attention mechanism to incorporate relational and temporal information into
entity embeddings. The approaches outperform the previous methods by using
temporal information. However, we believe that it is not necessary to learn the
embeddings of temporal information in KGs since most TKGs have uniform temporal
representations. Therefore, we propose a simple graph neural network (GNN)
model combined with a temporal information matching mechanism, which achieves
better performance with less time and fewer parameters. Furthermore, since
alignment seeds are difficult to label in real-world applications, we also
propose a method to generate unsupervised alignment seeds via the temporal
information of TKG. Extensive experiments on public datasets indicate that our
supervised method significantly outperforms the previous methods and the
unsupervised one has competitive performance."
Testing Relational Understanding in Text-Guided Image Generation,0.683805,"Relations are basic building blocks of human cognition. Classic and recent
work suggests that many relations are early developing, and quickly perceived.
Machine models that aspire to human-level perception and reasoning should
reflect the ability to recognize and reason generatively about relations. We
report a systematic empirical examination of a recent text-guided image
generation model (DALL-E 2), using a set of 15 basic physical and social
relations studied or proposed in the literature, and judgements from human
participants (N = 169). Overall, we find that only ~22% of images matched basic
relation prompts. Based on a quantitative examination of people's judgments, we
suggest that current image generation models do not yet have a grasp of even
basic relations involving simple objects and agents. We examine reasons for
model successes and failures, and suggest possible improvements based on
computations observed in biological intelligence."
GREC: Generalized Referring Expression Comprehension,0.481225,"The objective of Classic Referring Expression Comprehension (REC) is to
produce a bounding box corresponding to the object mentioned in a given textual
description. Commonly, existing datasets and techniques in classic REC are
tailored for expressions that pertain to a single target, meaning a sole
expression is linked to one specific object. Expressions that refer to multiple
targets or involve no specific target have not been taken into account. This
constraint hinders the practical applicability of REC. This study introduces a
new benchmark termed as Generalized Referring Expression Comprehension (GREC).
This benchmark extends the classic REC by permitting expressions to describe
any number of target objects. To achieve this goal, we have built the first
large-scale GREC dataset named gRefCOCO. This dataset encompasses a range of
expressions: those referring to multiple targets, expressions with no specific
target, and the single-target expressions. The design of GREC and gRefCOCO
ensures smooth compatibility with classic REC. The proposed gRefCOCO dataset, a
GREC method implementation code, and GREC evaluation code are available at
https://github.com/henghuiding/gRefCOCO."
A novel cluster internal evaluation index based on hyper-balls,0.106913,"It is crucial to evaluate the quality and determine the optimal number of
clusters in cluster analysis. In this paper, the multi-granularity
characterization of the data set is carried out to obtain the hyper-balls. The
cluster internal evaluation index based on hyper-balls(HCVI) is defined.
Moreover, a general method for determining the optimal number of clusters based
on HCVI is proposed. The proposed methods can evaluate the clustering results
produced by the several classic methods and determine the optimal cluster
number for data sets containing noises and clusters with arbitrary shapes. The
experimental results on synthetic and real data sets indicate that the new
index outperforms existing ones."
An Adaptive Contrastive Learning Model for Spike Sorting,0.0691182,"Brain-computer interfaces (BCIs), is ways for electronic devices to
communicate directly with the brain. For most medical-type brain-computer
interface tasks, the activity of multiple units of neurons or local field
potentials is sufficient for decoding. But for BCIs used in neuroscience
research, it is important to separate out the activity of individual neurons.
With the development of large-scale silicon technology and the increasing
number of probe channels, artificially interpreting and labeling spikes is
becoming increasingly impractical. In this paper, we propose a novel modeling
framework: Adaptive Contrastive Learning Model that learns representations from
spikes through contrastive learning based on the maximizing mutual information
loss function as a theoretical basis. Based on the fact that data with similar
features share the same labels whether they are multi-classified or
binary-classified. With this theoretical support, we simplify the
multi-classification problem into multiple binary-classification, improving
both the accuracy and the runtime efficiency. Moreover, we also introduce a
series of enhancements for the spikes, while solving the problem that the
classification effect is affected because of the overlapping spikes."
Multi-sensor large-scale dataset for multi-view 3D reconstruction,0.293736,"We present a new multi-sensor dataset for multi-view 3D surface
reconstruction. It includes registered RGB and depth data from sensors of
different resolutions and modalities: smartphones, Intel RealSense, Microsoft
Kinect, industrial cameras, and structured-light scanner. The scenes are
selected to emphasize a diverse set of material properties challenging for
existing algorithms. We provide around 1.4 million images of 107 different
scenes acquired from 100 viewing directions under 14 lighting conditions. We
expect our dataset will be useful for evaluation and training of 3D
reconstruction algorithms and for related tasks. The dataset is available at
skoltech3d.appliedai.tech."
Towards Few-Shot Identification of Morality Frames using In-Context Learning,0.111178,"Data scarcity is a common problem in NLP, especially when the annotation
pertains to nuanced socio-linguistic concepts that require specialized
knowledge. As a result, few-shot identification of these concepts is desirable.
Few-shot in-context learning using pre-trained Large Language Models (LLMs) has
been recently applied successfully in many NLP tasks. In this paper, we study
few-shot identification of a psycho-linguistic concept, Morality Frames (Roy et
al., 2021), using LLMs. Morality frames are a representation framework that
provides a holistic view of the moral sentiment expressed in text, identifying
the relevant moral foundation (Haidt and Graham, 2007) and at a finer level of
granularity, the moral sentiment expressed towards the entities mentioned in
the text. Previous studies relied on human annotation to identify morality
frames in text which is expensive. In this paper, we propose prompting-based
approaches using pretrained Large Language Models for identification of
morality frames, relying only on few-shot exemplars. We compare our models'
performance with few-shot RoBERTa and found promising results."
Provably Safe Deep Reinforcement Learning for Robotic Manipulation in Human Environments,0.791559,"Deep reinforcement learning (RL) has shown promising results in the motion
planning of manipulators. However, no method guarantees the safety of highly
dynamic obstacles, such as humans, in RL-based manipulator control. This lack
of formal safety assurances prevents the application of RL for manipulators in
real-world human environments. Therefore, we propose a shielding mechanism that
ensures ISO-verified human safety while training and deploying RL algorithms on
manipulators. We utilize a fast reachability analysis of humans and
manipulators to guarantee that the manipulator comes to a complete stop before
a human is within its range. Our proposed method guarantees safety and
significantly improves the RL performance by preventing episode-ending
collisions. We demonstrate the performance of our proposed method in simulation
using human motion capture data."
Sparse Teachers Can Be Dense with Knowledge,0.458622,"Recent advances in distilling pretrained language models have discovered
that, besides the expressiveness of knowledge, the student-friendliness should
be taken into consideration to realize a truly knowledgable teacher. Based on a
pilot study, we find that over-parameterized teachers can produce expressive
yet student-unfriendly knowledge and are thus limited in overall
knowledgableness. To remove the parameters that result in
student-unfriendliness, we propose a sparse teacher trick under the guidance of
an overall knowledgable score for each teacher parameter. The knowledgable
score is essentially an interpolation of the expressiveness and
student-friendliness scores. The aim is to ensure that the expressive
parameters are retained while the student-unfriendly ones are removed.
Extensive experiments on the GLUE benchmark show that the proposed sparse
teachers can be dense with knowledge and lead to students with compelling
performance in comparison with a series of competitive baselines."
Generative Adversarial Learning for Intelligent Trust Management in 6G Wireless Networks,0.942809,"Emerging six generation (6G) is the integration of heterogeneous wireless
networks, which can seamlessly support anywhere and anytime networking. But
high Quality-of-Trust should be offered by 6G to meet mobile user expectations.
Artificial intelligence (AI) is considered as one of the most important
components in 6G. Then AI-based trust management is a promising paradigm to
provide trusted and reliable services. In this article, a generative
adversarial learning-enabled trust management method is presented for 6G
wireless networks. Some typical AI-based trust management schemes are first
reviewed, and then a potential heterogeneous and intelligent 6G architecture is
introduced. Next, the integration of AI and trust management is developed to
optimize the intelligence and security. Finally, the presented AI-based trust
management method is applied to secure clustering to achieve reliable and
real-time communications. Simulation results have demonstrated its excellent
performance in guaranteeing network security and service quality."
DisDiff: Unsupervised Disentanglement of Diffusion Probabilistic Models,0.537509,"Targeting to understand the underlying explainable factors behind
observations and modeling the conditional generation process on these factors,
we connect disentangled representation learning to Diffusion Probabilistic
Models (DPMs) to take advantage of the remarkable modeling ability of DPMs. We
propose a new task, disentanglement of (DPMs): given a pre-trained DPM, without
any annotations of the factors, the task is to automatically discover the
inherent factors behind the observations and disentangle the gradient fields of
DPM into sub-gradient fields, each conditioned on the representation of each
discovered factor. With disentangled DPMs, those inherent factors can be
automatically discovered, explicitly represented, and clearly injected into the
diffusion process via the sub-gradient fields. To tackle this task, we devise
an unsupervised approach named DisDiff, achieving disentangled representation
learning in the framework of DPMs. Extensive experiments on synthetic and
real-world datasets demonstrate the effectiveness of DisDiff."
Ask to Know More: Generating Counterfactual Explanations for Fake Claims,0.379906,"Automated fact checking systems have been proposed that quickly provide
veracity prediction at scale to mitigate the negative influence of fake news on
people and on public opinion. However, most studies focus on veracity
classifiers of those systems, which merely predict the truthfulness of news
articles. We posit that effective fact checking also relies on people's
understanding of the predictions. In this paper, we propose elucidating fact
checking predictions using counterfactual explanations to help people
understand why a specific piece of news was identified as fake. In this work,
generating counterfactual explanations for fake news involves three steps:
asking good questions, finding contradictions, and reasoning appropriately. We
frame this research question as contradicted entailment reasoning through
question answering (QA). We first ask questions towards the false claim and
retrieve potential answers from the relevant evidence documents. Then, we
identify the most contradictory answer to the false claim by use of an
entailment classifier. Finally, a counterfactual explanation is created using a
matched QA pair with three different counterfactual explanation forms.
Experiments are conducted on the FEVER dataset for both system and human
evaluations. Results suggest that the proposed approach generates the most
helpful explanations compared to state-of-the-art methods."
"Deconstructing NLG Evaluation: Evaluation Practices, Assumptions, and Their Implications",0.208542,"There are many ways to express similar things in text, which makes evaluating
natural language generation (NLG) systems difficult. Compounding this
difficulty is the need to assess varying quality criteria depending on the
deployment setting. While the landscape of NLG evaluation has been well-mapped,
practitioners' goals, assumptions, and constraints -- which inform decisions
about what, when, and how to evaluate -- are often partially or implicitly
stated, or not stated at all. Combining a formative semi-structured interview
study of NLG practitioners (N=18) with a survey study of a broader sample of
practitioners (N=61), we surface goals, community practices, assumptions, and
constraints that shape NLG evaluations, examining their implications and how
they embody ethical considerations."
Questions Are All You Need to Train a Dense Passage Retriever,0.87667,"We introduce ART, a new corpus-level autoencoding approach for training dense
retrieval models that does not require any labeled training data. Dense
retrieval is a central challenge for open-domain tasks, such as Open QA, where
state-of-the-art methods typically require large supervised datasets with
custom hard-negative mining and denoising of positive examples. ART, in
contrast, only requires access to unpaired inputs and outputs (e.g. questions
and potential answer documents). It uses a new document-retrieval autoencoding
scheme, where (1) an input question is used to retrieve a set of evidence
documents, and (2) the documents are then used to compute the probability of
reconstructing the original question. Training for retrieval based on question
reconstruction enables effective unsupervised learning of both document and
question encoders, which can be later incorporated into complete Open QA
systems without any further finetuning. Extensive experiments demonstrate that
ART obtains state-of-the-art results on multiple QA retrieval benchmarks with
only generic initialization from a pre-trained language model, removing the
need for labeled data and task-specific losses."
Can GAN-induced Attribute Manipulations Impact Face Recognition?,0.0978514,"Impact due to demographic factors such as age, sex, race, etc., has been
studied extensively in automated face recognition systems. However, the impact
of \textit{digitally modified} demographic and facial attributes on face
recognition is relatively under-explored. In this work, we study the effect of
attribute manipulations induced via generative adversarial networks (GANs) on
face recognition performance. We conduct experiments on the CelebA dataset by
intentionally modifying thirteen attributes using AttGAN and STGAN and
evaluating their impact on two deep learning-based face verification methods,
ArcFace and VGGFace. Our findings indicate that some attribute manipulations
involving eyeglasses and digital alteration of sex cues can significantly
impair face recognition by up to 73% and need further analysis."
Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs,0.754654,"Large Language Models (LLMs) have demonstrated exceptional proficiency in
language-related tasks, but their deployment poses significant challenges due
to substantial memory and storage requirements. Weight-only quantization has
emerged as a promising solution to address these challenges. Previous research
suggests that fine-tuning through up and down rounding can enhance performance.
In this study, we introduce SignRound, a method that utilizes signed gradient
descent (SignSGD) to optimize rounding values and weight clipping within just
200 steps. SignRound integrates the advantages of Quantization-Aware Training
(QAT) and Post-Training Quantization (PTQ), achieving exceptional results
across 2 to 4 bits while maintaining low tuning costs and avoiding additional
inference overhead. For example, SignRound achieves absolute average accuracy
improvements ranging from 6.91\% to 33.22\% at 2 bits. It also demonstrates
robust generalization to recent models and achieves near-lossless quantization
in most scenarios at 4 bits. The source code is publicly available at
\url{https://github.com/intel/auto-round}."
MARLlib: A Scalable and Efficient Multi-agent Reinforcement Learning Library,0.393583,"A significant challenge facing researchers in the area of multi-agent
reinforcement learning (MARL) pertains to the identification of a library that
can offer fast and compatible development for multi-agent tasks and algorithm
combinations, while obviating the need to consider compatibility issues. In
this paper, we present MARLlib, a library designed to address the
aforementioned challenge by leveraging three key mechanisms: 1) a standardized
multi-agent environment wrapper, 2) an agent-level algorithm implementation,
and 3) a flexible policy mapping strategy. By utilizing these mechanisms,
MARLlib can effectively disentangle the intertwined nature of the multi-agent
task and the learning process of the algorithm, with the ability to
automatically alter the training strategy based on the current task's
attributes. The MARLlib library's source code is publicly accessible on GitHub:
\url{https://github.com/Replicable-MARL/MARLlib}."
TransESC: Smoothing Emotional Support Conversation via Turn-Level State Transition,0.770044,"Emotion Support Conversation (ESC) is an emerging and challenging task with
the goal of reducing the emotional distress of people. Previous attempts fail
to maintain smooth transitions between utterances in ESC because they ignore to
grasp the fine-grained transition information at each dialogue turn. To solve
this problem, we propose to take into account turn-level state
\textbf{Trans}itions of \textbf{ESC} (\textbf{TransESC}) from three
perspectives, including semantics transition, strategy transition and emotion
transition, to drive the conversation in a smooth and natural way.
Specifically, we construct the state transition graph with a two-step way,
named transit-then-interact, to grasp such three types of turn-level transition
information. Finally, they are injected into the transition-aware decoder to
generate more engaging responses. Both automatic and human evaluations on the
benchmark dataset demonstrate the superiority of TransESC to generate more
smooth and effective supportive responses. Our source code is available at
\url{https://github.com/circle-hit/TransESC}."
Pixel is All You Need: Adversarial Trajectory-Ensemble Active Learning for Salient Object Detection,0.068232,"Although weakly-supervised techniques can reduce the labeling effort, it is
unclear whether a saliency model trained with weakly-supervised data (e.g.,
point annotation) can achieve the equivalent performance of its
fully-supervised version. This paper attempts to answer this unexplored
question by proving a hypothesis: there is a point-labeled dataset where
saliency models trained on it can achieve equivalent performance when trained
on the densely annotated dataset. To prove this conjecture, we proposed a novel
yet effective adversarial trajectory-ensemble active learning (ATAL). Our
contributions are three-fold: 1) Our proposed adversarial attack triggering
uncertainty can conquer the overconfidence of existing active learning methods
and accurately locate these uncertain pixels. {2)} Our proposed
trajectory-ensemble uncertainty estimation method maintains the advantages of
the ensemble networks while significantly reducing the computational cost. {3)}
Our proposed relationship-aware diversity sampling algorithm can conquer
oversampling while boosting performance. Experimental results show that our
ATAL can find such a point-labeled dataset, where a saliency model trained on
it obtained $97\%$ -- $99\%$ performance of its fully-supervised version with
only ten annotated points per image."
MBSE analysis for energy sustainability improvement in manufacturing industry,0.0520171,"With the ever increasing complexity of Industry 4.0 systems, plant energy
management systems developed to improve energy sustainability become equally
complex. Based on a Model-Based Systems Engineering analysis, this paper aims
to provide a general approach to perform holistic development of an autonomous
energy management system for manufacturing industries. This Energy Management
System (EMS) will be capable of continuously improving its ability to assess,
predict, and act, in order to improve by monitoring and controlling the energy
sustainability of manufacturing systems. The approach was implemented with the
System Modeling Language (SysML)."
Unobserved Local Structures Make Compositional Generalization Hard,0.506526,"While recent work has convincingly showed that sequence-to-sequence models
struggle to generalize to new compositions (termed compositional
generalization), little is known on what makes compositional generalization
hard on a particular test instance. In this work, we investigate what are the
factors that make generalization to certain test instances challenging. We
first substantiate that indeed some examples are more difficult than others by
showing that different models consistently fail or succeed on the same test
instances. Then, we propose a criterion for the difficulty of an example: a
test instance is hard if it contains a local structure that was not observed at
training time. We formulate a simple decision rule based on this criterion and
empirically show it predicts instance-level generalization well across 5
different semantic parsing datasets, substantially better than alternative
decision rules. Last, we show local structures can be leveraged for creating
difficult adversarial compositional splits and also to improve compositional
generalization under limited training budgets by strategically selecting
examples for the training set."
What can Speech and Language Tell us About the Working Alliance in Psychotherapy,0.311523,"We are interested in the problem of conversational analysis and its
application to the health domain. Cognitive Behavioral Therapy is a structured
approach in psychotherapy, allowing the therapist to help the patient to
identify and modify the malicious thoughts, behavior, or actions. This
cooperative effort can be evaluated using the Working Alliance Inventory
Observer-rated Shortened - a 12 items inventory covering task, goal, and
relationship - which has a relevant influence on therapeutic outcomes. In this
work, we investigate the relation between this alliance inventory and the
spoken conversations (sessions) between the patient and the psychotherapist. We
have delivered eight weeks of e-therapy, collected their audio and video call
sessions, and manually transcribed them. The spoken conversations have been
annotated and evaluated with WAI ratings by professional therapists. We have
investigated speech and language features and their association with WAI items.
The feature types include turn dynamics, lexical entrainment, and
conversational descriptors extracted from the speech and language signals. Our
findings provide strong evidence that a subset of these features are strong
indicators of working alliance. To the best of our knowledge, this is the first
and a novel study to exploit speech and language for characterising working
alliance."
"Gaze-based intention estimation: principles, methodologies, and applications in HRI",0.964875,"Intention prediction has become a relevant field of research in Human-Machine
and Human-Robot Interaction. Indeed, any artificial system (co)-operating with
and along humans, designed to assist and coordinate its actions with a human
partner, would benefit from first inferring the human's current intention. To
spare the user the cognitive burden of explicitly uttering their goals, this
inference relies mostly on behavioral cues deemed indicative of the current
action. It has been long known that eye movements are highly anticipatory of
the single steps unfolding during a task, hence they can serve as a very early
and reliable behavioural cue for intention recognition. This review aims to
draw a line between insights in the psychological literature on visuomotor
control and relevant applications of gaze-based intention recognition in
technical domains, with a focus on teleoperated and assistive robotic systems.
Starting from the cognitive principles underlying the relationship between
intentions, eye movements, and action, the use of eye tracking and gaze-based
models for intent recognition in Human-Robot Interaction is considered, with
prevalent methodologies and their diverse applications. Finally, special
consideration is given to relevant human factors issues and current limitations
to be factored in when designing such systems."
HyperFormer: Enhancing Entity and Relation Interaction for Hyper-Relational Knowledge Graph Completion,0.370868,"Hyper-relational knowledge graphs (HKGs) extend standard knowledge graphs by
associating attribute-value qualifiers to triples, which effectively represent
additional fine-grained information about its associated triple.
Hyper-relational knowledge graph completion (HKGC) aims at inferring unknown
triples while considering its qualifiers. Most existing approaches to HKGC
exploit a global-level graph structure to encode hyper-relational knowledge
into the graph convolution message passing process. However, the addition of
multi-hop information might bring noise into the triple prediction process. To
address this problem, we propose HyperFormer, a model that considers
local-level sequential information, which encodes the content of the entities,
relations and qualifiers of a triple. More precisely, HyperFormer is composed
of three different modules: an entity neighbor aggregator module allowing to
integrate the information of the neighbors of an entity to capture different
perspectives of it; a relation qualifier aggregator module to integrate
hyper-relational knowledge into the corresponding relation to refine the
representation of relational content; a convolution-based bidirectional
interaction module based on a convolutional operation, capturing pairwise
bidirectional interactions of entity-relation, entity-qualifier, and
relation-qualifier. realize the depth perception of the content related to the
current statement. Furthermore, we introduce a Mixture-of-Experts strategy into
the feed-forward layers of HyperFormer to strengthen its representation
capabilities while reducing the amount of model parameters and computation.
Extensive experiments on three well-known datasets with four different
conditions demonstrate HyperFormer's effectiveness. Datasets and code are
available at https://github.com/zhiweihu1103/HKGC-HyperFormer."
Empowering Cross-lingual Abilities of Instruction-tuned Large Language Models by Translation-following demonstrations,0.77426,"The language ability of Large Language Models (LLMs) is often unbalanced
towards English because of the imbalance in the distribution of the
pre-training data. This disparity is demanded in further fine-tuning and
affecting the cross-lingual abilities of LLMs. In this paper, we propose to
empower Instructiontuned LLMs (It-LLMs) in languages other than English by
building semantic alignment between them. Hence, we propose CrossAlpaca, an
It-LLM with cross-lingual instruction-following and Translation-following
demonstrations to improve semantic alignment between languages. We validate our
approach on the multilingual Question Answering (QA) benchmarks XQUAD and MLQA
and adapted versions of MMLU and BBH. Our models, tested over six different
languages, outperform the It-LLMs tuned on monolingual data. The final results
show that instruction tuning on non-English data is not enough and that
semantic alignment can be further improved by Translation-following
demonstrations."
Dynamic Scenario Representation Learning for Motion Forecasting with Heterogeneous Graph Convolutional Recurrent Networks,0.420024,"Due to the complex and changing interactions in dynamic scenarios, motion
forecasting is a challenging problem in autonomous driving. Most existing works
exploit static road graphs to characterize scenarios and are limited in
modeling evolving spatio-temporal dependencies in dynamic scenarios. In this
paper, we resort to dynamic heterogeneous graphs to model the scenario. Various
scenario components including vehicles (agents) and lanes, multi-type
interactions, and their changes over time are jointly encoded. Furthermore, we
design a novel heterogeneous graph convolutional recurrent network, aggregating
diverse interaction information and capturing their evolution, to learn to
exploit intrinsic spatio-temporal dependencies in dynamic graphs and obtain
effective representations of dynamic scenarios. Finally, with a motion
forecasting decoder, our model predicts realistic and multi-modal future
trajectories of agents and outperforms state-of-the-art published works on
several motion forecasting benchmarks."
Oil Spill Segmentation using Deep Encoder-Decoder models,0.399888,"Crude oil is an integral component of the modern world economy. With the
growing demand for crude oil due to its widespread applications, accidental oil
spills are unavoidable. Even though oil spills are in and themselves difficult
to clean up, the first and foremost challenge is to detect spills. In this
research, the authors test the feasibility of deep encoder-decoder models that
can be trained effectively to detect oil spills. The work compares the results
from several segmentation models on high dimensional satellite Synthetic
Aperture Radar (SAR) image data. Multiple combinations of models are used in
running the experiments. The best-performing model is the one with the
ResNet-50 encoder and DeepLabV3+ decoder. It achieves a mean Intersection over
Union (IoU) of 64.868% and a class IoU of 61.549% for the ""oil spill"" class
when compared with the current benchmark model, which achieved a mean IoU of
65.05% and a class IoU of 53.38% for the ""oil spill"" class."
A Comparison Between Tsetlin Machines and Deep Neural Networks in the Context of Recommendation Systems,0.105515,"Recommendation Systems (RSs) are ubiquitous in modern society and are one of
the largest points of interaction between humans and AI. Modern RSs are often
implemented using deep learning models, which are infamously difficult to
interpret. This problem is particularly exasperated in the context of
recommendation scenarios, as it erodes the user's trust in the RS. In contrast,
the newly introduced Tsetlin Machines (TM) possess some valuable properties due
to their inherent interpretability. TMs are still fairly young as a technology.
As no RS has been developed for TMs before, it has become necessary to perform
some preliminary research regarding the practicality of such a system. In this
paper, we develop the first RS based on TMs to evaluate its practicality in
this application domain. This paper compares the viability of TMs with other
machine learning models prevalent in the field of RS. We train and investigate
the performance of the TM compared with a vanilla feed-forward deep learning
model. These comparisons are based on model performance,
interpretability/explainability, and scalability. Further, we provide some
benchmark performance comparisons to similar machine learning solutions
relevant to RSs."
On Data Scaling in Masked Image Modeling,0.759194,"An important goal of self-supervised learning is to enable model pre-training
to benefit from almost unlimited data. However, one method that has recently
become popular, namely masked image modeling (MIM), is suspected to be unable
to benefit from larger data. In this work, we break this misconception through
extensive experiments, with data scales ranging from 10\% of ImageNet-1K to
full ImageNet-22K, model sizes ranging from 49 million to 1 billion, and
training lengths ranging from 125K iterations to 500K iterations. Our study
reveals that: (i) Masked image modeling is also demanding on larger data. We
observed that very large models got over-fitted with relatively small data;
(ii) The length of training matters. Large models trained with masked image
modeling can benefit from more data with longer training; (iii) The validation
loss in pre-training is a good indicator to measure how well the model performs
for fine-tuning on multiple tasks. This observation allows us to pre-evaluate
pre-trained models in advance without having to make costly trial-and-error
assessments of downstream tasks. We hope that our findings will advance the
understanding of masked image modeling in terms of scaling ability."
ASQ-IT: Interactive Explanations for Reinforcement-Learning Agents,0.0289751,"As reinforcement learning methods increasingly amass accomplishments, the
need for comprehending their solutions becomes more crucial. Most explainable
reinforcement learning (XRL) methods generate a static explanation depicting
their developers' intuition of what should be explained and how. In contrast,
literature from the social sciences proposes that meaningful explanations are
structured as a dialog between the explainer and the explainee, suggesting a
more active role for the user and her communication with the agent. In this
paper, we present ASQ-IT -- an interactive tool that presents video clips of
the agent acting in its environment based on queries given by the user that
describe temporal properties of behaviors of interest. Our approach is based on
formal methods: queries in ASQ-IT's user interface map to a fragment of Linear
Temporal Logic over finite traces (LTLf), which we developed, and our algorithm
for query processing is based on automata theory. User studies show that
end-users can understand and formulate queries in ASQ-IT, and that using ASQ-IT
assists users in identifying faulty agent behaviors."
"From Perception to Programs: Regularize, Overparameterize, and Amortize",0.558913,"Toward combining inductive reasoning with perception abilities, we develop
techniques for neurosymbolic program synthesis where perceptual input is first
parsed by neural nets into a low-dimensional interpretable representation,
which is then processed by a synthesized program. We explore several techniques
for relaxing the problem and jointly learning all modules end-to-end with
gradient descent: multitask learning; amortized inference;
overparameterization; and a differentiable strategy for penalizing lengthy
programs. Collectedly this toolbox improves the stability of gradient-guided
program search, and suggests ways of learning both how to perceive input as
discrete abstractions, and how to symbolically process those abstractions as
programs."
Detecting Stance of Authorities towards Rumors in Arabic Tweets: A Preliminary Study,0.30504,"A myriad of studies addressed the problem of rumor verification in Twitter by
either utilizing evidence from the propagation networks or external evidence
from the Web. However, none of these studies exploited evidence from trusted
authorities. In this paper, we define the task of detecting the stance of
authorities towards rumors in tweets, i.e., whether a tweet from an authority
agrees, disagrees, or is unrelated to the rumor. We believe the task is useful
to augment the sources of evidence utilized by existing rumor verification
systems. We construct and release the first Authority STance towards Rumors
(AuSTR) dataset, where evidence is retrieved from authority timelines in Arabic
Twitter. Due to the relatively limited size of our dataset, we study the
usefulness of existing datasets for stance detection in our task. We show that
existing datasets are somewhat useful for the task; however, they are clearly
insufficient, which motivates the need to augment them with annotated data
constituting stance of authorities from Twitter."
Large Language Models Can Be Easily Distracted by Irrelevant Context,0.998703,"Large language models have achieved impressive performance on various natural
language processing tasks. However, so far they have been evaluated primarily
on benchmarks where all information in the input context is relevant for
solving the task. In this work, we investigate the distractibility of large
language models, i.e., how the model problem-solving accuracy can be influenced
by irrelevant context. In particular, we introduce Grade-School Math with
Irrelevant Context (GSM-IC), an arithmetic reasoning dataset with irrelevant
information in the problem description. We use this benchmark to measure the
distractibility of cutting-edge prompting techniques for large language models,
and find that the model performance is dramatically decreased when irrelevant
information is included. We also identify several approaches for mitigating
this deficiency, such as decoding with self-consistency and adding to the
prompt an instruction that tells the language model to ignore the irrelevant
information."
ScreenQA: Large-Scale Question-Answer Pairs over Mobile App Screenshots,0.650248,"We present a new task and dataset, ScreenQA, for screen content understanding
via question answering. The existing screen datasets are focused either on
structure and component-level understanding, or on a much higher-level
composite task such as navigation and task completion. We attempt to bridge the
gap between these two by annotating 86K question-answer pairs over the RICO
dataset in hope to benchmark the screen reading comprehension capacity."
Learning to Combine Instructions in LLVM Compiler,0.0776775,"Instruction combiner (IC) is a critical compiler optimization pass, which
replaces a sequence of instructions with an equivalent and optimized
instruction sequence at basic block level. There can be thousands of
instruction-combining patterns which need to be frequently updated as new
coding idioms/applications and novel hardware evolve over time. This results in
frequent updates to the IC optimization pass thereby incurring considerable
human effort and high software maintenance costs. To mitigate these challenges
associated with the traditional IC, we design and implement a Neural
Instruction Combiner (NIC) and demonstrate its feasibility by integrating it
into the standard LLVM compiler optimization pipeline. NIC leverages neural
sequence-to-sequence (Seq2Seq) models for generating optimized encoded IR
sequence from the unoptimized encoded IR sequence. To the best of our
knowledge, ours is the first work demonstrating the feasibility of a neural
instruction combiner built into a full-fledged compiler pipeline. Given the
novelty of this task, we built a new dataset for training our NIC neural model.
We show that NIC achieves exact match results percentage of 72% for optimized
sequences as compared to traditional IC and neural machine translation metric
Bleu precision score of 0.94, demonstrating its feasibility in a production
compiler pipeline."
AutoAdversary: A Pixel Pruning Method for Sparse Adversarial Attack,0.0603421,"Deep neural networks (DNNs) have been proven to be vulnerable to adversarial
examples. A special branch of adversarial examples, namely sparse adversarial
examples, can fool the target DNNs by perturbing only a few pixels. However,
many existing sparse adversarial attacks use heuristic methods to select the
pixels to be perturbed, and regard the pixel selection and the adversarial
attack as two separate steps. From the perspective of neural network pruning,
we propose a novel end-to-end sparse adversarial attack method, namely
AutoAdversary, which can find the most important pixels automatically by
integrating the pixel selection into the adversarial attack. Specifically, our
method utilizes a trainable neural network to generate a binary mask for the
pixel selection. After jointly optimizing the adversarial perturbation and the
neural network, only the pixels corresponding to the value 1 in the mask are
perturbed. Experiments demonstrate the superiority of our proposed method over
several state-of-the-art methods. Furthermore, since AutoAdversary does not
require a heuristic pixel selection process, it does not slow down excessively
as other methods when the image size increases."
Fixed-Time Convergence for a Class of Nonconvex-Nonconcave Min-Max Problems,0.13607,"This study develops a fixed-time convergent saddle point dynamical system for
solving min-max problems under a relaxation of standard convexity-concavity
assumption. In particular, it is shown that by leveraging the dynamical systems
viewpoint of an optimization algorithm, accelerated convergence to a saddle
point can be obtained. Instead of requiring the objective function to be
strongly-convex--strongly-concave (as necessitated for accelerated convergence
of several saddle-point algorithms), uniform fixed-time convergence is
guaranteed for functions satisfying only the two-sided Polyak-{\L}ojasiewicz
(PL) inequality. A large number of practical problems, including the robust
least squares estimation, are known to satisfy the two-sided PL inequality. The
proposed method achieves arbitrarily fast convergence compared to any other
state-of-the-art method with linear or even super-linear convergence, as also
corroborated in numerical case studies."
SKIPP'D: a SKy Images and Photovoltaic Power Generation Dataset for Short-term Solar Forecasting,0.62498,"Large-scale integration of photovoltaics (PV) into electricity grids is
challenged by the intermittent nature of solar power. Sky-image-based solar
forecasting using deep learning has been recognized as a promising approach to
predicting the short-term fluctuations. However, there are few publicly
available standardized benchmark datasets for image-based solar forecasting,
which limits the comparison of different forecasting models and the exploration
of forecasting methods. To fill these gaps, we introduce SKIPP'D -- a SKy
Images and Photovoltaic Power Generation Dataset. The dataset contains three
years (2017-2019) of quality-controlled down-sampled sky images and PV power
generation data that is ready-to-use for short-term solar forecasting using
deep learning. In addition, to support the flexibility in research, we provide
the high resolution, high frequency sky images and PV power generation data as
well as the concurrent sky video footage. We also include a code base
containing data processing scripts and baseline model implementations for
researchers to reproduce our previous work and accelerate their research in
solar forecasting."
MACC: Cross-Layer Multi-Agent Congestion Control with Deep Reinforcement Learning,0.101175,"Congestion Control (CC), as the core networking task to efficiently utilize
network capacity, received great attention and widely used in various Internet
communication applications such as 5G, Internet-of-Things, UAN, and more.
Various CC algorithms have been proposed both on network and transport layers
such as Active Queue Management (AQM) algorithm and Transmission Control
Protocol (TCP) congestion control mechanism. But it is hard to model dynamic
AQM/TCP system and cooperate two algorithms to obtain excellent performance
under different communication scenarios. In this paper, we explore the
performance of multi-agent reinforcement learning-based cross-layer congestion
control algorithms and present cooperation performance of two agents, known as
MACC (Multi-agent Congestion Control). We implement MACC in NS3. The simulation
results show that our scheme outperforms other congestion control combination
in terms of throughput and delay, etc. Not only does it proves that networking
protocols based on multi-agent deep reinforcement learning is efficient for
communication managing, but also verifies that networking area can be used as
new playground for machine learning algorithms."
Inertial Hallucinations -- When Wearable Inertial Devices Start Seeing Things,0.0782302,"We propose a novel approach to multimodal sensor fusion for Ambient Assisted
Living (AAL) which takes advantage of learning using privileged information
(LUPI). We address two major shortcomings of standard multimodal approaches,
limited area coverage and reduced reliability. Our new framework fuses the
concept of modality hallucination with triplet learning to train a model with
different modalities to handle missing sensors at inference time. We evaluate
the proposed model on inertial data from a wearable accelerometer device, using
RGB videos and skeletons as privileged modalities, and show an improvement of
accuracy of an average 6.6% on the UTD-MHAD dataset and an average 5.5% on the
Berkeley MHAD dataset, reaching a new state-of-the-art for inertial-only
classification accuracy on these datasets. We validate our framework through
several ablation studies."
One-Shot Transfer of Affordance Regions? AffCorrs!,0.567188,"In this work, we tackle one-shot visual search of object parts. Given a
single reference image of an object with annotated affordance regions, we
segment semantically corresponding parts within a target scene. We propose
AffCorrs, an unsupervised model that combines the properties of pre-trained
DINO-ViT's image descriptors and cyclic correspondences. We use AffCorrs to
find corresponding affordances both for intra- and inter-class one-shot part
segmentation. This task is more difficult than supervised alternatives, but
enables future work such as learning affordances via imitation and assisted
teleoperation."
Improving Generalization of Deep Neural Network Acoustic Models with Length Perturbation and N-best Based Label Smoothing,0.190791,"We introduce two techniques, length perturbation and n-best based label
smoothing, to improve generalization of deep neural network (DNN) acoustic
models for automatic speech recognition (ASR). Length perturbation is a data
augmentation algorithm that randomly drops and inserts frames of an utterance
to alter the length of the speech feature sequence. N-best based label
smoothing randomly injects noise to ground truth labels during training in
order to avoid overfitting, where the noisy labels are generated from n-best
hypotheses. We evaluate these two techniques extensively on the 300-hour
Switchboard (SWB300) dataset and an in-house 500-hour Japanese (JPN500) dataset
using recurrent neural network transducer (RNNT) acoustic models for ASR. We
show that both techniques improve the generalization of RNNT models
individually and they can also be complementary. In particular, they yield good
improvements over a strong SWB300 baseline and give state-of-art performance on
SWB300 using RNNT models."
EVA2.0: Investigating Open-Domain Chinese Dialogue Systems with Large-Scale Pre-Training,0.747584,"Large-scale pre-training has shown remarkable performance in building
open-domain dialogue systems. However, previous works mainly focus on showing
and evaluating the conversational performance of the released dialogue model,
ignoring the discussion of some key factors towards a powerful human-like
chatbot, especially in Chinese scenarios. In this paper, we conduct extensive
experiments to investigate these under-explored factors, including data quality
control, model architecture designs, training approaches, and decoding
strategies. We propose EVA2.0, a large-scale pre-trained open-domain Chinese
dialogue model with 2.8 billion parameters, and will make our models and codes
publicly available. Automatic and human evaluations show that EVA2.0
significantly outperforms other open-source counterparts. We also discuss the
limitations of this work by presenting some failure cases and pose some future
research directions on large-scale Chinese open-domain dialogue systems."
Walk the Random Walk: Learning to Discover and Reach Goals Without Supervision,0.17791,"Learning a diverse set of skills by interacting with an environment without
any external supervision is an important challenge. In particular, obtaining a
goal-conditioned agent that can reach any given state is useful in many
applications. We propose a novel method for training such a goal-conditioned
agent without any external rewards or any domain knowledge. We use random walk
to train a reachability network that predicts the similarity between two
states. This reachability network is then used in building goal memory
containing past observations that are diverse and well-balanced. Finally, we
train a goal-conditioned policy network with goals sampled from the goal memory
and reward it by the reachability network and the goal memory. All the
components are kept updated throughout training as the agent discovers and
learns new goals. We apply our method to a continuous control navigation and
robotic manipulation tasks."
Video compression dataset and benchmark of learning-based video-quality metrics,0.800812,"Video-quality measurement is a critical task in video processing. Nowadays,
many implementations of new encoding standards - such as AV1, VVC, and LCEVC -
use deep-learning-based decoding algorithms with perceptual metrics that serve
as optimization objectives. But investigations of the performance of modern
video- and image-quality metrics commonly employ videos compressed using older
standards, such as AVC. In this paper, we present a new benchmark for
video-quality metrics that evaluates video compression. It is based on a new
dataset consisting of about 2,500 streams encoded using different standards,
including AVC, HEVC, AV1, VP9, and VVC. Subjective scores were collected using
crowdsourced pairwise comparisons. The list of evaluated metrics includes
recent ones based on machine learning and neural networks. The results
demonstrate that new no-reference metrics exhibit a high correlation with
subjective quality and approach the capability of top full-reference metrics."
Text Classification of Cancer Clinical Trial Eligibility Criteria,0.80928,"Automatic identification of clinical trials for which a patient is eligible
is complicated by the fact that trial eligibility is stated in natural
language. A potential solution to this problem is to employ text classification
methods for common types of eligibility criteria. In this study, we focus on
seven common exclusion criteria in cancer trials: prior malignancy, human
immunodeficiency virus, hepatitis B, hepatitis C, psychiatric illness,
drug/substance abuse, and autoimmune illness. Our dataset consists of 764 phase
III cancer trials with these exclusions annotated at the trial level. We
experiment with common transformer models as well as a new pre-trained clinical
trial BERT model. Our results demonstrate the feasibility of automatically
classifying common exclusion criteria. Additionally, we demonstrate the value
of a pre-trained language model specifically for clinical trials, which yields
the highest average performance across all criteria."
Deep Reinforcement Learning for Exact Combinatorial Optimization: Learning to Branch,0.592686,"Branch-and-bound is a systematic enumerative method for combinatorial
optimization, where the performance highly relies on the variable selection
strategy. State-of-the-art handcrafted heuristic strategies suffer from
relatively slow inference time for each selection, while the current machine
learning methods require a significant amount of labeled data. We propose a new
approach for solving the data labeling and inference latency issues in
combinatorial optimization based on the use of the reinforcement learning (RL)
paradigm. We use imitation learning to bootstrap an RL agent and then use
Proximal Policy Optimization (PPO) to further explore global optimal actions.
Then, a value network is used to run Monte-Carlo tree search (MCTS) to enhance
the policy network. We evaluate the performance of our method on four different
categories of combinatorial optimization problems and show that our approach
performs strongly compared to the state-of-the-art machine learning and
heuristics based methods."
Domain-Generalized Textured Surface Anomaly Detection,0.370504,"Anomaly detection aims to identify abnormal data that deviates from the
normal ones, while typically requiring a sufficient amount of normal data to
train the model for performing this task. Despite the success of recent anomaly
detection methods, performing anomaly detection in an unseen domain remain a
challenging task. In this paper, we address the task of domain-generalized
textured surface anomaly detection. By observing normal and abnormal surface
data across multiple source domains, our model is expected to be generalized to
an unseen textured surface of interest, in which only a small number of normal
data can be observed during testing. Although with only image-level labels
observed in the training data, our patch-based meta-learning model exhibits
promising generalization ability: not only can it generalize to unseen image
domains, but it can also localize abnormal regions in the query image. Our
experiments verify that our model performs favorably against state-of-the-art
anomaly detection and domain generalization approaches in various settings."
"Understanding Factual Errors in Summarization: Errors, Summarizers, Datasets, Error Detectors",0.783852,"The propensity of abstractive summarization models to make factual errors has
been studied extensively, including design of metrics to detect factual errors
and annotation of errors in current systems' outputs. However, the
ever-evolving nature of summarization systems, metrics, and annotated
benchmarks makes factuality evaluation a moving target, and drawing clear
comparisons among metrics has become increasingly difficult. In this work, we
aggregate factuality error annotations from nine existing datasets and stratify
them according to the underlying summarization model. We compare performance of
state-of-the-art factuality metrics, including recent ChatGPT-based metrics, on
this stratified benchmark and show that their performance varies significantly
across different types of summarization models. Critically, our analysis shows
that much of the recent improvement in the factuality detection space has been
on summaries from older (pre-Transformer) models instead of more relevant
recent summarization models. We further perform a finer-grained analysis per
error-type and find similar performance variance across error types for
different factuality metrics. Our results show that no one metric is superior
in all settings or for all error types, and we provide recommendations for best
practices given these insights."
Bayesian Continual Learning via Spiking Neural Networks,0.704577,"Among the main features of biological intelligence are energy efficiency,
capacity for continual adaptation, and risk management via uncertainty
quantification. Neuromorphic engineering has been thus far mostly driven by the
goal of implementing energy-efficient machines that take inspiration from the
time-based computing paradigm of biological brains. In this paper, we take
steps towards the design of neuromorphic systems that are capable of adaptation
to changing learning tasks, while producing well-calibrated uncertainty
quantification estimates. To this end, we derive online learning rules for
spiking neural networks (SNNs) within a Bayesian continual learning framework.
In it, each synaptic weight is represented by parameters that quantify the
current epistemic uncertainty resulting from prior knowledge and observed data.
The proposed online rules update the distribution parameters in a streaming
fashion as data are observed. We instantiate the proposed approach for both
real-valued and binary synaptic weights. Experimental results using Intel's
Lava platform show the merits of Bayesian over frequentist learning in terms of
capacity for adaptation and uncertainty quantification."
An Interactive Interpretability System for Breast Cancer Screening with Deep Learning,0.0352361,"Deep learning methods, in particular convolutional neural networks, have
emerged as a powerful tool in medical image computing tasks. While these
complex models provide excellent performance, their black-box nature may hinder
real-world adoption in high-stakes decision-making. In this paper, we propose
an interactive system to take advantage of state-of-the-art interpretability
techniques to assist radiologists with breast cancer screening. Our system
integrates a deep learning model into the radiologists' workflow and provides
novel interactions to promote understanding of the model's decision-making
process. Moreover, we demonstrate that our system can take advantage of user
interactions progressively to provide finer-grained explainability reports with
little labeling overhead. Due to the generic nature of the adopted
interpretability technique, our system is domain-agnostic and can be used for
many different medical image computing tasks, presenting a novel perspective on
how we can leverage visual analytics to transform originally static
interpretability techniques to augment human decision making and promote the
adoption of medical AI."
KALA: Knowledge-Augmented Language Model Adaptation,0.747587,"Pre-trained language models (PLMs) have achieved remarkable success on
various natural language understanding tasks. Simple fine-tuning of PLMs, on
the other hand, might be suboptimal for domain-specific tasks because they
cannot possibly cover knowledge from all domains. While adaptive pre-training
of PLMs can help them obtain domain-specific knowledge, it requires a large
training cost. Moreover, adaptive pre-training can harm the PLM's performance
on the downstream task by causing catastrophic forgetting of its general
knowledge. To overcome such limitations of adaptive pre-training for PLM
adaption, we propose a novel domain adaption framework for PLMs coined as
Knowledge-Augmented Language model Adaptation (KALA), which modulates the
intermediate hidden representations of PLMs with domain knowledge, consisting
of entities and their relational facts. We validate the performance of our KALA
on question answering and named entity recognition tasks on multiple datasets
across various domains. The results show that, despite being computationally
efficient, our KALA largely outperforms adaptive pre-training. Code is
available at: https://github.com/Nardien/KALA/."
GLiNER: Generalist Model for Named Entity Recognition using Bidirectional Transformer,0.731505,"Named Entity Recognition (NER) is essential in various Natural Language
Processing (NLP) applications. Traditional NER models are effective but limited
to a set of predefined entity types. In contrast, Large Language Models (LLMs)
can extract arbitrary entities through natural language instructions, offering
greater flexibility. However, their size and cost, particularly for those
accessed via APIs like ChatGPT, make them impractical in resource-limited
scenarios. In this paper, we introduce a compact NER model trained to identify
any type of entity. Leveraging a bidirectional transformer encoder, our model,
GLiNER, facilitates parallel entity extraction, an advantage over the slow
sequential token generation of LLMs. Through comprehensive testing, GLiNER
demonstrate strong performance, outperforming both ChatGPT and fine-tuned LLMs
in zero-shot evaluations on various NER benchmarks."
Human activity recognition using deep learning approaches and single frame cnn and convolutional lstm,0.182888,"Human activity recognition is one of the most important tasks in computer
vision and has proved useful in different fields such as healthcare, sports
training and security. There are a number of approaches that have been explored
to solve this task, some of them involving sensor data, and some involving
video data. In this paper, we aim to explore two deep learning-based
approaches, namely single frame Convolutional Neural Networks (CNNs) and
convolutional Long Short-Term Memory to recognise human actions from videos.
Using a convolutional neural networks-based method is advantageous as CNNs can
extract features automatically and Long Short-Term Memory networks are great
when it comes to working on sequence data such as video. The two models were
trained and evaluated on a benchmark action recognition dataset, UCF50, and
another dataset that was created for the experimentation. Though both models
exhibit good accuracies, the single frame CNN model outperforms the
Convolutional LSTM model by having an accuracy of 99.8% with the UCF50 dataset."
KETOD: Knowledge-Enriched Task-Oriented Dialogue,0.911552,"Existing studies in dialogue system research mostly treat task-oriented
dialogue and chit-chat as separate domains. Towards building a human-like
assistant that can converse naturally and seamlessly with users, it is
important to build a dialogue system that conducts both types of conversations
effectively. In this work, we investigate how task-oriented dialogue and
knowledge-grounded chit-chat can be effectively integrated into a single model.
To this end, we create a new dataset, KETOD (Knowledge-Enriched Task-Oriented
Dialogue), where we naturally enrich task-oriented dialogues with chit-chat
based on relevant entity knowledge. We also propose two new models,
SimpleToDPlus and Combiner, for the proposed task. Experimental results on both
automatic and human evaluations show that the proposed methods can
significantly improve the performance in knowledge-enriched response generation
while maintaining a competitive task-oriented dialog performance. We believe
our new dataset will be a valuable resource for future studies. Our dataset and
code are publicly available at \url{https://github.com/facebookresearch/ketod}."
